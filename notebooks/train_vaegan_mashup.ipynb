{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxel VAE-GAN Training\n",
    "\n",
    "This notebook is designed to provide a wholistic vae-gan training experience. You can adjust the model and training parameters through the sacred configuration file, you can view training progress in tensorboard, and you can (wip) create reconstructions with the saved models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import env\n",
    "from train_vaegan import train_vaegan\n",
    "from data.thingi10k import Thingi10k\n",
    "from data.modelnet10 import ModelNet10\n",
    "from data import MODELNET10_TOILET_INDEX, MODELNET10_SOFA_INDEX\n",
    "from models import MODEL_DIR\n",
    "\n",
    "\n",
    "# plot things\n",
    "%matplotlib inline\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Sacred Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacred.observers import FileStorageObserver\n",
    "from sacred import Experiment\n",
    "import os\n",
    "\n",
    "ex = Experiment(name='voxel_vaegan_notebook', interactive=True)\n",
    "ex.observers.append(FileStorageObserver.create('experiments_vaegan'))\n",
    "\n",
    "@ex.main\n",
    "def run_experiment(cfg):\n",
    "    train_vaegan(cfg)\n",
    "\n",
    "import datetime\n",
    "last_model_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model Config\n",
    "\n",
    "The model dir is generated with a timestamp. This keeps you from overwriting past results and keeps results separate to avoid confusing tensorboard.\n",
    "\n",
    "But be warned! These model dirs can take up space, so you might need to periodically go back and delete ones you do not care about.\n",
    "\n",
    "Also, if you ever train a model that you would really like to keep, I recommend moving it to a new directory with a special name like \"best_model_ever\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CLASS = 'ModelNet10'\n",
    "INDEX = MODELNET10_SOFA_INDEX\n",
    "\n",
    "def make_cfg():\n",
    "    model_dir = os.path.join(MODEL_DIR, 'voxel_vaegan1/modelnet10/{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')))\n",
    "    print(model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "    cfg = {\n",
    "        'cfg': {\n",
    "            \"dataset\": {\n",
    "                \"class\": DATASET_CLASS,\n",
    "                \"index\": INDEX,\n",
    "                #\"tag\": \"animal\",\n",
    "                #\"filter_id\": 126660,\n",
    "                #\"pctile\": 1.0,\n",
    "                #\"splits\": True\n",
    "                #\"splits\": {\n",
    "                #    \"train\": .8,\n",
    "                #    \"dev\": .1,\n",
    "                #    \"test\": .1\n",
    "                #}\n",
    "            },\n",
    "            \"generator\": {\n",
    "                \"verbose\": True,\n",
    "                \"pad\": True\n",
    "            }, \n",
    "            \"model\": {\n",
    "                \"ckpt_dir\": model_dir,\n",
    "                \"voxels_dim\": 32,\n",
    "                \"batch_size\": 32,\n",
    "                # Do 0.0001 for 1 epoch, then 0.001 for rest of training\n",
    "                #\"learning_rate\": [(1, 0.0001), (None, 0.001)],\n",
    "                \"learning_rate\": 0.0001,\n",
    "                \"epochs\": 10,\n",
    "                \"keep_prob\": 0.8,\n",
    "                \"kl_div_loss_weight\": 1,\n",
    "                \"recon_loss_weight\": 10000,            \n",
    "                \"latent_dim\": 100,\n",
    "                \"verbose\": True,\n",
    "                \"debug\": False,\n",
    "                \"input_repeats\": 1,\n",
    "                \"display_step\": 6000,\n",
    "                #\"example_stl_id\": 126660,\n",
    "                \"voxel_prob_threshold\": 0.065,\n",
    "                \"dev_step\": 2,\n",
    "                \"save_step\": 5,\n",
    "                'launch_tensorboard': True,\n",
    "                'tb_dir': 'tb',\n",
    "                'tb_compare': [('best', '/home/jcworkma/jack/3d-form/models/voxel_vaegan1/modelnet10/best/tb')],\n",
    "                'no_gan': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard Prep\n",
    "\n",
    "We launch tensorboard with a call to the python subprocess module. Sometimes, that process does not die with the rest of the experiment and lingers on as a system process. This becomes a problem when we try to initialize tensorboard for the next experiment because they cannot share the same port!\n",
    "\n",
    "The function below is designed to solve this problem. It uses the linux pgrep utility to search for existing tensorboard processes and kill them. Note that this probably won't work on Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pgrep', 'tensorboard'] yielded -> b'29132\\n'\n",
      "killed b'29132'!\n"
     ]
    }
   ],
   "source": [
    "from utils import kill_tensorboard\n",
    "\n",
    "kill_tensorboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We start with a check that we are not attempting to overwrite the last MODEL_DIR. If you are blocked by the assert, re-execute the cfg code above to generate a new MODEL_DIR. This will allow you to move ahead with training.\n",
    "\n",
    "The sacred experiment will save away a copy of your experiment settings in an experiments directory. This can be accessed later in case we need to retrieve a prime config.\n",
    "\n",
    "If tensorboard is enabled, tune in at localhost:6006 or your_ip:6006\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_12-16-00\n",
      "['pgrep', 'tensorboard'] yielded -> b''\n"
     ]
    }
   ],
   "source": [
    "cfg = make_cfg()\n",
    "model_dir = cfg.get('cfg').get('model').get('ckpt_dir')\n",
    "kill_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - root - Added new config entry: \"cfg.dataset.class\"\n",
      "WARNING - root - Added new config entry: \"cfg.dataset.index\"\n",
      "WARNING - root - Added new config entry: \"cfg.generator.pad\"\n",
      "WARNING - root - Added new config entry: \"cfg.generator.verbose\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.batch_size\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.ckpt_dir\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.debug\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.dev_step\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.display_step\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.epochs\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.input_repeats\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.keep_prob\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.kl_div_loss_weight\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.latent_dim\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.launch_tensorboard\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.learning_rate\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.no_gan\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.recon_loss_weight\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.save_step\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.tb_compare\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.tb_dir\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.verbose\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.voxel_prob_threshold\"\n",
      "WARNING - root - Added new config entry: \"cfg.model.voxels_dim\"\n",
      "INFO - voxel_vaegan_notebook - Running command 'run_experiment'\n",
      "INFO - voxel_vaegan_notebook - Started run with ID \"122\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/jcworkma/jack/3d-form/src/logs/2019-03-15_10-33__root.log\n",
      "Starting train_vaegan main\n",
      "Numpy random seed: 576896164\n",
      "Saved cfg: /home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/cfg.json\n",
      "Dataset: <class 'data.modelnet10.ModelNet10'>\n",
      "Using dataset index /home/jcworkma/jack/3d-form/src/../data/processed/modelnet10_sofa_index.csv and pctile None\n",
      "Shuffling dataset\n",
      "dataset n_input=12480\n",
      "Num input = 12480\n",
      "Num batches per epoch = 390.00\n",
      "Initializing VoxelVaegan\n",
      "Running VAE-GAN in VAE-Only Mode\n",
      "['tensorboard', '--logdir', 'current:/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/tb,best:/home/jcworkma/jack/3d-form/models/voxel_vaegan1/modelnet10/best/tb']\n",
      "Epoch: 0, Elapsed Time: 0.01\n",
      "Epoch: 0 / 10, Batch: 0 (0 / 32), Elapsed time: 0.01 mins\n",
      "Enc Loss = 641.45, KL Divergence = 20.18, Reconstruction Loss = 2100.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.03 mins\n",
      "Epoch: 0 / 10, Batch: 1 (0 / 64), Elapsed time: 0.03 mins\n",
      "Enc Loss = 718.32, KL Divergence = 54.59, Reconstruction Loss = 2347.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.05 mins\n",
      "Epoch: 0 / 10, Batch: 2 (0 / 96), Elapsed time: 0.05 mins\n",
      "Enc Loss = 638.70, KL Divergence = 15.76, Reconstruction Loss = 2092.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.07 mins\n",
      "Epoch: 0 / 10, Batch: 3 (0 / 128), Elapsed time: 0.07 mins\n",
      "Enc Loss = 750.33, KL Divergence = 22.78, Reconstruction Loss = 2457.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.09 mins\n",
      "Epoch: 0 / 10, Batch: 4 (0 / 160), Elapsed time: 0.09 mins\n",
      "Enc Loss = 601.36, KL Divergence = 16.01, Reconstruction Loss = 1969.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.11 mins\n",
      "Epoch: 0 / 10, Batch: 5 (0 / 192), Elapsed time: 0.11 mins\n",
      "Enc Loss = 641.23, KL Divergence = 16.28, Reconstruction Loss = 2099.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.13 mins\n",
      "Epoch: 0 / 10, Batch: 6 (0 / 224), Elapsed time: 0.13 mins\n",
      "Enc Loss = 618.24, KL Divergence = 12.56, Reconstruction Loss = 2024.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.15 mins\n",
      "Epoch: 0 / 10, Batch: 7 (0 / 256), Elapsed time: 0.15 mins\n",
      "Enc Loss = 658.41, KL Divergence = 11.78, Reconstruction Loss = 2155.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.17 mins\n",
      "Epoch: 0 / 10, Batch: 8 (0 / 288), Elapsed time: 0.17 mins\n",
      "Enc Loss = 674.75, KL Divergence = 10.58, Reconstruction Loss = 2209.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.18 mins\n",
      "Epoch: 0 / 10, Batch: 9 (0 / 320), Elapsed time: 0.18 mins\n",
      "Enc Loss = 637.18, KL Divergence = 11.18, Reconstruction Loss = 2086.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.20 mins\n",
      "Epoch: 0 / 10, Batch: 10 (0 / 352), Elapsed time: 0.20 mins\n",
      "Enc Loss = 667.32, KL Divergence = 14.63, Reconstruction Loss = 2184.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.22 mins\n",
      "Epoch: 0 / 10, Batch: 11 (0 / 384), Elapsed time: 0.22 mins\n",
      "Enc Loss = 656.68, KL Divergence = 13.56, Reconstruction Loss = 2149.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.24 mins\n",
      "Epoch: 0 / 10, Batch: 12 (0 / 416), Elapsed time: 0.24 mins\n",
      "Enc Loss = 705.17, KL Divergence = 15.72, Reconstruction Loss = 2307.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.26 mins\n",
      "Epoch: 0 / 10, Batch: 13 (0 / 448), Elapsed time: 0.26 mins\n",
      "Enc Loss = 834.95, KL Divergence = 20.41, Reconstruction Loss = 2732.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.28 mins\n",
      "Epoch: 0 / 10, Batch: 14 (0 / 480), Elapsed time: 0.28 mins\n",
      "Enc Loss = 659.85, KL Divergence = 17.55, Reconstruction Loss = 2159.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.30 mins\n",
      "Epoch: 0 / 10, Batch: 15 (0 / 512), Elapsed time: 0.30 mins\n",
      "Enc Loss = 653.27, KL Divergence = 19.97, Reconstruction Loss = 2137.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.32 mins\n",
      "Epoch: 0 / 10, Batch: 16 (0 / 544), Elapsed time: 0.32 mins\n",
      "Enc Loss = 628.43, KL Divergence = 22.76, Reconstruction Loss = 2056.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.33 mins\n",
      "Epoch: 0 / 10, Batch: 17 (0 / 576), Elapsed time: 0.34 mins\n",
      "Enc Loss = 569.64, KL Divergence = 23.52, Reconstruction Loss = 1864.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.35 mins\n",
      "Epoch: 0 / 10, Batch: 18 (0 / 608), Elapsed time: 0.35 mins\n",
      "Enc Loss = 638.02, KL Divergence = 33.45, Reconstruction Loss = 2087.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.37 mins\n",
      "Epoch: 0 / 10, Batch: 19 (0 / 640), Elapsed time: 0.37 mins\n",
      "Enc Loss = 682.38, KL Divergence = 49.00, Reconstruction Loss = 2231.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.39 mins\n",
      "Epoch: 0 / 10, Batch: 20 (0 / 672), Elapsed time: 0.39 mins\n",
      "Enc Loss = 577.34, KL Divergence = 43.86, Reconstruction Loss = 1887.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.41 mins\n",
      "Epoch: 0 / 10, Batch: 21 (0 / 704), Elapsed time: 0.41 mins\n",
      "Enc Loss = 586.37, KL Divergence = 59.51, Reconstruction Loss = 1915.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.43 mins\n",
      "Epoch: 0 / 10, Batch: 22 (0 / 736), Elapsed time: 0.43 mins\n",
      "Enc Loss = 719.31, KL Divergence = 118.92, Reconstruction Loss = 2344.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.44 mins\n",
      "Epoch: 0 / 10, Batch: 23 (0 / 768), Elapsed time: 0.45 mins\n",
      "Enc Loss = 607.50, KL Divergence = 88.36, Reconstruction Loss = 1981.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.46 mins\n",
      "Epoch: 0 / 10, Batch: 24 (0 / 800), Elapsed time: 0.46 mins\n",
      "Enc Loss = 607.10, KL Divergence = 161.79, Reconstruction Loss = 1972.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.48 mins\n",
      "Epoch: 0 / 10, Batch: 25 (0 / 832), Elapsed time: 0.48 mins\n",
      "Enc Loss = 730.06, KL Divergence = 251.74, Reconstruction Loss = 2366.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.50 mins\n",
      "Epoch: 0 / 10, Batch: 26 (0 / 864), Elapsed time: 0.50 mins\n",
      "Enc Loss = 626.20, KL Divergence = 280.33, Reconstruction Loss = 2023.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.52 mins\n",
      "Epoch: 0 / 10, Batch: 27 (0 / 896), Elapsed time: 0.52 mins\n",
      "Enc Loss = 555.38, KL Divergence = 278.54, Reconstruction Loss = 1791.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.54 mins\n",
      "Epoch: 0 / 10, Batch: 28 (0 / 928), Elapsed time: 0.54 mins\n",
      "Enc Loss = 544.43, KL Divergence = 327.20, Reconstruction Loss = 1750.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.56 mins\n",
      "Epoch: 0 / 10, Batch: 29 (0 / 960), Elapsed time: 0.56 mins\n",
      "Enc Loss = 507.88, KL Divergence = 360.12, Reconstruction Loss = 1627.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.58 mins\n",
      "Epoch: 0 / 10, Batch: 30 (0 / 992), Elapsed time: 0.58 mins\n",
      "Enc Loss = 555.08, KL Divergence = 493.40, Reconstruction Loss = 1768.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.60 mins\n",
      "Epoch: 0 / 10, Batch: 31 (0 / 1024), Elapsed time: 0.60 mins\n",
      "Enc Loss = 549.78, KL Divergence = 640.78, Reconstruction Loss = 1735.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.61 mins\n",
      "Epoch: 0 / 10, Batch: 32 (0 / 1056), Elapsed time: 0.62 mins\n",
      "Enc Loss = 530.59, KL Divergence = 666.23, Reconstruction Loss = 1670.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.63 mins\n",
      "Epoch: 0 / 10, Batch: 33 (0 / 1088), Elapsed time: 0.63 mins\n",
      "Enc Loss = 544.78, KL Divergence = 828.59, Reconstruction Loss = 1700.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.65 mins\n",
      "Epoch: 0 / 10, Batch: 34 (0 / 1120), Elapsed time: 0.65 mins\n",
      "Enc Loss = 467.61, KL Divergence = 608.00, Reconstruction Loss = 1469.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.67 mins\n",
      "Epoch: 0 / 10, Batch: 35 (0 / 1152), Elapsed time: 0.67 mins\n",
      "Enc Loss = 484.58, KL Divergence = 767.86, Reconstruction Loss = 1509.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.69 mins\n",
      "Epoch: 0 / 10, Batch: 36 (0 / 1184), Elapsed time: 0.69 mins\n",
      "Enc Loss = 461.50, KL Divergence = 741.59, Reconstruction Loss = 1436.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.71 mins\n",
      "Epoch: 0 / 10, Batch: 37 (0 / 1216), Elapsed time: 0.71 mins\n",
      "Enc Loss = 471.08, KL Divergence = 810.86, Reconstruction Loss = 1460.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.73 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 10, Batch: 38 (0 / 1248), Elapsed time: 0.73 mins\n",
      "Enc Loss = 443.47, KL Divergence = 772.76, Reconstruction Loss = 1374.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.74 mins\n",
      "Epoch: 0 / 10, Batch: 39 (0 / 1280), Elapsed time: 0.75 mins\n",
      "Enc Loss = 417.90, KL Divergence = 724.02, Reconstruction Loss = 1295.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.76 mins\n",
      "Epoch: 0 / 10, Batch: 40 (0 / 1312), Elapsed time: 0.76 mins\n",
      "Enc Loss = 425.19, KL Divergence = 723.62, Reconstruction Loss = 1319.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.78 mins\n",
      "Epoch: 0 / 10, Batch: 41 (0 / 1344), Elapsed time: 0.78 mins\n",
      "Enc Loss = 418.39, KL Divergence = 801.10, Reconstruction Loss = 1288.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.80 mins\n",
      "Epoch: 0 / 10, Batch: 42 (0 / 1376), Elapsed time: 0.80 mins\n",
      "Enc Loss = 419.97, KL Divergence = 880.30, Reconstruction Loss = 1286.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.82 mins\n",
      "Epoch: 0 / 10, Batch: 43 (0 / 1408), Elapsed time: 0.82 mins\n",
      "Enc Loss = 403.25, KL Divergence = 868.26, Reconstruction Loss = 1232.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.84 mins\n",
      "Epoch: 0 / 10, Batch: 44 (0 / 1440), Elapsed time: 0.84 mins\n",
      "Enc Loss = 384.73, KL Divergence = 871.77, Reconstruction Loss = 1171.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.86 mins\n",
      "Epoch: 0 / 10, Batch: 45 (0 / 1472), Elapsed time: 0.86 mins\n",
      "Enc Loss = 371.71, KL Divergence = 894.83, Reconstruction Loss = 1126.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.87 mins\n",
      "Epoch: 0 / 10, Batch: 46 (0 / 1504), Elapsed time: 0.87 mins\n",
      "Enc Loss = 375.45, KL Divergence = 913.06, Reconstruction Loss = 1136.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.89 mins\n",
      "Epoch: 0 / 10, Batch: 47 (0 / 1536), Elapsed time: 0.89 mins\n",
      "Enc Loss = 373.00, KL Divergence = 965.63, Reconstruction Loss = 1123.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.91 mins\n",
      "Epoch: 0 / 10, Batch: 48 (0 / 1568), Elapsed time: 0.91 mins\n",
      "Enc Loss = 353.28, KL Divergence = 764.10, Reconstruction Loss = 1079.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.93 mins\n",
      "Epoch: 0 / 10, Batch: 49 (0 / 1600), Elapsed time: 0.93 mins\n",
      "Enc Loss = 368.69, KL Divergence = 936.17, Reconstruction Loss = 1112.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.95 mins\n",
      "Epoch: 0 / 10, Batch: 50 (0 / 1632), Elapsed time: 0.95 mins\n",
      "Enc Loss = 367.09, KL Divergence = 783.21, Reconstruction Loss = 1122.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.97 mins\n",
      "Epoch: 0 / 10, Batch: 51 (0 / 1664), Elapsed time: 0.97 mins\n",
      "Enc Loss = 358.07, KL Divergence = 757.29, Reconstruction Loss = 1095.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 0.99 mins\n",
      "Epoch: 0 / 10, Batch: 52 (0 / 1696), Elapsed time: 0.99 mins\n",
      "Enc Loss = 361.32, KL Divergence = 722.05, Reconstruction Loss = 1110.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 1.00 mins\n",
      "Epoch: 0 / 10, Batch: 53 (0 / 1728), Elapsed time: 1.00 mins\n",
      "Enc Loss = 361.55, KL Divergence = 814.10, Reconstruction Loss = 1101.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 1.02 mins\n",
      "Epoch: 0 / 10, Batch: 54 (0 / 1760), Elapsed time: 1.02 mins\n",
      "Epoch: 0 / 10, Batch: 160 (0 / 5152), Elapsed time: 3.00 mins\n",
      "Enc Loss = 301.59, KL Divergence = 852.37, Reconstruction Loss = 900.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.02 mins\n",
      "Epoch: 0 / 10, Batch: 161 (0 / 5184), Elapsed time: 3.02 mins\n",
      "Enc Loss = 294.07, KL Divergence = 879.12, Reconstruction Loss = 873.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.04 mins\n",
      "Epoch: 0 / 10, Batch: 162 (0 / 5216), Elapsed time: 3.04 mins\n",
      "Enc Loss = 302.90, KL Divergence = 848.97, Reconstruction Loss = 905.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.06 mins\n",
      "Epoch: 0 / 10, Batch: 163 (0 / 5248), Elapsed time: 3.06 mins\n",
      "Enc Loss = 310.39, KL Divergence = 1007.33, Reconstruction Loss = 913.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.07 mins\n",
      "Epoch: 0 / 10, Batch: 164 (0 / 5280), Elapsed time: 3.08 mins\n",
      "Enc Loss = 297.71, KL Divergence = 1014.96, Reconstruction Loss = 871.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.09 mins\n",
      "Epoch: 0 / 10, Batch: 165 (0 / 5312), Elapsed time: 3.09 mins\n",
      "Enc Loss = 283.61, KL Divergence = 850.69, Reconstruction Loss = 842.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.11 mins\n",
      "Epoch: 0 / 10, Batch: 166 (0 / 5344), Elapsed time: 3.11 mins\n",
      "Enc Loss = 297.42, KL Divergence = 841.64, Reconstruction Loss = 888.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.13 mins\n",
      "Epoch: 0 / 10, Batch: 167 (0 / 5376), Elapsed time: 3.13 mins\n",
      "Enc Loss = 292.10, KL Divergence = 725.48, Reconstruction Loss = 882.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.15 mins\n",
      "Epoch: 0 / 10, Batch: 168 (0 / 5408), Elapsed time: 3.15 mins\n",
      "Enc Loss = 304.52, KL Divergence = 914.02, Reconstruction Loss = 904.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.17 mins\n",
      "Epoch: 0 / 10, Batch: 169 (0 / 5440), Elapsed time: 3.17 mins\n",
      "Enc Loss = 300.94, KL Divergence = 820.02, Reconstruction Loss = 902.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.19 mins\n",
      "Epoch: 0 / 10, Batch: 170 (0 / 5472), Elapsed time: 3.19 mins\n",
      "Enc Loss = 296.64, KL Divergence = 804.86, Reconstruction Loss = 889.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.21 mins\n",
      "Epoch: 0 / 10, Batch: 171 (0 / 5504), Elapsed time: 3.21 mins\n",
      "Enc Loss = 309.44, KL Divergence = 918.68, Reconstruction Loss = 919.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.23 mins\n",
      "Epoch: 0 / 10, Batch: 172 (0 / 5536), Elapsed time: 3.23 mins\n",
      "Enc Loss = 294.69, KL Divergence = 1030.39, Reconstruction Loss = 860.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.25 mins\n",
      "Epoch: 0 / 10, Batch: 173 (0 / 5568), Elapsed time: 3.25 mins\n",
      "Enc Loss = 312.53, KL Divergence = 954.77, Reconstruction Loss = 926.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.26 mins\n",
      "Epoch: 0 / 10, Batch: 174 (0 / 5600), Elapsed time: 3.26 mins\n",
      "Enc Loss = 308.53, KL Divergence = 955.78, Reconstruction Loss = 913.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.28 mins\n",
      "Epoch: 0 / 10, Batch: 175 (0 / 5632), Elapsed time: 3.28 mins\n",
      "Enc Loss = 292.47, KL Divergence = 872.32, Reconstruction Loss = 869.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.30 mins\n",
      "Epoch: 0 / 10, Batch: 176 (0 / 5664), Elapsed time: 3.30 mins\n",
      "Enc Loss = 296.17, KL Divergence = 920.17, Reconstruction Loss = 876.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.32 mins\n",
      "Epoch: 0 / 10, Batch: 177 (0 / 5696), Elapsed time: 3.32 mins\n",
      "Enc Loss = 288.87, KL Divergence = 876.94, Reconstruction Loss = 856.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.34 mins\n",
      "Epoch: 0 / 10, Batch: 178 (0 / 5728), Elapsed time: 3.34 mins\n",
      "Enc Loss = 289.20, KL Divergence = 833.39, Reconstruction Loss = 862.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.36 mins\n",
      "Epoch: 0 / 10, Batch: 179 (0 / 5760), Elapsed time: 3.36 mins\n",
      "Enc Loss = 280.26, KL Divergence = 840.23, Reconstruction Loss = 832.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.38 mins\n",
      "Epoch: 0 / 10, Batch: 180 (0 / 5792), Elapsed time: 3.38 mins\n",
      "Enc Loss = 290.07, KL Divergence = 830.03, Reconstruction Loss = 865.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.40 mins\n",
      "Epoch: 0 / 10, Batch: 181 (0 / 5824), Elapsed time: 3.40 mins\n",
      "Enc Loss = 299.39, KL Divergence = 806.43, Reconstruction Loss = 898.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.41 mins\n",
      "Epoch: 0 / 10, Batch: 182 (0 / 5856), Elapsed time: 3.41 mins\n",
      "Enc Loss = 297.32, KL Divergence = 879.01, Reconstruction Loss = 884.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.43 mins\n",
      "Epoch: 0 / 10, Batch: 183 (0 / 5888), Elapsed time: 3.43 mins\n",
      "Enc Loss = 287.00, KL Divergence = 772.21, Reconstruction Loss = 861.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.45 mins\n",
      "Epoch: 0 / 10, Batch: 184 (0 / 5920), Elapsed time: 3.45 mins\n",
      "Enc Loss = 297.61, KL Divergence = 982.61, Reconstruction Loss = 874.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.47 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 10, Batch: 185 (0 / 5952), Elapsed time: 3.47 mins\n",
      "Enc Loss = 291.10, KL Divergence = 850.50, Reconstruction Loss = 866.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.49 mins\n",
      "Epoch: 0 / 10, Batch: 186 (0 / 5984), Elapsed time: 3.49 mins\n",
      "Enc Loss = 283.07, KL Divergence = 897.98, Reconstruction Loss = 835.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.51 mins\n",
      "Epoch: 0 / 10, Batch: 187 (0 / 6016), Elapsed time: 3.51 mins\n",
      "Enc Loss = 312.70, KL Divergence = 1035.84, Reconstruction Loss = 918.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.53 mins\n",
      "Epoch: 0 / 10, Batch: 188 (0 / 6048), Elapsed time: 3.53 mins\n",
      "Enc Loss = 302.62, KL Divergence = 861.00, Reconstruction Loss = 903.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.55 mins\n",
      "Epoch: 0 / 10, Batch: 189 (0 / 6080), Elapsed time: 3.55 mins\n",
      "Enc Loss = 275.32, KL Divergence = 905.09, Reconstruction Loss = 809.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.56 mins\n",
      "Epoch: 0 / 10, Batch: 190 (0 / 6112), Elapsed time: 3.56 mins\n",
      "Enc Loss = 305.60, KL Divergence = 868.40, Reconstruction Loss = 912.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.58 mins\n",
      "Epoch: 0 / 10, Batch: 191 (0 / 6144), Elapsed time: 3.58 mins\n",
      "Enc Loss = 289.18, KL Divergence = 857.30, Reconstruction Loss = 859.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.60 mins\n",
      "Epoch: 0 / 10, Batch: 192 (0 / 6176), Elapsed time: 3.60 mins\n",
      "Enc Loss = 290.93, KL Divergence = 943.46, Reconstruction Loss = 856.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.62 mins\n",
      "Epoch: 0 / 10, Batch: 193 (0 / 6208), Elapsed time: 3.62 mins\n",
      "Enc Loss = 275.16, KL Divergence = 949.66, Reconstruction Loss = 804.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.64 mins\n",
      "Epoch: 0 / 10, Batch: 194 (0 / 6240), Elapsed time: 3.64 mins\n",
      "Enc Loss = 294.41, KL Divergence = 911.46, Reconstruction Loss = 871.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.66 mins\n",
      "Epoch: 0 / 10, Batch: 195 (0 / 6272), Elapsed time: 3.66 mins\n",
      "Enc Loss = 273.63, KL Divergence = 793.26, Reconstruction Loss = 815.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.68 mins\n",
      "Epoch: 0 / 10, Batch: 196 (0 / 6304), Elapsed time: 3.68 mins\n",
      "Enc Loss = 297.03, KL Divergence = 844.17, Reconstruction Loss = 886.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.69 mins\n",
      "Epoch: 0 / 10, Batch: 197 (0 / 6336), Elapsed time: 3.69 mins\n",
      "Enc Loss = 273.05, KL Divergence = 813.56, Reconstruction Loss = 811.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.71 mins\n",
      "Epoch: 0 / 10, Batch: 198 (0 / 6368), Elapsed time: 3.71 mins\n",
      "Enc Loss = 289.51, KL Divergence = 942.92, Reconstruction Loss = 852.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.73 mins\n",
      "Epoch: 0 / 10, Batch: 199 (0 / 6400), Elapsed time: 3.73 mins\n",
      "Enc Loss = 291.16, KL Divergence = 984.72, Reconstruction Loss = 853.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.75 mins\n",
      "Epoch: 0 / 10, Batch: 200 (0 / 6432), Elapsed time: 3.75 mins\n",
      "Enc Loss = 282.90, KL Divergence = 973.10, Reconstruction Loss = 827.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.77 mins\n",
      "Epoch: 0 / 10, Batch: 201 (0 / 6464), Elapsed time: 3.77 mins\n",
      "Enc Loss = 297.44, KL Divergence = 1047.27, Reconstruction Loss = 867.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.79 mins\n",
      "Epoch: 0 / 10, Batch: 202 (0 / 6496), Elapsed time: 3.79 mins\n",
      "Enc Loss = 276.39, KL Divergence = 1006.15, Reconstruction Loss = 802.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.81 mins\n",
      "Epoch: 0 / 10, Batch: 203 (0 / 6528), Elapsed time: 3.81 mins\n",
      "Enc Loss = 274.75, KL Divergence = 958.46, Reconstruction Loss = 802.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.82 mins\n",
      "Epoch: 0 / 10, Batch: 204 (0 / 6560), Elapsed time: 3.82 mins\n",
      "Enc Loss = 263.40, KL Divergence = 846.63, Reconstruction Loss = 776.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.84 mins\n",
      "Epoch: 0 / 10, Batch: 205 (0 / 6592), Elapsed time: 3.84 mins\n",
      "Enc Loss = 288.56, KL Divergence = 998.03, Reconstruction Loss = 843.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.86 mins\n",
      "Epoch: 0 / 10, Batch: 206 (0 / 6624), Elapsed time: 3.86 mins\n",
      "Enc Loss = 284.53, KL Divergence = 1058.37, Reconstruction Loss = 823.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.88 mins\n",
      "Epoch: 0 / 10, Batch: 207 (0 / 6656), Elapsed time: 3.88 mins\n",
      "Enc Loss = 283.74, KL Divergence = 923.82, Reconstruction Loss = 835.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.90 mins\n",
      "Epoch: 0 / 10, Batch: 208 (0 / 6688), Elapsed time: 3.90 mins\n",
      "Enc Loss = 263.18, KL Divergence = 820.64, Reconstruction Loss = 778.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.92 mins\n",
      "Epoch: 0 / 10, Batch: 209 (0 / 6720), Elapsed time: 3.92 mins\n",
      "Enc Loss = 272.95, KL Divergence = 908.59, Reconstruction Loss = 801.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.94 mins\n",
      "Epoch: 0 / 10, Batch: 210 (0 / 6752), Elapsed time: 3.94 mins\n",
      "Enc Loss = 275.44, KL Divergence = 866.66, Reconstruction Loss = 813.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.96 mins\n",
      "Epoch: 0 / 10, Batch: 211 (0 / 6784), Elapsed time: 3.96 mins\n",
      "Enc Loss = 274.67, KL Divergence = 817.21, Reconstruction Loss = 816.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.97 mins\n",
      "Epoch: 0 / 10, Batch: 212 (0 / 6816), Elapsed time: 3.97 mins\n",
      "Enc Loss = 287.39, KL Divergence = 869.98, Reconstruction Loss = 852.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 3.99 mins\n",
      "Epoch: 0 / 10, Batch: 213 (0 / 6848), Elapsed time: 3.99 mins\n",
      "Enc Loss = 286.24, KL Divergence = 1029.77, Reconstruction Loss = 832.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.01 mins\n",
      "Epoch: 0 / 10, Batch: 214 (0 / 6880), Elapsed time: 4.01 mins\n",
      "Enc Loss = 289.40, KL Divergence = 1055.56, Reconstruction Loss = 840.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.03 mins\n",
      "Epoch: 0 / 10, Batch: 215 (0 / 6912), Elapsed time: 4.03 mins\n",
      "Enc Loss = 276.72, KL Divergence = 1012.30, Reconstruction Loss = 803.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.05 mins\n",
      "Epoch: 0 / 10, Batch: 216 (0 / 6944), Elapsed time: 4.05 mins\n",
      "Enc Loss = 282.40, KL Divergence = 1061.87, Reconstruction Loss = 816.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.07 mins\n",
      "Epoch: 0 / 10, Batch: 217 (0 / 6976), Elapsed time: 4.07 mins\n",
      "Enc Loss = 288.24, KL Divergence = 1160.39, Reconstruction Loss = 825.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.09 mins\n",
      "Epoch: 0 / 10, Batch: 218 (0 / 7008), Elapsed time: 4.09 mins\n",
      "Enc Loss = 289.02, KL Divergence = 1201.31, Reconstruction Loss = 824.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.11 mins\n",
      "Epoch: 0 / 10, Batch: 219 (0 / 7040), Elapsed time: 4.11 mins\n",
      "Enc Loss = 280.78, KL Divergence = 1169.86, Reconstruction Loss = 800.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.13 mins\n",
      "Epoch: 0 / 10, Batch: 220 (0 / 7072), Elapsed time: 4.13 mins\n",
      "Enc Loss = 280.71, KL Divergence = 1152.24, Reconstruction Loss = 801.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.14 mins\n",
      "Epoch: 0 / 10, Batch: 221 (0 / 7104), Elapsed time: 4.15 mins\n",
      "Enc Loss = 271.27, KL Divergence = 1047.83, Reconstruction Loss = 781.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.16 mins\n",
      "Epoch: 0 / 10, Batch: 222 (0 / 7136), Elapsed time: 4.16 mins\n",
      "Enc Loss = 263.37, KL Divergence = 1053.30, Reconstruction Loss = 755.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.18 mins\n",
      "Epoch: 0 / 10, Batch: 223 (0 / 7168), Elapsed time: 4.18 mins\n",
      "Enc Loss = 272.27, KL Divergence = 976.85, Reconstruction Loss = 792.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.20 mins\n",
      "Epoch: 0 / 10, Batch: 224 (0 / 7200), Elapsed time: 4.20 mins\n",
      "Enc Loss = 281.41, KL Divergence = 934.65, Reconstruction Loss = 826.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.22 mins\n",
      "Epoch: 0 / 10, Batch: 225 (0 / 7232), Elapsed time: 4.22 mins\n",
      "Enc Loss = 281.47, KL Divergence = 975.22, Reconstruction Loss = 822.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.24 mins\n",
      "Epoch: 0 / 10, Batch: 226 (0 / 7264), Elapsed time: 4.24 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 287.56, KL Divergence = 975.07, Reconstruction Loss = 842.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.26 mins\n",
      "Epoch: 0 / 10, Batch: 227 (0 / 7296), Elapsed time: 4.26 mins\n",
      "Enc Loss = 261.40, KL Divergence = 915.15, Reconstruction Loss = 762.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.28 mins\n",
      "Epoch: 0 / 10, Batch: 228 (0 / 7328), Elapsed time: 4.28 mins\n",
      "Enc Loss = 270.56, KL Divergence = 1038.75, Reconstruction Loss = 780.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.30 mins\n",
      "Epoch: 0 / 10, Batch: 229 (0 / 7360), Elapsed time: 4.30 mins\n",
      "Enc Loss = 269.93, KL Divergence = 990.12, Reconstruction Loss = 783.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.32 mins\n",
      "Epoch: 0 / 10, Batch: 230 (0 / 7392), Elapsed time: 4.32 mins\n",
      "Enc Loss = 300.04, KL Divergence = 1089.44, Reconstruction Loss = 871.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.33 mins\n",
      "Epoch: 0 / 10, Batch: 231 (0 / 7424), Elapsed time: 4.33 mins\n",
      "Enc Loss = 272.19, KL Divergence = 978.20, Reconstruction Loss = 791.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.35 mins\n",
      "Epoch: 0 / 10, Batch: 232 (0 / 7456), Elapsed time: 4.35 mins\n",
      "Enc Loss = 255.67, KL Divergence = 947.15, Reconstruction Loss = 740.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.37 mins\n",
      "Epoch: 0 / 10, Batch: 233 (0 / 7488), Elapsed time: 4.37 mins\n",
      "Enc Loss = 276.87, KL Divergence = 871.69, Reconstruction Loss = 817.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.39 mins\n",
      "Epoch: 0 / 10, Batch: 234 (0 / 7520), Elapsed time: 4.39 mins\n",
      "Enc Loss = 264.52, KL Divergence = 971.70, Reconstruction Loss = 767.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.41 mins\n",
      "Epoch: 0 / 10, Batch: 235 (0 / 7552), Elapsed time: 4.41 mins\n",
      "Enc Loss = 269.82, KL Divergence = 984.28, Reconstruction Loss = 783.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.43 mins\n",
      "Epoch: 0 / 10, Batch: 236 (0 / 7584), Elapsed time: 4.43 mins\n",
      "Enc Loss = 300.01, KL Divergence = 1064.36, Reconstruction Loss = 874.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.45 mins\n",
      "Epoch: 0 / 10, Batch: 237 (0 / 7616), Elapsed time: 4.45 mins\n",
      "Enc Loss = 266.82, KL Divergence = 993.56, Reconstruction Loss = 772.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.46 mins\n",
      "Epoch: 0 / 10, Batch: 238 (0 / 7648), Elapsed time: 4.47 mins\n",
      "Enc Loss = 275.55, KL Divergence = 965.09, Reconstruction Loss = 804.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.48 mins\n",
      "Epoch: 0 / 10, Batch: 239 (0 / 7680), Elapsed time: 4.48 mins\n",
      "Enc Loss = 269.41, KL Divergence = 1037.87, Reconstruction Loss = 776.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.50 mins\n",
      "Epoch: 0 / 10, Batch: 240 (0 / 7712), Elapsed time: 4.50 mins\n",
      "Enc Loss = 263.96, KL Divergence = 1149.59, Reconstruction Loss = 747.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.52 mins\n",
      "Epoch: 0 / 10, Batch: 241 (0 / 7744), Elapsed time: 4.52 mins\n",
      "Enc Loss = 277.47, KL Divergence = 1009.16, Reconstruction Loss = 805.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.54 mins\n",
      "Epoch: 0 / 10, Batch: 242 (0 / 7776), Elapsed time: 4.54 mins\n",
      "Enc Loss = 289.67, KL Divergence = 1121.85, Reconstruction Loss = 834.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.56 mins\n",
      "Epoch: 0 / 10, Batch: 243 (0 / 7808), Elapsed time: 4.56 mins\n",
      "Enc Loss = 283.29, KL Divergence = 1275.73, Reconstruction Loss = 797.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.58 mins\n",
      "Epoch: 0 / 10, Batch: 244 (0 / 7840), Elapsed time: 4.58 mins\n",
      "Enc Loss = 266.62, KL Divergence = 1063.28, Reconstruction Loss = 764.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.59 mins\n",
      "Epoch: 0 / 10, Batch: 245 (0 / 7872), Elapsed time: 4.60 mins\n",
      "Enc Loss = 269.65, KL Divergence = 1012.88, Reconstruction Loss = 779.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.61 mins\n",
      "Epoch: 0 / 10, Batch: 246 (0 / 7904), Elapsed time: 4.61 mins\n",
      "Enc Loss = 274.13, KL Divergence = 1059.64, Reconstruction Loss = 789.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.63 mins\n",
      "Epoch: 0 / 10, Batch: 247 (0 / 7936), Elapsed time: 4.63 mins\n",
      "Enc Loss = 264.61, KL Divergence = 966.54, Reconstruction Loss = 768.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.65 mins\n",
      "Epoch: 0 / 10, Batch: 248 (0 / 7968), Elapsed time: 4.65 mins\n",
      "Enc Loss = 266.55, KL Divergence = 1117.34, Reconstruction Loss = 759.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.67 mins\n",
      "Epoch: 0 / 10, Batch: 249 (0 / 8000), Elapsed time: 4.67 mins\n",
      "Enc Loss = 257.52, KL Divergence = 1086.50, Reconstruction Loss = 732.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.69 mins\n",
      "Epoch: 0 / 10, Batch: 250 (0 / 8032), Elapsed time: 4.69 mins\n",
      "Enc Loss = 271.83, KL Divergence = 995.07, Reconstruction Loss = 788.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.71 mins\n",
      "Epoch: 0 / 10, Batch: 251 (0 / 8064), Elapsed time: 4.71 mins\n",
      "Enc Loss = 266.53, KL Divergence = 1001.23, Reconstruction Loss = 770.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.72 mins\n",
      "Epoch: 0 / 10, Batch: 252 (0 / 8096), Elapsed time: 4.72 mins\n",
      "Enc Loss = 273.29, KL Divergence = 981.93, Reconstruction Loss = 794.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.74 mins\n",
      "Epoch: 0 / 10, Batch: 253 (0 / 8128), Elapsed time: 4.74 mins\n",
      "Enc Loss = 265.87, KL Divergence = 1034.63, Reconstruction Loss = 765.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.76 mins\n",
      "Epoch: 0 / 10, Batch: 254 (0 / 8160), Elapsed time: 4.76 mins\n",
      "Enc Loss = 267.08, KL Divergence = 1007.01, Reconstruction Loss = 772.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.78 mins\n",
      "Epoch: 0 / 10, Batch: 255 (0 / 8192), Elapsed time: 4.78 mins\n",
      "Enc Loss = 288.01, KL Divergence = 1161.57, Reconstruction Loss = 824.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.80 mins\n",
      "Epoch: 0 / 10, Batch: 256 (0 / 8224), Elapsed time: 4.80 mins\n",
      "Enc Loss = 276.01, KL Divergence = 1214.83, Reconstruction Loss = 780.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.82 mins\n",
      "Epoch: 0 / 10, Batch: 257 (0 / 8256), Elapsed time: 4.82 mins\n",
      "Enc Loss = 275.35, KL Divergence = 1241.41, Reconstruction Loss = 775.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.84 mins\n",
      "Epoch: 0 / 10, Batch: 258 (0 / 8288), Elapsed time: 4.84 mins\n",
      "Enc Loss = 251.33, KL Divergence = 1269.67, Reconstruction Loss = 693.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.86 mins\n",
      "Epoch: 0 / 10, Batch: 259 (0 / 8320), Elapsed time: 4.86 mins\n",
      "Enc Loss = 261.21, KL Divergence = 1224.34, Reconstruction Loss = 730.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.88 mins\n",
      "Epoch: 0 / 10, Batch: 260 (0 / 8352), Elapsed time: 4.88 mins\n",
      "Enc Loss = 279.70, KL Divergence = 1359.08, Reconstruction Loss = 777.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.89 mins\n",
      "Epoch: 0 / 10, Batch: 261 (0 / 8384), Elapsed time: 4.90 mins\n",
      "Enc Loss = 265.54, KL Divergence = 1179.15, Reconstruction Loss = 749.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.91 mins\n",
      "Epoch: 0 / 10, Batch: 262 (0 / 8416), Elapsed time: 4.91 mins\n",
      "Enc Loss = 326.09, KL Divergence = 1305.85, Reconstruction Loss = 934.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.93 mins\n",
      "Epoch: 0 / 10, Batch: 263 (0 / 8448), Elapsed time: 4.93 mins\n",
      "Enc Loss = 254.89, KL Divergence = 1097.61, Reconstruction Loss = 722.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.95 mins\n",
      "Epoch: 0 / 10, Batch: 264 (0 / 8480), Elapsed time: 4.95 mins\n",
      "Enc Loss = 298.26, KL Divergence = 1092.73, Reconstruction Loss = 865.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.97 mins\n",
      "Epoch: 0 / 10, Batch: 265 (0 / 8512), Elapsed time: 4.97 mins\n",
      "Enc Loss = 254.51, KL Divergence = 1081.47, Reconstruction Loss = 723.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 4.99 mins\n",
      "Epoch: 0 / 10, Batch: 266 (0 / 8544), Elapsed time: 4.99 mins\n",
      "Enc Loss = 261.81, KL Divergence = 1005.58, Reconstruction Loss = 754.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.00 mins\n",
      "Epoch: 0 / 10, Batch: 267 (0 / 8576), Elapsed time: 5.01 mins\n",
      "Enc Loss = 263.70, KL Divergence = 1072.28, Reconstruction Loss = 754.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.02 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 10, Batch: 268 (0 / 8608), Elapsed time: 5.02 mins\n",
      "Enc Loss = 262.52, KL Divergence = 1073.42, Reconstruction Loss = 750.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.04 mins\n",
      "Epoch: 0 / 10, Batch: 269 (0 / 8640), Elapsed time: 5.04 mins\n",
      "Enc Loss = 276.90, KL Divergence = 1051.94, Reconstruction Loss = 799.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.06 mins\n",
      "Epoch: 0 / 10, Batch: 270 (0 / 8672), Elapsed time: 5.06 mins\n",
      "Enc Loss = 255.94, KL Divergence = 1106.70, Reconstruction Loss = 725.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.08 mins\n",
      "Epoch: 0 / 10, Batch: 271 (0 / 8704), Elapsed time: 5.08 mins\n",
      "Enc Loss = 252.48, KL Divergence = 1103.76, Reconstruction Loss = 714.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.10 mins\n",
      "Epoch: 0 / 10, Batch: 272 (0 / 8736), Elapsed time: 5.10 mins\n",
      "Enc Loss = 278.04, KL Divergence = 1143.00, Reconstruction Loss = 794.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.12 mins\n",
      "Epoch: 0 / 10, Batch: 273 (0 / 8768), Elapsed time: 5.12 mins\n",
      "Enc Loss = 274.36, KL Divergence = 1208.77, Reconstruction Loss = 775.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.14 mins\n",
      "Epoch: 0 / 10, Batch: 274 (0 / 8800), Elapsed time: 5.14 mins\n",
      "Enc Loss = 255.98, KL Divergence = 1023.03, Reconstruction Loss = 734.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.15 mins\n",
      "Epoch: 0 / 10, Batch: 275 (0 / 8832), Elapsed time: 5.15 mins\n",
      "Enc Loss = 254.19, KL Divergence = 1103.47, Reconstruction Loss = 719.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.17 mins\n",
      "Epoch: 0 / 10, Batch: 276 (0 / 8864), Elapsed time: 5.17 mins\n",
      "Enc Loss = 268.30, KL Divergence = 1109.68, Reconstruction Loss = 765.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.19 mins\n",
      "Epoch: 0 / 10, Batch: 277 (0 / 8896), Elapsed time: 5.19 mins\n",
      "Enc Loss = 270.96, KL Divergence = 1083.57, Reconstruction Loss = 776.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.21 mins\n",
      "Epoch: 0 / 10, Batch: 278 (0 / 8928), Elapsed time: 5.21 mins\n",
      "Enc Loss = 258.43, KL Divergence = 1098.53, Reconstruction Loss = 734.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.23 mins\n",
      "Epoch: 0 / 10, Batch: 279 (0 / 8960), Elapsed time: 5.23 mins\n",
      "Enc Loss = 262.53, KL Divergence = 1156.76, Reconstruction Loss = 741.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.25 mins\n",
      "Epoch: 0 / 10, Batch: 280 (0 / 8992), Elapsed time: 5.25 mins\n",
      "Enc Loss = 298.53, KL Divergence = 1252.87, Reconstruction Loss = 849.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.27 mins\n",
      "Epoch: 0 / 10, Batch: 281 (0 / 9024), Elapsed time: 5.27 mins\n",
      "Enc Loss = 263.73, KL Divergence = 1189.36, Reconstruction Loss = 742.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.28 mins\n",
      "Epoch: 0 / 10, Batch: 282 (0 / 9056), Elapsed time: 5.28 mins\n",
      "Enc Loss = 260.64, KL Divergence = 1201.84, Reconstruction Loss = 730.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.30 mins\n",
      "Epoch: 0 / 10, Batch: 283 (0 / 9088), Elapsed time: 5.30 mins\n",
      "Enc Loss = 261.12, KL Divergence = 1212.00, Reconstruction Loss = 731.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.32 mins\n",
      "Epoch: 0 / 10, Batch: 284 (0 / 9120), Elapsed time: 5.32 mins\n",
      "Enc Loss = 272.68, KL Divergence = 1319.57, Reconstruction Loss = 758.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.34 mins\n",
      "Epoch: 0 / 10, Batch: 285 (0 / 9152), Elapsed time: 5.34 mins\n",
      "Enc Loss = 247.69, KL Divergence = 1172.72, Reconstruction Loss = 691.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.36 mins\n",
      "Epoch: 0 / 10, Batch: 286 (0 / 9184), Elapsed time: 5.36 mins\n",
      "Enc Loss = 256.82, KL Divergence = 1257.31, Reconstruction Loss = 712.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.38 mins\n",
      "Epoch: 0 / 10, Batch: 287 (0 / 9216), Elapsed time: 5.38 mins\n",
      "Enc Loss = 249.66, KL Divergence = 1107.56, Reconstruction Loss = 704.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.40 mins\n",
      "Epoch: 0 / 10, Batch: 288 (0 / 9248), Elapsed time: 5.40 mins\n",
      "Enc Loss = 262.78, KL Divergence = 1207.38, Reconstruction Loss = 737.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.42 mins\n",
      "Epoch: 0 / 10, Batch: 289 (0 / 9280), Elapsed time: 5.42 mins\n",
      "Enc Loss = 248.83, KL Divergence = 1107.21, Reconstruction Loss = 701.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.44 mins\n",
      "Epoch: 0 / 10, Batch: 290 (0 / 9312), Elapsed time: 5.44 mins\n",
      "Enc Loss = 245.58, KL Divergence = 1066.94, Reconstruction Loss = 695.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.45 mins\n",
      "Epoch: 0 / 10, Batch: 291 (0 / 9344), Elapsed time: 5.46 mins\n",
      "Enc Loss = 269.74, KL Divergence = 1120.93, Reconstruction Loss = 769.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.47 mins\n",
      "Epoch: 0 / 10, Batch: 292 (0 / 9376), Elapsed time: 5.47 mins\n",
      "Enc Loss = 245.08, KL Divergence = 1042.78, Reconstruction Loss = 696.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.49 mins\n",
      "Epoch: 0 / 10, Batch: 293 (0 / 9408), Elapsed time: 5.49 mins\n",
      "Enc Loss = 247.71, KL Divergence = 1042.06, Reconstruction Loss = 705.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.51 mins\n",
      "Epoch: 0 / 10, Batch: 294 (0 / 9440), Elapsed time: 5.51 mins\n",
      "Enc Loss = 268.60, KL Divergence = 1144.95, Reconstruction Loss = 762.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.53 mins\n",
      "Epoch: 0 / 10, Batch: 295 (0 / 9472), Elapsed time: 5.53 mins\n",
      "Enc Loss = 264.64, KL Divergence = 1161.76, Reconstruction Loss = 748.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.55 mins\n",
      "Epoch: 0 / 10, Batch: 296 (0 / 9504), Elapsed time: 5.55 mins\n",
      "Enc Loss = 244.86, KL Divergence = 1144.17, Reconstruction Loss = 685.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.57 mins\n",
      "Epoch: 0 / 10, Batch: 297 (0 / 9536), Elapsed time: 5.57 mins\n",
      "Enc Loss = 280.59, KL Divergence = 1236.31, Reconstruction Loss = 792.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.59 mins\n",
      "Epoch: 0 / 10, Batch: 298 (0 / 9568), Elapsed time: 5.59 mins\n",
      "Enc Loss = 278.16, KL Divergence = 1188.23, Reconstruction Loss = 789.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.60 mins\n",
      "Epoch: 0 / 10, Batch: 299 (0 / 9600), Elapsed time: 5.61 mins\n",
      "Enc Loss = 272.24, KL Divergence = 1447.58, Reconstruction Loss = 743.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.62 mins\n",
      "Epoch: 0 / 10, Batch: 300 (0 / 9632), Elapsed time: 5.62 mins\n",
      "Enc Loss = 258.57, KL Divergence = 1420.31, Reconstruction Loss = 701.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.64 mins\n",
      "Epoch: 0 / 10, Batch: 301 (0 / 9664), Elapsed time: 5.64 mins\n",
      "Enc Loss = 244.74, KL Divergence = 1273.24, Reconstruction Loss = 671.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.66 mins\n",
      "Epoch: 0 / 10, Batch: 302 (0 / 9696), Elapsed time: 5.66 mins\n",
      "Enc Loss = 255.32, KL Divergence = 1272.60, Reconstruction Loss = 706.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.68 mins\n",
      "Epoch: 0 / 10, Batch: 303 (0 / 9728), Elapsed time: 5.68 mins\n",
      "Enc Loss = 248.24, KL Divergence = 1189.61, Reconstruction Loss = 691.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.70 mins\n",
      "Epoch: 0 / 10, Batch: 304 (0 / 9760), Elapsed time: 5.70 mins\n",
      "Enc Loss = 263.78, KL Divergence = 1097.41, Reconstruction Loss = 751.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.72 mins\n",
      "Epoch: 0 / 10, Batch: 305 (0 / 9792), Elapsed time: 5.72 mins\n",
      "Enc Loss = 265.70, KL Divergence = 991.73, Reconstruction Loss = 769.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.74 mins\n",
      "Epoch: 0 / 10, Batch: 306 (0 / 9824), Elapsed time: 5.74 mins\n",
      "Enc Loss = 261.49, KL Divergence = 1000.76, Reconstruction Loss = 754.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.76 mins\n",
      "Epoch: 0 / 10, Batch: 307 (0 / 9856), Elapsed time: 5.76 mins\n",
      "Enc Loss = 263.81, KL Divergence = 1057.83, Reconstruction Loss = 756.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.78 mins\n",
      "Epoch: 0 / 10, Batch: 308 (0 / 9888), Elapsed time: 5.78 mins\n",
      "Enc Loss = 255.02, KL Divergence = 1058.25, Reconstruction Loss = 727.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.80 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 10, Batch: 309 (0 / 9920), Elapsed time: 5.80 mins\n",
      "Enc Loss = 264.28, KL Divergence = 1188.24, Reconstruction Loss = 744.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.81 mins\n",
      "Epoch: 0 / 10, Batch: 310 (0 / 9952), Elapsed time: 5.81 mins\n",
      "Enc Loss = 246.87, KL Divergence = 1050.03, Reconstruction Loss = 701.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.83 mins\n",
      "Epoch: 0 / 10, Batch: 311 (0 / 9984), Elapsed time: 5.83 mins\n",
      "Enc Loss = 249.72, KL Divergence = 1059.38, Reconstruction Loss = 709.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.85 mins\n",
      "Epoch: 0 / 10, Batch: 312 (0 / 10016), Elapsed time: 5.85 mins\n",
      "Enc Loss = 251.66, KL Divergence = 1202.16, Reconstruction Loss = 701.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.87 mins\n",
      "Epoch: 0 / 10, Batch: 313 (0 / 10048), Elapsed time: 5.87 mins\n",
      "Enc Loss = 253.37, KL Divergence = 1154.53, Reconstruction Loss = 712.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.89 mins\n",
      "Epoch: 0 / 10, Batch: 314 (0 / 10080), Elapsed time: 5.89 mins\n",
      "Enc Loss = 259.07, KL Divergence = 1220.15, Reconstruction Loss = 723.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.91 mins\n",
      "Epoch: 0 / 10, Batch: 315 (0 / 10112), Elapsed time: 5.91 mins\n",
      "Enc Loss = 271.63, KL Divergence = 1231.11, Reconstruction Loss = 764.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.93 mins\n",
      "Epoch: 0 / 10, Batch: 316 (0 / 10144), Elapsed time: 5.93 mins\n",
      "Enc Loss = 251.36, KL Divergence = 1138.09, Reconstruction Loss = 707.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.94 mins\n",
      "Epoch: 0 / 10, Batch: 317 (0 / 10176), Elapsed time: 5.95 mins\n",
      "Enc Loss = 248.65, KL Divergence = 1246.65, Reconstruction Loss = 687.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.96 mins\n",
      "Epoch: 0 / 10, Batch: 318 (0 / 10208), Elapsed time: 5.96 mins\n",
      "Enc Loss = 255.65, KL Divergence = 1122.73, Reconstruction Loss = 722.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 5.98 mins\n",
      "Epoch: 0 / 10, Batch: 319 (0 / 10240), Elapsed time: 5.98 mins\n",
      "Enc Loss = 250.80, KL Divergence = 1148.66, Reconstruction Loss = 704.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.00 mins\n",
      "Epoch: 0 / 10, Batch: 320 (0 / 10272), Elapsed time: 6.00 mins\n",
      "Enc Loss = 254.16, KL Divergence = 1238.21, Reconstruction Loss = 706.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.02 mins\n",
      "Epoch: 0 / 10, Batch: 321 (0 / 10304), Elapsed time: 6.02 mins\n",
      "Enc Loss = 284.54, KL Divergence = 1303.44, Reconstruction Loss = 798.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.04 mins\n",
      "Epoch: 0 / 10, Batch: 322 (0 / 10336), Elapsed time: 6.04 mins\n",
      "Enc Loss = 245.28, KL Divergence = 1257.00, Reconstruction Loss = 675.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.06 mins\n",
      "Epoch: 0 / 10, Batch: 323 (0 / 10368), Elapsed time: 6.06 mins\n",
      "Enc Loss = 256.73, KL Divergence = 1180.25, Reconstruction Loss = 720.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.08 mins\n",
      "Epoch: 0 / 10, Batch: 324 (0 / 10400), Elapsed time: 6.08 mins\n",
      "Enc Loss = 281.73, KL Divergence = 1340.07, Reconstruction Loss = 785.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.09 mins\n",
      "Epoch: 0 / 10, Batch: 325 (0 / 10432), Elapsed time: 6.09 mins\n",
      "Enc Loss = 263.19, KL Divergence = 1335.43, Reconstruction Loss = 725.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.11 mins\n",
      "Epoch: 0 / 10, Batch: 326 (0 / 10464), Elapsed time: 6.11 mins\n",
      "Enc Loss = 245.76, KL Divergence = 1248.98, Reconstruction Loss = 677.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.13 mins\n",
      "Epoch: 0 / 10, Batch: 327 (0 / 10496), Elapsed time: 6.13 mins\n",
      "Enc Loss = 247.70, KL Divergence = 1249.22, Reconstruction Loss = 683.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.15 mins\n",
      "Epoch: 0 / 10, Batch: 328 (0 / 10528), Elapsed time: 6.15 mins\n",
      "Enc Loss = 257.60, KL Divergence = 1367.07, Reconstruction Loss = 704.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.17 mins\n",
      "Epoch: 0 / 10, Batch: 329 (0 / 10560), Elapsed time: 6.17 mins\n",
      "Enc Loss = 243.59, KL Divergence = 1210.54, Reconstruction Loss = 674.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.19 mins\n",
      "Epoch: 0 / 10, Batch: 330 (0 / 10592), Elapsed time: 6.19 mins\n",
      "Enc Loss = 244.63, KL Divergence = 1185.58, Reconstruction Loss = 680.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.21 mins\n",
      "Epoch: 0 / 10, Batch: 331 (0 / 10624), Elapsed time: 6.21 mins\n",
      "Enc Loss = 247.05, KL Divergence = 1090.79, Reconstruction Loss = 697.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.23 mins\n",
      "Epoch: 0 / 10, Batch: 332 (0 / 10656), Elapsed time: 6.23 mins\n",
      "Enc Loss = 248.14, KL Divergence = 1038.06, Reconstruction Loss = 706.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.24 mins\n",
      "Epoch: 0 / 10, Batch: 333 (0 / 10688), Elapsed time: 6.24 mins\n",
      "Enc Loss = 284.05, KL Divergence = 1011.45, Reconstruction Loss = 827.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.26 mins\n",
      "Epoch: 0 / 10, Batch: 334 (0 / 10720), Elapsed time: 6.26 mins\n",
      "Enc Loss = 250.46, KL Divergence = 1211.12, Reconstruction Loss = 696.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.28 mins\n",
      "Epoch: 0 / 10, Batch: 335 (0 / 10752), Elapsed time: 6.28 mins\n",
      "Enc Loss = 257.51, KL Divergence = 1259.28, Reconstruction Loss = 714.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.30 mins\n",
      "Epoch: 0 / 10, Batch: 336 (0 / 10784), Elapsed time: 6.30 mins\n",
      "Enc Loss = 250.16, KL Divergence = 1243.16, Reconstruction Loss = 692.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.32 mins\n",
      "Epoch: 0 / 10, Batch: 337 (0 / 10816), Elapsed time: 6.32 mins\n",
      "Enc Loss = 254.11, KL Divergence = 1315.85, Reconstruction Loss = 697.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.34 mins\n",
      "Epoch: 0 / 10, Batch: 338 (0 / 10848), Elapsed time: 6.34 mins\n",
      "Enc Loss = 252.59, KL Divergence = 1273.86, Reconstruction Loss = 697.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.36 mins\n",
      "Epoch: 0 / 10, Batch: 339 (0 / 10880), Elapsed time: 6.36 mins\n",
      "Enc Loss = 268.81, KL Divergence = 1356.44, Reconstruction Loss = 741.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.38 mins\n",
      "Epoch: 0 / 10, Batch: 340 (0 / 10912), Elapsed time: 6.38 mins\n",
      "Enc Loss = 237.55, KL Divergence = 1243.23, Reconstruction Loss = 651.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.40 mins\n",
      "Epoch: 0 / 10, Batch: 341 (0 / 10944), Elapsed time: 6.40 mins\n",
      "Enc Loss = 242.44, KL Divergence = 1271.08, Reconstruction Loss = 664.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.41 mins\n",
      "Epoch: 0 / 10, Batch: 342 (0 / 10976), Elapsed time: 6.41 mins\n",
      "Enc Loss = 250.38, KL Divergence = 1265.50, Reconstruction Loss = 690.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.43 mins\n",
      "Epoch: 0 / 10, Batch: 343 (0 / 11008), Elapsed time: 6.43 mins\n",
      "Enc Loss = 256.65, KL Divergence = 1252.77, Reconstruction Loss = 712.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.45 mins\n",
      "Epoch: 0 / 10, Batch: 344 (0 / 11040), Elapsed time: 6.45 mins\n",
      "Enc Loss = 243.13, KL Divergence = 1177.05, Reconstruction Loss = 676.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.47 mins\n",
      "Epoch: 0 / 10, Batch: 345 (0 / 11072), Elapsed time: 6.47 mins\n",
      "Enc Loss = 237.91, KL Divergence = 1104.85, Reconstruction Loss = 666.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.49 mins\n",
      "Epoch: 0 / 10, Batch: 346 (0 / 11104), Elapsed time: 6.49 mins\n",
      "Enc Loss = 262.35, KL Divergence = 1170.45, Reconstruction Loss = 739.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.51 mins\n",
      "Epoch: 0 / 10, Batch: 347 (0 / 11136), Elapsed time: 6.51 mins\n",
      "Enc Loss = 246.67, KL Divergence = 1239.99, Reconstruction Loss = 681.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.53 mins\n",
      "Epoch: 0 / 10, Batch: 348 (0 / 11168), Elapsed time: 6.53 mins\n",
      "Enc Loss = 255.49, KL Divergence = 1367.14, Reconstruction Loss = 697.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.54 mins\n",
      "Epoch: 0 / 10, Batch: 349 (0 / 11200), Elapsed time: 6.55 mins\n",
      "Enc Loss = 238.27, KL Divergence = 1296.75, Reconstruction Loss = 647.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.56 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 10, Batch: 350 (0 / 11232), Elapsed time: 6.56 mins\n",
      "Enc Loss = 239.57, KL Divergence = 1295.64, Reconstruction Loss = 652.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.58 mins\n",
      "Epoch: 0 / 10, Batch: 351 (0 / 11264), Elapsed time: 6.58 mins\n",
      "Enc Loss = 248.48, KL Divergence = 1250.69, Reconstruction Loss = 686.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.60 mins\n",
      "Epoch: 0 / 10, Batch: 352 (0 / 11296), Elapsed time: 6.60 mins\n",
      "Enc Loss = 241.29, KL Divergence = 1209.89, Reconstruction Loss = 666.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.62 mins\n",
      "Epoch: 0 / 10, Batch: 353 (0 / 11328), Elapsed time: 6.62 mins\n",
      "Enc Loss = 233.74, KL Divergence = 1233.36, Reconstruction Loss = 639.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.64 mins\n",
      "Epoch: 0 / 10, Batch: 354 (0 / 11360), Elapsed time: 6.64 mins\n",
      "Enc Loss = 251.69, KL Divergence = 1263.07, Reconstruction Loss = 695.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.66 mins\n",
      "Epoch: 0 / 10, Batch: 355 (0 / 11392), Elapsed time: 6.66 mins\n",
      "Enc Loss = 229.00, KL Divergence = 1300.49, Reconstruction Loss = 617.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.68 mins\n",
      "Epoch: 0 / 10, Batch: 356 (0 / 11424), Elapsed time: 6.68 mins\n",
      "Enc Loss = 253.23, KL Divergence = 1321.66, Reconstruction Loss = 694.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.70 mins\n",
      "Epoch: 0 / 10, Batch: 357 (0 / 11456), Elapsed time: 6.70 mins\n",
      "Enc Loss = 268.34, KL Divergence = 1412.70, Reconstruction Loss = 734.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.72 mins\n",
      "Epoch: 0 / 10, Batch: 358 (0 / 11488), Elapsed time: 6.72 mins\n",
      "Enc Loss = 228.33, KL Divergence = 1048.27, Reconstruction Loss = 640.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.74 mins\n",
      "Epoch: 0 / 10, Batch: 359 (0 / 11520), Elapsed time: 6.74 mins\n",
      "Enc Loss = 236.05, KL Divergence = 1045.37, Reconstruction Loss = 666.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.75 mins\n",
      "Epoch: 0 / 10, Batch: 360 (0 / 11552), Elapsed time: 6.76 mins\n",
      "Enc Loss = 257.36, KL Divergence = 1215.23, Reconstruction Loss = 718.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.77 mins\n",
      "Epoch: 0 / 10, Batch: 361 (0 / 11584), Elapsed time: 6.77 mins\n",
      "Enc Loss = 239.12, KL Divergence = 1140.60, Reconstruction Loss = 666.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.79 mins\n",
      "Epoch: 0 / 10, Batch: 362 (0 / 11616), Elapsed time: 6.79 mins\n",
      "Enc Loss = 241.48, KL Divergence = 1152.74, Reconstruction Loss = 673.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.81 mins\n",
      "Epoch: 0 / 10, Batch: 363 (0 / 11648), Elapsed time: 6.81 mins\n",
      "Enc Loss = 234.83, KL Divergence = 1171.78, Reconstruction Loss = 649.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.83 mins\n",
      "Epoch: 0 / 10, Batch: 364 (0 / 11680), Elapsed time: 6.83 mins\n",
      "Enc Loss = 258.91, KL Divergence = 1211.47, Reconstruction Loss = 724.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.85 mins\n",
      "Epoch: 0 / 10, Batch: 365 (0 / 11712), Elapsed time: 6.85 mins\n",
      "Enc Loss = 235.06, KL Divergence = 1182.44, Reconstruction Loss = 649.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.87 mins\n",
      "Epoch: 0 / 10, Batch: 366 (0 / 11744), Elapsed time: 6.87 mins\n",
      "Enc Loss = 220.10, KL Divergence = 1150.54, Reconstruction Loss = 603.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.89 mins\n",
      "Epoch: 0 / 10, Batch: 367 (0 / 11776), Elapsed time: 6.89 mins\n",
      "Enc Loss = 231.13, KL Divergence = 1240.29, Reconstruction Loss = 630.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.90 mins\n",
      "Epoch: 0 / 10, Batch: 368 (0 / 11808), Elapsed time: 6.91 mins\n",
      "Enc Loss = 257.01, KL Divergence = 1390.36, Reconstruction Loss = 699.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.92 mins\n",
      "Epoch: 0 / 10, Batch: 369 (0 / 11840), Elapsed time: 6.92 mins\n",
      "Enc Loss = 247.17, KL Divergence = 1273.96, Reconstruction Loss = 679.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.94 mins\n",
      "Epoch: 0 / 10, Batch: 370 (0 / 11872), Elapsed time: 6.94 mins\n",
      "Enc Loss = 248.33, KL Divergence = 1375.91, Reconstruction Loss = 672.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.96 mins\n",
      "Epoch: 0 / 10, Batch: 371 (0 / 11904), Elapsed time: 6.96 mins\n",
      "Enc Loss = 240.11, KL Divergence = 1282.24, Reconstruction Loss = 655.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 6.98 mins\n",
      "Epoch: 0 / 10, Batch: 372 (0 / 11936), Elapsed time: 6.98 mins\n",
      "Enc Loss = 251.13, KL Divergence = 1429.88, Reconstruction Loss = 676.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.00 mins\n",
      "Epoch: 0 / 10, Batch: 373 (0 / 11968), Elapsed time: 7.00 mins\n",
      "Enc Loss = 232.07, KL Divergence = 1345.24, Reconstruction Loss = 622.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.02 mins\n",
      "Epoch: 0 / 10, Batch: 374 (0 / 12000), Elapsed time: 7.02 mins\n",
      "Enc Loss = 240.77, KL Divergence = 1387.57, Reconstruction Loss = 646.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.04 mins\n",
      "Epoch: 0 / 10, Batch: 375 (0 / 12032), Elapsed time: 7.04 mins\n",
      "Enc Loss = 235.42, KL Divergence = 1218.61, Reconstruction Loss = 646.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.06 mins\n",
      "Epoch: 0 / 10, Batch: 376 (0 / 12064), Elapsed time: 7.06 mins\n",
      "Enc Loss = 240.61, KL Divergence = 1244.90, Reconstruction Loss = 660.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.08 mins\n",
      "Epoch: 0 / 10, Batch: 377 (0 / 12096), Elapsed time: 7.08 mins\n",
      "Enc Loss = 235.03, KL Divergence = 1292.54, Reconstruction Loss = 637.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.10 mins\n",
      "Epoch: 0 / 10, Batch: 378 (0 / 12128), Elapsed time: 7.10 mins\n",
      "Enc Loss = 231.43, KL Divergence = 1142.39, Reconstruction Loss = 641.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.11 mins\n",
      "Epoch: 0 / 10, Batch: 379 (0 / 12160), Elapsed time: 7.11 mins\n",
      "Enc Loss = 239.18, KL Divergence = 1186.84, Reconstruction Loss = 662.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.13 mins\n",
      "Epoch: 0 / 10, Batch: 380 (0 / 12192), Elapsed time: 7.13 mins\n",
      "Enc Loss = 240.28, KL Divergence = 1201.73, Reconstruction Loss = 664.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.15 mins\n",
      "Epoch: 0 / 10, Batch: 381 (0 / 12224), Elapsed time: 7.15 mins\n",
      "Enc Loss = 306.64, KL Divergence = 1231.00, Reconstruction Loss = 878.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.17 mins\n",
      "Epoch: 0 / 10, Batch: 382 (0 / 12256), Elapsed time: 7.17 mins\n",
      "Enc Loss = 258.34, KL Divergence = 1394.92, Reconstruction Loss = 703.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.19 mins\n",
      "Epoch: 0 / 10, Batch: 383 (0 / 12288), Elapsed time: 7.19 mins\n",
      "Enc Loss = 234.32, KL Divergence = 1342.25, Reconstruction Loss = 630.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.21 mins\n",
      "Epoch: 0 / 10, Batch: 384 (0 / 12320), Elapsed time: 7.21 mins\n",
      "Enc Loss = 232.91, KL Divergence = 1459.99, Reconstruction Loss = 613.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.23 mins\n",
      "Epoch: 0 / 10, Batch: 385 (0 / 12352), Elapsed time: 7.23 mins\n",
      "Enc Loss = 250.44, KL Divergence = 1566.75, Reconstruction Loss = 660.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.24 mins\n",
      "Epoch: 0 / 10, Batch: 386 (0 / 12384), Elapsed time: 7.24 mins\n",
      "Enc Loss = 234.14, KL Divergence = 1423.36, Reconstruction Loss = 621.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.26 mins\n",
      "Epoch: 0 / 10, Batch: 387 (0 / 12416), Elapsed time: 7.26 mins\n",
      "Enc Loss = 245.05, KL Divergence = 1486.77, Reconstruction Loss = 650.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.28 mins\n",
      "Epoch: 0 / 10, Batch: 388 (0 / 12448), Elapsed time: 7.28 mins\n",
      "Enc Loss = 226.87, KL Divergence = 1322.00, Reconstruction Loss = 608.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.30 mins\n",
      "Epoch: 0 / 10, Batch: 389 (0 / 12480), Elapsed time: 7.30 mins\n",
      "Enc Loss = 242.93, KL Divergence = 1269.92, Reconstruction Loss = 665.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.32 mins\n",
      "Epoch: 0 / 10, Batch: 390 (0 / 12512), Elapsed time: 7.32 mins\n",
      "Enc Loss = 162.17, KL Divergence = 435.46, Reconstruction Loss = 486.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.34 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Elapsed Time: 7.34\n",
      "Epoch: 1 / 10, Batch: 0 (32 / 12512), Elapsed time: 7.34 mins\n",
      "Enc Loss = 244.14, KL Divergence = 1138.53, Reconstruction Loss = 683.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.36 mins\n",
      "Epoch: 1 / 10, Batch: 1 (64 / 12512), Elapsed time: 7.36 mins\n",
      "Enc Loss = 254.96, KL Divergence = 1120.56, Reconstruction Loss = 720.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.37 mins\n",
      "Epoch: 1 / 10, Batch: 2 (96 / 12512), Elapsed time: 7.37 mins\n",
      "Enc Loss = 239.73, KL Divergence = 1073.11, Reconstruction Loss = 675.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.39 mins\n",
      "Epoch: 1 / 10, Batch: 3 (128 / 12512), Elapsed time: 7.39 mins\n",
      "Enc Loss = 264.71, KL Divergence = 1258.31, Reconstruction Loss = 738.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.41 mins\n",
      "Epoch: 1 / 10, Batch: 4 (160 / 12512), Elapsed time: 7.41 mins\n",
      "Enc Loss = 217.28, KL Divergence = 1120.68, Reconstruction Loss = 597.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.43 mins\n",
      "Epoch: 1 / 10, Batch: 5 (192 / 12512), Elapsed time: 7.43 mins\n",
      "Enc Loss = 228.45, KL Divergence = 1191.83, Reconstruction Loss = 626.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.45 mins\n",
      "Epoch: 1 / 10, Batch: 6 (224 / 12512), Elapsed time: 7.45 mins\n",
      "Enc Loss = 230.86, KL Divergence = 1291.36, Reconstruction Loss = 624.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.47 mins\n",
      "Epoch: 1 / 10, Batch: 7 (256 / 12512), Elapsed time: 7.47 mins\n",
      "Enc Loss = 237.46, KL Divergence = 1395.65, Reconstruction Loss = 635.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.49 mins\n",
      "Epoch: 1 / 10, Batch: 8 (288 / 12512), Elapsed time: 7.49 mins\n",
      "Enc Loss = 239.52, KL Divergence = 1429.56, Reconstruction Loss = 638.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.50 mins\n",
      "Epoch: 1 / 10, Batch: 9 (320 / 12512), Elapsed time: 7.50 mins\n",
      "Enc Loss = 238.64, KL Divergence = 1412.37, Reconstruction Loss = 637.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.52 mins\n",
      "Epoch: 1 / 10, Batch: 10 (352 / 12512), Elapsed time: 7.52 mins\n",
      "Enc Loss = 239.60, KL Divergence = 1576.65, Reconstruction Loss = 623.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.54 mins\n",
      "Epoch: 1 / 10, Batch: 11 (384 / 12512), Elapsed time: 7.54 mins\n",
      "Enc Loss = 253.38, KL Divergence = 1412.73, Reconstruction Loss = 685.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.56 mins\n",
      "Epoch: 1 / 10, Batch: 12 (416 / 12512), Elapsed time: 7.56 mins\n",
      "Enc Loss = 241.05, KL Divergence = 1520.33, Reconstruction Loss = 634.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.58 mins\n",
      "Epoch: 1 / 10, Batch: 13 (448 / 12512), Elapsed time: 7.58 mins\n",
      "Enc Loss = 267.51, KL Divergence = 1573.11, Reconstruction Loss = 715.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.60 mins\n",
      "Epoch: 1 / 10, Batch: 14 (480 / 12512), Elapsed time: 7.60 mins\n",
      "Enc Loss = 244.31, KL Divergence = 1377.75, Reconstruction Loss = 659.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.62 mins\n",
      "Epoch: 1 / 10, Batch: 15 (512 / 12512), Elapsed time: 7.62 mins\n",
      "Enc Loss = 226.04, KL Divergence = 1303.77, Reconstruction Loss = 607.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.64 mins\n",
      "Epoch: 1 / 10, Batch: 16 (544 / 12512), Elapsed time: 7.64 mins\n",
      "Enc Loss = 226.13, KL Divergence = 1274.01, Reconstruction Loss = 610.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.66 mins\n",
      "Epoch: 1 / 10, Batch: 17 (576 / 12512), Elapsed time: 7.66 mins\n",
      "Enc Loss = 231.02, KL Divergence = 1151.65, Reconstruction Loss = 639.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.67 mins\n",
      "Epoch: 1 / 10, Batch: 18 (608 / 12512), Elapsed time: 7.67 mins\n",
      "Enc Loss = 236.40, KL Divergence = 1192.59, Reconstruction Loss = 652.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.69 mins\n",
      "Epoch: 1 / 10, Batch: 19 (640 / 12512), Elapsed time: 7.69 mins\n",
      "Enc Loss = 255.08, KL Divergence = 1158.56, Reconstruction Loss = 717.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.71 mins\n",
      "Epoch: 1 / 10, Batch: 20 (672 / 12512), Elapsed time: 7.71 mins\n",
      "Enc Loss = 234.93, KL Divergence = 1055.90, Reconstruction Loss = 661.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.73 mins\n",
      "Epoch: 1 / 10, Batch: 21 (704 / 12512), Elapsed time: 7.73 mins\n",
      "Enc Loss = 237.51, KL Divergence = 1095.15, Reconstruction Loss = 666.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.75 mins\n",
      "Epoch: 1 / 10, Batch: 22 (736 / 12512), Elapsed time: 7.75 mins\n",
      "Enc Loss = 253.04, KL Divergence = 1317.12, Reconstruction Loss = 694.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.77 mins\n",
      "Epoch: 1 / 10, Batch: 23 (768 / 12512), Elapsed time: 7.77 mins\n",
      "Enc Loss = 248.24, KL Divergence = 1250.53, Reconstruction Loss = 685.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.79 mins\n",
      "Epoch: 1 / 10, Batch: 24 (800 / 12512), Elapsed time: 7.79 mins\n",
      "Enc Loss = 230.66, KL Divergence = 1309.91, Reconstruction Loss = 621.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.80 mins\n",
      "Epoch: 1 / 10, Batch: 25 (832 / 12512), Elapsed time: 7.81 mins\n",
      "Enc Loss = 250.91, KL Divergence = 1576.43, Reconstruction Loss = 660.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.82 mins\n",
      "Epoch: 1 / 10, Batch: 26 (864 / 12512), Elapsed time: 7.82 mins\n",
      "Enc Loss = 243.37, KL Divergence = 1410.92, Reconstruction Loss = 653.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.84 mins\n",
      "Epoch: 1 / 10, Batch: 27 (896 / 12512), Elapsed time: 7.84 mins\n",
      "Enc Loss = 234.84, KL Divergence = 1274.38, Reconstruction Loss = 639.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.86 mins\n",
      "Epoch: 1 / 10, Batch: 28 (928 / 12512), Elapsed time: 7.86 mins\n",
      "Enc Loss = 221.64, KL Divergence = 1322.11, Reconstruction Loss = 590.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.88 mins\n",
      "Epoch: 1 / 10, Batch: 29 (960 / 12512), Elapsed time: 7.88 mins\n",
      "Enc Loss = 221.50, KL Divergence = 1226.94, Reconstruction Loss = 600.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.90 mins\n",
      "Epoch: 1 / 10, Batch: 30 (992 / 12512), Elapsed time: 7.90 mins\n",
      "Enc Loss = 240.00, KL Divergence = 1270.98, Reconstruction Loss = 656.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.92 mins\n",
      "Epoch: 1 / 10, Batch: 31 (1024 / 12512), Elapsed time: 7.92 mins\n",
      "Enc Loss = 230.25, KL Divergence = 1151.80, Reconstruction Loss = 636.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.93 mins\n",
      "Epoch: 1 / 10, Batch: 32 (1056 / 12512), Elapsed time: 7.94 mins\n",
      "Enc Loss = 228.09, KL Divergence = 1148.98, Reconstruction Loss = 629.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.95 mins\n",
      "Epoch: 1 / 10, Batch: 33 (1088 / 12512), Elapsed time: 7.95 mins\n",
      "Enc Loss = 225.04, KL Divergence = 1187.21, Reconstruction Loss = 615.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.97 mins\n",
      "Epoch: 1 / 10, Batch: 34 (1120 / 12512), Elapsed time: 7.97 mins\n",
      "Enc Loss = 229.20, KL Divergence = 1093.39, Reconstruction Loss = 639.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 7.99 mins\n",
      "Epoch: 1 / 10, Batch: 35 (1152 / 12512), Elapsed time: 7.99 mins\n",
      "Enc Loss = 232.12, KL Divergence = 1173.05, Reconstruction Loss = 640.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.01 mins\n",
      "Epoch: 1 / 10, Batch: 36 (1184 / 12512), Elapsed time: 8.01 mins\n",
      "Enc Loss = 218.50, KL Divergence = 1211.86, Reconstruction Loss = 591.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.03 mins\n",
      "Epoch: 1 / 10, Batch: 37 (1216 / 12512), Elapsed time: 8.03 mins\n",
      "Enc Loss = 238.88, KL Divergence = 1308.54, Reconstruction Loss = 648.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.04 mins\n",
      "Epoch: 1 / 10, Batch: 38 (1248 / 12512), Elapsed time: 8.04 mins\n",
      "Enc Loss = 226.42, KL Divergence = 1289.16, Reconstruction Loss = 609.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.06 mins\n",
      "Epoch: 1 / 10, Batch: 39 (1280 / 12512), Elapsed time: 8.06 mins\n",
      "Enc Loss = 217.91, KL Divergence = 1230.81, Reconstruction Loss = 588.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.08 mins\n",
      "Epoch: 1 / 10, Batch: 40 (1312 / 12512), Elapsed time: 8.08 mins\n",
      "Enc Loss = 214.78, KL Divergence = 1287.37, Reconstruction Loss = 571.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.10 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 10, Batch: 41 (1344 / 12512), Elapsed time: 8.10 mins\n",
      "Enc Loss = 218.16, KL Divergence = 1325.43, Reconstruction Loss = 579.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.12 mins\n",
      "Epoch: 1 / 10, Batch: 42 (1376 / 12512), Elapsed time: 8.12 mins\n",
      "Enc Loss = 235.44, KL Divergence = 1269.14, Reconstruction Loss = 641.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.14 mins\n",
      "Epoch: 1 / 10, Batch: 43 (1408 / 12512), Elapsed time: 8.14 mins\n",
      "Enc Loss = 233.90, KL Divergence = 1301.17, Reconstruction Loss = 633.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.16 mins\n",
      "Epoch: 1 / 10, Batch: 44 (1440 / 12512), Elapsed time: 8.16 mins\n",
      "Enc Loss = 235.67, KL Divergence = 1237.75, Reconstruction Loss = 645.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.17 mins\n",
      "Epoch: 1 / 10, Batch: 45 (1472 / 12512), Elapsed time: 8.17 mins\n",
      "Enc Loss = 216.29, KL Divergence = 1228.69, Reconstruction Loss = 582.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.19 mins\n",
      "Epoch: 1 / 10, Batch: 46 (1504 / 12512), Elapsed time: 8.19 mins\n",
      "Enc Loss = 236.05, KL Divergence = 1328.65, Reconstruction Loss = 637.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.21 mins\n",
      "Epoch: 1 / 10, Batch: 47 (1536 / 12512), Elapsed time: 8.21 mins\n",
      "Enc Loss = 236.31, KL Divergence = 1354.94, Reconstruction Loss = 635.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.23 mins\n",
      "Epoch: 1 / 10, Batch: 48 (1568 / 12512), Elapsed time: 8.23 mins\n",
      "Enc Loss = 209.80, KL Divergence = 1272.47, Reconstruction Loss = 557.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.25 mins\n",
      "Epoch: 1 / 10, Batch: 49 (1600 / 12512), Elapsed time: 8.25 mins\n",
      "Enc Loss = 243.31, KL Divergence = 1433.36, Reconstruction Loss = 650.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.27 mins\n",
      "Epoch: 1 / 10, Batch: 50 (1632 / 12512), Elapsed time: 8.27 mins\n",
      "Enc Loss = 227.75, KL Divergence = 1392.50, Reconstruction Loss = 603.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.29 mins\n",
      "Epoch: 1 / 10, Batch: 51 (1664 / 12512), Elapsed time: 8.29 mins\n",
      "Enc Loss = 219.88, KL Divergence = 1424.15, Reconstruction Loss = 574.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.30 mins\n",
      "Epoch: 1 / 10, Batch: 52 (1696 / 12512), Elapsed time: 8.30 mins\n",
      "Enc Loss = 221.53, KL Divergence = 1329.95, Reconstruction Loss = 589.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.32 mins\n",
      "Epoch: 1 / 10, Batch: 53 (1728 / 12512), Elapsed time: 8.32 mins\n",
      "Enc Loss = 219.53, KL Divergence = 1365.73, Reconstruction Loss = 579.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.34 mins\n",
      "Epoch: 1 / 10, Batch: 54 (1760 / 12512), Elapsed time: 8.34 mins\n",
      "Enc Loss = 216.97, KL Divergence = 1229.34, Reconstruction Loss = 585.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.36 mins\n",
      "Epoch: 1 / 10, Batch: 55 (1792 / 12512), Elapsed time: 8.36 mins\n",
      "Enc Loss = 238.66, KL Divergence = 1273.40, Reconstruction Loss = 651.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.38 mins\n",
      "Epoch: 1 / 10, Batch: 56 (1824 / 12512), Elapsed time: 8.38 mins\n",
      "Enc Loss = 232.05, KL Divergence = 1255.72, Reconstruction Loss = 631.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.40 mins\n",
      "Epoch: 1 / 10, Batch: 57 (1856 / 12512), Elapsed time: 8.40 mins\n",
      "Enc Loss = 223.74, KL Divergence = 1292.89, Reconstruction Loss = 600.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.42 mins\n",
      "Epoch: 1 / 10, Batch: 58 (1888 / 12512), Elapsed time: 8.42 mins\n",
      "Enc Loss = 216.11, KL Divergence = 1281.51, Reconstruction Loss = 576.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.44 mins\n",
      "Epoch: 1 / 10, Batch: 59 (1920 / 12512), Elapsed time: 8.44 mins\n",
      "Enc Loss = 240.01, KL Divergence = 1219.07, Reconstruction Loss = 661.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.45 mins\n",
      "Epoch: 1 / 10, Batch: 60 (1952 / 12512), Elapsed time: 8.45 mins\n",
      "Enc Loss = 227.08, KL Divergence = 1270.00, Reconstruction Loss = 614.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.47 mins\n",
      "Epoch: 1 / 10, Batch: 61 (1984 / 12512), Elapsed time: 8.47 mins\n",
      "Enc Loss = 214.35, KL Divergence = 1172.35, Reconstruction Loss = 582.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.49 mins\n",
      "Epoch: 1 / 10, Batch: 62 (2016 / 12512), Elapsed time: 8.49 mins\n",
      "Enc Loss = 223.29, KL Divergence = 1253.81, Reconstruction Loss = 603.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.51 mins\n",
      "Epoch: 1 / 10, Batch: 63 (2048 / 12512), Elapsed time: 8.51 mins\n",
      "Enc Loss = 220.76, KL Divergence = 1254.48, Reconstruction Loss = 594.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.53 mins\n",
      "Epoch: 1 / 10, Batch: 64 (2080 / 12512), Elapsed time: 8.53 mins\n",
      "Enc Loss = 228.39, KL Divergence = 1337.36, Reconstruction Loss = 611.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.55 mins\n",
      "Epoch: 1 / 10, Batch: 65 (2112 / 12512), Elapsed time: 8.55 mins\n",
      "Enc Loss = 219.91, KL Divergence = 1339.06, Reconstruction Loss = 583.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.57 mins\n",
      "Epoch: 1 / 10, Batch: 66 (2144 / 12512), Elapsed time: 8.57 mins\n",
      "Enc Loss = 223.32, KL Divergence = 1282.46, Reconstruction Loss = 600.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.58 mins\n",
      "Epoch: 1 / 10, Batch: 67 (2176 / 12512), Elapsed time: 8.58 mins\n",
      "Enc Loss = 222.00, KL Divergence = 1285.07, Reconstruction Loss = 595.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.60 mins\n",
      "Epoch: 1 / 10, Batch: 68 (2208 / 12512), Elapsed time: 8.60 mins\n",
      "Enc Loss = 228.20, KL Divergence = 1316.38, Reconstruction Loss = 612.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.62 mins\n",
      "Epoch: 1 / 10, Batch: 69 (2240 / 12512), Elapsed time: 8.62 mins\n",
      "Enc Loss = 222.73, KL Divergence = 1259.62, Reconstruction Loss = 600.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.64 mins\n",
      "Epoch: 1 / 10, Batch: 70 (2272 / 12512), Elapsed time: 8.64 mins\n",
      "Enc Loss = 213.38, KL Divergence = 1235.48, Reconstruction Loss = 572.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.66 mins\n",
      "Epoch: 1 / 10, Batch: 71 (2304 / 12512), Elapsed time: 8.66 mins\n",
      "Enc Loss = 233.66, KL Divergence = 1283.44, Reconstruction Loss = 634.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.68 mins\n",
      "Epoch: 1 / 10, Batch: 72 (2336 / 12512), Elapsed time: 8.68 mins\n",
      "Enc Loss = 226.53, KL Divergence = 1285.51, Reconstruction Loss = 610.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.70 mins\n",
      "Epoch: 1 / 10, Batch: 73 (2368 / 12512), Elapsed time: 8.70 mins\n",
      "Enc Loss = 214.16, KL Divergence = 1266.25, Reconstruction Loss = 572.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.71 mins\n",
      "Epoch: 1 / 10, Batch: 74 (2400 / 12512), Elapsed time: 8.71 mins\n",
      "Enc Loss = 246.46, KL Divergence = 1358.70, Reconstruction Loss = 668.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.73 mins\n",
      "Epoch: 1 / 10, Batch: 75 (2432 / 12512), Elapsed time: 8.73 mins\n",
      "Enc Loss = 233.42, KL Divergence = 1305.39, Reconstruction Loss = 631.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.75 mins\n",
      "Epoch: 1 / 10, Batch: 76 (2464 / 12512), Elapsed time: 8.75 mins\n",
      "Enc Loss = 230.51, KL Divergence = 1396.55, Reconstruction Loss = 612.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.77 mins\n",
      "Epoch: 1 / 10, Batch: 77 (2496 / 12512), Elapsed time: 8.77 mins\n",
      "Enc Loss = 229.06, KL Divergence = 1487.94, Reconstruction Loss = 598.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.79 mins\n",
      "Epoch: 1 / 10, Batch: 78 (2528 / 12512), Elapsed time: 8.79 mins\n",
      "Enc Loss = 227.30, KL Divergence = 1504.60, Reconstruction Loss = 590.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.81 mins\n",
      "Epoch: 1 / 10, Batch: 79 (2560 / 12512), Elapsed time: 8.81 mins\n",
      "Enc Loss = 228.69, KL Divergence = 1425.02, Reconstruction Loss = 603.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.82 mins\n",
      "Epoch: 1 / 10, Batch: 80 (2592 / 12512), Elapsed time: 8.83 mins\n",
      "Enc Loss = 215.79, KL Divergence = 1365.78, Reconstruction Loss = 567.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.84 mins\n",
      "Epoch: 1 / 10, Batch: 81 (2624 / 12512), Elapsed time: 8.84 mins\n",
      "Enc Loss = 202.82, KL Divergence = 1264.84, Reconstruction Loss = 535.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.86 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 10, Batch: 82 (2656 / 12512), Elapsed time: 8.86 mins\n",
      "Enc Loss = 231.21, KL Divergence = 1208.01, Reconstruction Loss = 633.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.88 mins\n",
      "Epoch: 1 / 10, Batch: 83 (2688 / 12512), Elapsed time: 8.88 mins\n",
      "Enc Loss = 228.48, KL Divergence = 1259.04, Reconstruction Loss = 619.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.90 mins\n",
      "Epoch: 1 / 10, Batch: 84 (2720 / 12512), Elapsed time: 8.90 mins\n",
      "Enc Loss = 227.87, KL Divergence = 1269.23, Reconstruction Loss = 616.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.92 mins\n",
      "Epoch: 1 / 10, Batch: 85 (2752 / 12512), Elapsed time: 8.92 mins\n",
      "Enc Loss = 235.83, KL Divergence = 1289.21, Reconstruction Loss = 640.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.94 mins\n",
      "Epoch: 1 / 10, Batch: 86 (2784 / 12512), Elapsed time: 8.94 mins\n",
      "Enc Loss = 213.93, KL Divergence = 1278.15, Reconstruction Loss = 570.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.96 mins\n",
      "Epoch: 1 / 10, Batch: 87 (2816 / 12512), Elapsed time: 8.96 mins\n",
      "Enc Loss = 212.87, KL Divergence = 1230.54, Reconstruction Loss = 571.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.98 mins\n",
      "Epoch: 1 / 10, Batch: 88 (2848 / 12512), Elapsed time: 8.98 mins\n",
      "Enc Loss = 221.41, KL Divergence = 1264.36, Reconstruction Loss = 596.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 8.99 mins\n",
      "Epoch: 1 / 10, Batch: 89 (2880 / 12512), Elapsed time: 8.99 mins\n",
      "Enc Loss = 218.85, KL Divergence = 1366.85, Reconstruction Loss = 577.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.01 mins\n",
      "Epoch: 1 / 10, Batch: 90 (2912 / 12512), Elapsed time: 9.01 mins\n",
      "Enc Loss = 219.41, KL Divergence = 1402.25, Reconstruction Loss = 575.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.03 mins\n",
      "Epoch: 1 / 10, Batch: 91 (2944 / 12512), Elapsed time: 9.03 mins\n",
      "Enc Loss = 235.72, KL Divergence = 1419.18, Reconstruction Loss = 627.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.05 mins\n",
      "Epoch: 1 / 10, Batch: 92 (2976 / 12512), Elapsed time: 9.05 mins\n",
      "Enc Loss = 232.78, KL Divergence = 1450.07, Reconstruction Loss = 614.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.07 mins\n",
      "Epoch: 1 / 10, Batch: 93 (3008 / 12512), Elapsed time: 9.07 mins\n",
      "Enc Loss = 205.52, KL Divergence = 1244.51, Reconstruction Loss = 545.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.09 mins\n",
      "Epoch: 1 / 10, Batch: 94 (3040 / 12512), Elapsed time: 9.09 mins\n",
      "Enc Loss = 208.34, KL Divergence = 1289.36, Reconstruction Loss = 550.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.10 mins\n",
      "Epoch: 1 / 10, Batch: 95 (3072 / 12512), Elapsed time: 9.11 mins\n",
      "Enc Loss = 216.53, KL Divergence = 1186.55, Reconstruction Loss = 588.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.12 mins\n",
      "Epoch: 1 / 10, Batch: 96 (3104 / 12512), Elapsed time: 9.12 mins\n",
      "Enc Loss = 233.20, KL Divergence = 1220.01, Reconstruction Loss = 639.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.14 mins\n",
      "Epoch: 1 / 10, Batch: 97 (3136 / 12512), Elapsed time: 9.14 mins\n",
      "Enc Loss = 227.20, KL Divergence = 1213.79, Reconstruction Loss = 620.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.16 mins\n",
      "Epoch: 1 / 10, Batch: 98 (3168 / 12512), Elapsed time: 9.16 mins\n",
      "Enc Loss = 241.32, KL Divergence = 1359.76, Reconstruction Loss = 651.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.18 mins\n",
      "Epoch: 1 / 10, Batch: 99 (3200 / 12512), Elapsed time: 9.18 mins\n",
      "Enc Loss = 222.45, KL Divergence = 1282.82, Reconstruction Loss = 597.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.20 mins\n",
      "Epoch: 1 / 10, Batch: 100 (3232 / 12512), Elapsed time: 9.20 mins\n",
      "Enc Loss = 220.12, KL Divergence = 1258.05, Reconstruction Loss = 592.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.22 mins\n",
      "Epoch: 1 / 10, Batch: 101 (3264 / 12512), Elapsed time: 9.22 mins\n",
      "Enc Loss = 223.29, KL Divergence = 1319.45, Reconstruction Loss = 596.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.24 mins\n",
      "Epoch: 1 / 10, Batch: 102 (3296 / 12512), Elapsed time: 9.24 mins\n",
      "Enc Loss = 225.28, KL Divergence = 1333.47, Reconstruction Loss = 601.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.25 mins\n",
      "Epoch: 1 / 10, Batch: 103 (3328 / 12512), Elapsed time: 9.25 mins\n",
      "Enc Loss = 214.85, KL Divergence = 1381.31, Reconstruction Loss = 562.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.27 mins\n",
      "Epoch: 1 / 10, Batch: 104 (3360 / 12512), Elapsed time: 9.27 mins\n",
      "Enc Loss = 218.76, KL Divergence = 1423.97, Reconstruction Loss = 571.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.29 mins\n",
      "Epoch: 1 / 10, Batch: 105 (3392 / 12512), Elapsed time: 9.29 mins\n",
      "Enc Loss = 210.04, KL Divergence = 1357.01, Reconstruction Loss = 549.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.31 mins\n",
      "Epoch: 1 / 10, Batch: 106 (3424 / 12512), Elapsed time: 9.31 mins\n",
      "Enc Loss = 218.28, KL Divergence = 1462.53, Reconstruction Loss = 565.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.33 mins\n",
      "Epoch: 1 / 10, Batch: 107 (3456 / 12512), Elapsed time: 9.33 mins\n",
      "Enc Loss = 206.61, KL Divergence = 1261.57, Reconstruction Loss = 547.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.35 mins\n",
      "Epoch: 1 / 10, Batch: 108 (3488 / 12512), Elapsed time: 9.35 mins\n",
      "Enc Loss = 212.94, KL Divergence = 1223.79, Reconstruction Loss = 572.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.37 mins\n",
      "Epoch: 1 / 10, Batch: 109 (3520 / 12512), Elapsed time: 9.37 mins\n",
      "Enc Loss = 222.83, KL Divergence = 1271.31, Reconstruction Loss = 600.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.38 mins\n",
      "Epoch: 1 / 10, Batch: 110 (3552 / 12512), Elapsed time: 9.39 mins\n",
      "Enc Loss = 211.39, KL Divergence = 1210.23, Reconstruction Loss = 568.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.40 mins\n",
      "Epoch: 1 / 10, Batch: 111 (3584 / 12512), Elapsed time: 9.40 mins\n",
      "Enc Loss = 208.08, KL Divergence = 1170.71, Reconstruction Loss = 561.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.42 mins\n",
      "Epoch: 1 / 10, Batch: 112 (3616 / 12512), Elapsed time: 9.42 mins\n",
      "Enc Loss = 206.61, KL Divergence = 1175.58, Reconstruction Loss = 556.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.44 mins\n",
      "Epoch: 1 / 10, Batch: 113 (3648 / 12512), Elapsed time: 9.44 mins\n",
      "Enc Loss = 208.51, KL Divergence = 1136.42, Reconstruction Loss = 566.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.46 mins\n",
      "Epoch: 1 / 10, Batch: 114 (3680 / 12512), Elapsed time: 9.46 mins\n",
      "Enc Loss = 212.22, KL Divergence = 1204.80, Reconstruction Loss = 572.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.48 mins\n",
      "Epoch: 1 / 10, Batch: 115 (3712 / 12512), Elapsed time: 9.48 mins\n",
      "Enc Loss = 234.10, KL Divergence = 1306.18, Reconstruction Loss = 633.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.50 mins\n",
      "Epoch: 1 / 10, Batch: 116 (3744 / 12512), Elapsed time: 9.50 mins\n",
      "Enc Loss = 213.72, KL Divergence = 1287.25, Reconstruction Loss = 568.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.51 mins\n",
      "Epoch: 1 / 10, Batch: 117 (3776 / 12512), Elapsed time: 9.51 mins\n",
      "Enc Loss = 218.89, KL Divergence = 1334.84, Reconstruction Loss = 580.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.53 mins\n",
      "Epoch: 1 / 10, Batch: 118 (3808 / 12512), Elapsed time: 9.53 mins\n",
      "Enc Loss = 211.49, KL Divergence = 1388.75, Reconstruction Loss = 550.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.55 mins\n",
      "Epoch: 1 / 10, Batch: 119 (3840 / 12512), Elapsed time: 9.55 mins\n",
      "Enc Loss = 225.03, KL Divergence = 1410.99, Reconstruction Loss = 592.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.57 mins\n",
      "Epoch: 1 / 10, Batch: 120 (3872 / 12512), Elapsed time: 9.57 mins\n",
      "Enc Loss = 211.56, KL Divergence = 1476.92, Reconstruction Loss = 542.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.59 mins\n",
      "Epoch: 1 / 10, Batch: 121 (3904 / 12512), Elapsed time: 9.59 mins\n",
      "Enc Loss = 222.01, KL Divergence = 1460.10, Reconstruction Loss = 577.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.61 mins\n",
      "Epoch: 1 / 10, Batch: 122 (3936 / 12512), Elapsed time: 9.61 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 218.49, KL Divergence = 1370.09, Reconstruction Loss = 575.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.63 mins\n",
      "Epoch: 1 / 10, Batch: 123 (3968 / 12512), Elapsed time: 9.63 mins\n",
      "Enc Loss = 205.04, KL Divergence = 1413.63, Reconstruction Loss = 527.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.65 mins\n",
      "Epoch: 1 / 10, Batch: 124 (4000 / 12512), Elapsed time: 9.65 mins\n",
      "Enc Loss = 199.86, KL Divergence = 1243.21, Reconstruction Loss = 527.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.66 mins\n",
      "Epoch: 1 / 10, Batch: 125 (4032 / 12512), Elapsed time: 9.66 mins\n",
      "Enc Loss = 220.07, KL Divergence = 1247.27, Reconstruction Loss = 593.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.68 mins\n",
      "Epoch: 1 / 10, Batch: 126 (4064 / 12512), Elapsed time: 9.68 mins\n",
      "Enc Loss = 206.31, KL Divergence = 1169.38, Reconstruction Loss = 556.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.70 mins\n",
      "Epoch: 1 / 10, Batch: 127 (4096 / 12512), Elapsed time: 9.70 mins\n",
      "Enc Loss = 202.16, KL Divergence = 1117.83, Reconstruction Loss = 547.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.72 mins\n",
      "Epoch: 1 / 10, Batch: 128 (4128 / 12512), Elapsed time: 9.72 mins\n",
      "Enc Loss = 203.88, KL Divergence = 1046.05, Reconstruction Loss = 560.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.74 mins\n",
      "Epoch: 1 / 10, Batch: 129 (4160 / 12512), Elapsed time: 9.74 mins\n",
      "Enc Loss = 210.35, KL Divergence = 1145.41, Reconstruction Loss = 571.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.76 mins\n",
      "Epoch: 1 / 10, Batch: 130 (4192 / 12512), Elapsed time: 9.76 mins\n",
      "Enc Loss = 201.78, KL Divergence = 1151.39, Reconstruction Loss = 543.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.78 mins\n",
      "Epoch: 1 / 10, Batch: 131 (4224 / 12512), Elapsed time: 9.78 mins\n",
      "Enc Loss = 215.47, KL Divergence = 1183.07, Reconstruction Loss = 584.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.80 mins\n",
      "Epoch: 1 / 10, Batch: 132 (4256 / 12512), Elapsed time: 9.80 mins\n",
      "Enc Loss = 219.58, KL Divergence = 1130.75, Reconstruction Loss = 603.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.82 mins\n",
      "Epoch: 1 / 10, Batch: 133 (4288 / 12512), Elapsed time: 9.82 mins\n",
      "Enc Loss = 207.53, KL Divergence = 1278.03, Reconstruction Loss = 549.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.83 mins\n",
      "Epoch: 1 / 10, Batch: 134 (4320 / 12512), Elapsed time: 9.83 mins\n",
      "Enc Loss = 209.77, KL Divergence = 1384.50, Reconstruction Loss = 545.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.85 mins\n",
      "Epoch: 1 / 10, Batch: 135 (4352 / 12512), Elapsed time: 9.85 mins\n",
      "Enc Loss = 229.81, KL Divergence = 1412.87, Reconstruction Loss = 608.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.87 mins\n",
      "Epoch: 1 / 10, Batch: 136 (4384 / 12512), Elapsed time: 9.87 mins\n",
      "Enc Loss = 235.70, KL Divergence = 1638.32, Reconstruction Loss = 604.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.89 mins\n",
      "Epoch: 1 / 10, Batch: 137 (4416 / 12512), Elapsed time: 9.89 mins\n",
      "Enc Loss = 216.45, KL Divergence = 1447.34, Reconstruction Loss = 561.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.91 mins\n",
      "Epoch: 1 / 10, Batch: 138 (4448 / 12512), Elapsed time: 9.91 mins\n",
      "Enc Loss = 216.78, KL Divergence = 1415.38, Reconstruction Loss = 565.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.93 mins\n",
      "Epoch: 1 / 10, Batch: 139 (4480 / 12512), Elapsed time: 9.93 mins\n",
      "Enc Loss = 223.50, KL Divergence = 1553.73, Reconstruction Loss = 573.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.94 mins\n",
      "Epoch: 1 / 10, Batch: 140 (4512 / 12512), Elapsed time: 9.94 mins\n",
      "Enc Loss = 218.59, KL Divergence = 1475.69, Reconstruction Loss = 565.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.96 mins\n",
      "Epoch: 1 / 10, Batch: 141 (4544 / 12512), Elapsed time: 9.96 mins\n",
      "Enc Loss = 237.16, KL Divergence = 1449.04, Reconstruction Loss = 628.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 9.98 mins\n",
      "Epoch: 1 / 10, Batch: 142 (4576 / 12512), Elapsed time: 9.98 mins\n",
      "Enc Loss = 214.33, KL Divergence = 1377.85, Reconstruction Loss = 561.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.00 mins\n",
      "Epoch: 1 / 10, Batch: 143 (4608 / 12512), Elapsed time: 10.00 mins\n",
      "Enc Loss = 210.43, KL Divergence = 1349.91, Reconstruction Loss = 551.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.02 mins\n",
      "Epoch: 1 / 10, Batch: 144 (4640 / 12512), Elapsed time: 10.02 mins\n",
      "Enc Loss = 208.88, KL Divergence = 1357.06, Reconstruction Loss = 545.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.04 mins\n",
      "Epoch: 1 / 10, Batch: 145 (4672 / 12512), Elapsed time: 10.04 mins\n",
      "Enc Loss = 207.38, KL Divergence = 1314.16, Reconstruction Loss = 544.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.06 mins\n",
      "Epoch: 1 / 10, Batch: 146 (4704 / 12512), Elapsed time: 10.06 mins\n",
      "Enc Loss = 201.73, KL Divergence = 1269.53, Reconstruction Loss = 531.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.08 mins\n",
      "Epoch: 1 / 10, Batch: 147 (4736 / 12512), Elapsed time: 10.08 mins\n",
      "Enc Loss = 207.51, KL Divergence = 1227.44, Reconstruction Loss = 554.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.09 mins\n",
      "Epoch: 1 / 10, Batch: 148 (4768 / 12512), Elapsed time: 10.09 mins\n",
      "Enc Loss = 200.82, KL Divergence = 1086.79, Reconstruction Loss = 546.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.11 mins\n",
      "Epoch: 1 / 10, Batch: 149 (4800 / 12512), Elapsed time: 10.11 mins\n",
      "Enc Loss = 212.51, KL Divergence = 1179.99, Reconstruction Loss = 575.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.13 mins\n",
      "Epoch: 1 / 10, Batch: 150 (4832 / 12512), Elapsed time: 10.13 mins\n",
      "Enc Loss = 201.84, KL Divergence = 1074.83, Reconstruction Loss = 551.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.15 mins\n",
      "Epoch: 1 / 10, Batch: 151 (4864 / 12512), Elapsed time: 10.15 mins\n",
      "Enc Loss = 196.46, KL Divergence = 1091.34, Reconstruction Loss = 532.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.17 mins\n",
      "Epoch: 1 / 10, Batch: 152 (4896 / 12512), Elapsed time: 10.17 mins\n",
      "Enc Loss = 216.45, KL Divergence = 1143.93, Reconstruction Loss = 592.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.19 mins\n",
      "Epoch: 1 / 10, Batch: 153 (4928 / 12512), Elapsed time: 10.19 mins\n",
      "Enc Loss = 221.54, KL Divergence = 1093.49, Reconstruction Loss = 613.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.21 mins\n",
      "Epoch: 1 / 10, Batch: 154 (4960 / 12512), Elapsed time: 10.21 mins\n",
      "Enc Loss = 198.04, KL Divergence = 1111.99, Reconstruction Loss = 535.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.22 mins\n",
      "Epoch: 1 / 10, Batch: 155 (4992 / 12512), Elapsed time: 10.22 mins\n",
      "Enc Loss = 194.20, KL Divergence = 1269.40, Reconstruction Loss = 506.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.24 mins\n",
      "Epoch: 1 / 10, Batch: 156 (5024 / 12512), Elapsed time: 10.24 mins\n",
      "Enc Loss = 192.52, KL Divergence = 1274.24, Reconstruction Loss = 500.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.26 mins\n",
      "Epoch: 1 / 10, Batch: 157 (5056 / 12512), Elapsed time: 10.26 mins\n",
      "Enc Loss = 195.57, KL Divergence = 1187.53, Reconstruction Loss = 519.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.28 mins\n",
      "Epoch: 1 / 10, Batch: 158 (5088 / 12512), Elapsed time: 10.28 mins\n",
      "Enc Loss = 211.30, KL Divergence = 1305.41, Reconstruction Loss = 558.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.30 mins\n",
      "Epoch: 1 / 10, Batch: 159 (5120 / 12512), Elapsed time: 10.30 mins\n",
      "Enc Loss = 231.84, KL Divergence = 1333.56, Reconstruction Loss = 623.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.32 mins\n",
      "Epoch: 1 / 10, Batch: 160 (5152 / 12512), Elapsed time: 10.32 mins\n",
      "Enc Loss = 209.32, KL Divergence = 1478.81, Reconstruction Loss = 534.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.34 mins\n",
      "Epoch: 1 / 10, Batch: 161 (5184 / 12512), Elapsed time: 10.34 mins\n",
      "Enc Loss = 193.58, KL Divergence = 1498.05, Reconstruction Loss = 480.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.35 mins\n",
      "Epoch: 1 / 10, Batch: 162 (5216 / 12512), Elapsed time: 10.36 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 205.60, KL Divergence = 1390.84, Reconstruction Loss = 531.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.37 mins\n",
      "Epoch: 1 / 10, Batch: 163 (5248 / 12512), Elapsed time: 10.37 mins\n",
      "Enc Loss = 216.45, KL Divergence = 1538.70, Reconstruction Loss = 551.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.39 mins\n",
      "Epoch: 1 / 10, Batch: 164 (5280 / 12512), Elapsed time: 10.39 mins\n",
      "Enc Loss = 215.06, KL Divergence = 1498.55, Reconstruction Loss = 551.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.41 mins\n",
      "Epoch: 1 / 10, Batch: 165 (5312 / 12512), Elapsed time: 10.41 mins\n",
      "Enc Loss = 201.57, KL Divergence = 1247.92, Reconstruction Loss = 532.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.43 mins\n",
      "Epoch: 1 / 10, Batch: 166 (5344 / 12512), Elapsed time: 10.43 mins\n",
      "Enc Loss = 207.64, KL Divergence = 1259.73, Reconstruction Loss = 551.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.45 mins\n",
      "Epoch: 1 / 10, Batch: 167 (5376 / 12512), Elapsed time: 10.45 mins\n",
      "Enc Loss = 199.61, KL Divergence = 1133.78, Reconstruction Loss = 537.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.47 mins\n",
      "Epoch: 1 / 10, Batch: 168 (5408 / 12512), Elapsed time: 10.47 mins\n",
      "Enc Loss = 225.14, KL Divergence = 1295.64, Reconstruction Loss = 605.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.49 mins\n",
      "Epoch: 1 / 10, Batch: 169 (5440 / 12512), Elapsed time: 10.49 mins\n",
      "Enc Loss = 203.80, KL Divergence = 1174.12, Reconstruction Loss = 547.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.50 mins\n",
      "Epoch: 1 / 10, Batch: 170 (5472 / 12512), Elapsed time: 10.50 mins\n",
      "Enc Loss = 200.36, KL Divergence = 1181.54, Reconstruction Loss = 535.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.52 mins\n",
      "Epoch: 1 / 10, Batch: 171 (5504 / 12512), Elapsed time: 10.52 mins\n",
      "Enc Loss = 227.26, KL Divergence = 1337.00, Reconstruction Loss = 607.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.54 mins\n",
      "Epoch: 1 / 10, Batch: 172 (5536 / 12512), Elapsed time: 10.54 mins\n",
      "Enc Loss = 204.36, KL Divergence = 1453.27, Reconstruction Loss = 520.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.56 mins\n",
      "Epoch: 1 / 10, Batch: 173 (5568 / 12512), Elapsed time: 10.56 mins\n",
      "Enc Loss = 218.83, KL Divergence = 1461.62, Reconstruction Loss = 567.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.58 mins\n",
      "Epoch: 1 / 10, Batch: 174 (5600 / 12512), Elapsed time: 10.58 mins\n",
      "Enc Loss = 228.19, KL Divergence = 1428.18, Reconstruction Loss = 601.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.60 mins\n",
      "Epoch: 1 / 10, Batch: 175 (5632 / 12512), Elapsed time: 10.60 mins\n",
      "Enc Loss = 197.90, KL Divergence = 1351.42, Reconstruction Loss = 510.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.62 mins\n",
      "Epoch: 1 / 10, Batch: 176 (5664 / 12512), Elapsed time: 10.62 mins\n",
      "Enc Loss = 213.08, KL Divergence = 1432.51, Reconstruction Loss = 551.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.63 mins\n",
      "Epoch: 1 / 10, Batch: 177 (5696 / 12512), Elapsed time: 10.63 mins\n",
      "Enc Loss = 201.42, KL Divergence = 1379.02, Reconstruction Loss = 518.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.65 mins\n",
      "Epoch: 1 / 10, Batch: 178 (5728 / 12512), Elapsed time: 10.65 mins\n",
      "Enc Loss = 204.78, KL Divergence = 1368.26, Reconstruction Loss = 530.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.67 mins\n",
      "Epoch: 1 / 10, Batch: 179 (5760 / 12512), Elapsed time: 10.67 mins\n",
      "Enc Loss = 200.87, KL Divergence = 1292.95, Reconstruction Loss = 525.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.69 mins\n",
      "Epoch: 1 / 10, Batch: 180 (5792 / 12512), Elapsed time: 10.69 mins\n",
      "Enc Loss = 215.46, KL Divergence = 1302.78, Reconstruction Loss = 572.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.71 mins\n",
      "Epoch: 1 / 10, Batch: 181 (5824 / 12512), Elapsed time: 10.71 mins\n",
      "Enc Loss = 214.58, KL Divergence = 1241.20, Reconstruction Loss = 576.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.73 mins\n",
      "Epoch: 1 / 10, Batch: 182 (5856 / 12512), Elapsed time: 10.73 mins\n",
      "Enc Loss = 197.46, KL Divergence = 1307.72, Reconstruction Loss = 513.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.74 mins\n",
      "Epoch: 1 / 10, Batch: 183 (5888 / 12512), Elapsed time: 10.75 mins\n",
      "Enc Loss = 197.34, KL Divergence = 1151.64, Reconstruction Loss = 528.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.76 mins\n",
      "Epoch: 1 / 10, Batch: 184 (5920 / 12512), Elapsed time: 10.76 mins\n",
      "Enc Loss = 206.03, KL Divergence = 1397.70, Reconstruction Loss = 532.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.78 mins\n",
      "Epoch: 1 / 10, Batch: 185 (5952 / 12512), Elapsed time: 10.78 mins\n",
      "Enc Loss = 194.57, KL Divergence = 1169.17, Reconstruction Loss = 517.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.80 mins\n",
      "Epoch: 1 / 10, Batch: 186 (5984 / 12512), Elapsed time: 10.80 mins\n",
      "Enc Loss = 205.05, KL Divergence = 1190.20, Reconstruction Loss = 550.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.82 mins\n",
      "Epoch: 1 / 10, Batch: 187 (6016 / 12512), Elapsed time: 10.82 mins\n",
      "Enc Loss = 218.51, KL Divergence = 1335.83, Reconstruction Loss = 579.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.84 mins\n",
      "Epoch: 1 / 10, Batch: 188 (6048 / 12512), Elapsed time: 10.84 mins\n",
      "Enc Loss = 205.02, KL Divergence = 1201.44, Reconstruction Loss = 548.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.86 mins\n",
      "Epoch: 1 / 10, Batch: 189 (6080 / 12512), Elapsed time: 10.86 mins\n",
      "Enc Loss = 194.61, KL Divergence = 1245.27, Reconstruction Loss = 510.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.87 mins\n",
      "Epoch: 1 / 10, Batch: 190 (6112 / 12512), Elapsed time: 10.87 mins\n",
      "Enc Loss = 209.61, KL Divergence = 1256.98, Reconstruction Loss = 558.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.89 mins\n",
      "Epoch: 1 / 10, Batch: 191 (6144 / 12512), Elapsed time: 10.89 mins\n",
      "Enc Loss = 203.46, KL Divergence = 1307.98, Reconstruction Loss = 532.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.91 mins\n",
      "Epoch: 1 / 10, Batch: 192 (6176 / 12512), Elapsed time: 10.91 mins\n",
      "Enc Loss = 200.05, KL Divergence = 1418.23, Reconstruction Loss = 510.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.93 mins\n",
      "Epoch: 1 / 10, Batch: 193 (6208 / 12512), Elapsed time: 10.93 mins\n",
      "Enc Loss = 193.56, KL Divergence = 1314.70, Reconstruction Loss = 499.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.95 mins\n",
      "Epoch: 1 / 10, Batch: 194 (6240 / 12512), Elapsed time: 10.95 mins\n",
      "Enc Loss = 202.36, KL Divergence = 1356.90, Reconstruction Loss = 524.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.97 mins\n",
      "Epoch: 1 / 10, Batch: 195 (6272 / 12512), Elapsed time: 10.97 mins\n",
      "Enc Loss = 194.47, KL Divergence = 1117.74, Reconstruction Loss = 522.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 10.99 mins\n",
      "Epoch: 1 / 10, Batch: 196 (6304 / 12512), Elapsed time: 10.99 mins\n",
      "Enc Loss = 213.00, KL Divergence = 1254.83, Reconstruction Loss = 569.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.01 mins\n",
      "Epoch: 1 / 10, Batch: 197 (6336 / 12512), Elapsed time: 11.01 mins\n",
      "Enc Loss = 191.16, KL Divergence = 1110.27, Reconstruction Loss = 512.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.02 mins\n",
      "Epoch: 1 / 10, Batch: 198 (6368 / 12512), Elapsed time: 11.03 mins\n",
      "Enc Loss = 201.37, KL Divergence = 1206.18, Reconstruction Loss = 536.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.04 mins\n",
      "Epoch: 1 / 10, Batch: 199 (6400 / 12512), Elapsed time: 11.04 mins\n",
      "Enc Loss = 222.53, KL Divergence = 1229.82, Reconstruction Loss = 603.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.06 mins\n",
      "Epoch: 1 / 10, Batch: 200 (6432 / 12512), Elapsed time: 11.06 mins\n",
      "Enc Loss = 196.39, KL Divergence = 1182.09, Reconstruction Loss = 522.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.08 mins\n",
      "Epoch: 1 / 10, Batch: 201 (6464 / 12512), Elapsed time: 11.08 mins\n",
      "Enc Loss = 204.65, KL Divergence = 1311.77, Reconstruction Loss = 536.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.10 mins\n",
      "Epoch: 1 / 10, Batch: 202 (6496 / 12512), Elapsed time: 11.10 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 201.49, KL Divergence = 1203.85, Reconstruction Loss = 536.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.12 mins\n",
      "Epoch: 1 / 10, Batch: 203 (6528 / 12512), Elapsed time: 11.12 mins\n",
      "Enc Loss = 191.52, KL Divergence = 1245.13, Reconstruction Loss = 500.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.14 mins\n",
      "Epoch: 1 / 10, Batch: 204 (6560 / 12512), Elapsed time: 11.14 mins\n",
      "Enc Loss = 190.54, KL Divergence = 1088.90, Reconstruction Loss = 512.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.16 mins\n",
      "Epoch: 1 / 10, Batch: 205 (6592 / 12512), Elapsed time: 11.16 mins\n",
      "Enc Loss = 198.54, KL Divergence = 1359.05, Reconstruction Loss = 511.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.17 mins\n",
      "Epoch: 1 / 10, Batch: 206 (6624 / 12512), Elapsed time: 11.17 mins\n",
      "Enc Loss = 202.43, KL Divergence = 1411.31, Reconstruction Loss = 518.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.19 mins\n",
      "Epoch: 1 / 10, Batch: 207 (6656 / 12512), Elapsed time: 11.19 mins\n",
      "Enc Loss = 212.05, KL Divergence = 1219.08, Reconstruction Loss = 570.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.21 mins\n",
      "Epoch: 1 / 10, Batch: 208 (6688 / 12512), Elapsed time: 11.21 mins\n",
      "Enc Loss = 190.65, KL Divergence = 1193.38, Reconstruction Loss = 502.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.23 mins\n",
      "Epoch: 1 / 10, Batch: 209 (6720 / 12512), Elapsed time: 11.23 mins\n",
      "Enc Loss = 191.54, KL Divergence = 1257.79, Reconstruction Loss = 498.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.25 mins\n",
      "Epoch: 1 / 10, Batch: 210 (6752 / 12512), Elapsed time: 11.25 mins\n",
      "Enc Loss = 192.32, KL Divergence = 1170.59, Reconstruction Loss = 510.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.27 mins\n",
      "Epoch: 1 / 10, Batch: 211 (6784 / 12512), Elapsed time: 11.27 mins\n",
      "Enc Loss = 185.03, KL Divergence = 1125.77, Reconstruction Loss = 491.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.29 mins\n",
      "Epoch: 1 / 10, Batch: 212 (6816 / 12512), Elapsed time: 11.29 mins\n",
      "Enc Loss = 202.42, KL Divergence = 1190.68, Reconstruction Loss = 541.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.31 mins\n",
      "Epoch: 1 / 10, Batch: 213 (6848 / 12512), Elapsed time: 11.31 mins\n",
      "Enc Loss = 207.20, KL Divergence = 1269.30, Reconstruction Loss = 548.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.33 mins\n",
      "Epoch: 1 / 10, Batch: 214 (6880 / 12512), Elapsed time: 11.33 mins\n",
      "Enc Loss = 208.18, KL Divergence = 1228.44, Reconstruction Loss = 556.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.35 mins\n",
      "Epoch: 1 / 10, Batch: 215 (6912 / 12512), Elapsed time: 11.35 mins\n",
      "Enc Loss = 213.84, KL Divergence = 1233.85, Reconstruction Loss = 574.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.36 mins\n",
      "Epoch: 1 / 10, Batch: 216 (6944 / 12512), Elapsed time: 11.36 mins\n",
      "Enc Loss = 199.26, KL Divergence = 1333.81, Reconstruction Loss = 516.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.38 mins\n",
      "Epoch: 1 / 10, Batch: 217 (6976 / 12512), Elapsed time: 11.38 mins\n",
      "Enc Loss = 199.65, KL Divergence = 1432.65, Reconstruction Loss = 507.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.40 mins\n",
      "Epoch: 1 / 10, Batch: 218 (7008 / 12512), Elapsed time: 11.40 mins\n",
      "Enc Loss = 224.93, KL Divergence = 1513.03, Reconstruction Loss = 582.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.42 mins\n",
      "Epoch: 1 / 10, Batch: 219 (7040 / 12512), Elapsed time: 11.42 mins\n",
      "Enc Loss = 198.14, KL Divergence = 1592.99, Reconstruction Loss = 486.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.44 mins\n",
      "Epoch: 1 / 10, Batch: 220 (7072 / 12512), Elapsed time: 11.44 mins\n",
      "Enc Loss = 216.68, KL Divergence = 1564.14, Reconstruction Loss = 549.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.46 mins\n",
      "Epoch: 1 / 10, Batch: 221 (7104 / 12512), Elapsed time: 11.46 mins\n",
      "Enc Loss = 199.38, KL Divergence = 1508.91, Reconstruction Loss = 498.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.48 mins\n",
      "Epoch: 1 / 10, Batch: 222 (7136 / 12512), Elapsed time: 11.48 mins\n",
      "Enc Loss = 198.40, KL Divergence = 1525.01, Reconstruction Loss = 493.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.50 mins\n",
      "Epoch: 1 / 10, Batch: 223 (7168 / 12512), Elapsed time: 11.50 mins\n",
      "Enc Loss = 194.03, KL Divergence = 1365.92, Reconstruction Loss = 495.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.51 mins\n",
      "Epoch: 1 / 10, Batch: 224 (7200 / 12512), Elapsed time: 11.51 mins\n",
      "Enc Loss = 190.76, KL Divergence = 1300.67, Reconstruction Loss = 491.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.53 mins\n",
      "Epoch: 1 / 10, Batch: 225 (7232 / 12512), Elapsed time: 11.53 mins\n",
      "Enc Loss = 202.13, KL Divergence = 1270.01, Reconstruction Loss = 532.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.55 mins\n",
      "Epoch: 1 / 10, Batch: 226 (7264 / 12512), Elapsed time: 11.55 mins\n",
      "Enc Loss = 206.70, KL Divergence = 1280.69, Reconstruction Loss = 546.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.57 mins\n",
      "Epoch: 1 / 10, Batch: 227 (7296 / 12512), Elapsed time: 11.57 mins\n",
      "Enc Loss = 177.62, KL Divergence = 1073.49, Reconstruction Loss = 472.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.59 mins\n",
      "Epoch: 1 / 10, Batch: 228 (7328 / 12512), Elapsed time: 11.59 mins\n",
      "Enc Loss = 193.23, KL Divergence = 1159.60, Reconstruction Loss = 514.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.61 mins\n",
      "Epoch: 1 / 10, Batch: 229 (7360 / 12512), Elapsed time: 11.61 mins\n",
      "Enc Loss = 192.78, KL Divergence = 1099.58, Reconstruction Loss = 519.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.63 mins\n",
      "Epoch: 1 / 10, Batch: 230 (7392 / 12512), Elapsed time: 11.63 mins\n",
      "Enc Loss = 230.30, KL Divergence = 1218.55, Reconstruction Loss = 629.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.64 mins\n",
      "Epoch: 1 / 10, Batch: 231 (7424 / 12512), Elapsed time: 11.64 mins\n",
      "Enc Loss = 197.71, KL Divergence = 1102.69, Reconstruction Loss = 534.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.66 mins\n",
      "Epoch: 1 / 10, Batch: 232 (7456 / 12512), Elapsed time: 11.67 mins\n",
      "Enc Loss = 192.69, KL Divergence = 1091.96, Reconstruction Loss = 519.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.68 mins\n",
      "Epoch: 1 / 10, Batch: 233 (7488 / 12512), Elapsed time: 11.68 mins\n",
      "Enc Loss = 190.37, KL Divergence = 1141.09, Reconstruction Loss = 506.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.70 mins\n",
      "Epoch: 1 / 10, Batch: 234 (7520 / 12512), Elapsed time: 11.70 mins\n",
      "Enc Loss = 188.94, KL Divergence = 1222.85, Reconstruction Loss = 493.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.72 mins\n",
      "Epoch: 1 / 10, Batch: 235 (7552 / 12512), Elapsed time: 11.72 mins\n",
      "Enc Loss = 189.12, KL Divergence = 1278.70, Reconstruction Loss = 488.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.74 mins\n",
      "Epoch: 1 / 10, Batch: 236 (7584 / 12512), Elapsed time: 11.74 mins\n",
      "Enc Loss = 221.07, KL Divergence = 1484.38, Reconstruction Loss = 572.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.76 mins\n",
      "Epoch: 1 / 10, Batch: 237 (7616 / 12512), Elapsed time: 11.76 mins\n",
      "Enc Loss = 181.50, KL Divergence = 1326.23, Reconstruction Loss = 458.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.78 mins\n",
      "Epoch: 1 / 10, Batch: 238 (7648 / 12512), Elapsed time: 11.78 mins\n",
      "Enc Loss = 194.53, KL Divergence = 1320.86, Reconstruction Loss = 502.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.80 mins\n",
      "Epoch: 1 / 10, Batch: 239 (7680 / 12512), Elapsed time: 11.80 mins\n",
      "Enc Loss = 200.49, KL Divergence = 1413.37, Reconstruction Loss = 512.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.81 mins\n",
      "Epoch: 1 / 10, Batch: 240 (7712 / 12512), Elapsed time: 11.81 mins\n",
      "Enc Loss = 199.31, KL Divergence = 1465.30, Reconstruction Loss = 503.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.83 mins\n",
      "Epoch: 1 / 10, Batch: 241 (7744 / 12512), Elapsed time: 11.83 mins\n",
      "Enc Loss = 201.97, KL Divergence = 1281.60, Reconstruction Loss = 530.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.85 mins\n",
      "Epoch: 1 / 10, Batch: 242 (7776 / 12512), Elapsed time: 11.85 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 223.32, KL Divergence = 1410.84, Reconstruction Loss = 587.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.87 mins\n",
      "Epoch: 1 / 10, Batch: 243 (7808 / 12512), Elapsed time: 11.87 mins\n",
      "Enc Loss = 216.64, KL Divergence = 1510.30, Reconstruction Loss = 555.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.89 mins\n",
      "Epoch: 1 / 10, Batch: 244 (7840 / 12512), Elapsed time: 11.89 mins\n",
      "Enc Loss = 185.78, KL Divergence = 1265.06, Reconstruction Loss = 479.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.91 mins\n",
      "Epoch: 1 / 10, Batch: 245 (7872 / 12512), Elapsed time: 11.91 mins\n",
      "Enc Loss = 188.42, KL Divergence = 1249.50, Reconstruction Loss = 489.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.93 mins\n",
      "Epoch: 1 / 10, Batch: 246 (7904 / 12512), Elapsed time: 11.93 mins\n",
      "Enc Loss = 197.25, KL Divergence = 1319.92, Reconstruction Loss = 511.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.94 mins\n",
      "Epoch: 1 / 10, Batch: 247 (7936 / 12512), Elapsed time: 11.94 mins\n",
      "Enc Loss = 182.78, KL Divergence = 1158.48, Reconstruction Loss = 480.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.96 mins\n",
      "Epoch: 1 / 10, Batch: 248 (7968 / 12512), Elapsed time: 11.96 mins\n",
      "Enc Loss = 189.40, KL Divergence = 1273.80, Reconstruction Loss = 490.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 11.98 mins\n",
      "Epoch: 1 / 10, Batch: 249 (8000 / 12512), Elapsed time: 11.98 mins\n",
      "Enc Loss = 186.79, KL Divergence = 1294.91, Reconstruction Loss = 479.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.00 mins\n",
      "Epoch: 1 / 10, Batch: 250 (8032 / 12512), Elapsed time: 12.00 mins\n",
      "Enc Loss = 199.43, KL Divergence = 1172.39, Reconstruction Loss = 533.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.02 mins\n",
      "Epoch: 1 / 10, Batch: 251 (8064 / 12512), Elapsed time: 12.02 mins\n",
      "Enc Loss = 195.85, KL Divergence = 1176.83, Reconstruction Loss = 521.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.04 mins\n",
      "Epoch: 1 / 10, Batch: 252 (8096 / 12512), Elapsed time: 12.04 mins\n",
      "Enc Loss = 208.59, KL Divergence = 1178.74, Reconstruction Loss = 562.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.06 mins\n",
      "Epoch: 1 / 10, Batch: 253 (8128 / 12512), Elapsed time: 12.06 mins\n",
      "Enc Loss = 199.09, KL Divergence = 1213.43, Reconstruction Loss = 528.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.08 mins\n",
      "Epoch: 1 / 10, Batch: 254 (8160 / 12512), Elapsed time: 12.08 mins\n",
      "Enc Loss = 199.37, KL Divergence = 1157.96, Reconstruction Loss = 534.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.10 mins\n",
      "Epoch: 1 / 10, Batch: 255 (8192 / 12512), Elapsed time: 12.10 mins\n",
      "Enc Loss = 213.94, KL Divergence = 1340.59, Reconstruction Loss = 563.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.12 mins\n",
      "Epoch: 1 / 10, Batch: 256 (8224 / 12512), Elapsed time: 12.12 mins\n",
      "Enc Loss = 193.84, KL Divergence = 1459.83, Reconstruction Loss = 485.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.13 mins\n",
      "Epoch: 1 / 10, Batch: 257 (8256 / 12512), Elapsed time: 12.14 mins\n",
      "Enc Loss = 194.82, KL Divergence = 1384.50, Reconstruction Loss = 496.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.15 mins\n",
      "Epoch: 1 / 10, Batch: 258 (8288 / 12512), Elapsed time: 12.15 mins\n",
      "Enc Loss = 188.23, KL Divergence = 1394.87, Reconstruction Loss = 473.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.17 mins\n",
      "Epoch: 1 / 10, Batch: 259 (8320 / 12512), Elapsed time: 12.17 mins\n",
      "Enc Loss = 190.86, KL Divergence = 1348.92, Reconstruction Loss = 487.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.19 mins\n",
      "Epoch: 1 / 10, Batch: 260 (8352 / 12512), Elapsed time: 12.19 mins\n",
      "Enc Loss = 230.95, KL Divergence = 1539.45, Reconstruction Loss = 599.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.21 mins\n",
      "Epoch: 1 / 10, Batch: 261 (8384 / 12512), Elapsed time: 12.21 mins\n",
      "Enc Loss = 191.27, KL Divergence = 1341.51, Reconstruction Loss = 489.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.23 mins\n",
      "Epoch: 1 / 10, Batch: 262 (8416 / 12512), Elapsed time: 12.23 mins\n",
      "Enc Loss = 237.93, KL Divergence = 1620.29, Reconstruction Loss = 613.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.25 mins\n",
      "Epoch: 1 / 10, Batch: 263 (8448 / 12512), Elapsed time: 12.25 mins\n",
      "Enc Loss = 187.79, KL Divergence = 1396.34, Reconstruction Loss = 472.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.26 mins\n",
      "Epoch: 1 / 10, Batch: 264 (8480 / 12512), Elapsed time: 12.26 mins\n",
      "Enc Loss = 212.00, KL Divergence = 1435.43, Reconstruction Loss = 547.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.28 mins\n",
      "Epoch: 1 / 10, Batch: 265 (8512 / 12512), Elapsed time: 12.28 mins\n",
      "Enc Loss = 191.72, KL Divergence = 1395.54, Reconstruction Loss = 485.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.30 mins\n",
      "Epoch: 1 / 10, Batch: 266 (8544 / 12512), Elapsed time: 12.30 mins\n",
      "Enc Loss = 192.86, KL Divergence = 1301.79, Reconstruction Loss = 498.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.32 mins\n",
      "Epoch: 1 / 10, Batch: 267 (8576 / 12512), Elapsed time: 12.32 mins\n",
      "Enc Loss = 199.56, KL Divergence = 1323.13, Reconstruction Loss = 518.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.34 mins\n",
      "Epoch: 1 / 10, Batch: 268 (8608 / 12512), Elapsed time: 12.34 mins\n",
      "Enc Loss = 190.77, KL Divergence = 1329.82, Reconstruction Loss = 488.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.36 mins\n",
      "Epoch: 1 / 10, Batch: 269 (8640 / 12512), Elapsed time: 12.36 mins\n",
      "Enc Loss = 196.88, KL Divergence = 1238.04, Reconstruction Loss = 518.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.37 mins\n",
      "Epoch: 1 / 10, Batch: 270 (8672 / 12512), Elapsed time: 12.37 mins\n",
      "Enc Loss = 197.01, KL Divergence = 1257.91, Reconstruction Loss = 516.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.39 mins\n",
      "Epoch: 1 / 10, Batch: 271 (8704 / 12512), Elapsed time: 12.39 mins\n",
      "Enc Loss = 191.67, KL Divergence = 1157.51, Reconstruction Loss = 509.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.41 mins\n",
      "Epoch: 1 / 10, Batch: 272 (8736 / 12512), Elapsed time: 12.41 mins\n",
      "Enc Loss = 217.95, KL Divergence = 1226.68, Reconstruction Loss = 588.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.43 mins\n",
      "Epoch: 1 / 10, Batch: 273 (8768 / 12512), Elapsed time: 12.43 mins\n",
      "Enc Loss = 210.81, KL Divergence = 1246.37, Reconstruction Loss = 563.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.45 mins\n",
      "Epoch: 1 / 10, Batch: 274 (8800 / 12512), Elapsed time: 12.45 mins\n",
      "Enc Loss = 193.15, KL Divergence = 1156.25, Reconstruction Loss = 514.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.47 mins\n",
      "Epoch: 1 / 10, Batch: 275 (8832 / 12512), Elapsed time: 12.47 mins\n",
      "Enc Loss = 183.44, KL Divergence = 1260.36, Reconstruction Loss = 472.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.49 mins\n",
      "Epoch: 1 / 10, Batch: 276 (8864 / 12512), Elapsed time: 12.49 mins\n",
      "Enc Loss = 190.16, KL Divergence = 1393.71, Reconstruction Loss = 480.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.51 mins\n",
      "Epoch: 1 / 10, Batch: 277 (8896 / 12512), Elapsed time: 12.51 mins\n",
      "Enc Loss = 203.99, KL Divergence = 1314.94, Reconstruction Loss = 533.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.52 mins\n",
      "Epoch: 1 / 10, Batch: 278 (8928 / 12512), Elapsed time: 12.52 mins\n",
      "Enc Loss = 186.37, KL Divergence = 1372.77, Reconstruction Loss = 470.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.54 mins\n",
      "Epoch: 1 / 10, Batch: 279 (8960 / 12512), Elapsed time: 12.54 mins\n",
      "Enc Loss = 196.78, KL Divergence = 1458.47, Reconstruction Loss = 495.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.56 mins\n",
      "Epoch: 1 / 10, Batch: 280 (8992 / 12512), Elapsed time: 12.56 mins\n",
      "Enc Loss = 243.40, KL Divergence = 1410.20, Reconstruction Loss = 653.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.58 mins\n",
      "Epoch: 1 / 10, Batch: 281 (9024 / 12512), Elapsed time: 12.58 mins\n",
      "Enc Loss = 201.39, KL Divergence = 1371.21, Reconstruction Loss = 519.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.60 mins\n",
      "Epoch: 1 / 10, Batch: 282 (9056 / 12512), Elapsed time: 12.60 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 212.00, KL Divergence = 1340.65, Reconstruction Loss = 557.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.62 mins\n",
      "Epoch: 1 / 10, Batch: 283 (9088 / 12512), Elapsed time: 12.62 mins\n",
      "Enc Loss = 188.05, KL Divergence = 1389.45, Reconstruction Loss = 473.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.64 mins\n",
      "Epoch: 1 / 10, Batch: 284 (9120 / 12512), Elapsed time: 12.64 mins\n",
      "Enc Loss = 205.46, KL Divergence = 1489.19, Reconstruction Loss = 520.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.66 mins\n",
      "Epoch: 1 / 10, Batch: 285 (9152 / 12512), Elapsed time: 12.66 mins\n",
      "Enc Loss = 194.26, KL Divergence = 1339.02, Reconstruction Loss = 499.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.67 mins\n",
      "Epoch: 1 / 10, Batch: 286 (9184 / 12512), Elapsed time: 12.67 mins\n",
      "Enc Loss = 199.67, KL Divergence = 1387.26, Reconstruction Loss = 512.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.69 mins\n",
      "Epoch: 1 / 10, Batch: 287 (9216 / 12512), Elapsed time: 12.69 mins\n",
      "Enc Loss = 183.83, KL Divergence = 1288.26, Reconstruction Loss = 470.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.71 mins\n",
      "Epoch: 1 / 10, Batch: 288 (9248 / 12512), Elapsed time: 12.71 mins\n",
      "Enc Loss = 184.20, KL Divergence = 1300.45, Reconstruction Loss = 470.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.73 mins\n",
      "Epoch: 1 / 10, Batch: 289 (9280 / 12512), Elapsed time: 12.73 mins\n",
      "Enc Loss = 186.29, KL Divergence = 1271.85, Reconstruction Loss = 480.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.75 mins\n",
      "Epoch: 1 / 10, Batch: 290 (9312 / 12512), Elapsed time: 12.75 mins\n",
      "Enc Loss = 176.08, KL Divergence = 1155.78, Reconstruction Loss = 458.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.77 mins\n",
      "Epoch: 1 / 10, Batch: 291 (9344 / 12512), Elapsed time: 12.77 mins\n",
      "Enc Loss = 197.82, KL Divergence = 1228.04, Reconstruction Loss = 522.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.79 mins\n",
      "Epoch: 1 / 10, Batch: 292 (9376 / 12512), Elapsed time: 12.79 mins\n",
      "Enc Loss = 193.15, KL Divergence = 1153.62, Reconstruction Loss = 514.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.81 mins\n",
      "Epoch: 1 / 10, Batch: 293 (9408 / 12512), Elapsed time: 12.81 mins\n",
      "Enc Loss = 173.45, KL Divergence = 1102.00, Reconstruction Loss = 455.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.82 mins\n",
      "Epoch: 1 / 10, Batch: 294 (9440 / 12512), Elapsed time: 12.82 mins\n",
      "Enc Loss = 205.34, KL Divergence = 1126.16, Reconstruction Loss = 557.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.84 mins\n",
      "Epoch: 1 / 10, Batch: 295 (9472 / 12512), Elapsed time: 12.84 mins\n",
      "Enc Loss = 195.22, KL Divergence = 1121.01, Reconstruction Loss = 524.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.86 mins\n",
      "Epoch: 1 / 10, Batch: 296 (9504 / 12512), Elapsed time: 12.86 mins\n",
      "Enc Loss = 186.18, KL Divergence = 1074.83, Reconstruction Loss = 500.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.88 mins\n",
      "Epoch: 1 / 10, Batch: 297 (9536 / 12512), Elapsed time: 12.88 mins\n",
      "Enc Loss = 218.75, KL Divergence = 1210.92, Reconstruction Loss = 592.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.90 mins\n",
      "Epoch: 1 / 10, Batch: 298 (9568 / 12512), Elapsed time: 12.90 mins\n",
      "Enc Loss = 203.96, KL Divergence = 1111.97, Reconstruction Loss = 554.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.92 mins\n",
      "Epoch: 1 / 10, Batch: 299 (9600 / 12512), Elapsed time: 12.92 mins\n",
      "Enc Loss = 209.30, KL Divergence = 1306.28, Reconstruction Loss = 552.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.94 mins\n",
      "Epoch: 1 / 10, Batch: 300 (9632 / 12512), Elapsed time: 12.94 mins\n",
      "Enc Loss = 196.68, KL Divergence = 1407.58, Reconstruction Loss = 500.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.96 mins\n",
      "Epoch: 1 / 10, Batch: 301 (9664 / 12512), Elapsed time: 12.96 mins\n",
      "Enc Loss = 192.01, KL Divergence = 1486.85, Reconstruction Loss = 476.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.98 mins\n",
      "Epoch: 1 / 10, Batch: 302 (9696 / 12512), Elapsed time: 12.98 mins\n",
      "Enc Loss = 198.81, KL Divergence = 1536.01, Reconstruction Loss = 494.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 12.99 mins\n",
      "Epoch: 1 / 10, Batch: 303 (9728 / 12512), Elapsed time: 13.00 mins\n",
      "Enc Loss = 195.83, KL Divergence = 1529.40, Reconstruction Loss = 485.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.01 mins\n",
      "Epoch: 1 / 10, Batch: 304 (9760 / 12512), Elapsed time: 13.01 mins\n",
      "Enc Loss = 202.57, KL Divergence = 1418.32, Reconstruction Loss = 518.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.03 mins\n",
      "Epoch: 1 / 10, Batch: 305 (9792 / 12512), Elapsed time: 13.03 mins\n",
      "Enc Loss = 199.07, KL Divergence = 1363.78, Reconstruction Loss = 512.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.05 mins\n",
      "Epoch: 1 / 10, Batch: 306 (9824 / 12512), Elapsed time: 13.05 mins\n",
      "Enc Loss = 197.12, KL Divergence = 1344.56, Reconstruction Loss = 508.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.07 mins\n",
      "Epoch: 1 / 10, Batch: 307 (9856 / 12512), Elapsed time: 13.07 mins\n",
      "Enc Loss = 195.62, KL Divergence = 1288.18, Reconstruction Loss = 509.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.09 mins\n",
      "Epoch: 1 / 10, Batch: 308 (9888 / 12512), Elapsed time: 13.09 mins\n",
      "Enc Loss = 184.58, KL Divergence = 1193.40, Reconstruction Loss = 482.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.11 mins\n",
      "Epoch: 1 / 10, Batch: 309 (9920 / 12512), Elapsed time: 13.11 mins\n",
      "Enc Loss = 202.79, KL Divergence = 1245.18, Reconstruction Loss = 537.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.13 mins\n",
      "Epoch: 1 / 10, Batch: 310 (9952 / 12512), Elapsed time: 13.13 mins\n",
      "Enc Loss = 184.12, KL Divergence = 1070.85, Reconstruction Loss = 493.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.15 mins\n",
      "Epoch: 1 / 10, Batch: 311 (9984 / 12512), Elapsed time: 13.15 mins\n",
      "Enc Loss = 195.62, KL Divergence = 1013.08, Reconstruction Loss = 537.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.17 mins\n",
      "Epoch: 1 / 10, Batch: 312 (10016 / 12512), Elapsed time: 13.17 mins\n",
      "Enc Loss = 180.69, KL Divergence = 1088.50, Reconstruction Loss = 480.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.18 mins\n",
      "Epoch: 1 / 10, Batch: 313 (10048 / 12512), Elapsed time: 13.19 mins\n",
      "Enc Loss = 196.91, KL Divergence = 1081.60, Reconstruction Loss = 534.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.20 mins\n",
      "Epoch: 1 / 10, Batch: 314 (10080 / 12512), Elapsed time: 13.20 mins\n",
      "Enc Loss = 192.19, KL Divergence = 1080.79, Reconstruction Loss = 519.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.22 mins\n",
      "Epoch: 1 / 10, Batch: 315 (10112 / 12512), Elapsed time: 13.22 mins\n",
      "Enc Loss = 209.57, KL Divergence = 1192.12, Reconstruction Loss = 564.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.24 mins\n",
      "Epoch: 1 / 10, Batch: 316 (10144 / 12512), Elapsed time: 13.24 mins\n",
      "Enc Loss = 188.36, KL Divergence = 1129.90, Reconstruction Loss = 501.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.26 mins\n",
      "Epoch: 1 / 10, Batch: 317 (10176 / 12512), Elapsed time: 13.26 mins\n",
      "Enc Loss = 183.37, KL Divergence = 1320.63, Reconstruction Loss = 465.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.28 mins\n",
      "Epoch: 1 / 10, Batch: 318 (10208 / 12512), Elapsed time: 13.28 mins\n",
      "Enc Loss = 200.48, KL Divergence = 1289.78, Reconstruction Loss = 524.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.30 mins\n",
      "Epoch: 1 / 10, Batch: 319 (10240 / 12512), Elapsed time: 13.30 mins\n",
      "Enc Loss = 183.83, KL Divergence = 1324.52, Reconstruction Loss = 466.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.32 mins\n",
      "Epoch: 1 / 10, Batch: 320 (10272 / 12512), Elapsed time: 13.32 mins\n",
      "Enc Loss = 198.68, KL Divergence = 1493.61, Reconstruction Loss = 498.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.34 mins\n",
      "Epoch: 1 / 10, Batch: 321 (10304 / 12512), Elapsed time: 13.34 mins\n",
      "Enc Loss = 199.24, KL Divergence = 1512.64, Reconstruction Loss = 497.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.35 mins\n",
      "Epoch: 1 / 10, Batch: 322 (10336 / 12512), Elapsed time: 13.35 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 193.23, KL Divergence = 1467.72, Reconstruction Loss = 482.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.37 mins\n",
      "Epoch: 1 / 10, Batch: 323 (10368 / 12512), Elapsed time: 13.37 mins\n",
      "Enc Loss = 194.88, KL Divergence = 1453.94, Reconstruction Loss = 489.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.39 mins\n",
      "Epoch: 1 / 10, Batch: 324 (10400 / 12512), Elapsed time: 13.39 mins\n",
      "Enc Loss = 214.61, KL Divergence = 1546.53, Reconstruction Loss = 544.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.41 mins\n",
      "Epoch: 1 / 10, Batch: 325 (10432 / 12512), Elapsed time: 13.41 mins\n",
      "Enc Loss = 183.38, KL Divergence = 1481.73, Reconstruction Loss = 449.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.43 mins\n",
      "Epoch: 1 / 10, Batch: 326 (10464 / 12512), Elapsed time: 13.43 mins\n",
      "Enc Loss = 191.92, KL Divergence = 1277.82, Reconstruction Loss = 498.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.45 mins\n",
      "Epoch: 1 / 10, Batch: 327 (10496 / 12512), Elapsed time: 13.45 mins\n",
      "Enc Loss = 185.06, KL Divergence = 1252.80, Reconstruction Loss = 478.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.47 mins\n",
      "Epoch: 1 / 10, Batch: 328 (10528 / 12512), Elapsed time: 13.47 mins\n",
      "Enc Loss = 207.97, KL Divergence = 1373.16, Reconstruction Loss = 540.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.48 mins\n",
      "Epoch: 1 / 10, Batch: 329 (10560 / 12512), Elapsed time: 13.49 mins\n",
      "Enc Loss = 184.00, KL Divergence = 1240.71, Reconstruction Loss = 475.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.50 mins\n",
      "Epoch: 1 / 10, Batch: 330 (10592 / 12512), Elapsed time: 13.50 mins\n",
      "Enc Loss = 196.30, KL Divergence = 1208.81, Reconstruction Loss = 519.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.52 mins\n",
      "Epoch: 1 / 10, Batch: 331 (10624 / 12512), Elapsed time: 13.52 mins\n",
      "Enc Loss = 185.05, KL Divergence = 1171.98, Reconstruction Loss = 486.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.54 mins\n",
      "Epoch: 1 / 10, Batch: 332 (10656 / 12512), Elapsed time: 13.54 mins\n",
      "Enc Loss = 181.20, KL Divergence = 1085.51, Reconstruction Loss = 482.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.56 mins\n",
      "Epoch: 1 / 10, Batch: 333 (10688 / 12512), Elapsed time: 13.56 mins\n",
      "Enc Loss = 213.54, KL Divergence = 1059.87, Reconstruction Loss = 591.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.58 mins\n",
      "Epoch: 1 / 10, Batch: 334 (10720 / 12512), Elapsed time: 13.58 mins\n",
      "Enc Loss = 208.16, KL Divergence = 1284.25, Reconstruction Loss = 550.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.60 mins\n",
      "Epoch: 1 / 10, Batch: 335 (10752 / 12512), Elapsed time: 13.60 mins\n",
      "Enc Loss = 192.89, KL Divergence = 1323.17, Reconstruction Loss = 496.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.62 mins\n",
      "Epoch: 1 / 10, Batch: 336 (10784 / 12512), Elapsed time: 13.62 mins\n",
      "Enc Loss = 178.83, KL Divergence = 1279.25, Reconstruction Loss = 454.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.64 mins\n",
      "Epoch: 1 / 10, Batch: 337 (10816 / 12512), Elapsed time: 13.64 mins\n",
      "Enc Loss = 190.31, KL Divergence = 1301.42, Reconstruction Loss = 490.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.66 mins\n",
      "Epoch: 1 / 10, Batch: 338 (10848 / 12512), Elapsed time: 13.66 mins\n",
      "Enc Loss = 180.86, KL Divergence = 1343.42, Reconstruction Loss = 455.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.68 mins\n",
      "Epoch: 1 / 10, Batch: 339 (10880 / 12512), Elapsed time: 13.68 mins\n",
      "Enc Loss = 208.56, KL Divergence = 1404.14, Reconstruction Loss = 539.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.70 mins\n",
      "Epoch: 1 / 10, Batch: 340 (10912 / 12512), Elapsed time: 13.70 mins\n",
      "Enc Loss = 180.34, KL Divergence = 1257.13, Reconstruction Loss = 462.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.71 mins\n",
      "Epoch: 1 / 10, Batch: 341 (10944 / 12512), Elapsed time: 13.71 mins\n",
      "Enc Loss = 187.59, KL Divergence = 1365.24, Reconstruction Loss = 474.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.73 mins\n",
      "Epoch: 1 / 10, Batch: 342 (10976 / 12512), Elapsed time: 13.73 mins\n",
      "Enc Loss = 189.14, KL Divergence = 1336.53, Reconstruction Loss = 482.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.75 mins\n",
      "Epoch: 1 / 10, Batch: 343 (11008 / 12512), Elapsed time: 13.75 mins\n",
      "Enc Loss = 200.97, KL Divergence = 1304.26, Reconstruction Loss = 524.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.77 mins\n",
      "Epoch: 1 / 10, Batch: 344 (11040 / 12512), Elapsed time: 13.77 mins\n",
      "Enc Loss = 193.86, KL Divergence = 1177.97, Reconstruction Loss = 514.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.79 mins\n",
      "Epoch: 1 / 10, Batch: 345 (11072 / 12512), Elapsed time: 13.79 mins\n",
      "Enc Loss = 176.56, KL Divergence = 1152.06, Reconstruction Loss = 460.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.81 mins\n",
      "Epoch: 1 / 10, Batch: 346 (11104 / 12512), Elapsed time: 13.81 mins\n",
      "Enc Loss = 191.34, KL Divergence = 1191.81, Reconstruction Loss = 504.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.83 mins\n",
      "Epoch: 1 / 10, Batch: 347 (11136 / 12512), Elapsed time: 13.83 mins\n",
      "Enc Loss = 191.18, KL Divergence = 1120.18, Reconstruction Loss = 511.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.84 mins\n",
      "Epoch: 1 / 10, Batch: 348 (11168 / 12512), Elapsed time: 13.84 mins\n",
      "Enc Loss = 223.13, KL Divergence = 1269.21, Reconstruction Loss = 601.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.86 mins\n",
      "Epoch: 1 / 10, Batch: 349 (11200 / 12512), Elapsed time: 13.86 mins\n",
      "Enc Loss = 177.28, KL Divergence = 1193.86, Reconstruction Loss = 458.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.88 mins\n",
      "Epoch: 1 / 10, Batch: 350 (11232 / 12512), Elapsed time: 13.88 mins\n",
      "Enc Loss = 185.38, KL Divergence = 1237.33, Reconstruction Loss = 480.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.90 mins\n",
      "Epoch: 1 / 10, Batch: 351 (11264 / 12512), Elapsed time: 13.90 mins\n",
      "Enc Loss = 181.83, KL Divergence = 1200.75, Reconstruction Loss = 472.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.92 mins\n",
      "Epoch: 1 / 10, Batch: 352 (11296 / 12512), Elapsed time: 13.92 mins\n",
      "Enc Loss = 195.62, KL Divergence = 1228.83, Reconstruction Loss = 515.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.94 mins\n",
      "Epoch: 1 / 10, Batch: 353 (11328 / 12512), Elapsed time: 13.94 mins\n",
      "Enc Loss = 185.16, KL Divergence = 1308.75, Reconstruction Loss = 472.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.96 mins\n",
      "Epoch: 1 / 10, Batch: 354 (11360 / 12512), Elapsed time: 13.96 mins\n",
      "Enc Loss = 194.72, KL Divergence = 1370.61, Reconstruction Loss = 497.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.98 mins\n",
      "Epoch: 1 / 10, Batch: 355 (11392 / 12512), Elapsed time: 13.98 mins\n",
      "Enc Loss = 180.97, KL Divergence = 1429.05, Reconstruction Loss = 446.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 13.99 mins\n",
      "Epoch: 1 / 10, Batch: 356 (11424 / 12512), Elapsed time: 14.00 mins\n",
      "Enc Loss = 189.50, KL Divergence = 1421.79, Reconstruction Loss = 475.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.01 mins\n",
      "Epoch: 1 / 10, Batch: 357 (11456 / 12512), Elapsed time: 14.01 mins\n",
      "Enc Loss = 214.09, KL Divergence = 1534.23, Reconstruction Loss = 544.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.03 mins\n",
      "Epoch: 1 / 10, Batch: 358 (11488 / 12512), Elapsed time: 14.03 mins\n",
      "Enc Loss = 172.00, KL Divergence = 1169.24, Reconstruction Loss = 443.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.05 mins\n",
      "Epoch: 1 / 10, Batch: 359 (11520 / 12512), Elapsed time: 14.05 mins\n",
      "Enc Loss = 177.22, KL Divergence = 1176.58, Reconstruction Loss = 460.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.07 mins\n",
      "Epoch: 1 / 10, Batch: 360 (11552 / 12512), Elapsed time: 14.07 mins\n",
      "Enc Loss = 200.93, KL Divergence = 1296.26, Reconstruction Loss = 525.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.09 mins\n",
      "Epoch: 1 / 10, Batch: 361 (11584 / 12512), Elapsed time: 14.09 mins\n",
      "Enc Loss = 183.68, KL Divergence = 1177.75, Reconstruction Loss = 481.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.11 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 10, Batch: 362 (11616 / 12512), Elapsed time: 14.11 mins\n",
      "Enc Loss = 177.98, KL Divergence = 1188.06, Reconstruction Loss = 461.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.12 mins\n",
      "Epoch: 1 / 10, Batch: 363 (11648 / 12512), Elapsed time: 14.12 mins\n",
      "Enc Loss = 175.47, KL Divergence = 1224.08, Reconstruction Loss = 449.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.14 mins\n",
      "Epoch: 1 / 10, Batch: 364 (11680 / 12512), Elapsed time: 14.14 mins\n",
      "Enc Loss = 191.19, KL Divergence = 1179.90, Reconstruction Loss = 505.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.16 mins\n",
      "Epoch: 1 / 10, Batch: 365 (11712 / 12512), Elapsed time: 14.16 mins\n",
      "Enc Loss = 180.86, KL Divergence = 1203.78, Reconstruction Loss = 469.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.18 mins\n",
      "Epoch: 1 / 10, Batch: 366 (11744 / 12512), Elapsed time: 14.18 mins\n",
      "Enc Loss = 173.97, KL Divergence = 1124.71, Reconstruction Loss = 454.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.20 mins\n",
      "Epoch: 1 / 10, Batch: 367 (11776 / 12512), Elapsed time: 14.20 mins\n",
      "Enc Loss = 179.01, KL Divergence = 1177.18, Reconstruction Loss = 466.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.22 mins\n",
      "Epoch: 1 / 10, Batch: 368 (11808 / 12512), Elapsed time: 14.22 mins\n",
      "Enc Loss = 201.32, KL Divergence = 1279.87, Reconstruction Loss = 528.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.24 mins\n",
      "Epoch: 1 / 10, Batch: 369 (11840 / 12512), Elapsed time: 14.24 mins\n",
      "Enc Loss = 186.74, KL Divergence = 1187.32, Reconstruction Loss = 490.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.26 mins\n",
      "Epoch: 1 / 10, Batch: 370 (11872 / 12512), Elapsed time: 14.26 mins\n",
      "Enc Loss = 197.39, KL Divergence = 1297.25, Reconstruction Loss = 513.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.28 mins\n",
      "Epoch: 1 / 10, Batch: 371 (11904 / 12512), Elapsed time: 14.28 mins\n",
      "Enc Loss = 182.83, KL Divergence = 1211.03, Reconstruction Loss = 475.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.29 mins\n",
      "Epoch: 1 / 10, Batch: 372 (11936 / 12512), Elapsed time: 14.30 mins\n",
      "Enc Loss = 193.51, KL Divergence = 1358.80, Reconstruction Loss = 494.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.31 mins\n",
      "Epoch: 1 / 10, Batch: 373 (11968 / 12512), Elapsed time: 14.31 mins\n",
      "Enc Loss = 183.89, KL Divergence = 1357.09, Reconstruction Loss = 463.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.33 mins\n",
      "Epoch: 1 / 10, Batch: 374 (12000 / 12512), Elapsed time: 14.33 mins\n",
      "Enc Loss = 195.32, KL Divergence = 1400.43, Reconstruction Loss = 496.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.35 mins\n",
      "Epoch: 1 / 10, Batch: 375 (12032 / 12512), Elapsed time: 14.35 mins\n",
      "Enc Loss = 181.38, KL Divergence = 1273.24, Reconstruction Loss = 463.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.37 mins\n",
      "Epoch: 1 / 10, Batch: 376 (12064 / 12512), Elapsed time: 14.37 mins\n",
      "Enc Loss = 178.67, KL Divergence = 1353.50, Reconstruction Loss = 446.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.39 mins\n",
      "Epoch: 1 / 10, Batch: 377 (12096 / 12512), Elapsed time: 14.39 mins\n",
      "Enc Loss = 184.15, KL Divergence = 1420.17, Reconstruction Loss = 458.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.41 mins\n",
      "Epoch: 1 / 10, Batch: 378 (12128 / 12512), Elapsed time: 14.41 mins\n",
      "Enc Loss = 185.56, KL Divergence = 1229.63, Reconstruction Loss = 482.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.43 mins\n",
      "Epoch: 1 / 10, Batch: 379 (12160 / 12512), Elapsed time: 14.43 mins\n",
      "Enc Loss = 179.21, KL Divergence = 1333.23, Reconstruction Loss = 450.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.44 mins\n",
      "Epoch: 1 / 10, Batch: 380 (12192 / 12512), Elapsed time: 14.44 mins\n",
      "Enc Loss = 179.59, KL Divergence = 1319.72, Reconstruction Loss = 453.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.46 mins\n",
      "Epoch: 1 / 10, Batch: 381 (12224 / 12512), Elapsed time: 14.46 mins\n",
      "Enc Loss = 248.02, KL Divergence = 1316.40, Reconstruction Loss = 677.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.48 mins\n",
      "Epoch: 1 / 10, Batch: 382 (12256 / 12512), Elapsed time: 14.48 mins\n",
      "Enc Loss = 207.48, KL Divergence = 1376.74, Reconstruction Loss = 538.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.50 mins\n",
      "Epoch: 1 / 10, Batch: 383 (12288 / 12512), Elapsed time: 14.50 mins\n",
      "Enc Loss = 174.07, KL Divergence = 1220.87, Reconstruction Loss = 445.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.52 mins\n",
      "Epoch: 1 / 10, Batch: 384 (12320 / 12512), Elapsed time: 14.52 mins\n",
      "Enc Loss = 186.97, KL Divergence = 1358.25, Reconstruction Loss = 473.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.54 mins\n",
      "Epoch: 1 / 10, Batch: 385 (12352 / 12512), Elapsed time: 14.54 mins\n",
      "Enc Loss = 191.40, KL Divergence = 1389.98, Reconstruction Loss = 484.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.56 mins\n",
      "Epoch: 1 / 10, Batch: 386 (12384 / 12512), Elapsed time: 14.56 mins\n",
      "Enc Loss = 181.34, KL Divergence = 1311.69, Reconstruction Loss = 459.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.57 mins\n",
      "Epoch: 1 / 10, Batch: 387 (12416 / 12512), Elapsed time: 14.57 mins\n",
      "Enc Loss = 187.86, KL Divergence = 1349.30, Reconstruction Loss = 477.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.59 mins\n",
      "Epoch: 1 / 10, Batch: 388 (12448 / 12512), Elapsed time: 14.59 mins\n",
      "Enc Loss = 178.60, KL Divergence = 1281.67, Reconstruction Loss = 453.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.61 mins\n",
      "Epoch: 1 / 10, Batch: 389 (12480 / 12512), Elapsed time: 14.61 mins\n",
      "Enc Loss = 198.18, KL Divergence = 1218.87, Reconstruction Loss = 524.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.63 mins\n",
      "Epoch: 1 / 10, Batch: 390 (12512 / 12512), Elapsed time: 14.63 mins\n",
      "Enc Loss = 139.29, KL Divergence = 438.91, Reconstruction Loss = 411.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.65 mins\n",
      "Epoch: 2, Elapsed Time: 14.65\n",
      "Epoch: 2 / 10, Batch: 0 (32 / 12512), Elapsed time: 14.65 mins\n",
      "Enc Loss = 184.53, KL Divergence = 1255.02, Reconstruction Loss = 476.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.67 mins\n",
      "Epoch: 2 / 10, Batch: 1 (64 / 12512), Elapsed time: 14.67 mins\n",
      "Enc Loss = 203.92, KL Divergence = 1297.95, Reconstruction Loss = 535.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.69 mins\n",
      "Epoch: 2 / 10, Batch: 2 (96 / 12512), Elapsed time: 14.69 mins\n",
      "Enc Loss = 191.04, KL Divergence = 1226.85, Reconstruction Loss = 500.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.71 mins\n",
      "Epoch: 2 / 10, Batch: 3 (128 / 12512), Elapsed time: 14.71 mins\n",
      "Enc Loss = 198.73, KL Divergence = 1411.47, Reconstruction Loss = 506.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.73 mins\n",
      "Epoch: 2 / 10, Batch: 4 (160 / 12512), Elapsed time: 14.73 mins\n",
      "Enc Loss = 170.03, KL Divergence = 1254.88, Reconstruction Loss = 428.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.74 mins\n",
      "Epoch: 2 / 10, Batch: 5 (192 / 12512), Elapsed time: 14.74 mins\n",
      "Enc Loss = 176.31, KL Divergence = 1239.35, Reconstruction Loss = 450.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.76 mins\n",
      "Epoch: 2 / 10, Batch: 6 (224 / 12512), Elapsed time: 14.76 mins\n",
      "Enc Loss = 207.82, KL Divergence = 1269.46, Reconstruction Loss = 550.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.78 mins\n",
      "Epoch: 2 / 10, Batch: 7 (256 / 12512), Elapsed time: 14.78 mins\n",
      "Enc Loss = 178.37, KL Divergence = 1355.66, Reconstruction Loss = 445.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.80 mins\n",
      "Epoch: 2 / 10, Batch: 8 (288 / 12512), Elapsed time: 14.80 mins\n",
      "Enc Loss = 185.36, KL Divergence = 1343.57, Reconstruction Loss = 469.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.82 mins\n",
      "Epoch: 2 / 10, Batch: 9 (320 / 12512), Elapsed time: 14.82 mins\n",
      "Enc Loss = 179.17, KL Divergence = 1301.81, Reconstruction Loss = 453.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.84 mins\n",
      "Epoch: 2 / 10, Batch: 10 (352 / 12512), Elapsed time: 14.84 mins\n",
      "Enc Loss = 186.89, KL Divergence = 1415.82, Reconstruction Loss = 467.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.86 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 10, Batch: 11 (384 / 12512), Elapsed time: 14.86 mins\n",
      "Enc Loss = 200.39, KL Divergence = 1323.89, Reconstruction Loss = 521.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.88 mins\n",
      "Epoch: 2 / 10, Batch: 12 (416 / 12512), Elapsed time: 14.88 mins\n",
      "Enc Loss = 195.24, KL Divergence = 1431.11, Reconstruction Loss = 493.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.89 mins\n",
      "Epoch: 2 / 10, Batch: 13 (448 / 12512), Elapsed time: 14.90 mins\n",
      "Enc Loss = 219.44, KL Divergence = 1573.66, Reconstruction Loss = 557.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.91 mins\n",
      "Epoch: 2 / 10, Batch: 14 (480 / 12512), Elapsed time: 14.91 mins\n",
      "Enc Loss = 201.53, KL Divergence = 1482.30, Reconstruction Loss = 508.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.93 mins\n",
      "Epoch: 2 / 10, Batch: 15 (512 / 12512), Elapsed time: 14.93 mins\n",
      "Enc Loss = 176.73, KL Divergence = 1361.56, Reconstruction Loss = 439.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.95 mins\n",
      "Epoch: 2 / 10, Batch: 16 (544 / 12512), Elapsed time: 14.95 mins\n",
      "Enc Loss = 190.76, KL Divergence = 1405.55, Reconstruction Loss = 481.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.97 mins\n",
      "Epoch: 2 / 10, Batch: 17 (576 / 12512), Elapsed time: 14.97 mins\n",
      "Enc Loss = 188.84, KL Divergence = 1360.18, Reconstruction Loss = 479.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 14.99 mins\n",
      "Epoch: 2 / 10, Batch: 18 (608 / 12512), Elapsed time: 14.99 mins\n",
      "Enc Loss = 179.87, KL Divergence = 1318.85, Reconstruction Loss = 454.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.01 mins\n",
      "Epoch: 2 / 10, Batch: 19 (640 / 12512), Elapsed time: 15.01 mins\n",
      "Enc Loss = 200.44, KL Divergence = 1422.45, Reconstruction Loss = 511.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.03 mins\n",
      "Epoch: 2 / 10, Batch: 20 (672 / 12512), Elapsed time: 15.03 mins\n",
      "Enc Loss = 186.02, KL Divergence = 1172.50, Reconstruction Loss = 489.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.04 mins\n",
      "Epoch: 2 / 10, Batch: 21 (704 / 12512), Elapsed time: 15.04 mins\n",
      "Enc Loss = 186.40, KL Divergence = 1133.31, Reconstruction Loss = 494.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.06 mins\n",
      "Epoch: 2 / 10, Batch: 22 (736 / 12512), Elapsed time: 15.06 mins\n",
      "Enc Loss = 213.79, KL Divergence = 1321.34, Reconstruction Loss = 565.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.08 mins\n",
      "Epoch: 2 / 10, Batch: 23 (768 / 12512), Elapsed time: 15.08 mins\n",
      "Enc Loss = 224.55, KL Divergence = 1163.02, Reconstruction Loss = 616.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.10 mins\n",
      "Epoch: 2 / 10, Batch: 24 (800 / 12512), Elapsed time: 15.10 mins\n",
      "Enc Loss = 198.71, KL Divergence = 1169.56, Reconstruction Loss = 531.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.12 mins\n",
      "Epoch: 2 / 10, Batch: 25 (832 / 12512), Elapsed time: 15.12 mins\n",
      "Enc Loss = 213.38, KL Divergence = 1437.07, Reconstruction Loss = 552.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.14 mins\n",
      "Epoch: 2 / 10, Batch: 26 (864 / 12512), Elapsed time: 15.14 mins\n",
      "Enc Loss = 188.28, KL Divergence = 1266.54, Reconstruction Loss = 487.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.16 mins\n",
      "Epoch: 2 / 10, Batch: 27 (896 / 12512), Elapsed time: 15.16 mins\n",
      "Enc Loss = 174.64, KL Divergence = 1214.10, Reconstruction Loss = 447.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.17 mins\n",
      "Epoch: 2 / 10, Batch: 28 (928 / 12512), Elapsed time: 15.17 mins\n",
      "Enc Loss = 175.62, KL Divergence = 1317.21, Reconstruction Loss = 440.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.19 mins\n",
      "Epoch: 2 / 10, Batch: 29 (960 / 12512), Elapsed time: 15.19 mins\n",
      "Enc Loss = 193.49, KL Divergence = 1314.21, Reconstruction Loss = 499.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.21 mins\n",
      "Epoch: 2 / 10, Batch: 30 (992 / 12512), Elapsed time: 15.21 mins\n",
      "Enc Loss = 190.31, KL Divergence = 1456.89, Reconstruction Loss = 474.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.23 mins\n",
      "Epoch: 2 / 10, Batch: 31 (1024 / 12512), Elapsed time: 15.23 mins\n",
      "Enc Loss = 188.12, KL Divergence = 1360.64, Reconstruction Loss = 477.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.25 mins\n",
      "Epoch: 2 / 10, Batch: 32 (1056 / 12512), Elapsed time: 15.25 mins\n",
      "Enc Loss = 181.63, KL Divergence = 1400.87, Reconstruction Loss = 451.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.27 mins\n",
      "Epoch: 2 / 10, Batch: 33 (1088 / 12512), Elapsed time: 15.27 mins\n",
      "Enc Loss = 188.49, KL Divergence = 1426.65, Reconstruction Loss = 471.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.29 mins\n",
      "Epoch: 2 / 10, Batch: 34 (1120 / 12512), Elapsed time: 15.29 mins\n",
      "Enc Loss = 185.00, KL Divergence = 1259.59, Reconstruction Loss = 477.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.31 mins\n",
      "Epoch: 2 / 10, Batch: 35 (1152 / 12512), Elapsed time: 15.31 mins\n",
      "Enc Loss = 188.58, KL Divergence = 1337.66, Reconstruction Loss = 480.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.33 mins\n",
      "Epoch: 2 / 10, Batch: 36 (1184 / 12512), Elapsed time: 15.33 mins\n",
      "Enc Loss = 174.29, KL Divergence = 1262.37, Reconstruction Loss = 441.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.35 mins\n",
      "Epoch: 2 / 10, Batch: 37 (1216 / 12512), Elapsed time: 15.35 mins\n",
      "Enc Loss = 188.00, KL Divergence = 1220.05, Reconstruction Loss = 491.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.36 mins\n",
      "Epoch: 2 / 10, Batch: 38 (1248 / 12512), Elapsed time: 15.36 mins\n",
      "Enc Loss = 190.77, KL Divergence = 1194.61, Reconstruction Loss = 502.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.38 mins\n",
      "Epoch: 2 / 10, Batch: 39 (1280 / 12512), Elapsed time: 15.38 mins\n",
      "Enc Loss = 176.63, KL Divergence = 1096.63, Reconstruction Loss = 466.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.40 mins\n",
      "Epoch: 2 / 10, Batch: 40 (1312 / 12512), Elapsed time: 15.40 mins\n",
      "Enc Loss = 171.12, KL Divergence = 1185.23, Reconstruction Loss = 439.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.42 mins\n",
      "Epoch: 2 / 10, Batch: 41 (1344 / 12512), Elapsed time: 15.42 mins\n",
      "Enc Loss = 183.43, KL Divergence = 1228.94, Reconstruction Loss = 475.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.44 mins\n",
      "Epoch: 2 / 10, Batch: 42 (1376 / 12512), Elapsed time: 15.44 mins\n",
      "Enc Loss = 180.23, KL Divergence = 1177.91, Reconstruction Loss = 469.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.46 mins\n",
      "Epoch: 2 / 10, Batch: 43 (1408 / 12512), Elapsed time: 15.46 mins\n",
      "Enc Loss = 177.27, KL Divergence = 1274.24, Reconstruction Loss = 450.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.48 mins\n",
      "Epoch: 2 / 10, Batch: 44 (1440 / 12512), Elapsed time: 15.48 mins\n",
      "Enc Loss = 178.75, KL Divergence = 1259.15, Reconstruction Loss = 456.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.50 mins\n",
      "Epoch: 2 / 10, Batch: 45 (1472 / 12512), Elapsed time: 15.50 mins\n",
      "Enc Loss = 177.25, KL Divergence = 1209.13, Reconstruction Loss = 456.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.51 mins\n",
      "Epoch: 2 / 10, Batch: 46 (1504 / 12512), Elapsed time: 15.52 mins\n",
      "Enc Loss = 197.74, KL Divergence = 1332.36, Reconstruction Loss = 511.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.53 mins\n",
      "Epoch: 2 / 10, Batch: 47 (1536 / 12512), Elapsed time: 15.53 mins\n",
      "Enc Loss = 184.32, KL Divergence = 1260.85, Reconstruction Loss = 474.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.55 mins\n",
      "Epoch: 2 / 10, Batch: 48 (1568 / 12512), Elapsed time: 15.55 mins\n",
      "Enc Loss = 172.76, KL Divergence = 1179.51, Reconstruction Loss = 445.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.57 mins\n",
      "Epoch: 2 / 10, Batch: 49 (1600 / 12512), Elapsed time: 15.57 mins\n",
      "Enc Loss = 188.22, KL Divergence = 1451.45, Reconstruction Loss = 468.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.59 mins\n",
      "Epoch: 2 / 10, Batch: 50 (1632 / 12512), Elapsed time: 15.59 mins\n",
      "Enc Loss = 186.52, KL Divergence = 1296.24, Reconstruction Loss = 478.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.61 mins\n",
      "Epoch: 2 / 10, Batch: 51 (1664 / 12512), Elapsed time: 15.61 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 178.69, KL Divergence = 1275.90, Reconstruction Loss = 454.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.63 mins\n",
      "Epoch: 2 / 10, Batch: 52 (1696 / 12512), Elapsed time: 15.63 mins\n",
      "Enc Loss = 189.38, KL Divergence = 1195.40, Reconstruction Loss = 498.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.64 mins\n",
      "Epoch: 2 / 10, Batch: 53 (1728 / 12512), Elapsed time: 15.64 mins\n",
      "Enc Loss = 176.41, KL Divergence = 1269.68, Reconstruction Loss = 448.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.66 mins\n",
      "Epoch: 2 / 10, Batch: 54 (1760 / 12512), Elapsed time: 15.66 mins\n",
      "Enc Loss = 172.71, KL Divergence = 1214.70, Reconstruction Loss = 441.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.68 mins\n",
      "Epoch: 2 / 10, Batch: 55 (1792 / 12512), Elapsed time: 15.68 mins\n",
      "Enc Loss = 177.92, KL Divergence = 1297.70, Reconstruction Loss = 450.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.70 mins\n",
      "Epoch: 2 / 10, Batch: 56 (1824 / 12512), Elapsed time: 15.70 mins\n",
      "Enc Loss = 181.20, KL Divergence = 1295.02, Reconstruction Loss = 461.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.72 mins\n",
      "Epoch: 2 / 10, Batch: 57 (1856 / 12512), Elapsed time: 15.72 mins\n",
      "Enc Loss = 185.10, KL Divergence = 1373.92, Reconstruction Loss = 465.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.74 mins\n",
      "Epoch: 2 / 10, Batch: 58 (1888 / 12512), Elapsed time: 15.74 mins\n",
      "Enc Loss = 184.46, KL Divergence = 1438.07, Reconstruction Loss = 457.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.76 mins\n",
      "Epoch: 2 / 10, Batch: 59 (1920 / 12512), Elapsed time: 15.76 mins\n",
      "Enc Loss = 180.75, KL Divergence = 1297.21, Reconstruction Loss = 459.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.78 mins\n",
      "Epoch: 2 / 10, Batch: 60 (1952 / 12512), Elapsed time: 15.78 mins\n",
      "Enc Loss = 187.33, KL Divergence = 1379.49, Reconstruction Loss = 472.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.80 mins\n",
      "Epoch: 2 / 10, Batch: 61 (1984 / 12512), Elapsed time: 15.80 mins\n",
      "Enc Loss = 164.16, KL Divergence = 1214.08, Reconstruction Loss = 413.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.81 mins\n",
      "Epoch: 2 / 10, Batch: 62 (2016 / 12512), Elapsed time: 15.82 mins\n",
      "Enc Loss = 179.20, KL Divergence = 1283.70, Reconstruction Loss = 455.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.83 mins\n",
      "Epoch: 2 / 10, Batch: 63 (2048 / 12512), Elapsed time: 15.83 mins\n",
      "Enc Loss = 174.29, KL Divergence = 1227.57, Reconstruction Loss = 445.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.85 mins\n",
      "Epoch: 2 / 10, Batch: 64 (2080 / 12512), Elapsed time: 15.85 mins\n",
      "Enc Loss = 197.71, KL Divergence = 1302.12, Reconstruction Loss = 514.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.87 mins\n",
      "Epoch: 2 / 10, Batch: 65 (2112 / 12512), Elapsed time: 15.87 mins\n",
      "Enc Loss = 172.40, KL Divergence = 1309.22, Reconstruction Loss = 430.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.89 mins\n",
      "Epoch: 2 / 10, Batch: 66 (2144 / 12512), Elapsed time: 15.89 mins\n",
      "Enc Loss = 180.94, KL Divergence = 1291.17, Reconstruction Loss = 460.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.91 mins\n",
      "Epoch: 2 / 10, Batch: 67 (2176 / 12512), Elapsed time: 15.91 mins\n",
      "Enc Loss = 182.23, KL Divergence = 1188.60, Reconstruction Loss = 475.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.93 mins\n",
      "Epoch: 2 / 10, Batch: 68 (2208 / 12512), Elapsed time: 15.93 mins\n",
      "Enc Loss = 198.82, KL Divergence = 1255.82, Reconstruction Loss = 522.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.94 mins\n",
      "Epoch: 2 / 10, Batch: 69 (2240 / 12512), Elapsed time: 15.94 mins\n",
      "Enc Loss = 179.89, KL Divergence = 1229.17, Reconstruction Loss = 463.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.96 mins\n",
      "Epoch: 2 / 10, Batch: 70 (2272 / 12512), Elapsed time: 15.96 mins\n",
      "Enc Loss = 176.58, KL Divergence = 1245.16, Reconstruction Loss = 451.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 15.98 mins\n",
      "Epoch: 2 / 10, Batch: 71 (2304 / 12512), Elapsed time: 15.98 mins\n",
      "Enc Loss = 184.88, KL Divergence = 1341.90, Reconstruction Loss = 468.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.00 mins\n",
      "Epoch: 2 / 10, Batch: 72 (2336 / 12512), Elapsed time: 16.00 mins\n",
      "Enc Loss = 178.26, KL Divergence = 1296.13, Reconstruction Loss = 451.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.02 mins\n",
      "Epoch: 2 / 10, Batch: 73 (2368 / 12512), Elapsed time: 16.02 mins\n",
      "Enc Loss = 172.62, KL Divergence = 1280.54, Reconstruction Loss = 434.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.04 mins\n",
      "Epoch: 2 / 10, Batch: 74 (2400 / 12512), Elapsed time: 16.04 mins\n",
      "Enc Loss = 209.62, KL Divergence = 1347.91, Reconstruction Loss = 548.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.06 mins\n",
      "Epoch: 2 / 10, Batch: 75 (2432 / 12512), Elapsed time: 16.06 mins\n",
      "Enc Loss = 186.49, KL Divergence = 1327.18, Reconstruction Loss = 475.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.08 mins\n",
      "Epoch: 2 / 10, Batch: 76 (2464 / 12512), Elapsed time: 16.08 mins\n",
      "Enc Loss = 186.87, KL Divergence = 1349.81, Reconstruction Loss = 474.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.10 mins\n",
      "Epoch: 2 / 10, Batch: 77 (2496 / 12512), Elapsed time: 16.10 mins\n",
      "Enc Loss = 177.68, KL Divergence = 1462.82, Reconstruction Loss = 432.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.11 mins\n",
      "Epoch: 2 / 10, Batch: 78 (2528 / 12512), Elapsed time: 16.12 mins\n",
      "Enc Loss = 195.08, KL Divergence = 1457.44, Reconstruction Loss = 490.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.14 mins\n",
      "Epoch: 2 / 10, Batch: 79 (2560 / 12512), Elapsed time: 16.14 mins\n",
      "Enc Loss = 178.11, KL Divergence = 1334.97, Reconstruction Loss = 446.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.15 mins\n",
      "Epoch: 2 / 10, Batch: 80 (2592 / 12512), Elapsed time: 16.15 mins\n",
      "Enc Loss = 166.63, KL Divergence = 1361.73, Reconstruction Loss = 406.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.17 mins\n",
      "Epoch: 2 / 10, Batch: 81 (2624 / 12512), Elapsed time: 16.17 mins\n",
      "Enc Loss = 171.40, KL Divergence = 1268.49, Reconstruction Loss = 431.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.19 mins\n",
      "Epoch: 2 / 10, Batch: 82 (2656 / 12512), Elapsed time: 16.19 mins\n",
      "Enc Loss = 198.74, KL Divergence = 1299.63, Reconstruction Loss = 518.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.21 mins\n",
      "Epoch: 2 / 10, Batch: 83 (2688 / 12512), Elapsed time: 16.21 mins\n",
      "Enc Loss = 178.69, KL Divergence = 1348.48, Reconstruction Loss = 447.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.23 mins\n",
      "Epoch: 2 / 10, Batch: 84 (2720 / 12512), Elapsed time: 16.23 mins\n",
      "Enc Loss = 191.51, KL Divergence = 1342.34, Reconstruction Loss = 490.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.25 mins\n",
      "Epoch: 2 / 10, Batch: 85 (2752 / 12512), Elapsed time: 16.25 mins\n",
      "Enc Loss = 186.64, KL Divergence = 1356.22, Reconstruction Loss = 472.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.26 mins\n",
      "Epoch: 2 / 10, Batch: 86 (2784 / 12512), Elapsed time: 16.27 mins\n",
      "Enc Loss = 184.81, KL Divergence = 1342.54, Reconstruction Loss = 468.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.28 mins\n",
      "Epoch: 2 / 10, Batch: 87 (2816 / 12512), Elapsed time: 16.28 mins\n",
      "Enc Loss = 183.29, KL Divergence = 1253.75, Reconstruction Loss = 472.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.30 mins\n",
      "Epoch: 2 / 10, Batch: 88 (2848 / 12512), Elapsed time: 16.30 mins\n",
      "Enc Loss = 191.64, KL Divergence = 1225.32, Reconstruction Loss = 502.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.32 mins\n",
      "Epoch: 2 / 10, Batch: 89 (2880 / 12512), Elapsed time: 16.32 mins\n",
      "Enc Loss = 185.26, KL Divergence = 1296.10, Reconstruction Loss = 474.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.34 mins\n",
      "Epoch: 2 / 10, Batch: 90 (2912 / 12512), Elapsed time: 16.34 mins\n",
      "Enc Loss = 176.40, KL Divergence = 1329.03, Reconstruction Loss = 441.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.36 mins\n",
      "Epoch: 2 / 10, Batch: 91 (2944 / 12512), Elapsed time: 16.36 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 200.36, KL Divergence = 1336.50, Reconstruction Loss = 519.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.38 mins\n",
      "Epoch: 2 / 10, Batch: 92 (2976 / 12512), Elapsed time: 16.38 mins\n",
      "Enc Loss = 190.49, KL Divergence = 1422.00, Reconstruction Loss = 478.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.40 mins\n",
      "Epoch: 2 / 10, Batch: 93 (3008 / 12512), Elapsed time: 16.40 mins\n",
      "Enc Loss = 169.49, KL Divergence = 1254.18, Reconstruction Loss = 426.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.41 mins\n",
      "Epoch: 2 / 10, Batch: 94 (3040 / 12512), Elapsed time: 16.41 mins\n",
      "Enc Loss = 175.81, KL Divergence = 1344.62, Reconstruction Loss = 438.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.43 mins\n",
      "Epoch: 2 / 10, Batch: 95 (3072 / 12512), Elapsed time: 16.43 mins\n",
      "Enc Loss = 177.25, KL Divergence = 1300.46, Reconstruction Loss = 447.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.45 mins\n",
      "Epoch: 2 / 10, Batch: 96 (3104 / 12512), Elapsed time: 16.45 mins\n",
      "Enc Loss = 196.04, KL Divergence = 1401.83, Reconstruction Loss = 498.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.47 mins\n",
      "Epoch: 2 / 10, Batch: 97 (3136 / 12512), Elapsed time: 16.47 mins\n",
      "Enc Loss = 184.76, KL Divergence = 1393.76, Reconstruction Loss = 462.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.49 mins\n",
      "Epoch: 2 / 10, Batch: 98 (3168 / 12512), Elapsed time: 16.49 mins\n",
      "Enc Loss = 194.44, KL Divergence = 1443.30, Reconstruction Loss = 489.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.51 mins\n",
      "Epoch: 2 / 10, Batch: 99 (3200 / 12512), Elapsed time: 16.51 mins\n",
      "Enc Loss = 172.02, KL Divergence = 1349.10, Reconstruction Loss = 425.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.53 mins\n",
      "Epoch: 2 / 10, Batch: 100 (3232 / 12512), Elapsed time: 16.53 mins\n",
      "Enc Loss = 171.63, KL Divergence = 1275.30, Reconstruction Loss = 431.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.54 mins\n",
      "Epoch: 2 / 10, Batch: 101 (3264 / 12512), Elapsed time: 16.54 mins\n",
      "Enc Loss = 180.68, KL Divergence = 1205.92, Reconstruction Loss = 468.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.56 mins\n",
      "Epoch: 2 / 10, Batch: 102 (3296 / 12512), Elapsed time: 16.56 mins\n",
      "Enc Loss = 178.27, KL Divergence = 1212.47, Reconstruction Loss = 460.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.58 mins\n",
      "Epoch: 2 / 10, Batch: 103 (3328 / 12512), Elapsed time: 16.58 mins\n",
      "Enc Loss = 184.54, KL Divergence = 1193.37, Reconstruction Loss = 482.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.60 mins\n",
      "Epoch: 2 / 10, Batch: 104 (3360 / 12512), Elapsed time: 16.60 mins\n",
      "Enc Loss = 179.59, KL Divergence = 1232.84, Reconstruction Loss = 462.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.62 mins\n",
      "Epoch: 2 / 10, Batch: 105 (3392 / 12512), Elapsed time: 16.62 mins\n",
      "Enc Loss = 187.11, KL Divergence = 1188.77, Reconstruction Loss = 491.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.64 mins\n",
      "Epoch: 2 / 10, Batch: 106 (3424 / 12512), Elapsed time: 16.64 mins\n",
      "Enc Loss = 182.40, KL Divergence = 1324.81, Reconstruction Loss = 462.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.66 mins\n",
      "Epoch: 2 / 10, Batch: 107 (3456 / 12512), Elapsed time: 16.66 mins\n",
      "Enc Loss = 171.05, KL Divergence = 1187.56, Reconstruction Loss = 438.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.68 mins\n",
      "Epoch: 2 / 10, Batch: 108 (3488 / 12512), Elapsed time: 16.68 mins\n",
      "Enc Loss = 179.92, KL Divergence = 1229.44, Reconstruction Loss = 463.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.70 mins\n",
      "Epoch: 2 / 10, Batch: 109 (3520 / 12512), Elapsed time: 16.70 mins\n",
      "Enc Loss = 187.85, KL Divergence = 1298.51, Reconstruction Loss = 482.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.71 mins\n",
      "Epoch: 2 / 10, Batch: 110 (3552 / 12512), Elapsed time: 16.72 mins\n",
      "Enc Loss = 183.72, KL Divergence = 1301.41, Reconstruction Loss = 468.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.73 mins\n",
      "Epoch: 2 / 10, Batch: 111 (3584 / 12512), Elapsed time: 16.73 mins\n",
      "Enc Loss = 187.35, KL Divergence = 1303.00, Reconstruction Loss = 480.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.75 mins\n",
      "Epoch: 2 / 10, Batch: 112 (3616 / 12512), Elapsed time: 16.75 mins\n",
      "Enc Loss = 170.04, KL Divergence = 1321.39, Reconstruction Loss = 421.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.77 mins\n",
      "Epoch: 2 / 10, Batch: 113 (3648 / 12512), Elapsed time: 16.77 mins\n",
      "Enc Loss = 171.25, KL Divergence = 1292.23, Reconstruction Loss = 428.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.79 mins\n",
      "Epoch: 2 / 10, Batch: 114 (3680 / 12512), Elapsed time: 16.79 mins\n",
      "Enc Loss = 174.78, KL Divergence = 1292.22, Reconstruction Loss = 440.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.81 mins\n",
      "Epoch: 2 / 10, Batch: 115 (3712 / 12512), Elapsed time: 16.81 mins\n",
      "Enc Loss = 194.04, KL Divergence = 1373.85, Reconstruction Loss = 495.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.83 mins\n",
      "Epoch: 2 / 10, Batch: 116 (3744 / 12512), Elapsed time: 16.83 mins\n",
      "Enc Loss = 181.63, KL Divergence = 1290.14, Reconstruction Loss = 463.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.85 mins\n",
      "Epoch: 2 / 10, Batch: 117 (3776 / 12512), Elapsed time: 16.85 mins\n",
      "Enc Loss = 184.43, KL Divergence = 1278.55, Reconstruction Loss = 473.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.87 mins\n",
      "Epoch: 2 / 10, Batch: 118 (3808 / 12512), Elapsed time: 16.87 mins\n",
      "Enc Loss = 186.98, KL Divergence = 1254.33, Reconstruction Loss = 484.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.89 mins\n",
      "Epoch: 2 / 10, Batch: 119 (3840 / 12512), Elapsed time: 16.89 mins\n",
      "Enc Loss = 174.55, KL Divergence = 1236.68, Reconstruction Loss = 445.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.90 mins\n",
      "Epoch: 2 / 10, Batch: 120 (3872 / 12512), Elapsed time: 16.91 mins\n",
      "Enc Loss = 178.53, KL Divergence = 1284.91, Reconstruction Loss = 453.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.92 mins\n",
      "Epoch: 2 / 10, Batch: 121 (3904 / 12512), Elapsed time: 16.92 mins\n",
      "Enc Loss = 186.95, KL Divergence = 1354.73, Reconstruction Loss = 473.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.94 mins\n",
      "Epoch: 2 / 10, Batch: 122 (3936 / 12512), Elapsed time: 16.94 mins\n",
      "Enc Loss = 184.41, KL Divergence = 1238.27, Reconstruction Loss = 477.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.96 mins\n",
      "Epoch: 2 / 10, Batch: 123 (3968 / 12512), Elapsed time: 16.96 mins\n",
      "Enc Loss = 176.32, KL Divergence = 1323.47, Reconstruction Loss = 442.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 16.98 mins\n",
      "Epoch: 2 / 10, Batch: 124 (4000 / 12512), Elapsed time: 16.98 mins\n",
      "Enc Loss = 167.26, KL Divergence = 1185.28, Reconstruction Loss = 426.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.00 mins\n",
      "Epoch: 2 / 10, Batch: 125 (4032 / 12512), Elapsed time: 17.00 mins\n",
      "Enc Loss = 174.42, KL Divergence = 1285.31, Reconstruction Loss = 439.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.02 mins\n",
      "Epoch: 2 / 10, Batch: 126 (4064 / 12512), Elapsed time: 17.02 mins\n",
      "Enc Loss = 167.20, KL Divergence = 1186.58, Reconstruction Loss = 426.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.04 mins\n",
      "Epoch: 2 / 10, Batch: 127 (4096 / 12512), Elapsed time: 17.04 mins\n",
      "Enc Loss = 170.20, KL Divergence = 1148.95, Reconstruction Loss = 440.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.06 mins\n",
      "Epoch: 2 / 10, Batch: 128 (4128 / 12512), Elapsed time: 17.06 mins\n",
      "Enc Loss = 167.52, KL Divergence = 1068.92, Reconstruction Loss = 439.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.07 mins\n",
      "Epoch: 2 / 10, Batch: 129 (4160 / 12512), Elapsed time: 17.08 mins\n",
      "Enc Loss = 181.96, KL Divergence = 1119.49, Reconstruction Loss = 481.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.09 mins\n",
      "Epoch: 2 / 10, Batch: 130 (4192 / 12512), Elapsed time: 17.09 mins\n",
      "Enc Loss = 168.31, KL Divergence = 1129.57, Reconstruction Loss = 435.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.11 mins\n",
      "Epoch: 2 / 10, Batch: 131 (4224 / 12512), Elapsed time: 17.11 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 179.48, KL Divergence = 1161.65, Reconstruction Loss = 469.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.13 mins\n",
      "Epoch: 2 / 10, Batch: 132 (4256 / 12512), Elapsed time: 17.13 mins\n",
      "Enc Loss = 180.69, KL Divergence = 1087.05, Reconstruction Loss = 480.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.15 mins\n",
      "Epoch: 2 / 10, Batch: 133 (4288 / 12512), Elapsed time: 17.15 mins\n",
      "Enc Loss = 192.38, KL Divergence = 1184.54, Reconstruction Loss = 509.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.17 mins\n",
      "Epoch: 2 / 10, Batch: 134 (4320 / 12512), Elapsed time: 17.17 mins\n",
      "Enc Loss = 185.23, KL Divergence = 1257.56, Reconstruction Loss = 478.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.19 mins\n",
      "Epoch: 2 / 10, Batch: 135 (4352 / 12512), Elapsed time: 17.19 mins\n",
      "Enc Loss = 186.09, KL Divergence = 1398.01, Reconstruction Loss = 466.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.21 mins\n",
      "Epoch: 2 / 10, Batch: 136 (4384 / 12512), Elapsed time: 17.21 mins\n",
      "Enc Loss = 205.30, KL Divergence = 1616.67, Reconstruction Loss = 507.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.23 mins\n",
      "Epoch: 2 / 10, Batch: 137 (4416 / 12512), Elapsed time: 17.23 mins\n",
      "Enc Loss = 180.20, KL Divergence = 1444.83, Reconstruction Loss = 442.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.25 mins\n",
      "Epoch: 2 / 10, Batch: 138 (4448 / 12512), Elapsed time: 17.25 mins\n",
      "Enc Loss = 180.48, KL Divergence = 1453.25, Reconstruction Loss = 442.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.26 mins\n",
      "Epoch: 2 / 10, Batch: 139 (4480 / 12512), Elapsed time: 17.26 mins\n",
      "Enc Loss = 187.59, KL Divergence = 1675.31, Reconstruction Loss = 443.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.28 mins\n",
      "Epoch: 2 / 10, Batch: 140 (4512 / 12512), Elapsed time: 17.28 mins\n",
      "Enc Loss = 186.48, KL Divergence = 1526.96, Reconstruction Loss = 454.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.30 mins\n",
      "Epoch: 2 / 10, Batch: 141 (4544 / 12512), Elapsed time: 17.30 mins\n",
      "Enc Loss = 190.93, KL Divergence = 1543.11, Reconstruction Loss = 467.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.32 mins\n",
      "Epoch: 2 / 10, Batch: 142 (4576 / 12512), Elapsed time: 17.32 mins\n",
      "Enc Loss = 191.44, KL Divergence = 1463.38, Reconstruction Loss = 477.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.34 mins\n",
      "Epoch: 2 / 10, Batch: 143 (4608 / 12512), Elapsed time: 17.34 mins\n",
      "Enc Loss = 183.08, KL Divergence = 1376.93, Reconstruction Loss = 458.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.36 mins\n",
      "Epoch: 2 / 10, Batch: 144 (4640 / 12512), Elapsed time: 17.36 mins\n",
      "Enc Loss = 180.31, KL Divergence = 1339.15, Reconstruction Loss = 453.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.38 mins\n",
      "Epoch: 2 / 10, Batch: 145 (4672 / 12512), Elapsed time: 17.38 mins\n",
      "Enc Loss = 181.48, KL Divergence = 1283.05, Reconstruction Loss = 463.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.40 mins\n",
      "Epoch: 2 / 10, Batch: 146 (4704 / 12512), Elapsed time: 17.40 mins\n",
      "Enc Loss = 171.73, KL Divergence = 1233.08, Reconstruction Loss = 436.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.41 mins\n",
      "Epoch: 2 / 10, Batch: 147 (4736 / 12512), Elapsed time: 17.42 mins\n",
      "Enc Loss = 169.90, KL Divergence = 1212.58, Reconstruction Loss = 432.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.43 mins\n",
      "Epoch: 2 / 10, Batch: 148 (4768 / 12512), Elapsed time: 17.43 mins\n",
      "Enc Loss = 160.32, KL Divergence = 1041.83, Reconstruction Loss = 418.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.45 mins\n",
      "Epoch: 2 / 10, Batch: 149 (4800 / 12512), Elapsed time: 17.45 mins\n",
      "Enc Loss = 180.67, KL Divergence = 1118.41, Reconstruction Loss = 477.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.47 mins\n",
      "Epoch: 2 / 10, Batch: 150 (4832 / 12512), Elapsed time: 17.47 mins\n",
      "Enc Loss = 176.71, KL Divergence = 1005.22, Reconstruction Loss = 476.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.49 mins\n",
      "Epoch: 2 / 10, Batch: 151 (4864 / 12512), Elapsed time: 17.49 mins\n",
      "Enc Loss = 175.45, KL Divergence = 1023.44, Reconstruction Loss = 470.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.51 mins\n",
      "Epoch: 2 / 10, Batch: 152 (4896 / 12512), Elapsed time: 17.51 mins\n",
      "Enc Loss = 188.56, KL Divergence = 1138.71, Reconstruction Loss = 501.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.53 mins\n",
      "Epoch: 2 / 10, Batch: 153 (4928 / 12512), Elapsed time: 17.53 mins\n",
      "Enc Loss = 188.80, KL Divergence = 1138.24, Reconstruction Loss = 502.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.54 mins\n",
      "Epoch: 2 / 10, Batch: 154 (4960 / 12512), Elapsed time: 17.54 mins\n",
      "Enc Loss = 160.75, KL Divergence = 1081.90, Reconstruction Loss = 415.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.56 mins\n",
      "Epoch: 2 / 10, Batch: 155 (4992 / 12512), Elapsed time: 17.56 mins\n",
      "Enc Loss = 176.56, KL Divergence = 1247.33, Reconstruction Loss = 450.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.58 mins\n",
      "Epoch: 2 / 10, Batch: 156 (5024 / 12512), Elapsed time: 17.58 mins\n",
      "Enc Loss = 159.95, KL Divergence = 1246.96, Reconstruction Loss = 396.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.60 mins\n",
      "Epoch: 2 / 10, Batch: 157 (5056 / 12512), Elapsed time: 17.60 mins\n",
      "Enc Loss = 167.15, KL Divergence = 1264.56, Reconstruction Loss = 418.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.62 mins\n",
      "Epoch: 2 / 10, Batch: 158 (5088 / 12512), Elapsed time: 17.62 mins\n",
      "Enc Loss = 185.33, KL Divergence = 1371.26, Reconstruction Loss = 466.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.64 mins\n",
      "Epoch: 2 / 10, Batch: 159 (5120 / 12512), Elapsed time: 17.64 mins\n",
      "Enc Loss = 198.53, KL Divergence = 1408.85, Reconstruction Loss = 506.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.66 mins\n",
      "Epoch: 2 / 10, Batch: 160 (5152 / 12512), Elapsed time: 17.66 mins\n",
      "Enc Loss = 178.76, KL Divergence = 1461.27, Reconstruction Loss = 436.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.68 mins\n",
      "Epoch: 2 / 10, Batch: 161 (5184 / 12512), Elapsed time: 17.68 mins\n",
      "Enc Loss = 173.88, KL Divergence = 1531.05, Reconstruction Loss = 413.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.70 mins\n",
      "Epoch: 2 / 10, Batch: 162 (5216 / 12512), Elapsed time: 17.70 mins\n",
      "Enc Loss = 166.85, KL Divergence = 1429.79, Reconstruction Loss = 400.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.71 mins\n",
      "Epoch: 2 / 10, Batch: 163 (5248 / 12512), Elapsed time: 17.71 mins\n",
      "Enc Loss = 186.27, KL Divergence = 1631.32, Reconstruction Loss = 443.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.73 mins\n",
      "Epoch: 2 / 10, Batch: 164 (5280 / 12512), Elapsed time: 17.73 mins\n",
      "Enc Loss = 188.93, KL Divergence = 1597.87, Reconstruction Loss = 455.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.75 mins\n",
      "Epoch: 2 / 10, Batch: 165 (5312 / 12512), Elapsed time: 17.75 mins\n",
      "Enc Loss = 167.88, KL Divergence = 1352.15, Reconstruction Loss = 411.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.77 mins\n",
      "Epoch: 2 / 10, Batch: 166 (5344 / 12512), Elapsed time: 17.77 mins\n",
      "Enc Loss = 173.16, KL Divergence = 1330.97, Reconstruction Loss = 431.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.79 mins\n",
      "Epoch: 2 / 10, Batch: 167 (5376 / 12512), Elapsed time: 17.79 mins\n",
      "Enc Loss = 162.22, KL Divergence = 1135.90, Reconstruction Loss = 415.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.81 mins\n",
      "Epoch: 2 / 10, Batch: 168 (5408 / 12512), Elapsed time: 17.81 mins\n",
      "Enc Loss = 194.35, KL Divergence = 1365.82, Reconstruction Loss = 496.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.83 mins\n",
      "Epoch: 2 / 10, Batch: 169 (5440 / 12512), Elapsed time: 17.83 mins\n",
      "Enc Loss = 170.40, KL Divergence = 1126.97, Reconstruction Loss = 442.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.85 mins\n",
      "Epoch: 2 / 10, Batch: 170 (5472 / 12512), Elapsed time: 17.85 mins\n",
      "Enc Loss = 169.44, KL Divergence = 1118.45, Reconstruction Loss = 440.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.87 mins\n",
      "Epoch: 2 / 10, Batch: 171 (5504 / 12512), Elapsed time: 17.87 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 195.52, KL Divergence = 1219.80, Reconstruction Loss = 515.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.89 mins\n",
      "Epoch: 2 / 10, Batch: 172 (5536 / 12512), Elapsed time: 17.89 mins\n",
      "Enc Loss = 189.29, KL Divergence = 1269.27, Reconstruction Loss = 490.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.90 mins\n",
      "Epoch: 2 / 10, Batch: 173 (5568 / 12512), Elapsed time: 17.90 mins\n",
      "Enc Loss = 185.63, KL Divergence = 1243.05, Reconstruction Loss = 481.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.92 mins\n",
      "Epoch: 2 / 10, Batch: 174 (5600 / 12512), Elapsed time: 17.92 mins\n",
      "Enc Loss = 193.47, KL Divergence = 1249.08, Reconstruction Loss = 506.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.94 mins\n",
      "Epoch: 2 / 10, Batch: 175 (5632 / 12512), Elapsed time: 17.94 mins\n",
      "Enc Loss = 169.69, KL Divergence = 1165.45, Reconstruction Loss = 436.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.96 mins\n",
      "Epoch: 2 / 10, Batch: 176 (5664 / 12512), Elapsed time: 17.96 mins\n",
      "Enc Loss = 173.20, KL Divergence = 1299.31, Reconstruction Loss = 434.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 17.98 mins\n",
      "Epoch: 2 / 10, Batch: 177 (5696 / 12512), Elapsed time: 17.98 mins\n",
      "Enc Loss = 179.43, KL Divergence = 1252.55, Reconstruction Loss = 459.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.00 mins\n",
      "Epoch: 2 / 10, Batch: 178 (5728 / 12512), Elapsed time: 18.00 mins\n",
      "Enc Loss = 171.02, KL Divergence = 1271.48, Reconstruction Loss = 430.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.02 mins\n",
      "Epoch: 2 / 10, Batch: 179 (5760 / 12512), Elapsed time: 18.02 mins\n",
      "Enc Loss = 175.60, KL Divergence = 1221.96, Reconstruction Loss = 450.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.04 mins\n",
      "Epoch: 2 / 10, Batch: 180 (5792 / 12512), Elapsed time: 18.04 mins\n",
      "Enc Loss = 175.25, KL Divergence = 1240.82, Reconstruction Loss = 447.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.05 mins\n",
      "Epoch: 2 / 10, Batch: 181 (5824 / 12512), Elapsed time: 18.05 mins\n",
      "Enc Loss = 175.71, KL Divergence = 1232.17, Reconstruction Loss = 449.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.07 mins\n",
      "Epoch: 2 / 10, Batch: 182 (5856 / 12512), Elapsed time: 18.07 mins\n",
      "Enc Loss = 173.99, KL Divergence = 1256.28, Reconstruction Loss = 441.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.09 mins\n",
      "Epoch: 2 / 10, Batch: 183 (5888 / 12512), Elapsed time: 18.09 mins\n",
      "Enc Loss = 162.33, KL Divergence = 1132.02, Reconstruction Loss = 416.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.11 mins\n",
      "Epoch: 2 / 10, Batch: 184 (5920 / 12512), Elapsed time: 18.11 mins\n",
      "Enc Loss = 201.66, KL Divergence = 1391.36, Reconstruction Loss = 518.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.13 mins\n",
      "Epoch: 2 / 10, Batch: 185 (5952 / 12512), Elapsed time: 18.13 mins\n",
      "Enc Loss = 163.29, KL Divergence = 1177.67, Reconstruction Loss = 414.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.15 mins\n",
      "Epoch: 2 / 10, Batch: 186 (5984 / 12512), Elapsed time: 18.15 mins\n",
      "Enc Loss = 168.88, KL Divergence = 1226.65, Reconstruction Loss = 427.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.17 mins\n",
      "Epoch: 2 / 10, Batch: 187 (6016 / 12512), Elapsed time: 18.17 mins\n",
      "Enc Loss = 200.07, KL Divergence = 1382.04, Reconstruction Loss = 514.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.19 mins\n",
      "Epoch: 2 / 10, Batch: 188 (6048 / 12512), Elapsed time: 18.19 mins\n",
      "Enc Loss = 166.85, KL Divergence = 1220.18, Reconstruction Loss = 421.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.21 mins\n",
      "Epoch: 2 / 10, Batch: 189 (6080 / 12512), Elapsed time: 18.21 mins\n",
      "Enc Loss = 163.86, KL Divergence = 1236.65, Reconstruction Loss = 410.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.23 mins\n",
      "Epoch: 2 / 10, Batch: 190 (6112 / 12512), Elapsed time: 18.23 mins\n",
      "Enc Loss = 169.54, KL Divergence = 1258.57, Reconstruction Loss = 426.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.24 mins\n",
      "Epoch: 2 / 10, Batch: 191 (6144 / 12512), Elapsed time: 18.24 mins\n",
      "Enc Loss = 177.98, KL Divergence = 1309.39, Reconstruction Loss = 449.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.26 mins\n",
      "Epoch: 2 / 10, Batch: 192 (6176 / 12512), Elapsed time: 18.26 mins\n",
      "Enc Loss = 173.98, KL Divergence = 1409.30, Reconstruction Loss = 425.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.28 mins\n",
      "Epoch: 2 / 10, Batch: 193 (6208 / 12512), Elapsed time: 18.28 mins\n",
      "Enc Loss = 166.47, KL Divergence = 1370.66, Reconstruction Loss = 405.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.30 mins\n",
      "Epoch: 2 / 10, Batch: 194 (6240 / 12512), Elapsed time: 18.30 mins\n",
      "Enc Loss = 176.71, KL Divergence = 1417.48, Reconstruction Loss = 433.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.32 mins\n",
      "Epoch: 2 / 10, Batch: 195 (6272 / 12512), Elapsed time: 18.32 mins\n",
      "Enc Loss = 164.03, KL Divergence = 1231.92, Reconstruction Loss = 411.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.34 mins\n",
      "Epoch: 2 / 10, Batch: 196 (6304 / 12512), Elapsed time: 18.34 mins\n",
      "Enc Loss = 178.67, KL Divergence = 1287.62, Reconstruction Loss = 453.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.36 mins\n",
      "Epoch: 2 / 10, Batch: 197 (6336 / 12512), Elapsed time: 18.36 mins\n",
      "Enc Loss = 168.27, KL Divergence = 1202.79, Reconstruction Loss = 428.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.38 mins\n",
      "Epoch: 2 / 10, Batch: 198 (6368 / 12512), Elapsed time: 18.38 mins\n",
      "Enc Loss = 173.43, KL Divergence = 1253.78, Reconstruction Loss = 439.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.40 mins\n",
      "Epoch: 2 / 10, Batch: 199 (6400 / 12512), Elapsed time: 18.40 mins\n",
      "Enc Loss = 194.00, KL Divergence = 1343.30, Reconstruction Loss = 498.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.42 mins\n",
      "Epoch: 2 / 10, Batch: 200 (6432 / 12512), Elapsed time: 18.42 mins\n",
      "Enc Loss = 164.56, KL Divergence = 1226.69, Reconstruction Loss = 413.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.43 mins\n",
      "Epoch: 2 / 10, Batch: 201 (6464 / 12512), Elapsed time: 18.43 mins\n",
      "Enc Loss = 177.97, KL Divergence = 1263.87, Reconstruction Loss = 453.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.45 mins\n",
      "Epoch: 2 / 10, Batch: 202 (6496 / 12512), Elapsed time: 18.45 mins\n",
      "Enc Loss = 161.31, KL Divergence = 1165.50, Reconstruction Loss = 409.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.47 mins\n",
      "Epoch: 2 / 10, Batch: 203 (6528 / 12512), Elapsed time: 18.47 mins\n",
      "Enc Loss = 156.03, KL Divergence = 1145.40, Reconstruction Loss = 393.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.49 mins\n",
      "Epoch: 2 / 10, Batch: 204 (6560 / 12512), Elapsed time: 18.49 mins\n",
      "Enc Loss = 160.45, KL Divergence = 964.14, Reconstruction Loss = 427.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.51 mins\n",
      "Epoch: 2 / 10, Batch: 205 (6592 / 12512), Elapsed time: 18.51 mins\n",
      "Enc Loss = 172.05, KL Divergence = 1160.79, Reconstruction Loss = 444.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.53 mins\n",
      "Epoch: 2 / 10, Batch: 206 (6624 / 12512), Elapsed time: 18.53 mins\n",
      "Enc Loss = 178.11, KL Divergence = 1213.05, Reconstruction Loss = 459.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.55 mins\n",
      "Epoch: 2 / 10, Batch: 207 (6656 / 12512), Elapsed time: 18.55 mins\n",
      "Enc Loss = 195.06, KL Divergence = 1107.59, Reconstruction Loss = 525.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.57 mins\n",
      "Epoch: 2 / 10, Batch: 208 (6688 / 12512), Elapsed time: 18.57 mins\n",
      "Enc Loss = 168.51, KL Divergence = 1095.56, Reconstruction Loss = 439.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.58 mins\n",
      "Epoch: 2 / 10, Batch: 209 (6720 / 12512), Elapsed time: 18.58 mins\n",
      "Enc Loss = 180.58, KL Divergence = 1232.56, Reconstruction Loss = 465.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.60 mins\n",
      "Epoch: 2 / 10, Batch: 210 (6752 / 12512), Elapsed time: 18.60 mins\n",
      "Enc Loss = 165.59, KL Divergence = 1184.52, Reconstruction Loss = 421.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.62 mins\n",
      "Epoch: 2 / 10, Batch: 211 (6784 / 12512), Elapsed time: 18.62 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 166.00, KL Divergence = 1173.29, Reconstruction Loss = 423.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.64 mins\n",
      "Epoch: 2 / 10, Batch: 212 (6816 / 12512), Elapsed time: 18.64 mins\n",
      "Enc Loss = 176.58, KL Divergence = 1260.26, Reconstruction Loss = 449.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.66 mins\n",
      "Epoch: 2 / 10, Batch: 213 (6848 / 12512), Elapsed time: 18.66 mins\n",
      "Enc Loss = 177.44, KL Divergence = 1383.64, Reconstruction Loss = 439.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.68 mins\n",
      "Epoch: 2 / 10, Batch: 214 (6880 / 12512), Elapsed time: 18.68 mins\n",
      "Enc Loss = 170.38, KL Divergence = 1313.09, Reconstruction Loss = 423.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.70 mins\n",
      "Epoch: 2 / 10, Batch: 215 (6912 / 12512), Elapsed time: 18.70 mins\n",
      "Enc Loss = 169.46, KL Divergence = 1272.15, Reconstruction Loss = 425.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.72 mins\n",
      "Epoch: 2 / 10, Batch: 216 (6944 / 12512), Elapsed time: 18.72 mins\n",
      "Enc Loss = 166.19, KL Divergence = 1260.40, Reconstruction Loss = 415.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.73 mins\n",
      "Epoch: 2 / 10, Batch: 217 (6976 / 12512), Elapsed time: 18.73 mins\n",
      "Enc Loss = 172.78, KL Divergence = 1297.31, Reconstruction Loss = 433.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.75 mins\n",
      "Epoch: 2 / 10, Batch: 218 (7008 / 12512), Elapsed time: 18.75 mins\n",
      "Enc Loss = 195.43, KL Divergence = 1395.62, Reconstruction Loss = 497.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.77 mins\n",
      "Epoch: 2 / 10, Batch: 219 (7040 / 12512), Elapsed time: 18.77 mins\n",
      "Enc Loss = 164.74, KL Divergence = 1427.93, Reconstruction Loss = 393.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.79 mins\n",
      "Epoch: 2 / 10, Batch: 220 (7072 / 12512), Elapsed time: 18.79 mins\n",
      "Enc Loss = 172.22, KL Divergence = 1372.96, Reconstruction Loss = 423.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.81 mins\n",
      "Epoch: 2 / 10, Batch: 221 (7104 / 12512), Elapsed time: 18.81 mins\n",
      "Enc Loss = 174.10, KL Divergence = 1331.74, Reconstruction Loss = 434.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.83 mins\n",
      "Epoch: 2 / 10, Batch: 222 (7136 / 12512), Elapsed time: 18.83 mins\n",
      "Enc Loss = 164.04, KL Divergence = 1345.64, Reconstruction Loss = 399.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.85 mins\n",
      "Epoch: 2 / 10, Batch: 223 (7168 / 12512), Elapsed time: 18.85 mins\n",
      "Enc Loss = 167.09, KL Divergence = 1264.70, Reconstruction Loss = 418.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.86 mins\n",
      "Epoch: 2 / 10, Batch: 224 (7200 / 12512), Elapsed time: 18.86 mins\n",
      "Enc Loss = 165.31, KL Divergence = 1235.93, Reconstruction Loss = 415.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.88 mins\n",
      "Epoch: 2 / 10, Batch: 225 (7232 / 12512), Elapsed time: 18.88 mins\n",
      "Enc Loss = 180.47, KL Divergence = 1311.56, Reconstruction Loss = 457.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.90 mins\n",
      "Epoch: 2 / 10, Batch: 226 (7264 / 12512), Elapsed time: 18.90 mins\n",
      "Enc Loss = 184.50, KL Divergence = 1345.70, Reconstruction Loss = 466.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.92 mins\n",
      "Epoch: 2 / 10, Batch: 227 (7296 / 12512), Elapsed time: 18.92 mins\n",
      "Enc Loss = 152.26, KL Divergence = 1121.08, Reconstruction Loss = 384.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.94 mins\n",
      "Epoch: 2 / 10, Batch: 228 (7328 / 12512), Elapsed time: 18.94 mins\n",
      "Enc Loss = 170.01, KL Divergence = 1213.27, Reconstruction Loss = 432.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.96 mins\n",
      "Epoch: 2 / 10, Batch: 229 (7360 / 12512), Elapsed time: 18.96 mins\n",
      "Enc Loss = 164.08, KL Divergence = 1194.24, Reconstruction Loss = 415.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 18.98 mins\n",
      "Epoch: 2 / 10, Batch: 230 (7392 / 12512), Elapsed time: 18.98 mins\n",
      "Enc Loss = 191.27, KL Divergence = 1298.32, Reconstruction Loss = 493.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.00 mins\n",
      "Epoch: 2 / 10, Batch: 231 (7424 / 12512), Elapsed time: 19.00 mins\n",
      "Enc Loss = 179.58, KL Divergence = 1163.83, Reconstruction Loss = 469.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.01 mins\n",
      "Epoch: 2 / 10, Batch: 232 (7456 / 12512), Elapsed time: 19.01 mins\n",
      "Enc Loss = 167.08, KL Divergence = 1116.11, Reconstruction Loss = 433.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.03 mins\n",
      "Epoch: 2 / 10, Batch: 233 (7488 / 12512), Elapsed time: 19.03 mins\n",
      "Enc Loss = 178.45, KL Divergence = 1112.54, Reconstruction Loss = 470.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.05 mins\n",
      "Epoch: 2 / 10, Batch: 234 (7520 / 12512), Elapsed time: 19.05 mins\n",
      "Enc Loss = 158.11, KL Divergence = 1155.73, Reconstruction Loss = 399.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.07 mins\n",
      "Epoch: 2 / 10, Batch: 235 (7552 / 12512), Elapsed time: 19.07 mins\n",
      "Enc Loss = 163.24, KL Divergence = 1191.92, Reconstruction Loss = 412.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.09 mins\n",
      "Epoch: 2 / 10, Batch: 236 (7584 / 12512), Elapsed time: 19.09 mins\n",
      "Enc Loss = 182.97, KL Divergence = 1337.21, Reconstruction Loss = 462.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.11 mins\n",
      "Epoch: 2 / 10, Batch: 237 (7616 / 12512), Elapsed time: 19.11 mins\n",
      "Enc Loss = 161.04, KL Divergence = 1205.17, Reconstruction Loss = 404.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.13 mins\n",
      "Epoch: 2 / 10, Batch: 238 (7648 / 12512), Elapsed time: 19.13 mins\n",
      "Enc Loss = 175.14, KL Divergence = 1248.86, Reconstruction Loss = 446.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.15 mins\n",
      "Epoch: 2 / 10, Batch: 239 (7680 / 12512), Elapsed time: 19.15 mins\n",
      "Enc Loss = 177.04, KL Divergence = 1358.73, Reconstruction Loss = 441.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.17 mins\n",
      "Epoch: 2 / 10, Batch: 240 (7712 / 12512), Elapsed time: 19.17 mins\n",
      "Enc Loss = 173.48, KL Divergence = 1449.20, Reconstruction Loss = 420.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.19 mins\n",
      "Epoch: 2 / 10, Batch: 241 (7744 / 12512), Elapsed time: 19.19 mins\n",
      "Enc Loss = 173.33, KL Divergence = 1267.60, Reconstruction Loss = 438.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.20 mins\n",
      "Epoch: 2 / 10, Batch: 242 (7776 / 12512), Elapsed time: 19.20 mins\n",
      "Enc Loss = 192.87, KL Divergence = 1376.02, Reconstruction Loss = 491.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.22 mins\n",
      "Epoch: 2 / 10, Batch: 243 (7808 / 12512), Elapsed time: 19.22 mins\n",
      "Enc Loss = 182.16, KL Divergence = 1500.43, Reconstruction Loss = 443.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.24 mins\n",
      "Epoch: 2 / 10, Batch: 244 (7840 / 12512), Elapsed time: 19.24 mins\n",
      "Enc Loss = 161.81, KL Divergence = 1246.72, Reconstruction Loss = 402.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.26 mins\n",
      "Epoch: 2 / 10, Batch: 245 (7872 / 12512), Elapsed time: 19.26 mins\n",
      "Enc Loss = 164.92, KL Divergence = 1238.45, Reconstruction Loss = 413.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.28 mins\n",
      "Epoch: 2 / 10, Batch: 246 (7904 / 12512), Elapsed time: 19.28 mins\n",
      "Enc Loss = 170.76, KL Divergence = 1293.61, Reconstruction Loss = 427.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.30 mins\n",
      "Epoch: 2 / 10, Batch: 247 (7936 / 12512), Elapsed time: 19.30 mins\n",
      "Enc Loss = 154.66, KL Divergence = 1111.56, Reconstruction Loss = 392.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.32 mins\n",
      "Epoch: 2 / 10, Batch: 248 (7968 / 12512), Elapsed time: 19.32 mins\n",
      "Enc Loss = 177.65, KL Divergence = 1239.85, Reconstruction Loss = 455.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.34 mins\n",
      "Epoch: 2 / 10, Batch: 249 (8000 / 12512), Elapsed time: 19.34 mins\n",
      "Enc Loss = 166.52, KL Divergence = 1280.81, Reconstruction Loss = 414.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.35 mins\n",
      "Epoch: 2 / 10, Batch: 250 (8032 / 12512), Elapsed time: 19.35 mins\n",
      "Enc Loss = 169.97, KL Divergence = 1184.82, Reconstruction Loss = 435.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.37 mins\n",
      "Epoch: 2 / 10, Batch: 251 (8064 / 12512), Elapsed time: 19.37 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 159.95, KL Divergence = 1128.83, Reconstruction Loss = 408.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.39 mins\n",
      "Epoch: 2 / 10, Batch: 252 (8096 / 12512), Elapsed time: 19.39 mins\n",
      "Enc Loss = 162.32, KL Divergence = 1123.73, Reconstruction Loss = 416.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.41 mins\n",
      "Epoch: 2 / 10, Batch: 253 (8128 / 12512), Elapsed time: 19.41 mins\n",
      "Enc Loss = 167.30, KL Divergence = 1111.86, Reconstruction Loss = 434.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.43 mins\n",
      "Epoch: 2 / 10, Batch: 254 (8160 / 12512), Elapsed time: 19.43 mins\n",
      "Enc Loss = 162.62, KL Divergence = 1044.62, Reconstruction Loss = 425.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.45 mins\n",
      "Epoch: 2 / 10, Batch: 255 (8192 / 12512), Elapsed time: 19.45 mins\n",
      "Enc Loss = 177.77, KL Divergence = 1159.22, Reconstruction Loss = 463.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.47 mins\n",
      "Epoch: 2 / 10, Batch: 256 (8224 / 12512), Elapsed time: 19.47 mins\n",
      "Enc Loss = 187.72, KL Divergence = 1250.44, Reconstruction Loss = 487.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.49 mins\n",
      "Epoch: 2 / 10, Batch: 257 (8256 / 12512), Elapsed time: 19.49 mins\n",
      "Enc Loss = 180.36, KL Divergence = 1259.54, Reconstruction Loss = 462.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.50 mins\n",
      "Epoch: 2 / 10, Batch: 258 (8288 / 12512), Elapsed time: 19.50 mins\n",
      "Enc Loss = 167.53, KL Divergence = 1254.23, Reconstruction Loss = 420.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.52 mins\n",
      "Epoch: 2 / 10, Batch: 259 (8320 / 12512), Elapsed time: 19.52 mins\n",
      "Enc Loss = 164.97, KL Divergence = 1234.79, Reconstruction Loss = 414.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.54 mins\n",
      "Epoch: 2 / 10, Batch: 260 (8352 / 12512), Elapsed time: 19.54 mins\n",
      "Enc Loss = 187.55, KL Divergence = 1549.34, Reconstruction Loss = 455.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.56 mins\n",
      "Epoch: 2 / 10, Batch: 261 (8384 / 12512), Elapsed time: 19.56 mins\n",
      "Enc Loss = 172.07, KL Divergence = 1360.86, Reconstruction Loss = 424.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.58 mins\n",
      "Epoch: 2 / 10, Batch: 262 (8416 / 12512), Elapsed time: 19.58 mins\n",
      "Enc Loss = 196.62, KL Divergence = 1578.52, Reconstruction Loss = 482.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.60 mins\n",
      "Epoch: 2 / 10, Batch: 263 (8448 / 12512), Elapsed time: 19.60 mins\n",
      "Enc Loss = 164.00, KL Divergence = 1413.91, Reconstruction Loss = 392.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.62 mins\n",
      "Epoch: 2 / 10, Batch: 264 (8480 / 12512), Elapsed time: 19.62 mins\n",
      "Enc Loss = 187.34, KL Divergence = 1459.29, Reconstruction Loss = 464.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.64 mins\n",
      "Epoch: 2 / 10, Batch: 265 (8512 / 12512), Elapsed time: 19.64 mins\n",
      "Enc Loss = 172.00, KL Divergence = 1409.06, Reconstruction Loss = 419.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.66 mins\n",
      "Epoch: 2 / 10, Batch: 266 (8544 / 12512), Elapsed time: 19.66 mins\n",
      "Enc Loss = 166.06, KL Divergence = 1309.21, Reconstruction Loss = 410.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.67 mins\n",
      "Epoch: 2 / 10, Batch: 267 (8576 / 12512), Elapsed time: 19.68 mins\n",
      "Enc Loss = 167.86, KL Divergence = 1332.07, Reconstruction Loss = 413.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.69 mins\n",
      "Epoch: 2 / 10, Batch: 268 (8608 / 12512), Elapsed time: 19.69 mins\n",
      "Enc Loss = 162.33, KL Divergence = 1336.53, Reconstruction Loss = 395.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.71 mins\n",
      "Epoch: 2 / 10, Batch: 269 (8640 / 12512), Elapsed time: 19.71 mins\n",
      "Enc Loss = 177.80, KL Divergence = 1227.88, Reconstruction Loss = 456.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.73 mins\n",
      "Epoch: 2 / 10, Batch: 270 (8672 / 12512), Elapsed time: 19.73 mins\n",
      "Enc Loss = 170.36, KL Divergence = 1265.82, Reconstruction Loss = 428.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.75 mins\n",
      "Epoch: 2 / 10, Batch: 271 (8704 / 12512), Elapsed time: 19.75 mins\n",
      "Enc Loss = 170.64, KL Divergence = 1157.02, Reconstruction Loss = 440.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.77 mins\n",
      "Epoch: 2 / 10, Batch: 272 (8736 / 12512), Elapsed time: 19.77 mins\n",
      "Enc Loss = 190.08, KL Divergence = 1235.72, Reconstruction Loss = 496.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.79 mins\n",
      "Epoch: 2 / 10, Batch: 273 (8768 / 12512), Elapsed time: 19.79 mins\n",
      "Enc Loss = 186.68, KL Divergence = 1226.91, Reconstruction Loss = 486.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.81 mins\n",
      "Epoch: 2 / 10, Batch: 274 (8800 / 12512), Elapsed time: 19.81 mins\n",
      "Enc Loss = 169.28, KL Divergence = 1131.11, Reconstruction Loss = 438.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.82 mins\n",
      "Epoch: 2 / 10, Batch: 275 (8832 / 12512), Elapsed time: 19.83 mins\n",
      "Enc Loss = 160.46, KL Divergence = 1201.57, Reconstruction Loss = 402.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.84 mins\n",
      "Epoch: 2 / 10, Batch: 276 (8864 / 12512), Elapsed time: 19.84 mins\n",
      "Enc Loss = 175.20, KL Divergence = 1335.89, Reconstruction Loss = 437.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.86 mins\n",
      "Epoch: 2 / 10, Batch: 277 (8896 / 12512), Elapsed time: 19.86 mins\n",
      "Enc Loss = 167.17, KL Divergence = 1250.40, Reconstruction Loss = 419.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.88 mins\n",
      "Epoch: 2 / 10, Batch: 278 (8928 / 12512), Elapsed time: 19.88 mins\n",
      "Enc Loss = 172.14, KL Divergence = 1316.75, Reconstruction Loss = 429.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.90 mins\n",
      "Epoch: 2 / 10, Batch: 279 (8960 / 12512), Elapsed time: 19.90 mins\n",
      "Enc Loss = 183.97, KL Divergence = 1381.59, Reconstruction Loss = 461.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.92 mins\n",
      "Epoch: 2 / 10, Batch: 280 (8992 / 12512), Elapsed time: 19.92 mins\n",
      "Enc Loss = 193.97, KL Divergence = 1352.12, Reconstruction Loss = 497.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.94 mins\n",
      "Epoch: 2 / 10, Batch: 281 (9024 / 12512), Elapsed time: 19.94 mins\n",
      "Enc Loss = 175.54, KL Divergence = 1336.19, Reconstruction Loss = 438.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.96 mins\n",
      "Epoch: 2 / 10, Batch: 282 (9056 / 12512), Elapsed time: 19.96 mins\n",
      "Enc Loss = 171.37, KL Divergence = 1270.95, Reconstruction Loss = 431.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.98 mins\n",
      "Epoch: 2 / 10, Batch: 283 (9088 / 12512), Elapsed time: 19.98 mins\n",
      "Enc Loss = 161.87, KL Divergence = 1279.65, Reconstruction Loss = 399.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 19.99 mins\n",
      "Epoch: 2 / 10, Batch: 284 (9120 / 12512), Elapsed time: 19.99 mins\n",
      "Enc Loss = 184.28, KL Divergence = 1356.02, Reconstruction Loss = 464.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.01 mins\n",
      "Epoch: 2 / 10, Batch: 285 (9152 / 12512), Elapsed time: 20.01 mins\n",
      "Enc Loss = 166.95, KL Divergence = 1216.62, Reconstruction Loss = 422.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.03 mins\n",
      "Epoch: 2 / 10, Batch: 286 (9184 / 12512), Elapsed time: 20.03 mins\n",
      "Enc Loss = 172.87, KL Divergence = 1266.65, Reconstruction Loss = 436.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.05 mins\n",
      "Epoch: 2 / 10, Batch: 287 (9216 / 12512), Elapsed time: 20.05 mins\n",
      "Enc Loss = 160.60, KL Divergence = 1139.99, Reconstruction Loss = 409.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.07 mins\n",
      "Epoch: 2 / 10, Batch: 288 (9248 / 12512), Elapsed time: 20.07 mins\n",
      "Enc Loss = 158.59, KL Divergence = 1137.92, Reconstruction Loss = 403.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.09 mins\n",
      "Epoch: 2 / 10, Batch: 289 (9280 / 12512), Elapsed time: 20.09 mins\n",
      "Enc Loss = 162.91, KL Divergence = 1161.86, Reconstruction Loss = 414.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.11 mins\n",
      "Epoch: 2 / 10, Batch: 290 (9312 / 12512), Elapsed time: 20.11 mins\n",
      "Enc Loss = 154.23, KL Divergence = 1080.93, Reconstruction Loss = 394.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.13 mins\n",
      "Epoch: 2 / 10, Batch: 291 (9344 / 12512), Elapsed time: 20.13 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 173.47, KL Divergence = 1164.70, Reconstruction Loss = 449.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.14 mins\n",
      "Epoch: 2 / 10, Batch: 292 (9376 / 12512), Elapsed time: 20.14 mins\n",
      "Enc Loss = 164.19, KL Divergence = 1156.56, Reconstruction Loss = 419.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.16 mins\n",
      "Epoch: 2 / 10, Batch: 293 (9408 / 12512), Elapsed time: 20.16 mins\n",
      "Enc Loss = 163.88, KL Divergence = 1076.76, Reconstruction Loss = 426.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.18 mins\n",
      "Epoch: 2 / 10, Batch: 294 (9440 / 12512), Elapsed time: 20.18 mins\n",
      "Enc Loss = 166.67, KL Divergence = 1197.10, Reconstruction Loss = 423.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.20 mins\n",
      "Epoch: 2 / 10, Batch: 295 (9472 / 12512), Elapsed time: 20.20 mins\n",
      "Enc Loss = 170.20, KL Divergence = 1177.28, Reconstruction Loss = 437.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.22 mins\n",
      "Epoch: 2 / 10, Batch: 296 (9504 / 12512), Elapsed time: 20.22 mins\n",
      "Enc Loss = 163.65, KL Divergence = 1169.57, Reconstruction Loss = 416.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.24 mins\n",
      "Epoch: 2 / 10, Batch: 297 (9536 / 12512), Elapsed time: 20.24 mins\n",
      "Enc Loss = 197.31, KL Divergence = 1288.87, Reconstruction Loss = 514.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.26 mins\n",
      "Epoch: 2 / 10, Batch: 298 (9568 / 12512), Elapsed time: 20.26 mins\n",
      "Enc Loss = 169.07, KL Divergence = 1153.96, Reconstruction Loss = 435.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.28 mins\n",
      "Epoch: 2 / 10, Batch: 299 (9600 / 12512), Elapsed time: 20.28 mins\n",
      "Enc Loss = 173.07, KL Divergence = 1304.55, Reconstruction Loss = 433.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.30 mins\n",
      "Epoch: 2 / 10, Batch: 300 (9632 / 12512), Elapsed time: 20.30 mins\n",
      "Enc Loss = 168.05, KL Divergence = 1338.39, Reconstruction Loss = 413.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.32 mins\n",
      "Epoch: 2 / 10, Batch: 301 (9664 / 12512), Elapsed time: 20.32 mins\n",
      "Enc Loss = 176.18, KL Divergence = 1391.01, Reconstruction Loss = 434.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.33 mins\n",
      "Epoch: 2 / 10, Batch: 302 (9696 / 12512), Elapsed time: 20.33 mins\n",
      "Enc Loss = 173.53, KL Divergence = 1430.67, Reconstruction Loss = 422.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.35 mins\n",
      "Epoch: 2 / 10, Batch: 303 (9728 / 12512), Elapsed time: 20.35 mins\n",
      "Enc Loss = 173.50, KL Divergence = 1372.74, Reconstruction Loss = 427.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.37 mins\n",
      "Epoch: 2 / 10, Batch: 304 (9760 / 12512), Elapsed time: 20.37 mins\n",
      "Enc Loss = 170.66, KL Divergence = 1258.36, Reconstruction Loss = 430.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.39 mins\n",
      "Epoch: 2 / 10, Batch: 305 (9792 / 12512), Elapsed time: 20.39 mins\n",
      "Enc Loss = 168.49, KL Divergence = 1198.00, Reconstruction Loss = 429.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.41 mins\n",
      "Epoch: 2 / 10, Batch: 306 (9824 / 12512), Elapsed time: 20.41 mins\n",
      "Enc Loss = 169.46, KL Divergence = 1194.18, Reconstruction Loss = 433.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.43 mins\n",
      "Epoch: 2 / 10, Batch: 307 (9856 / 12512), Elapsed time: 20.43 mins\n",
      "Enc Loss = 169.56, KL Divergence = 1139.98, Reconstruction Loss = 438.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.45 mins\n",
      "Epoch: 2 / 10, Batch: 308 (9888 / 12512), Elapsed time: 20.45 mins\n",
      "Enc Loss = 159.56, KL Divergence = 1095.19, Reconstruction Loss = 410.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.47 mins\n",
      "Epoch: 2 / 10, Batch: 309 (9920 / 12512), Elapsed time: 20.47 mins\n",
      "Enc Loss = 183.64, KL Divergence = 1163.99, Reconstruction Loss = 482.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.48 mins\n",
      "Epoch: 2 / 10, Batch: 310 (9952 / 12512), Elapsed time: 20.48 mins\n",
      "Enc Loss = 168.82, KL Divergence = 1050.90, Reconstruction Loss = 445.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.50 mins\n",
      "Epoch: 2 / 10, Batch: 311 (9984 / 12512), Elapsed time: 20.50 mins\n",
      "Enc Loss = 165.69, KL Divergence = 1043.06, Reconstruction Loss = 436.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.52 mins\n",
      "Epoch: 2 / 10, Batch: 312 (10016 / 12512), Elapsed time: 20.52 mins\n",
      "Enc Loss = 156.55, KL Divergence = 1096.98, Reconstruction Loss = 400.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.54 mins\n",
      "Epoch: 2 / 10, Batch: 313 (10048 / 12512), Elapsed time: 20.54 mins\n",
      "Enc Loss = 177.55, KL Divergence = 1110.53, Reconstruction Loss = 468.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.56 mins\n",
      "Epoch: 2 / 10, Batch: 314 (10080 / 12512), Elapsed time: 20.56 mins\n",
      "Enc Loss = 178.73, KL Divergence = 1188.38, Reconstruction Loss = 463.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.58 mins\n",
      "Epoch: 2 / 10, Batch: 315 (10112 / 12512), Elapsed time: 20.58 mins\n",
      "Enc Loss = 173.08, KL Divergence = 1310.16, Reconstruction Loss = 432.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.60 mins\n",
      "Epoch: 2 / 10, Batch: 316 (10144 / 12512), Elapsed time: 20.60 mins\n",
      "Enc Loss = 163.24, KL Divergence = 1247.91, Reconstruction Loss = 407.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.61 mins\n",
      "Epoch: 2 / 10, Batch: 317 (10176 / 12512), Elapsed time: 20.61 mins\n",
      "Enc Loss = 163.67, KL Divergence = 1398.15, Reconstruction Loss = 393.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.63 mins\n",
      "Epoch: 2 / 10, Batch: 318 (10208 / 12512), Elapsed time: 20.63 mins\n",
      "Enc Loss = 173.01, KL Divergence = 1341.73, Reconstruction Loss = 429.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.65 mins\n",
      "Epoch: 2 / 10, Batch: 319 (10240 / 12512), Elapsed time: 20.65 mins\n",
      "Enc Loss = 162.72, KL Divergence = 1331.46, Reconstruction Loss = 396.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.67 mins\n",
      "Epoch: 2 / 10, Batch: 320 (10272 / 12512), Elapsed time: 20.67 mins\n",
      "Enc Loss = 171.54, KL Divergence = 1499.47, Reconstruction Loss = 408.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.69 mins\n",
      "Epoch: 2 / 10, Batch: 321 (10304 / 12512), Elapsed time: 20.69 mins\n",
      "Enc Loss = 181.93, KL Divergence = 1460.08, Reconstruction Loss = 446.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.71 mins\n",
      "Epoch: 2 / 10, Batch: 322 (10336 / 12512), Elapsed time: 20.71 mins\n",
      "Enc Loss = 174.06, KL Divergence = 1391.80, Reconstruction Loss = 427.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.73 mins\n",
      "Epoch: 2 / 10, Batch: 323 (10368 / 12512), Elapsed time: 20.73 mins\n",
      "Enc Loss = 183.67, KL Divergence = 1309.20, Reconstruction Loss = 467.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.74 mins\n",
      "Epoch: 2 / 10, Batch: 324 (10400 / 12512), Elapsed time: 20.75 mins\n",
      "Enc Loss = 210.09, KL Divergence = 1443.01, Reconstruction Loss = 540.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.76 mins\n",
      "Epoch: 2 / 10, Batch: 325 (10432 / 12512), Elapsed time: 20.76 mins\n",
      "Enc Loss = 172.21, KL Divergence = 1371.62, Reconstruction Loss = 423.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.78 mins\n",
      "Epoch: 2 / 10, Batch: 326 (10464 / 12512), Elapsed time: 20.78 mins\n",
      "Enc Loss = 168.71, KL Divergence = 1230.57, Reconstruction Loss = 426.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.80 mins\n",
      "Epoch: 2 / 10, Batch: 327 (10496 / 12512), Elapsed time: 20.80 mins\n",
      "Enc Loss = 177.56, KL Divergence = 1257.26, Reconstruction Loss = 453.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.82 mins\n",
      "Epoch: 2 / 10, Batch: 328 (10528 / 12512), Elapsed time: 20.82 mins\n",
      "Enc Loss = 174.49, KL Divergence = 1381.72, Reconstruction Loss = 430.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.84 mins\n",
      "Epoch: 2 / 10, Batch: 329 (10560 / 12512), Elapsed time: 20.84 mins\n",
      "Enc Loss = 168.79, KL Divergence = 1297.98, Reconstruction Loss = 420.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.86 mins\n",
      "Epoch: 2 / 10, Batch: 330 (10592 / 12512), Elapsed time: 20.86 mins\n",
      "Enc Loss = 163.89, KL Divergence = 1311.00, Reconstruction Loss = 402.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.88 mins\n",
      "Epoch: 2 / 10, Batch: 331 (10624 / 12512), Elapsed time: 20.88 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 168.89, KL Divergence = 1221.03, Reconstruction Loss = 428.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.90 mins\n",
      "Epoch: 2 / 10, Batch: 332 (10656 / 12512), Elapsed time: 20.90 mins\n",
      "Enc Loss = 163.46, KL Divergence = 1146.24, Reconstruction Loss = 418.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.92 mins\n",
      "Epoch: 2 / 10, Batch: 333 (10688 / 12512), Elapsed time: 20.92 mins\n",
      "Enc Loss = 190.62, KL Divergence = 1106.43, Reconstruction Loss = 511.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.94 mins\n",
      "Epoch: 2 / 10, Batch: 334 (10720 / 12512), Elapsed time: 20.94 mins\n",
      "Enc Loss = 185.93, KL Divergence = 1338.96, Reconstruction Loss = 472.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.95 mins\n",
      "Epoch: 2 / 10, Batch: 335 (10752 / 12512), Elapsed time: 20.95 mins\n",
      "Enc Loss = 171.31, KL Divergence = 1274.04, Reconstruction Loss = 430.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.97 mins\n",
      "Epoch: 2 / 10, Batch: 336 (10784 / 12512), Elapsed time: 20.97 mins\n",
      "Enc Loss = 157.00, KL Divergence = 1210.63, Reconstruction Loss = 390.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 20.99 mins\n",
      "Epoch: 2 / 10, Batch: 337 (10816 / 12512), Elapsed time: 20.99 mins\n",
      "Enc Loss = 160.70, KL Divergence = 1210.31, Reconstruction Loss = 402.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.01 mins\n",
      "Epoch: 2 / 10, Batch: 338 (10848 / 12512), Elapsed time: 21.01 mins\n",
      "Enc Loss = 169.95, KL Divergence = 1254.83, Reconstruction Loss = 428.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.03 mins\n",
      "Epoch: 2 / 10, Batch: 339 (10880 / 12512), Elapsed time: 21.03 mins\n",
      "Enc Loss = 178.51, KL Divergence = 1314.65, Reconstruction Loss = 450.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.05 mins\n",
      "Epoch: 2 / 10, Batch: 340 (10912 / 12512), Elapsed time: 21.05 mins\n",
      "Enc Loss = 150.82, KL Divergence = 1186.41, Reconstruction Loss = 372.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.07 mins\n",
      "Epoch: 2 / 10, Batch: 341 (10944 / 12512), Elapsed time: 21.07 mins\n",
      "Enc Loss = 168.43, KL Divergence = 1299.28, Reconstruction Loss = 418.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.09 mins\n",
      "Epoch: 2 / 10, Batch: 342 (10976 / 12512), Elapsed time: 21.09 mins\n",
      "Enc Loss = 167.12, KL Divergence = 1248.78, Reconstruction Loss = 419.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.11 mins\n",
      "Epoch: 2 / 10, Batch: 343 (11008 / 12512), Elapsed time: 21.11 mins\n",
      "Enc Loss = 174.02, KL Divergence = 1248.40, Reconstruction Loss = 442.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.13 mins\n",
      "Epoch: 2 / 10, Batch: 344 (11040 / 12512), Elapsed time: 21.13 mins\n",
      "Enc Loss = 178.40, KL Divergence = 1131.92, Reconstruction Loss = 468.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.14 mins\n",
      "Epoch: 2 / 10, Batch: 345 (11072 / 12512), Elapsed time: 21.14 mins\n",
      "Enc Loss = 161.49, KL Divergence = 1166.82, Reconstruction Loss = 409.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.16 mins\n",
      "Epoch: 2 / 10, Batch: 346 (11104 / 12512), Elapsed time: 21.16 mins\n",
      "Enc Loss = 178.71, KL Divergence = 1190.53, Reconstruction Loss = 463.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.18 mins\n",
      "Epoch: 2 / 10, Batch: 347 (11136 / 12512), Elapsed time: 21.18 mins\n",
      "Enc Loss = 160.76, KL Divergence = 1155.44, Reconstruction Loss = 408.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.20 mins\n",
      "Epoch: 2 / 10, Batch: 348 (11168 / 12512), Elapsed time: 21.20 mins\n",
      "Enc Loss = 199.47, KL Divergence = 1297.52, Reconstruction Loss = 520.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.22 mins\n",
      "Epoch: 2 / 10, Batch: 349 (11200 / 12512), Elapsed time: 21.22 mins\n",
      "Enc Loss = 157.76, KL Divergence = 1189.01, Reconstruction Loss = 395.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.24 mins\n",
      "Epoch: 2 / 10, Batch: 350 (11232 / 12512), Elapsed time: 21.24 mins\n",
      "Enc Loss = 157.07, KL Divergence = 1222.33, Reconstruction Loss = 389.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.26 mins\n",
      "Epoch: 2 / 10, Batch: 351 (11264 / 12512), Elapsed time: 21.26 mins\n",
      "Enc Loss = 158.30, KL Divergence = 1175.13, Reconstruction Loss = 398.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.28 mins\n",
      "Epoch: 2 / 10, Batch: 352 (11296 / 12512), Elapsed time: 21.28 mins\n",
      "Enc Loss = 170.79, KL Divergence = 1153.19, Reconstruction Loss = 441.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.30 mins\n",
      "Epoch: 2 / 10, Batch: 353 (11328 / 12512), Elapsed time: 21.30 mins\n",
      "Enc Loss = 169.19, KL Divergence = 1224.85, Reconstruction Loss = 428.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.32 mins\n",
      "Epoch: 2 / 10, Batch: 354 (11360 / 12512), Elapsed time: 21.32 mins\n",
      "Enc Loss = 171.40, KL Divergence = 1292.04, Reconstruction Loss = 429.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.34 mins\n",
      "Epoch: 2 / 10, Batch: 355 (11392 / 12512), Elapsed time: 21.34 mins\n",
      "Enc Loss = 166.68, KL Divergence = 1304.89, Reconstruction Loss = 412.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.35 mins\n",
      "Epoch: 2 / 10, Batch: 356 (11424 / 12512), Elapsed time: 21.35 mins\n",
      "Enc Loss = 168.05, KL Divergence = 1326.69, Reconstruction Loss = 414.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.37 mins\n",
      "Epoch: 2 / 10, Batch: 357 (11456 / 12512), Elapsed time: 21.37 mins\n",
      "Enc Loss = 194.19, KL Divergence = 1429.39, Reconstruction Loss = 489.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.39 mins\n",
      "Epoch: 2 / 10, Batch: 358 (11488 / 12512), Elapsed time: 21.39 mins\n",
      "Enc Loss = 157.16, KL Divergence = 1122.36, Reconstruction Loss = 400.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.41 mins\n",
      "Epoch: 2 / 10, Batch: 359 (11520 / 12512), Elapsed time: 21.41 mins\n",
      "Enc Loss = 163.29, KL Divergence = 1132.89, Reconstruction Loss = 419.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.43 mins\n",
      "Epoch: 2 / 10, Batch: 360 (11552 / 12512), Elapsed time: 21.43 mins\n",
      "Enc Loss = 177.41, KL Divergence = 1319.03, Reconstruction Loss = 446.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.45 mins\n",
      "Epoch: 2 / 10, Batch: 361 (11584 / 12512), Elapsed time: 21.45 mins\n",
      "Enc Loss = 155.32, KL Divergence = 1193.07, Reconstruction Loss = 386.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.47 mins\n",
      "Epoch: 2 / 10, Batch: 362 (11616 / 12512), Elapsed time: 21.47 mins\n",
      "Enc Loss = 162.46, KL Divergence = 1209.89, Reconstruction Loss = 408.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.49 mins\n",
      "Epoch: 2 / 10, Batch: 363 (11648 / 12512), Elapsed time: 21.49 mins\n",
      "Enc Loss = 156.56, KL Divergence = 1226.96, Reconstruction Loss = 387.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.50 mins\n",
      "Epoch: 2 / 10, Batch: 364 (11680 / 12512), Elapsed time: 21.50 mins\n",
      "Enc Loss = 157.50, KL Divergence = 1171.27, Reconstruction Loss = 396.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.52 mins\n",
      "Epoch: 2 / 10, Batch: 365 (11712 / 12512), Elapsed time: 21.52 mins\n",
      "Enc Loss = 166.43, KL Divergence = 1189.38, Reconstruction Loss = 423.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.54 mins\n",
      "Epoch: 2 / 10, Batch: 366 (11744 / 12512), Elapsed time: 21.54 mins\n",
      "Enc Loss = 157.10, KL Divergence = 1095.14, Reconstruction Loss = 402.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.56 mins\n",
      "Epoch: 2 / 10, Batch: 367 (11776 / 12512), Elapsed time: 21.56 mins\n",
      "Enc Loss = 155.74, KL Divergence = 1143.26, Reconstruction Loss = 393.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.58 mins\n",
      "Epoch: 2 / 10, Batch: 368 (11808 / 12512), Elapsed time: 21.58 mins\n",
      "Enc Loss = 172.02, KL Divergence = 1233.29, Reconstruction Loss = 437.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.60 mins\n",
      "Epoch: 2 / 10, Batch: 369 (11840 / 12512), Elapsed time: 21.60 mins\n",
      "Enc Loss = 163.79, KL Divergence = 1115.94, Reconstruction Loss = 422.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.62 mins\n",
      "Epoch: 2 / 10, Batch: 370 (11872 / 12512), Elapsed time: 21.62 mins\n",
      "Enc Loss = 168.63, KL Divergence = 1184.66, Reconstruction Loss = 431.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.64 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 / 10, Batch: 371 (11904 / 12512), Elapsed time: 21.64 mins\n",
      "Enc Loss = 151.61, KL Divergence = 1091.27, Reconstruction Loss = 385.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.65 mins\n",
      "Epoch: 2 / 10, Batch: 372 (11936 / 12512), Elapsed time: 21.65 mins\n",
      "Enc Loss = 169.33, KL Divergence = 1223.56, Reconstruction Loss = 429.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.67 mins\n",
      "Epoch: 2 / 10, Batch: 373 (11968 / 12512), Elapsed time: 21.67 mins\n",
      "Enc Loss = 166.84, KL Divergence = 1233.20, Reconstruction Loss = 420.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.69 mins\n",
      "Epoch: 2 / 10, Batch: 374 (12000 / 12512), Elapsed time: 21.69 mins\n",
      "Enc Loss = 169.38, KL Divergence = 1210.62, Reconstruction Loss = 431.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.71 mins\n",
      "Epoch: 2 / 10, Batch: 375 (12032 / 12512), Elapsed time: 21.71 mins\n",
      "Enc Loss = 159.85, KL Divergence = 1130.42, Reconstruction Loss = 408.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.73 mins\n",
      "Epoch: 2 / 10, Batch: 376 (12064 / 12512), Elapsed time: 21.73 mins\n",
      "Enc Loss = 163.37, KL Divergence = 1181.29, Reconstruction Loss = 414.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.75 mins\n",
      "Epoch: 2 / 10, Batch: 377 (12096 / 12512), Elapsed time: 21.75 mins\n",
      "Enc Loss = 177.41, KL Divergence = 1271.74, Reconstruction Loss = 451.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.77 mins\n",
      "Epoch: 2 / 10, Batch: 378 (12128 / 12512), Elapsed time: 21.77 mins\n",
      "Enc Loss = 160.84, KL Divergence = 1088.54, Reconstruction Loss = 415.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.79 mins\n",
      "Epoch: 2 / 10, Batch: 379 (12160 / 12512), Elapsed time: 21.79 mins\n",
      "Enc Loss = 166.44, KL Divergence = 1213.16, Reconstruction Loss = 421.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.80 mins\n",
      "Epoch: 2 / 10, Batch: 380 (12192 / 12512), Elapsed time: 21.81 mins\n",
      "Enc Loss = 164.42, KL Divergence = 1217.80, Reconstruction Loss = 414.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.82 mins\n",
      "Epoch: 2 / 10, Batch: 381 (12224 / 12512), Elapsed time: 21.82 mins\n",
      "Enc Loss = 220.27, KL Divergence = 1242.61, Reconstruction Loss = 594.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.84 mins\n",
      "Epoch: 2 / 10, Batch: 382 (12256 / 12512), Elapsed time: 21.84 mins\n",
      "Enc Loss = 176.85, KL Divergence = 1304.29, Reconstruction Loss = 445.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.86 mins\n",
      "Epoch: 2 / 10, Batch: 383 (12288 / 12512), Elapsed time: 21.86 mins\n",
      "Enc Loss = 158.29, KL Divergence = 1180.01, Reconstruction Loss = 397.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.88 mins\n",
      "Epoch: 2 / 10, Batch: 384 (12320 / 12512), Elapsed time: 21.88 mins\n",
      "Enc Loss = 170.44, KL Divergence = 1327.93, Reconstruction Loss = 422.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.90 mins\n",
      "Epoch: 2 / 10, Batch: 385 (12352 / 12512), Elapsed time: 21.90 mins\n",
      "Enc Loss = 178.83, KL Divergence = 1362.67, Reconstruction Loss = 446.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.92 mins\n",
      "Epoch: 2 / 10, Batch: 386 (12384 / 12512), Elapsed time: 21.92 mins\n",
      "Enc Loss = 161.48, KL Divergence = 1325.45, Reconstruction Loss = 393.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.94 mins\n",
      "Epoch: 2 / 10, Batch: 387 (12416 / 12512), Elapsed time: 21.94 mins\n",
      "Enc Loss = 161.36, KL Divergence = 1327.45, Reconstruction Loss = 392.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.95 mins\n",
      "Epoch: 2 / 10, Batch: 388 (12448 / 12512), Elapsed time: 21.95 mins\n",
      "Enc Loss = 159.61, KL Divergence = 1290.69, Reconstruction Loss = 390.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.97 mins\n",
      "Epoch: 2 / 10, Batch: 389 (12480 / 12512), Elapsed time: 21.97 mins\n",
      "Enc Loss = 180.48, KL Divergence = 1226.18, Reconstruction Loss = 465.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 21.99 mins\n",
      "Epoch: 2 / 10, Batch: 390 (12512 / 12512), Elapsed time: 21.99 mins\n",
      "Enc Loss = 128.58, KL Divergence = 489.62, Reconstruction Loss = 371.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.01 mins\n",
      "Epoch: 3, Elapsed Time: 22.01\n",
      "Epoch: 3 / 10, Batch: 0 (32 / 12512), Elapsed time: 22.01 mins\n",
      "Enc Loss = 167.21, KL Divergence = 1260.94, Reconstruction Loss = 418.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.03 mins\n",
      "Epoch: 3 / 10, Batch: 1 (64 / 12512), Elapsed time: 22.03 mins\n",
      "Enc Loss = 172.05, KL Divergence = 1256.27, Reconstruction Loss = 435.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.05 mins\n",
      "Epoch: 3 / 10, Batch: 2 (96 / 12512), Elapsed time: 22.05 mins\n",
      "Enc Loss = 174.20, KL Divergence = 1205.76, Reconstruction Loss = 447.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.07 mins\n",
      "Epoch: 3 / 10, Batch: 3 (128 / 12512), Elapsed time: 22.07 mins\n",
      "Enc Loss = 194.51, KL Divergence = 1403.52, Reconstruction Loss = 493.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.09 mins\n",
      "Epoch: 3 / 10, Batch: 4 (160 / 12512), Elapsed time: 22.09 mins\n",
      "Enc Loss = 154.55, KL Divergence = 1225.27, Reconstruction Loss = 380.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.11 mins\n",
      "Epoch: 3 / 10, Batch: 5 (192 / 12512), Elapsed time: 22.11 mins\n",
      "Enc Loss = 153.56, KL Divergence = 1210.60, Reconstruction Loss = 379.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.13 mins\n",
      "Epoch: 3 / 10, Batch: 6 (224 / 12512), Elapsed time: 22.13 mins\n",
      "Enc Loss = 175.81, KL Divergence = 1275.94, Reconstruction Loss = 445.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.14 mins\n",
      "Epoch: 3 / 10, Batch: 7 (256 / 12512), Elapsed time: 22.14 mins\n",
      "Enc Loss = 161.41, KL Divergence = 1321.14, Reconstruction Loss = 393.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.16 mins\n",
      "Epoch: 3 / 10, Batch: 8 (288 / 12512), Elapsed time: 22.16 mins\n",
      "Enc Loss = 164.74, KL Divergence = 1344.80, Reconstruction Loss = 402.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.18 mins\n",
      "Epoch: 3 / 10, Batch: 9 (320 / 12512), Elapsed time: 22.18 mins\n",
      "Enc Loss = 165.10, KL Divergence = 1274.30, Reconstruction Loss = 410.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.20 mins\n",
      "Epoch: 3 / 10, Batch: 10 (352 / 12512), Elapsed time: 22.20 mins\n",
      "Enc Loss = 160.53, KL Divergence = 1331.85, Reconstruction Loss = 389.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.22 mins\n",
      "Epoch: 3 / 10, Batch: 11 (384 / 12512), Elapsed time: 22.22 mins\n",
      "Enc Loss = 174.66, KL Divergence = 1264.27, Reconstruction Loss = 442.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.24 mins\n",
      "Epoch: 3 / 10, Batch: 12 (416 / 12512), Elapsed time: 22.24 mins\n",
      "Enc Loss = 177.76, KL Divergence = 1289.20, Reconstruction Loss = 450.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.26 mins\n",
      "Epoch: 3 / 10, Batch: 13 (448 / 12512), Elapsed time: 22.26 mins\n",
      "Enc Loss = 191.28, KL Divergence = 1523.95, Reconstruction Loss = 470.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.28 mins\n",
      "Epoch: 3 / 10, Batch: 14 (480 / 12512), Elapsed time: 22.28 mins\n",
      "Enc Loss = 188.62, KL Divergence = 1330.64, Reconstruction Loss = 481.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.30 mins\n",
      "Epoch: 3 / 10, Batch: 15 (512 / 12512), Elapsed time: 22.30 mins\n",
      "Enc Loss = 157.66, KL Divergence = 1224.53, Reconstruction Loss = 391.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.31 mins\n",
      "Epoch: 3 / 10, Batch: 16 (544 / 12512), Elapsed time: 22.31 mins\n",
      "Enc Loss = 168.45, KL Divergence = 1286.77, Reconstruction Loss = 420.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.33 mins\n",
      "Epoch: 3 / 10, Batch: 17 (576 / 12512), Elapsed time: 22.33 mins\n",
      "Enc Loss = 170.72, KL Divergence = 1243.38, Reconstruction Loss = 432.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.35 mins\n",
      "Epoch: 3 / 10, Batch: 18 (608 / 12512), Elapsed time: 22.35 mins\n",
      "Enc Loss = 162.06, KL Divergence = 1217.74, Reconstruction Loss = 406.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.37 mins\n",
      "Epoch: 3 / 10, Batch: 19 (640 / 12512), Elapsed time: 22.37 mins\n",
      "Enc Loss = 191.14, KL Divergence = 1328.97, Reconstruction Loss = 490.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.39 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 10, Batch: 20 (672 / 12512), Elapsed time: 22.39 mins\n",
      "Enc Loss = 179.12, KL Divergence = 1120.67, Reconstruction Loss = 472.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.41 mins\n",
      "Epoch: 3 / 10, Batch: 21 (704 / 12512), Elapsed time: 22.41 mins\n",
      "Enc Loss = 170.09, KL Divergence = 1133.18, Reconstruction Loss = 441.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.43 mins\n",
      "Epoch: 3 / 10, Batch: 22 (736 / 12512), Elapsed time: 22.43 mins\n",
      "Enc Loss = 203.30, KL Divergence = 1400.71, Reconstruction Loss = 522.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.45 mins\n",
      "Epoch: 3 / 10, Batch: 23 (768 / 12512), Elapsed time: 22.45 mins\n",
      "Enc Loss = 182.83, KL Divergence = 1264.45, Reconstruction Loss = 469.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.47 mins\n",
      "Epoch: 3 / 10, Batch: 24 (800 / 12512), Elapsed time: 22.47 mins\n",
      "Enc Loss = 167.17, KL Divergence = 1279.92, Reconstruction Loss = 416.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.49 mins\n",
      "Epoch: 3 / 10, Batch: 25 (832 / 12512), Elapsed time: 22.49 mins\n",
      "Enc Loss = 194.52, KL Divergence = 1571.31, Reconstruction Loss = 476.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.50 mins\n",
      "Epoch: 3 / 10, Batch: 26 (864 / 12512), Elapsed time: 22.50 mins\n",
      "Enc Loss = 178.42, KL Divergence = 1332.41, Reconstruction Loss = 448.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.52 mins\n",
      "Epoch: 3 / 10, Batch: 27 (896 / 12512), Elapsed time: 22.52 mins\n",
      "Enc Loss = 154.06, KL Divergence = 1282.04, Reconstruction Loss = 373.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.54 mins\n",
      "Epoch: 3 / 10, Batch: 28 (928 / 12512), Elapsed time: 22.54 mins\n",
      "Enc Loss = 164.52, KL Divergence = 1334.36, Reconstruction Loss = 402.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.56 mins\n",
      "Epoch: 3 / 10, Batch: 29 (960 / 12512), Elapsed time: 22.56 mins\n",
      "Enc Loss = 174.18, KL Divergence = 1290.95, Reconstruction Loss = 438.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.58 mins\n",
      "Epoch: 3 / 10, Batch: 30 (992 / 12512), Elapsed time: 22.58 mins\n",
      "Enc Loss = 174.77, KL Divergence = 1446.26, Reconstruction Loss = 424.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.60 mins\n",
      "Epoch: 3 / 10, Batch: 31 (1024 / 12512), Elapsed time: 22.60 mins\n",
      "Enc Loss = 168.80, KL Divergence = 1338.90, Reconstruction Loss = 416.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.62 mins\n",
      "Epoch: 3 / 10, Batch: 32 (1056 / 12512), Elapsed time: 22.62 mins\n",
      "Enc Loss = 164.37, KL Divergence = 1303.18, Reconstruction Loss = 405.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.64 mins\n",
      "Epoch: 3 / 10, Batch: 33 (1088 / 12512), Elapsed time: 22.64 mins\n",
      "Enc Loss = 163.57, KL Divergence = 1327.32, Reconstruction Loss = 400.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.66 mins\n",
      "Epoch: 3 / 10, Batch: 34 (1120 / 12512), Elapsed time: 22.66 mins\n",
      "Enc Loss = 158.79, KL Divergence = 1163.32, Reconstruction Loss = 401.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.68 mins\n",
      "Epoch: 3 / 10, Batch: 35 (1152 / 12512), Elapsed time: 22.68 mins\n",
      "Enc Loss = 174.72, KL Divergence = 1254.32, Reconstruction Loss = 444.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.70 mins\n",
      "Epoch: 3 / 10, Batch: 36 (1184 / 12512), Elapsed time: 22.70 mins\n",
      "Enc Loss = 154.73, KL Divergence = 1173.89, Reconstruction Loss = 386.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.71 mins\n",
      "Epoch: 3 / 10, Batch: 37 (1216 / 12512), Elapsed time: 22.72 mins\n",
      "Enc Loss = 163.85, KL Divergence = 1167.17, Reconstruction Loss = 417.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.73 mins\n",
      "Epoch: 3 / 10, Batch: 38 (1248 / 12512), Elapsed time: 22.73 mins\n",
      "Enc Loss = 159.61, KL Divergence = 1152.68, Reconstruction Loss = 404.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.75 mins\n",
      "Epoch: 3 / 10, Batch: 39 (1280 / 12512), Elapsed time: 22.75 mins\n",
      "Enc Loss = 151.38, KL Divergence = 1063.49, Reconstruction Loss = 387.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.77 mins\n",
      "Epoch: 3 / 10, Batch: 40 (1312 / 12512), Elapsed time: 22.77 mins\n",
      "Enc Loss = 162.51, KL Divergence = 1148.16, Reconstruction Loss = 414.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.79 mins\n",
      "Epoch: 3 / 10, Batch: 41 (1344 / 12512), Elapsed time: 22.79 mins\n",
      "Enc Loss = 162.38, KL Divergence = 1178.32, Reconstruction Loss = 411.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.81 mins\n",
      "Epoch: 3 / 10, Batch: 42 (1376 / 12512), Elapsed time: 22.81 mins\n",
      "Enc Loss = 167.30, KL Divergence = 1116.14, Reconstruction Loss = 433.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.83 mins\n",
      "Epoch: 3 / 10, Batch: 43 (1408 / 12512), Elapsed time: 22.83 mins\n",
      "Enc Loss = 162.98, KL Divergence = 1180.49, Reconstruction Loss = 413.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.85 mins\n",
      "Epoch: 3 / 10, Batch: 44 (1440 / 12512), Elapsed time: 22.85 mins\n",
      "Enc Loss = 159.62, KL Divergence = 1183.13, Reconstruction Loss = 401.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.87 mins\n",
      "Epoch: 3 / 10, Batch: 45 (1472 / 12512), Elapsed time: 22.87 mins\n",
      "Enc Loss = 168.00, KL Divergence = 1159.89, Reconstruction Loss = 431.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.88 mins\n",
      "Epoch: 3 / 10, Batch: 46 (1504 / 12512), Elapsed time: 22.89 mins\n",
      "Enc Loss = 174.03, KL Divergence = 1281.80, Reconstruction Loss = 439.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.90 mins\n",
      "Epoch: 3 / 10, Batch: 47 (1536 / 12512), Elapsed time: 22.91 mins\n",
      "Enc Loss = 161.92, KL Divergence = 1220.31, Reconstruction Loss = 405.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.92 mins\n",
      "Epoch: 3 / 10, Batch: 48 (1568 / 12512), Elapsed time: 22.92 mins\n",
      "Enc Loss = 152.56, KL Divergence = 1128.13, Reconstruction Loss = 384.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.94 mins\n",
      "Epoch: 3 / 10, Batch: 49 (1600 / 12512), Elapsed time: 22.94 mins\n",
      "Enc Loss = 175.74, KL Divergence = 1426.85, Reconstruction Loss = 429.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.96 mins\n",
      "Epoch: 3 / 10, Batch: 50 (1632 / 12512), Elapsed time: 22.96 mins\n",
      "Enc Loss = 170.27, KL Divergence = 1270.81, Reconstruction Loss = 427.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 22.98 mins\n",
      "Epoch: 3 / 10, Batch: 51 (1664 / 12512), Elapsed time: 22.98 mins\n",
      "Enc Loss = 168.58, KL Divergence = 1241.59, Reconstruction Loss = 425.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.00 mins\n",
      "Epoch: 3 / 10, Batch: 52 (1696 / 12512), Elapsed time: 23.00 mins\n",
      "Enc Loss = 156.56, KL Divergence = 1175.69, Reconstruction Loss = 392.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.02 mins\n",
      "Epoch: 3 / 10, Batch: 53 (1728 / 12512), Elapsed time: 23.02 mins\n",
      "Enc Loss = 173.40, KL Divergence = 1212.15, Reconstruction Loss = 444.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.04 mins\n",
      "Epoch: 3 / 10, Batch: 54 (1760 / 12512), Elapsed time: 23.04 mins\n",
      "Enc Loss = 153.04, KL Divergence = 1159.89, Reconstruction Loss = 382.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.05 mins\n",
      "Epoch: 3 / 10, Batch: 55 (1792 / 12512), Elapsed time: 23.05 mins\n",
      "Enc Loss = 157.22, KL Divergence = 1228.49, Reconstruction Loss = 389.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.07 mins\n",
      "Epoch: 3 / 10, Batch: 56 (1824 / 12512), Elapsed time: 23.07 mins\n",
      "Enc Loss = 162.17, KL Divergence = 1262.43, Reconstruction Loss = 402.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.09 mins\n",
      "Epoch: 3 / 10, Batch: 57 (1856 / 12512), Elapsed time: 23.09 mins\n",
      "Enc Loss = 172.22, KL Divergence = 1347.55, Reconstruction Loss = 426.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.11 mins\n",
      "Epoch: 3 / 10, Batch: 58 (1888 / 12512), Elapsed time: 23.11 mins\n",
      "Enc Loss = 182.33, KL Divergence = 1374.61, Reconstruction Loss = 456.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.13 mins\n",
      "Epoch: 3 / 10, Batch: 59 (1920 / 12512), Elapsed time: 23.13 mins\n",
      "Enc Loss = 151.81, KL Divergence = 1204.80, Reconstruction Loss = 374.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.15 mins\n",
      "Epoch: 3 / 10, Batch: 60 (1952 / 12512), Elapsed time: 23.15 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 170.14, KL Divergence = 1332.34, Reconstruction Loss = 421.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.17 mins\n",
      "Epoch: 3 / 10, Batch: 61 (1984 / 12512), Elapsed time: 23.17 mins\n",
      "Enc Loss = 148.99, KL Divergence = 1171.86, Reconstruction Loss = 368.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.19 mins\n",
      "Epoch: 3 / 10, Batch: 62 (2016 / 12512), Elapsed time: 23.19 mins\n",
      "Enc Loss = 159.66, KL Divergence = 1241.05, Reconstruction Loss = 396.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.20 mins\n",
      "Epoch: 3 / 10, Batch: 63 (2048 / 12512), Elapsed time: 23.21 mins\n",
      "Enc Loss = 150.67, KL Divergence = 1208.30, Reconstruction Loss = 369.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.22 mins\n",
      "Epoch: 3 / 10, Batch: 64 (2080 / 12512), Elapsed time: 23.22 mins\n",
      "Enc Loss = 168.43, KL Divergence = 1323.97, Reconstruction Loss = 416.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.24 mins\n",
      "Epoch: 3 / 10, Batch: 65 (2112 / 12512), Elapsed time: 23.24 mins\n",
      "Enc Loss = 167.73, KL Divergence = 1273.94, Reconstruction Loss = 419.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.26 mins\n",
      "Epoch: 3 / 10, Batch: 66 (2144 / 12512), Elapsed time: 23.26 mins\n",
      "Enc Loss = 163.49, KL Divergence = 1248.90, Reconstruction Loss = 407.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.28 mins\n",
      "Epoch: 3 / 10, Batch: 67 (2176 / 12512), Elapsed time: 23.28 mins\n",
      "Enc Loss = 150.99, KL Divergence = 1143.38, Reconstruction Loss = 377.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.30 mins\n",
      "Epoch: 3 / 10, Batch: 68 (2208 / 12512), Elapsed time: 23.30 mins\n",
      "Enc Loss = 175.99, KL Divergence = 1212.27, Reconstruction Loss = 452.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.32 mins\n",
      "Epoch: 3 / 10, Batch: 69 (2240 / 12512), Elapsed time: 23.32 mins\n",
      "Enc Loss = 166.68, KL Divergence = 1183.04, Reconstruction Loss = 425.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.34 mins\n",
      "Epoch: 3 / 10, Batch: 70 (2272 / 12512), Elapsed time: 23.34 mins\n",
      "Enc Loss = 155.97, KL Divergence = 1191.94, Reconstruction Loss = 389.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.36 mins\n",
      "Epoch: 3 / 10, Batch: 71 (2304 / 12512), Elapsed time: 23.36 mins\n",
      "Enc Loss = 160.44, KL Divergence = 1288.75, Reconstruction Loss = 393.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.38 mins\n",
      "Epoch: 3 / 10, Batch: 72 (2336 / 12512), Elapsed time: 23.38 mins\n",
      "Enc Loss = 161.11, KL Divergence = 1220.74, Reconstruction Loss = 402.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.40 mins\n",
      "Epoch: 3 / 10, Batch: 73 (2368 / 12512), Elapsed time: 23.40 mins\n",
      "Enc Loss = 163.27, KL Divergence = 1242.94, Reconstruction Loss = 407.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.42 mins\n",
      "Epoch: 3 / 10, Batch: 74 (2400 / 12512), Elapsed time: 23.42 mins\n",
      "Enc Loss = 193.74, KL Divergence = 1321.86, Reconstruction Loss = 499.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.43 mins\n",
      "Epoch: 3 / 10, Batch: 75 (2432 / 12512), Elapsed time: 23.44 mins\n",
      "Enc Loss = 168.27, KL Divergence = 1266.62, Reconstruction Loss = 421.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.45 mins\n",
      "Epoch: 3 / 10, Batch: 76 (2464 / 12512), Elapsed time: 23.45 mins\n",
      "Enc Loss = 163.07, KL Divergence = 1332.93, Reconstruction Loss = 397.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.47 mins\n",
      "Epoch: 3 / 10, Batch: 77 (2496 / 12512), Elapsed time: 23.47 mins\n",
      "Enc Loss = 166.96, KL Divergence = 1435.08, Reconstruction Loss = 400.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.49 mins\n",
      "Epoch: 3 / 10, Batch: 78 (2528 / 12512), Elapsed time: 23.49 mins\n",
      "Enc Loss = 184.85, KL Divergence = 1434.29, Reconstruction Loss = 458.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.51 mins\n",
      "Epoch: 3 / 10, Batch: 79 (2560 / 12512), Elapsed time: 23.51 mins\n",
      "Enc Loss = 170.94, KL Divergence = 1302.72, Reconstruction Loss = 426.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.53 mins\n",
      "Epoch: 3 / 10, Batch: 80 (2592 / 12512), Elapsed time: 23.53 mins\n",
      "Enc Loss = 152.76, KL Divergence = 1316.42, Reconstruction Loss = 365.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.55 mins\n",
      "Epoch: 3 / 10, Batch: 81 (2624 / 12512), Elapsed time: 23.55 mins\n",
      "Enc Loss = 152.96, KL Divergence = 1232.68, Reconstruction Loss = 375.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.57 mins\n",
      "Epoch: 3 / 10, Batch: 82 (2656 / 12512), Elapsed time: 23.57 mins\n",
      "Enc Loss = 170.40, KL Divergence = 1250.28, Reconstruction Loss = 430.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.58 mins\n",
      "Epoch: 3 / 10, Batch: 83 (2688 / 12512), Elapsed time: 23.58 mins\n",
      "Enc Loss = 167.17, KL Divergence = 1261.47, Reconstruction Loss = 418.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.60 mins\n",
      "Epoch: 3 / 10, Batch: 84 (2720 / 12512), Elapsed time: 23.60 mins\n",
      "Enc Loss = 163.73, KL Divergence = 1249.79, Reconstruction Loss = 408.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.62 mins\n",
      "Epoch: 3 / 10, Batch: 85 (2752 / 12512), Elapsed time: 23.62 mins\n",
      "Enc Loss = 167.05, KL Divergence = 1274.39, Reconstruction Loss = 416.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.64 mins\n",
      "Epoch: 3 / 10, Batch: 86 (2784 / 12512), Elapsed time: 23.64 mins\n",
      "Enc Loss = 162.36, KL Divergence = 1245.31, Reconstruction Loss = 404.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.66 mins\n",
      "Epoch: 3 / 10, Batch: 87 (2816 / 12512), Elapsed time: 23.66 mins\n",
      "Enc Loss = 156.70, KL Divergence = 1155.40, Reconstruction Loss = 395.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.68 mins\n",
      "Epoch: 3 / 10, Batch: 88 (2848 / 12512), Elapsed time: 23.68 mins\n",
      "Enc Loss = 165.34, KL Divergence = 1095.52, Reconstruction Loss = 429.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.70 mins\n",
      "Epoch: 3 / 10, Batch: 89 (2880 / 12512), Elapsed time: 23.70 mins\n",
      "Enc Loss = 158.59, KL Divergence = 1183.57, Reconstruction Loss = 398.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.71 mins\n",
      "Epoch: 3 / 10, Batch: 90 (2912 / 12512), Elapsed time: 23.72 mins\n",
      "Enc Loss = 166.00, KL Divergence = 1178.85, Reconstruction Loss = 423.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.73 mins\n",
      "Epoch: 3 / 10, Batch: 91 (2944 / 12512), Elapsed time: 23.73 mins\n",
      "Enc Loss = 182.55, KL Divergence = 1207.52, Reconstruction Loss = 474.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.75 mins\n",
      "Epoch: 3 / 10, Batch: 92 (2976 / 12512), Elapsed time: 23.75 mins\n",
      "Enc Loss = 170.65, KL Divergence = 1244.10, Reconstruction Loss = 431.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.77 mins\n",
      "Epoch: 3 / 10, Batch: 93 (3008 / 12512), Elapsed time: 23.77 mins\n",
      "Enc Loss = 152.97, KL Divergence = 1053.79, Reconstruction Loss = 393.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.79 mins\n",
      "Epoch: 3 / 10, Batch: 94 (3040 / 12512), Elapsed time: 23.79 mins\n",
      "Enc Loss = 159.60, KL Divergence = 1187.38, Reconstruction Loss = 401.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.81 mins\n",
      "Epoch: 3 / 10, Batch: 95 (3072 / 12512), Elapsed time: 23.81 mins\n",
      "Enc Loss = 164.85, KL Divergence = 1125.09, Reconstruction Loss = 424.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.83 mins\n",
      "Epoch: 3 / 10, Batch: 96 (3104 / 12512), Elapsed time: 23.83 mins\n",
      "Enc Loss = 176.98, KL Divergence = 1264.74, Reconstruction Loss = 450.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.85 mins\n",
      "Epoch: 3 / 10, Batch: 97 (3136 / 12512), Elapsed time: 23.85 mins\n",
      "Enc Loss = 166.72, KL Divergence = 1268.66, Reconstruction Loss = 416.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.87 mins\n",
      "Epoch: 3 / 10, Batch: 98 (3168 / 12512), Elapsed time: 23.87 mins\n",
      "Enc Loss = 172.63, KL Divergence = 1368.99, Reconstruction Loss = 425.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.89 mins\n",
      "Epoch: 3 / 10, Batch: 99 (3200 / 12512), Elapsed time: 23.89 mins\n",
      "Enc Loss = 161.16, KL Divergence = 1207.29, Reconstruction Loss = 404.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.90 mins\n",
      "Epoch: 3 / 10, Batch: 100 (3232 / 12512), Elapsed time: 23.90 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 159.35, KL Divergence = 1173.36, Reconstruction Loss = 402.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.92 mins\n",
      "Epoch: 3 / 10, Batch: 101 (3264 / 12512), Elapsed time: 23.92 mins\n",
      "Enc Loss = 162.13, KL Divergence = 1122.60, Reconstruction Loss = 416.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.94 mins\n",
      "Epoch: 3 / 10, Batch: 102 (3296 / 12512), Elapsed time: 23.94 mins\n",
      "Enc Loss = 160.58, KL Divergence = 1168.76, Reconstruction Loss = 406.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.96 mins\n",
      "Epoch: 3 / 10, Batch: 103 (3328 / 12512), Elapsed time: 23.96 mins\n",
      "Enc Loss = 160.06, KL Divergence = 1155.40, Reconstruction Loss = 406.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 23.98 mins\n",
      "Epoch: 3 / 10, Batch: 104 (3360 / 12512), Elapsed time: 23.98 mins\n",
      "Enc Loss = 164.72, KL Divergence = 1199.16, Reconstruction Loss = 416.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.00 mins\n",
      "Epoch: 3 / 10, Batch: 105 (3392 / 12512), Elapsed time: 24.00 mins\n",
      "Enc Loss = 164.92, KL Divergence = 1182.97, Reconstruction Loss = 419.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.02 mins\n",
      "Epoch: 3 / 10, Batch: 106 (3424 / 12512), Elapsed time: 24.02 mins\n",
      "Enc Loss = 167.83, KL Divergence = 1308.16, Reconstruction Loss = 415.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.04 mins\n",
      "Epoch: 3 / 10, Batch: 107 (3456 / 12512), Elapsed time: 24.04 mins\n",
      "Enc Loss = 151.14, KL Divergence = 1155.13, Reconstruction Loss = 376.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.06 mins\n",
      "Epoch: 3 / 10, Batch: 108 (3488 / 12512), Elapsed time: 24.06 mins\n",
      "Enc Loss = 170.07, KL Divergence = 1234.72, Reconstruction Loss = 430.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.08 mins\n",
      "Epoch: 3 / 10, Batch: 109 (3520 / 12512), Elapsed time: 24.08 mins\n",
      "Enc Loss = 165.52, KL Divergence = 1259.39, Reconstruction Loss = 413.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.09 mins\n",
      "Epoch: 3 / 10, Batch: 110 (3552 / 12512), Elapsed time: 24.10 mins\n",
      "Enc Loss = 160.85, KL Divergence = 1272.12, Reconstruction Loss = 396.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.11 mins\n",
      "Epoch: 3 / 10, Batch: 111 (3584 / 12512), Elapsed time: 24.12 mins\n",
      "Enc Loss = 169.92, KL Divergence = 1316.02, Reconstruction Loss = 422.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.13 mins\n",
      "Epoch: 3 / 10, Batch: 112 (3616 / 12512), Elapsed time: 24.13 mins\n",
      "Enc Loss = 155.19, KL Divergence = 1274.77, Reconstruction Loss = 377.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.15 mins\n",
      "Epoch: 3 / 10, Batch: 113 (3648 / 12512), Elapsed time: 24.15 mins\n",
      "Enc Loss = 166.27, KL Divergence = 1272.95, Reconstruction Loss = 414.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.17 mins\n",
      "Epoch: 3 / 10, Batch: 114 (3680 / 12512), Elapsed time: 24.17 mins\n",
      "Enc Loss = 162.99, KL Divergence = 1264.57, Reconstruction Loss = 404.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.19 mins\n",
      "Epoch: 3 / 10, Batch: 115 (3712 / 12512), Elapsed time: 24.19 mins\n",
      "Enc Loss = 178.11, KL Divergence = 1392.82, Reconstruction Loss = 441.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.21 mins\n",
      "Epoch: 3 / 10, Batch: 116 (3744 / 12512), Elapsed time: 24.21 mins\n",
      "Enc Loss = 165.57, KL Divergence = 1315.62, Reconstruction Loss = 407.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.23 mins\n",
      "Epoch: 3 / 10, Batch: 117 (3776 / 12512), Elapsed time: 24.23 mins\n",
      "Enc Loss = 165.21, KL Divergence = 1311.82, Reconstruction Loss = 407.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.25 mins\n",
      "Epoch: 3 / 10, Batch: 118 (3808 / 12512), Elapsed time: 24.25 mins\n",
      "Enc Loss = 168.94, KL Divergence = 1264.20, Reconstruction Loss = 424.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.27 mins\n",
      "Epoch: 3 / 10, Batch: 119 (3840 / 12512), Elapsed time: 24.27 mins\n",
      "Enc Loss = 170.42, KL Divergence = 1244.17, Reconstruction Loss = 431.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.29 mins\n",
      "Epoch: 3 / 10, Batch: 120 (3872 / 12512), Elapsed time: 24.29 mins\n",
      "Enc Loss = 156.93, KL Divergence = 1300.95, Reconstruction Loss = 381.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.30 mins\n",
      "Epoch: 3 / 10, Batch: 121 (3904 / 12512), Elapsed time: 24.30 mins\n",
      "Enc Loss = 178.77, KL Divergence = 1343.46, Reconstruction Loss = 448.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.32 mins\n",
      "Epoch: 3 / 10, Batch: 122 (3936 / 12512), Elapsed time: 24.32 mins\n",
      "Enc Loss = 170.03, KL Divergence = 1222.91, Reconstruction Loss = 431.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.34 mins\n",
      "Epoch: 3 / 10, Batch: 123 (3968 / 12512), Elapsed time: 24.34 mins\n",
      "Enc Loss = 162.59, KL Divergence = 1336.81, Reconstruction Loss = 395.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.36 mins\n",
      "Epoch: 3 / 10, Batch: 124 (4000 / 12512), Elapsed time: 24.36 mins\n",
      "Enc Loss = 153.89, KL Divergence = 1183.21, Reconstruction Loss = 383.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.38 mins\n",
      "Epoch: 3 / 10, Batch: 125 (4032 / 12512), Elapsed time: 24.38 mins\n",
      "Enc Loss = 153.86, KL Divergence = 1262.70, Reconstruction Loss = 374.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.40 mins\n",
      "Epoch: 3 / 10, Batch: 126 (4064 / 12512), Elapsed time: 24.40 mins\n",
      "Enc Loss = 164.36, KL Divergence = 1168.89, Reconstruction Loss = 418.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.42 mins\n",
      "Epoch: 3 / 10, Batch: 127 (4096 / 12512), Elapsed time: 24.42 mins\n",
      "Enc Loss = 155.67, KL Divergence = 1141.08, Reconstruction Loss = 393.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.44 mins\n",
      "Epoch: 3 / 10, Batch: 128 (4128 / 12512), Elapsed time: 24.44 mins\n",
      "Enc Loss = 159.15, KL Divergence = 1052.63, Reconstruction Loss = 413.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.45 mins\n",
      "Epoch: 3 / 10, Batch: 129 (4160 / 12512), Elapsed time: 24.45 mins\n",
      "Enc Loss = 162.58, KL Divergence = 1115.67, Reconstruction Loss = 418.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.47 mins\n",
      "Epoch: 3 / 10, Batch: 130 (4192 / 12512), Elapsed time: 24.47 mins\n",
      "Enc Loss = 157.60, KL Divergence = 1119.23, Reconstruction Loss = 401.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.49 mins\n",
      "Epoch: 3 / 10, Batch: 131 (4224 / 12512), Elapsed time: 24.49 mins\n",
      "Enc Loss = 154.39, KL Divergence = 1116.68, Reconstruction Loss = 391.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.51 mins\n",
      "Epoch: 3 / 10, Batch: 132 (4256 / 12512), Elapsed time: 24.51 mins\n",
      "Enc Loss = 157.91, KL Divergence = 1029.11, Reconstruction Loss = 412.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.53 mins\n",
      "Epoch: 3 / 10, Batch: 133 (4288 / 12512), Elapsed time: 24.53 mins\n",
      "Enc Loss = 169.90, KL Divergence = 1139.92, Reconstruction Loss = 439.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.55 mins\n",
      "Epoch: 3 / 10, Batch: 134 (4320 / 12512), Elapsed time: 24.55 mins\n",
      "Enc Loss = 175.48, KL Divergence = 1143.12, Reconstruction Loss = 457.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.57 mins\n",
      "Epoch: 3 / 10, Batch: 135 (4352 / 12512), Elapsed time: 24.57 mins\n",
      "Enc Loss = 176.18, KL Divergence = 1257.65, Reconstruction Loss = 448.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.59 mins\n",
      "Epoch: 3 / 10, Batch: 136 (4384 / 12512), Elapsed time: 24.59 mins\n",
      "Enc Loss = 188.38, KL Divergence = 1453.67, Reconstruction Loss = 468.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.61 mins\n",
      "Epoch: 3 / 10, Batch: 137 (4416 / 12512), Elapsed time: 24.61 mins\n",
      "Enc Loss = 155.98, KL Divergence = 1273.42, Reconstruction Loss = 380.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.62 mins\n",
      "Epoch: 3 / 10, Batch: 138 (4448 / 12512), Elapsed time: 24.62 mins\n",
      "Enc Loss = 162.88, KL Divergence = 1256.55, Reconstruction Loss = 405.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.64 mins\n",
      "Epoch: 3 / 10, Batch: 139 (4480 / 12512), Elapsed time: 24.64 mins\n",
      "Enc Loss = 170.83, KL Divergence = 1459.95, Reconstruction Loss = 410.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.66 mins\n",
      "Epoch: 3 / 10, Batch: 140 (4512 / 12512), Elapsed time: 24.66 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 174.43, KL Divergence = 1348.77, Reconstruction Loss = 433.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.68 mins\n",
      "Epoch: 3 / 10, Batch: 141 (4544 / 12512), Elapsed time: 24.68 mins\n",
      "Enc Loss = 167.74, KL Divergence = 1363.72, Reconstruction Loss = 410.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.70 mins\n",
      "Epoch: 3 / 10, Batch: 142 (4576 / 12512), Elapsed time: 24.70 mins\n",
      "Enc Loss = 178.69, KL Divergence = 1328.97, Reconstruction Loss = 449.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.72 mins\n",
      "Epoch: 3 / 10, Batch: 143 (4608 / 12512), Elapsed time: 24.72 mins\n",
      "Enc Loss = 160.84, KL Divergence = 1270.86, Reconstruction Loss = 396.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.74 mins\n",
      "Epoch: 3 / 10, Batch: 144 (4640 / 12512), Elapsed time: 24.74 mins\n",
      "Enc Loss = 162.89, KL Divergence = 1252.81, Reconstruction Loss = 405.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.76 mins\n",
      "Epoch: 3 / 10, Batch: 145 (4672 / 12512), Elapsed time: 24.76 mins\n",
      "Enc Loss = 160.57, KL Divergence = 1203.84, Reconstruction Loss = 402.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.78 mins\n",
      "Epoch: 3 / 10, Batch: 146 (4704 / 12512), Elapsed time: 24.78 mins\n",
      "Enc Loss = 157.32, KL Divergence = 1158.76, Reconstruction Loss = 396.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.80 mins\n",
      "Epoch: 3 / 10, Batch: 147 (4736 / 12512), Elapsed time: 24.80 mins\n",
      "Enc Loss = 156.43, KL Divergence = 1145.42, Reconstruction Loss = 395.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.82 mins\n",
      "Epoch: 3 / 10, Batch: 148 (4768 / 12512), Elapsed time: 24.82 mins\n",
      "Enc Loss = 149.93, KL Divergence = 1010.54, Reconstruction Loss = 387.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.83 mins\n",
      "Epoch: 3 / 10, Batch: 149 (4800 / 12512), Elapsed time: 24.83 mins\n",
      "Enc Loss = 158.06, KL Divergence = 1082.35, Reconstruction Loss = 407.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.85 mins\n",
      "Epoch: 3 / 10, Batch: 150 (4832 / 12512), Elapsed time: 24.85 mins\n",
      "Enc Loss = 150.80, KL Divergence = 987.46, Reconstruction Loss = 393.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.87 mins\n",
      "Epoch: 3 / 10, Batch: 151 (4864 / 12512), Elapsed time: 24.87 mins\n",
      "Enc Loss = 149.51, KL Divergence = 1011.48, Reconstruction Loss = 386.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.89 mins\n",
      "Epoch: 3 / 10, Batch: 152 (4896 / 12512), Elapsed time: 24.89 mins\n",
      "Enc Loss = 177.24, KL Divergence = 1118.30, Reconstruction Loss = 466.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.91 mins\n",
      "Epoch: 3 / 10, Batch: 153 (4928 / 12512), Elapsed time: 24.91 mins\n",
      "Enc Loss = 182.46, KL Divergence = 1102.54, Reconstruction Loss = 484.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.93 mins\n",
      "Epoch: 3 / 10, Batch: 154 (4960 / 12512), Elapsed time: 24.93 mins\n",
      "Enc Loss = 140.55, KL Divergence = 1037.81, Reconstruction Loss = 354.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.95 mins\n",
      "Epoch: 3 / 10, Batch: 155 (4992 / 12512), Elapsed time: 24.95 mins\n",
      "Enc Loss = 153.34, KL Divergence = 1189.83, Reconstruction Loss = 380.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.97 mins\n",
      "Epoch: 3 / 10, Batch: 156 (5024 / 12512), Elapsed time: 24.97 mins\n",
      "Enc Loss = 152.55, KL Divergence = 1132.83, Reconstruction Loss = 383.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 24.99 mins\n",
      "Epoch: 3 / 10, Batch: 157 (5056 / 12512), Elapsed time: 24.99 mins\n",
      "Enc Loss = 155.01, KL Divergence = 1144.17, Reconstruction Loss = 390.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.01 mins\n",
      "Epoch: 3 / 10, Batch: 158 (5088 / 12512), Elapsed time: 25.01 mins\n",
      "Enc Loss = 173.48, KL Divergence = 1240.48, Reconstruction Loss = 441.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.03 mins\n",
      "Epoch: 3 / 10, Batch: 159 (5120 / 12512), Elapsed time: 25.03 mins\n",
      "Enc Loss = 176.54, KL Divergence = 1230.64, Reconstruction Loss = 452.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.04 mins\n",
      "Epoch: 3 / 10, Batch: 160 (5152 / 12512), Elapsed time: 25.05 mins\n",
      "Enc Loss = 166.69, KL Divergence = 1304.36, Reconstruction Loss = 412.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.06 mins\n",
      "Epoch: 3 / 10, Batch: 161 (5184 / 12512), Elapsed time: 25.06 mins\n",
      "Enc Loss = 158.77, KL Divergence = 1393.09, Reconstruction Loss = 377.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.08 mins\n",
      "Epoch: 3 / 10, Batch: 162 (5216 / 12512), Elapsed time: 25.08 mins\n",
      "Enc Loss = 152.47, KL Divergence = 1261.94, Reconstruction Loss = 370.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.10 mins\n",
      "Epoch: 3 / 10, Batch: 163 (5248 / 12512), Elapsed time: 25.10 mins\n",
      "Enc Loss = 168.37, KL Divergence = 1463.62, Reconstruction Loss = 401.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.12 mins\n",
      "Epoch: 3 / 10, Batch: 164 (5280 / 12512), Elapsed time: 25.12 mins\n",
      "Enc Loss = 175.28, KL Divergence = 1526.46, Reconstruction Loss = 418.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.14 mins\n",
      "Epoch: 3 / 10, Batch: 165 (5312 / 12512), Elapsed time: 25.14 mins\n",
      "Enc Loss = 154.77, KL Divergence = 1229.54, Reconstruction Loss = 381.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.16 mins\n",
      "Epoch: 3 / 10, Batch: 166 (5344 / 12512), Elapsed time: 25.16 mins\n",
      "Enc Loss = 157.80, KL Divergence = 1224.46, Reconstruction Loss = 391.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.18 mins\n",
      "Epoch: 3 / 10, Batch: 167 (5376 / 12512), Elapsed time: 25.18 mins\n",
      "Enc Loss = 151.10, KL Divergence = 1036.54, Reconstruction Loss = 388.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.19 mins\n",
      "Epoch: 3 / 10, Batch: 168 (5408 / 12512), Elapsed time: 25.19 mins\n",
      "Enc Loss = 180.84, KL Divergence = 1302.12, Reconstruction Loss = 459.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.21 mins\n",
      "Epoch: 3 / 10, Batch: 169 (5440 / 12512), Elapsed time: 25.21 mins\n",
      "Enc Loss = 164.58, KL Divergence = 1058.53, Reconstruction Loss = 430.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.23 mins\n",
      "Epoch: 3 / 10, Batch: 170 (5472 / 12512), Elapsed time: 25.23 mins\n",
      "Enc Loss = 153.06, KL Divergence = 1079.78, Reconstruction Loss = 390.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.25 mins\n",
      "Epoch: 3 / 10, Batch: 171 (5504 / 12512), Elapsed time: 25.25 mins\n",
      "Enc Loss = 174.68, KL Divergence = 1167.09, Reconstruction Loss = 452.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.27 mins\n",
      "Epoch: 3 / 10, Batch: 172 (5536 / 12512), Elapsed time: 25.27 mins\n",
      "Enc Loss = 167.51, KL Divergence = 1281.91, Reconstruction Loss = 417.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.29 mins\n",
      "Epoch: 3 / 10, Batch: 173 (5568 / 12512), Elapsed time: 25.29 mins\n",
      "Enc Loss = 165.25, KL Divergence = 1186.78, Reconstruction Loss = 419.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.31 mins\n",
      "Epoch: 3 / 10, Batch: 174 (5600 / 12512), Elapsed time: 25.31 mins\n",
      "Enc Loss = 171.53, KL Divergence = 1227.28, Reconstruction Loss = 436.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.33 mins\n",
      "Epoch: 3 / 10, Batch: 175 (5632 / 12512), Elapsed time: 25.33 mins\n",
      "Enc Loss = 156.44, KL Divergence = 1125.47, Reconstruction Loss = 397.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.35 mins\n",
      "Epoch: 3 / 10, Batch: 176 (5664 / 12512), Elapsed time: 25.35 mins\n",
      "Enc Loss = 164.86, KL Divergence = 1237.56, Reconstruction Loss = 413.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.36 mins\n",
      "Epoch: 3 / 10, Batch: 177 (5696 / 12512), Elapsed time: 25.37 mins\n",
      "Enc Loss = 159.72, KL Divergence = 1191.32, Reconstruction Loss = 401.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.38 mins\n",
      "Epoch: 3 / 10, Batch: 178 (5728 / 12512), Elapsed time: 25.38 mins\n",
      "Enc Loss = 159.13, KL Divergence = 1219.26, Reconstruction Loss = 396.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.40 mins\n",
      "Epoch: 3 / 10, Batch: 179 (5760 / 12512), Elapsed time: 25.40 mins\n",
      "Enc Loss = 159.71, KL Divergence = 1180.69, Reconstruction Loss = 402.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.42 mins\n",
      "Epoch: 3 / 10, Batch: 180 (5792 / 12512), Elapsed time: 25.42 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 172.68, KL Divergence = 1216.09, Reconstruction Loss = 441.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.44 mins\n",
      "Epoch: 3 / 10, Batch: 181 (5824 / 12512), Elapsed time: 25.44 mins\n",
      "Enc Loss = 160.40, KL Divergence = 1235.06, Reconstruction Loss = 399.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.46 mins\n",
      "Epoch: 3 / 10, Batch: 182 (5856 / 12512), Elapsed time: 25.46 mins\n",
      "Enc Loss = 156.03, KL Divergence = 1289.25, Reconstruction Loss = 379.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.48 mins\n",
      "Epoch: 3 / 10, Batch: 183 (5888 / 12512), Elapsed time: 25.48 mins\n",
      "Enc Loss = 150.87, KL Divergence = 1153.57, Reconstruction Loss = 376.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.50 mins\n",
      "Epoch: 3 / 10, Batch: 184 (5920 / 12512), Elapsed time: 25.50 mins\n",
      "Enc Loss = 180.66, KL Divergence = 1489.55, Reconstruction Loss = 439.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.52 mins\n",
      "Epoch: 3 / 10, Batch: 185 (5952 / 12512), Elapsed time: 25.52 mins\n",
      "Enc Loss = 151.99, KL Divergence = 1238.82, Reconstruction Loss = 371.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.54 mins\n",
      "Epoch: 3 / 10, Batch: 186 (5984 / 12512), Elapsed time: 25.54 mins\n",
      "Enc Loss = 158.48, KL Divergence = 1253.83, Reconstruction Loss = 390.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.55 mins\n",
      "Epoch: 3 / 10, Batch: 187 (6016 / 12512), Elapsed time: 25.55 mins\n",
      "Enc Loss = 172.78, KL Divergence = 1454.08, Reconstruction Loss = 417.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.57 mins\n",
      "Epoch: 3 / 10, Batch: 188 (6048 / 12512), Elapsed time: 25.57 mins\n",
      "Enc Loss = 162.83, KL Divergence = 1170.29, Reconstruction Loss = 413.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.59 mins\n",
      "Epoch: 3 / 10, Batch: 189 (6080 / 12512), Elapsed time: 25.59 mins\n",
      "Enc Loss = 149.09, KL Divergence = 1198.77, Reconstruction Loss = 365.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.61 mins\n",
      "Epoch: 3 / 10, Batch: 190 (6112 / 12512), Elapsed time: 25.61 mins\n",
      "Enc Loss = 167.49, KL Divergence = 1171.42, Reconstruction Loss = 428.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.63 mins\n",
      "Epoch: 3 / 10, Batch: 191 (6144 / 12512), Elapsed time: 25.63 mins\n",
      "Enc Loss = 156.99, KL Divergence = 1243.33, Reconstruction Loss = 387.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.65 mins\n",
      "Epoch: 3 / 10, Batch: 192 (6176 / 12512), Elapsed time: 25.65 mins\n",
      "Enc Loss = 159.63, KL Divergence = 1317.97, Reconstruction Loss = 388.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.67 mins\n",
      "Epoch: 3 / 10, Batch: 193 (6208 / 12512), Elapsed time: 25.67 mins\n",
      "Enc Loss = 153.02, KL Divergence = 1267.29, Reconstruction Loss = 371.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.69 mins\n",
      "Epoch: 3 / 10, Batch: 194 (6240 / 12512), Elapsed time: 25.69 mins\n",
      "Enc Loss = 167.04, KL Divergence = 1294.30, Reconstruction Loss = 414.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.71 mins\n",
      "Epoch: 3 / 10, Batch: 195 (6272 / 12512), Elapsed time: 25.71 mins\n",
      "Enc Loss = 152.07, KL Divergence = 1120.27, Reconstruction Loss = 383.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.73 mins\n",
      "Epoch: 3 / 10, Batch: 196 (6304 / 12512), Elapsed time: 25.73 mins\n",
      "Enc Loss = 157.61, KL Divergence = 1160.65, Reconstruction Loss = 397.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.74 mins\n",
      "Epoch: 3 / 10, Batch: 197 (6336 / 12512), Elapsed time: 25.74 mins\n",
      "Enc Loss = 149.14, KL Divergence = 1091.26, Reconstruction Loss = 376.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.76 mins\n",
      "Epoch: 3 / 10, Batch: 198 (6368 / 12512), Elapsed time: 25.76 mins\n",
      "Enc Loss = 152.82, KL Divergence = 1126.93, Reconstruction Loss = 385.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.78 mins\n",
      "Epoch: 3 / 10, Batch: 199 (6400 / 12512), Elapsed time: 25.78 mins\n",
      "Enc Loss = 182.11, KL Divergence = 1173.01, Reconstruction Loss = 476.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.80 mins\n",
      "Epoch: 3 / 10, Batch: 200 (6432 / 12512), Elapsed time: 25.80 mins\n",
      "Enc Loss = 152.84, KL Divergence = 1075.65, Reconstruction Loss = 390.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.82 mins\n",
      "Epoch: 3 / 10, Batch: 201 (6464 / 12512), Elapsed time: 25.82 mins\n",
      "Enc Loss = 164.78, KL Divergence = 1154.26, Reconstruction Loss = 421.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.84 mins\n",
      "Epoch: 3 / 10, Batch: 202 (6496 / 12512), Elapsed time: 25.84 mins\n",
      "Enc Loss = 150.85, KL Divergence = 1038.13, Reconstruction Loss = 387.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.86 mins\n",
      "Epoch: 3 / 10, Batch: 203 (6528 / 12512), Elapsed time: 25.86 mins\n",
      "Enc Loss = 150.00, KL Divergence = 1051.95, Reconstruction Loss = 383.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.87 mins\n",
      "Epoch: 3 / 10, Batch: 204 (6560 / 12512), Elapsed time: 25.88 mins\n",
      "Enc Loss = 155.56, KL Divergence = 909.95, Reconstruction Loss = 416.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.89 mins\n",
      "Epoch: 3 / 10, Batch: 205 (6592 / 12512), Elapsed time: 25.89 mins\n",
      "Enc Loss = 155.24, KL Divergence = 1117.15, Reconstruction Loss = 394.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.91 mins\n",
      "Epoch: 3 / 10, Batch: 206 (6624 / 12512), Elapsed time: 25.91 mins\n",
      "Enc Loss = 175.05, KL Divergence = 1224.53, Reconstruction Loss = 448.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.93 mins\n",
      "Epoch: 3 / 10, Batch: 207 (6656 / 12512), Elapsed time: 25.93 mins\n",
      "Enc Loss = 174.50, KL Divergence = 1147.97, Reconstruction Loss = 454.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.95 mins\n",
      "Epoch: 3 / 10, Batch: 208 (6688 / 12512), Elapsed time: 25.95 mins\n",
      "Enc Loss = 164.01, KL Divergence = 1110.05, Reconstruction Loss = 423.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.97 mins\n",
      "Epoch: 3 / 10, Batch: 209 (6720 / 12512), Elapsed time: 25.97 mins\n",
      "Enc Loss = 161.48, KL Divergence = 1243.18, Reconstruction Loss = 401.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 25.99 mins\n",
      "Epoch: 3 / 10, Batch: 210 (6752 / 12512), Elapsed time: 25.99 mins\n",
      "Enc Loss = 155.90, KL Divergence = 1180.94, Reconstruction Loss = 389.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.01 mins\n",
      "Epoch: 3 / 10, Batch: 211 (6784 / 12512), Elapsed time: 26.01 mins\n",
      "Enc Loss = 147.78, KL Divergence = 1164.88, Reconstruction Loss = 364.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.03 mins\n",
      "Epoch: 3 / 10, Batch: 212 (6816 / 12512), Elapsed time: 26.03 mins\n",
      "Enc Loss = 160.65, KL Divergence = 1244.75, Reconstruction Loss = 398.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.04 mins\n",
      "Epoch: 3 / 10, Batch: 213 (6848 / 12512), Elapsed time: 26.04 mins\n",
      "Enc Loss = 163.16, KL Divergence = 1337.00, Reconstruction Loss = 397.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.06 mins\n",
      "Epoch: 3 / 10, Batch: 214 (6880 / 12512), Elapsed time: 26.06 mins\n",
      "Enc Loss = 163.88, KL Divergence = 1236.25, Reconstruction Loss = 410.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.08 mins\n",
      "Epoch: 3 / 10, Batch: 215 (6912 / 12512), Elapsed time: 26.08 mins\n",
      "Enc Loss = 184.35, KL Divergence = 1179.82, Reconstruction Loss = 483.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.10 mins\n",
      "Epoch: 3 / 10, Batch: 216 (6944 / 12512), Elapsed time: 26.10 mins\n",
      "Enc Loss = 152.35, KL Divergence = 1211.22, Reconstruction Loss = 375.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.12 mins\n",
      "Epoch: 3 / 10, Batch: 217 (6976 / 12512), Elapsed time: 26.12 mins\n",
      "Enc Loss = 157.36, KL Divergence = 1284.40, Reconstruction Loss = 384.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.14 mins\n",
      "Epoch: 3 / 10, Batch: 218 (7008 / 12512), Elapsed time: 26.14 mins\n",
      "Enc Loss = 170.87, KL Divergence = 1402.74, Reconstruction Loss = 416.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.16 mins\n",
      "Epoch: 3 / 10, Batch: 219 (7040 / 12512), Elapsed time: 26.16 mins\n",
      "Enc Loss = 160.71, KL Divergence = 1343.44, Reconstruction Loss = 389.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.18 mins\n",
      "Epoch: 3 / 10, Batch: 220 (7072 / 12512), Elapsed time: 26.18 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 165.96, KL Divergence = 1293.82, Reconstruction Loss = 411.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.20 mins\n",
      "Epoch: 3 / 10, Batch: 221 (7104 / 12512), Elapsed time: 26.20 mins\n",
      "Enc Loss = 159.81, KL Divergence = 1263.02, Reconstruction Loss = 394.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.21 mins\n",
      "Epoch: 3 / 10, Batch: 222 (7136 / 12512), Elapsed time: 26.21 mins\n",
      "Enc Loss = 153.35, KL Divergence = 1231.49, Reconstruction Loss = 376.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.23 mins\n",
      "Epoch: 3 / 10, Batch: 223 (7168 / 12512), Elapsed time: 26.23 mins\n",
      "Enc Loss = 153.48, KL Divergence = 1184.57, Reconstruction Loss = 381.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.25 mins\n",
      "Epoch: 3 / 10, Batch: 224 (7200 / 12512), Elapsed time: 26.25 mins\n",
      "Enc Loss = 151.10, KL Divergence = 1135.19, Reconstruction Loss = 378.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.27 mins\n",
      "Epoch: 3 / 10, Batch: 225 (7232 / 12512), Elapsed time: 26.27 mins\n",
      "Enc Loss = 170.41, KL Divergence = 1181.84, Reconstruction Loss = 437.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.29 mins\n",
      "Epoch: 3 / 10, Batch: 226 (7264 / 12512), Elapsed time: 26.29 mins\n",
      "Enc Loss = 165.20, KL Divergence = 1237.84, Reconstruction Loss = 414.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.31 mins\n",
      "Epoch: 3 / 10, Batch: 227 (7296 / 12512), Elapsed time: 26.31 mins\n",
      "Enc Loss = 137.75, KL Divergence = 1029.36, Reconstruction Loss = 345.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.33 mins\n",
      "Epoch: 3 / 10, Batch: 228 (7328 / 12512), Elapsed time: 26.33 mins\n",
      "Enc Loss = 152.36, KL Divergence = 1132.89, Reconstruction Loss = 383.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.35 mins\n",
      "Epoch: 3 / 10, Batch: 229 (7360 / 12512), Elapsed time: 26.35 mins\n",
      "Enc Loss = 155.35, KL Divergence = 1127.79, Reconstruction Loss = 393.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.37 mins\n",
      "Epoch: 3 / 10, Batch: 230 (7392 / 12512), Elapsed time: 26.37 mins\n",
      "Enc Loss = 180.34, KL Divergence = 1211.82, Reconstruction Loss = 466.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.38 mins\n",
      "Epoch: 3 / 10, Batch: 231 (7424 / 12512), Elapsed time: 26.39 mins\n",
      "Enc Loss = 159.03, KL Divergence = 1118.87, Reconstruction Loss = 406.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.40 mins\n",
      "Epoch: 3 / 10, Batch: 232 (7456 / 12512), Elapsed time: 26.40 mins\n",
      "Enc Loss = 150.09, KL Divergence = 1126.42, Reconstruction Loss = 376.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.42 mins\n",
      "Epoch: 3 / 10, Batch: 233 (7488 / 12512), Elapsed time: 26.42 mins\n",
      "Enc Loss = 157.87, KL Divergence = 1128.52, Reconstruction Loss = 401.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.44 mins\n",
      "Epoch: 3 / 10, Batch: 234 (7520 / 12512), Elapsed time: 26.44 mins\n",
      "Enc Loss = 149.96, KL Divergence = 1150.97, Reconstruction Loss = 373.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.46 mins\n",
      "Epoch: 3 / 10, Batch: 235 (7552 / 12512), Elapsed time: 26.46 mins\n",
      "Enc Loss = 148.35, KL Divergence = 1182.46, Reconstruction Loss = 365.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.48 mins\n",
      "Epoch: 3 / 10, Batch: 236 (7584 / 12512), Elapsed time: 26.48 mins\n",
      "Enc Loss = 167.03, KL Divergence = 1301.99, Reconstruction Loss = 414.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.50 mins\n",
      "Epoch: 3 / 10, Batch: 237 (7616 / 12512), Elapsed time: 26.50 mins\n",
      "Enc Loss = 150.27, KL Divergence = 1175.04, Reconstruction Loss = 372.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.52 mins\n",
      "Epoch: 3 / 10, Batch: 238 (7648 / 12512), Elapsed time: 26.52 mins\n",
      "Enc Loss = 162.36, KL Divergence = 1195.50, Reconstruction Loss = 409.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.54 mins\n",
      "Epoch: 3 / 10, Batch: 239 (7680 / 12512), Elapsed time: 26.54 mins\n",
      "Enc Loss = 163.56, KL Divergence = 1277.20, Reconstruction Loss = 405.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.56 mins\n",
      "Epoch: 3 / 10, Batch: 240 (7712 / 12512), Elapsed time: 26.56 mins\n",
      "Enc Loss = 163.69, KL Divergence = 1328.54, Reconstruction Loss = 400.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.58 mins\n",
      "Epoch: 3 / 10, Batch: 241 (7744 / 12512), Elapsed time: 26.58 mins\n",
      "Enc Loss = 160.58, KL Divergence = 1178.47, Reconstruction Loss = 405.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.59 mins\n",
      "Epoch: 3 / 10, Batch: 242 (7776 / 12512), Elapsed time: 26.59 mins\n",
      "Enc Loss = 191.74, KL Divergence = 1274.12, Reconstruction Loss = 497.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.61 mins\n",
      "Epoch: 3 / 10, Batch: 243 (7808 / 12512), Elapsed time: 26.61 mins\n",
      "Enc Loss = 173.35, KL Divergence = 1400.38, Reconstruction Loss = 424.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.63 mins\n",
      "Epoch: 3 / 10, Batch: 244 (7840 / 12512), Elapsed time: 26.63 mins\n",
      "Enc Loss = 150.12, KL Divergence = 1198.23, Reconstruction Loss = 369.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.65 mins\n",
      "Epoch: 3 / 10, Batch: 245 (7872 / 12512), Elapsed time: 26.65 mins\n",
      "Enc Loss = 153.55, KL Divergence = 1186.28, Reconstruction Loss = 381.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.67 mins\n",
      "Epoch: 3 / 10, Batch: 246 (7904 / 12512), Elapsed time: 26.67 mins\n",
      "Enc Loss = 153.46, KL Divergence = 1289.68, Reconstruction Loss = 370.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.69 mins\n",
      "Epoch: 3 / 10, Batch: 247 (7936 / 12512), Elapsed time: 26.69 mins\n",
      "Enc Loss = 143.15, KL Divergence = 1109.59, Reconstruction Loss = 355.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.71 mins\n",
      "Epoch: 3 / 10, Batch: 248 (7968 / 12512), Elapsed time: 26.71 mins\n",
      "Enc Loss = 153.77, KL Divergence = 1239.36, Reconstruction Loss = 376.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.73 mins\n",
      "Epoch: 3 / 10, Batch: 249 (8000 / 12512), Elapsed time: 26.73 mins\n",
      "Enc Loss = 162.31, KL Divergence = 1271.18, Reconstruction Loss = 401.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.74 mins\n",
      "Epoch: 3 / 10, Batch: 250 (8032 / 12512), Elapsed time: 26.74 mins\n",
      "Enc Loss = 167.77, KL Divergence = 1175.33, Reconstruction Loss = 429.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.76 mins\n",
      "Epoch: 3 / 10, Batch: 251 (8064 / 12512), Elapsed time: 26.76 mins\n",
      "Enc Loss = 145.51, KL Divergence = 1129.29, Reconstruction Loss = 361.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.78 mins\n",
      "Epoch: 3 / 10, Batch: 252 (8096 / 12512), Elapsed time: 26.78 mins\n",
      "Enc Loss = 161.88, KL Divergence = 1131.88, Reconstruction Loss = 414.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.80 mins\n",
      "Epoch: 3 / 10, Batch: 253 (8128 / 12512), Elapsed time: 26.80 mins\n",
      "Enc Loss = 149.37, KL Divergence = 1122.42, Reconstruction Loss = 374.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.82 mins\n",
      "Epoch: 3 / 10, Batch: 254 (8160 / 12512), Elapsed time: 26.82 mins\n",
      "Enc Loss = 154.45, KL Divergence = 1049.46, Reconstruction Loss = 398.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.84 mins\n",
      "Epoch: 3 / 10, Batch: 255 (8192 / 12512), Elapsed time: 26.84 mins\n",
      "Enc Loss = 181.86, KL Divergence = 1170.68, Reconstruction Loss = 476.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.86 mins\n",
      "Epoch: 3 / 10, Batch: 256 (8224 / 12512), Elapsed time: 26.86 mins\n",
      "Enc Loss = 165.07, KL Divergence = 1354.35, Reconstruction Loss = 402.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.88 mins\n",
      "Epoch: 3 / 10, Batch: 257 (8256 / 12512), Elapsed time: 26.88 mins\n",
      "Enc Loss = 168.75, KL Divergence = 1296.90, Reconstruction Loss = 420.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.90 mins\n",
      "Epoch: 3 / 10, Batch: 258 (8288 / 12512), Elapsed time: 26.90 mins\n",
      "Enc Loss = 150.96, KL Divergence = 1312.34, Reconstruction Loss = 360.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.92 mins\n",
      "Epoch: 3 / 10, Batch: 259 (8320 / 12512), Elapsed time: 26.92 mins\n",
      "Enc Loss = 151.03, KL Divergence = 1291.16, Reconstruction Loss = 362.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.93 mins\n",
      "Epoch: 3 / 10, Batch: 260 (8352 / 12512), Elapsed time: 26.94 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 174.57, KL Divergence = 1545.34, Reconstruction Loss = 413.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.95 mins\n",
      "Epoch: 3 / 10, Batch: 261 (8384 / 12512), Elapsed time: 26.95 mins\n",
      "Enc Loss = 157.08, KL Divergence = 1311.07, Reconstruction Loss = 380.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.97 mins\n",
      "Epoch: 3 / 10, Batch: 262 (8416 / 12512), Elapsed time: 26.97 mins\n",
      "Enc Loss = 188.56, KL Divergence = 1560.54, Reconstruction Loss = 458.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 26.99 mins\n",
      "Epoch: 3 / 10, Batch: 263 (8448 / 12512), Elapsed time: 26.99 mins\n",
      "Enc Loss = 152.46, KL Divergence = 1348.58, Reconstruction Loss = 361.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.01 mins\n",
      "Epoch: 3 / 10, Batch: 264 (8480 / 12512), Elapsed time: 27.01 mins\n",
      "Enc Loss = 178.46, KL Divergence = 1371.05, Reconstruction Loss = 444.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.03 mins\n",
      "Epoch: 3 / 10, Batch: 265 (8512 / 12512), Elapsed time: 27.03 mins\n",
      "Enc Loss = 160.54, KL Divergence = 1337.69, Reconstruction Loss = 389.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.05 mins\n",
      "Epoch: 3 / 10, Batch: 266 (8544 / 12512), Elapsed time: 27.05 mins\n",
      "Enc Loss = 159.24, KL Divergence = 1240.72, Reconstruction Loss = 394.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.07 mins\n",
      "Epoch: 3 / 10, Batch: 267 (8576 / 12512), Elapsed time: 27.07 mins\n",
      "Enc Loss = 157.19, KL Divergence = 1227.22, Reconstruction Loss = 389.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.09 mins\n",
      "Epoch: 3 / 10, Batch: 268 (8608 / 12512), Elapsed time: 27.09 mins\n",
      "Enc Loss = 150.37, KL Divergence = 1263.84, Reconstruction Loss = 363.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.11 mins\n",
      "Epoch: 3 / 10, Batch: 269 (8640 / 12512), Elapsed time: 27.11 mins\n",
      "Enc Loss = 160.13, KL Divergence = 1148.54, Reconstruction Loss = 407.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.13 mins\n",
      "Epoch: 3 / 10, Batch: 270 (8672 / 12512), Elapsed time: 27.13 mins\n",
      "Enc Loss = 157.53, KL Divergence = 1195.93, Reconstruction Loss = 393.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.15 mins\n",
      "Epoch: 3 / 10, Batch: 271 (8704 / 12512), Elapsed time: 27.15 mins\n",
      "Enc Loss = 157.95, KL Divergence = 1113.80, Reconstruction Loss = 403.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.17 mins\n",
      "Epoch: 3 / 10, Batch: 272 (8736 / 12512), Elapsed time: 27.17 mins\n",
      "Enc Loss = 184.95, KL Divergence = 1146.42, Reconstruction Loss = 488.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.19 mins\n",
      "Epoch: 3 / 10, Batch: 273 (8768 / 12512), Elapsed time: 27.19 mins\n",
      "Enc Loss = 174.75, KL Divergence = 1143.76, Reconstruction Loss = 455.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.20 mins\n",
      "Epoch: 3 / 10, Batch: 274 (8800 / 12512), Elapsed time: 27.20 mins\n",
      "Enc Loss = 155.69, KL Divergence = 1033.48, Reconstruction Loss = 404.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.22 mins\n",
      "Epoch: 3 / 10, Batch: 275 (8832 / 12512), Elapsed time: 27.22 mins\n",
      "Enc Loss = 158.83, KL Divergence = 1129.89, Reconstruction Loss = 404.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.24 mins\n",
      "Epoch: 3 / 10, Batch: 276 (8864 / 12512), Elapsed time: 27.24 mins\n",
      "Enc Loss = 166.92, KL Divergence = 1274.45, Reconstruction Loss = 416.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.26 mins\n",
      "Epoch: 3 / 10, Batch: 277 (8896 / 12512), Elapsed time: 27.26 mins\n",
      "Enc Loss = 160.84, KL Divergence = 1198.06, Reconstruction Loss = 404.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.28 mins\n",
      "Epoch: 3 / 10, Batch: 278 (8928 / 12512), Elapsed time: 27.28 mins\n",
      "Enc Loss = 153.78, KL Divergence = 1259.29, Reconstruction Loss = 374.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.30 mins\n",
      "Epoch: 3 / 10, Batch: 279 (8960 / 12512), Elapsed time: 27.30 mins\n",
      "Enc Loss = 161.24, KL Divergence = 1355.69, Reconstruction Loss = 389.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.32 mins\n",
      "Epoch: 3 / 10, Batch: 280 (8992 / 12512), Elapsed time: 27.32 mins\n",
      "Enc Loss = 175.21, KL Divergence = 1329.56, Reconstruction Loss = 437.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.34 mins\n",
      "Epoch: 3 / 10, Batch: 281 (9024 / 12512), Elapsed time: 27.34 mins\n",
      "Enc Loss = 163.56, KL Divergence = 1291.79, Reconstruction Loss = 403.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.36 mins\n",
      "Epoch: 3 / 10, Batch: 282 (9056 / 12512), Elapsed time: 27.36 mins\n",
      "Enc Loss = 163.47, KL Divergence = 1241.20, Reconstruction Loss = 408.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.38 mins\n",
      "Epoch: 3 / 10, Batch: 283 (9088 / 12512), Elapsed time: 27.38 mins\n",
      "Enc Loss = 150.04, KL Divergence = 1203.01, Reconstruction Loss = 368.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.40 mins\n",
      "Epoch: 3 / 10, Batch: 284 (9120 / 12512), Elapsed time: 27.40 mins\n",
      "Enc Loss = 173.21, KL Divergence = 1355.81, Reconstruction Loss = 428.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.41 mins\n",
      "Epoch: 3 / 10, Batch: 285 (9152 / 12512), Elapsed time: 27.42 mins\n",
      "Enc Loss = 152.27, KL Divergence = 1177.04, Reconstruction Loss = 378.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.43 mins\n",
      "Epoch: 3 / 10, Batch: 286 (9184 / 12512), Elapsed time: 27.43 mins\n",
      "Enc Loss = 167.74, KL Divergence = 1238.15, Reconstruction Loss = 422.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.45 mins\n",
      "Epoch: 3 / 10, Batch: 287 (9216 / 12512), Elapsed time: 27.45 mins\n",
      "Enc Loss = 143.37, KL Divergence = 1106.17, Reconstruction Loss = 356.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.47 mins\n",
      "Epoch: 3 / 10, Batch: 288 (9248 / 12512), Elapsed time: 27.47 mins\n",
      "Enc Loss = 153.64, KL Divergence = 1090.77, Reconstruction Loss = 391.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.49 mins\n",
      "Epoch: 3 / 10, Batch: 289 (9280 / 12512), Elapsed time: 27.49 mins\n",
      "Enc Loss = 153.05, KL Divergence = 1161.80, Reconstruction Loss = 382.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.51 mins\n",
      "Epoch: 3 / 10, Batch: 290 (9312 / 12512), Elapsed time: 27.51 mins\n",
      "Enc Loss = 145.36, KL Divergence = 1062.75, Reconstruction Loss = 367.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.53 mins\n",
      "Epoch: 3 / 10, Batch: 291 (9344 / 12512), Elapsed time: 27.53 mins\n",
      "Enc Loss = 170.70, KL Divergence = 1200.72, Reconstruction Loss = 436.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.55 mins\n",
      "Epoch: 3 / 10, Batch: 292 (9376 / 12512), Elapsed time: 27.55 mins\n",
      "Enc Loss = 162.67, KL Divergence = 1184.25, Reconstruction Loss = 411.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.57 mins\n",
      "Epoch: 3 / 10, Batch: 293 (9408 / 12512), Elapsed time: 27.57 mins\n",
      "Enc Loss = 144.07, KL Divergence = 1129.42, Reconstruction Loss = 356.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.59 mins\n",
      "Epoch: 3 / 10, Batch: 294 (9440 / 12512), Elapsed time: 27.59 mins\n",
      "Enc Loss = 167.60, KL Divergence = 1226.72, Reconstruction Loss = 423.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.61 mins\n",
      "Epoch: 3 / 10, Batch: 295 (9472 / 12512), Elapsed time: 27.61 mins\n",
      "Enc Loss = 155.01, KL Divergence = 1185.68, Reconstruction Loss = 386.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.62 mins\n",
      "Epoch: 3 / 10, Batch: 296 (9504 / 12512), Elapsed time: 27.62 mins\n",
      "Enc Loss = 158.15, KL Divergence = 1179.87, Reconstruction Loss = 397.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.64 mins\n",
      "Epoch: 3 / 10, Batch: 297 (9536 / 12512), Elapsed time: 27.64 mins\n",
      "Enc Loss = 179.32, KL Divergence = 1305.62, Reconstruction Loss = 453.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.66 mins\n",
      "Epoch: 3 / 10, Batch: 298 (9568 / 12512), Elapsed time: 27.66 mins\n",
      "Enc Loss = 168.41, KL Divergence = 1165.30, Reconstruction Loss = 432.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.68 mins\n",
      "Epoch: 3 / 10, Batch: 299 (9600 / 12512), Elapsed time: 27.68 mins\n",
      "Enc Loss = 182.93, KL Divergence = 1323.46, Reconstruction Loss = 463.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.70 mins\n",
      "Epoch: 3 / 10, Batch: 300 (9632 / 12512), Elapsed time: 27.70 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 158.90, KL Divergence = 1313.87, Reconstruction Loss = 386.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.72 mins\n",
      "Epoch: 3 / 10, Batch: 301 (9664 / 12512), Elapsed time: 27.72 mins\n",
      "Enc Loss = 163.00, KL Divergence = 1388.65, Reconstruction Loss = 391.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.74 mins\n",
      "Epoch: 3 / 10, Batch: 302 (9696 / 12512), Elapsed time: 27.74 mins\n",
      "Enc Loss = 168.86, KL Divergence = 1404.57, Reconstruction Loss = 409.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.76 mins\n",
      "Epoch: 3 / 10, Batch: 303 (9728 / 12512), Elapsed time: 27.76 mins\n",
      "Enc Loss = 159.39, KL Divergence = 1339.87, Reconstruction Loss = 385.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.78 mins\n",
      "Epoch: 3 / 10, Batch: 304 (9760 / 12512), Elapsed time: 27.78 mins\n",
      "Enc Loss = 162.40, KL Divergence = 1251.23, Reconstruction Loss = 404.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.80 mins\n",
      "Epoch: 3 / 10, Batch: 305 (9792 / 12512), Elapsed time: 27.80 mins\n",
      "Enc Loss = 157.04, KL Divergence = 1181.56, Reconstruction Loss = 393.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.81 mins\n",
      "Epoch: 3 / 10, Batch: 306 (9824 / 12512), Elapsed time: 27.81 mins\n",
      "Enc Loss = 155.75, KL Divergence = 1205.44, Reconstruction Loss = 386.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.83 mins\n",
      "Epoch: 3 / 10, Batch: 307 (9856 / 12512), Elapsed time: 27.83 mins\n",
      "Enc Loss = 167.24, KL Divergence = 1153.87, Reconstruction Loss = 429.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.85 mins\n",
      "Epoch: 3 / 10, Batch: 308 (9888 / 12512), Elapsed time: 27.85 mins\n",
      "Enc Loss = 147.82, KL Divergence = 1135.65, Reconstruction Loss = 368.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.87 mins\n",
      "Epoch: 3 / 10, Batch: 309 (9920 / 12512), Elapsed time: 27.87 mins\n",
      "Enc Loss = 166.06, KL Divergence = 1227.10, Reconstruction Loss = 418.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.89 mins\n",
      "Epoch: 3 / 10, Batch: 310 (9952 / 12512), Elapsed time: 27.89 mins\n",
      "Enc Loss = 150.19, KL Divergence = 1096.27, Reconstruction Loss = 379.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.91 mins\n",
      "Epoch: 3 / 10, Batch: 311 (9984 / 12512), Elapsed time: 27.91 mins\n",
      "Enc Loss = 155.63, KL Divergence = 1078.14, Reconstruction Loss = 399.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.93 mins\n",
      "Epoch: 3 / 10, Batch: 312 (10016 / 12512), Elapsed time: 27.93 mins\n",
      "Enc Loss = 145.92, KL Divergence = 1064.99, Reconstruction Loss = 369.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.95 mins\n",
      "Epoch: 3 / 10, Batch: 313 (10048 / 12512), Elapsed time: 27.95 mins\n",
      "Enc Loss = 159.56, KL Divergence = 1081.90, Reconstruction Loss = 412.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.97 mins\n",
      "Epoch: 3 / 10, Batch: 314 (10080 / 12512), Elapsed time: 27.97 mins\n",
      "Enc Loss = 161.19, KL Divergence = 1091.73, Reconstruction Loss = 416.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 27.99 mins\n",
      "Epoch: 3 / 10, Batch: 315 (10112 / 12512), Elapsed time: 27.99 mins\n",
      "Enc Loss = 168.58, KL Divergence = 1185.16, Reconstruction Loss = 431.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.01 mins\n",
      "Epoch: 3 / 10, Batch: 316 (10144 / 12512), Elapsed time: 28.01 mins\n",
      "Enc Loss = 183.20, KL Divergence = 1063.46, Reconstruction Loss = 491.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.03 mins\n",
      "Epoch: 3 / 10, Batch: 317 (10176 / 12512), Elapsed time: 28.03 mins\n",
      "Enc Loss = 158.72, KL Divergence = 1226.41, Reconstruction Loss = 394.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.04 mins\n",
      "Epoch: 3 / 10, Batch: 318 (10208 / 12512), Elapsed time: 28.04 mins\n",
      "Enc Loss = 154.85, KL Divergence = 1208.57, Reconstruction Loss = 383.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.06 mins\n",
      "Epoch: 3 / 10, Batch: 319 (10240 / 12512), Elapsed time: 28.06 mins\n",
      "Enc Loss = 151.25, KL Divergence = 1227.02, Reconstruction Loss = 369.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.08 mins\n",
      "Epoch: 3 / 10, Batch: 320 (10272 / 12512), Elapsed time: 28.08 mins\n",
      "Enc Loss = 170.58, KL Divergence = 1419.46, Reconstruction Loss = 413.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.10 mins\n",
      "Epoch: 3 / 10, Batch: 321 (10304 / 12512), Elapsed time: 28.10 mins\n",
      "Enc Loss = 174.81, KL Divergence = 1392.93, Reconstruction Loss = 430.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.12 mins\n",
      "Epoch: 3 / 10, Batch: 322 (10336 / 12512), Elapsed time: 28.12 mins\n",
      "Enc Loss = 171.01, KL Divergence = 1381.59, Reconstruction Loss = 418.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.14 mins\n",
      "Epoch: 3 / 10, Batch: 323 (10368 / 12512), Elapsed time: 28.14 mins\n",
      "Enc Loss = 163.74, KL Divergence = 1340.91, Reconstruction Loss = 399.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.16 mins\n",
      "Epoch: 3 / 10, Batch: 324 (10400 / 12512), Elapsed time: 28.16 mins\n",
      "Enc Loss = 184.96, KL Divergence = 1475.86, Reconstruction Loss = 454.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.18 mins\n",
      "Epoch: 3 / 10, Batch: 325 (10432 / 12512), Elapsed time: 28.18 mins\n",
      "Enc Loss = 162.30, KL Divergence = 1465.92, Reconstruction Loss = 381.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.19 mins\n",
      "Epoch: 3 / 10, Batch: 326 (10464 / 12512), Elapsed time: 28.20 mins\n",
      "Enc Loss = 163.12, KL Divergence = 1302.88, Reconstruction Loss = 401.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.21 mins\n",
      "Epoch: 3 / 10, Batch: 327 (10496 / 12512), Elapsed time: 28.22 mins\n",
      "Enc Loss = 172.46, KL Divergence = 1335.82, Reconstruction Loss = 428.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.23 mins\n",
      "Epoch: 3 / 10, Batch: 328 (10528 / 12512), Elapsed time: 28.24 mins\n",
      "Enc Loss = 190.36, KL Divergence = 1462.09, Reconstruction Loss = 474.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.25 mins\n",
      "Epoch: 3 / 10, Batch: 329 (10560 / 12512), Elapsed time: 28.25 mins\n",
      "Enc Loss = 169.63, KL Divergence = 1324.73, Reconstruction Loss = 420.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.27 mins\n",
      "Epoch: 3 / 10, Batch: 330 (10592 / 12512), Elapsed time: 28.27 mins\n",
      "Enc Loss = 161.18, KL Divergence = 1327.72, Reconstruction Loss = 392.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.29 mins\n",
      "Epoch: 3 / 10, Batch: 331 (10624 / 12512), Elapsed time: 28.29 mins\n",
      "Enc Loss = 158.62, KL Divergence = 1259.09, Reconstruction Loss = 390.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.31 mins\n",
      "Epoch: 3 / 10, Batch: 332 (10656 / 12512), Elapsed time: 28.31 mins\n",
      "Enc Loss = 154.56, KL Divergence = 1197.74, Reconstruction Loss = 383.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.33 mins\n",
      "Epoch: 3 / 10, Batch: 333 (10688 / 12512), Elapsed time: 28.33 mins\n",
      "Enc Loss = 176.91, KL Divergence = 1124.27, Reconstruction Loss = 464.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.35 mins\n",
      "Epoch: 3 / 10, Batch: 334 (10720 / 12512), Elapsed time: 28.35 mins\n",
      "Enc Loss = 182.14, KL Divergence = 1366.18, Reconstruction Loss = 456.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.37 mins\n",
      "Epoch: 3 / 10, Batch: 335 (10752 / 12512), Elapsed time: 28.37 mins\n",
      "Enc Loss = 172.53, KL Divergence = 1250.90, Reconstruction Loss = 437.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.39 mins\n",
      "Epoch: 3 / 10, Batch: 336 (10784 / 12512), Elapsed time: 28.39 mins\n",
      "Enc Loss = 147.94, KL Divergence = 1164.36, Reconstruction Loss = 365.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.40 mins\n",
      "Epoch: 3 / 10, Batch: 337 (10816 / 12512), Elapsed time: 28.41 mins\n",
      "Enc Loss = 147.22, KL Divergence = 1165.42, Reconstruction Loss = 363.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.42 mins\n",
      "Epoch: 3 / 10, Batch: 338 (10848 / 12512), Elapsed time: 28.42 mins\n",
      "Enc Loss = 152.23, KL Divergence = 1199.46, Reconstruction Loss = 376.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.44 mins\n",
      "Epoch: 3 / 10, Batch: 339 (10880 / 12512), Elapsed time: 28.44 mins\n",
      "Enc Loss = 169.86, KL Divergence = 1228.43, Reconstruction Loss = 430.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.46 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 10, Batch: 340 (10912 / 12512), Elapsed time: 28.46 mins\n",
      "Enc Loss = 146.28, KL Divergence = 1090.95, Reconstruction Loss = 367.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.48 mins\n",
      "Epoch: 3 / 10, Batch: 341 (10944 / 12512), Elapsed time: 28.48 mins\n",
      "Enc Loss = 157.75, KL Divergence = 1212.25, Reconstruction Loss = 392.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.50 mins\n",
      "Epoch: 3 / 10, Batch: 342 (10976 / 12512), Elapsed time: 28.50 mins\n",
      "Enc Loss = 153.28, KL Divergence = 1112.97, Reconstruction Loss = 388.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.52 mins\n",
      "Epoch: 3 / 10, Batch: 343 (11008 / 12512), Elapsed time: 28.52 mins\n",
      "Enc Loss = 167.02, KL Divergence = 1145.13, Reconstruction Loss = 430.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.54 mins\n",
      "Epoch: 3 / 10, Batch: 344 (11040 / 12512), Elapsed time: 28.54 mins\n",
      "Enc Loss = 159.62, KL Divergence = 1028.30, Reconstruction Loss = 417.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.55 mins\n",
      "Epoch: 3 / 10, Batch: 345 (11072 / 12512), Elapsed time: 28.56 mins\n",
      "Enc Loss = 154.99, KL Divergence = 1075.05, Reconstruction Loss = 397.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.57 mins\n",
      "Epoch: 3 / 10, Batch: 346 (11104 / 12512), Elapsed time: 28.57 mins\n",
      "Enc Loss = 172.16, KL Divergence = 1098.02, Reconstruction Loss = 451.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.59 mins\n",
      "Epoch: 3 / 10, Batch: 347 (11136 / 12512), Elapsed time: 28.59 mins\n",
      "Enc Loss = 150.70, KL Divergence = 1047.71, Reconstruction Loss = 386.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.61 mins\n",
      "Epoch: 3 / 10, Batch: 348 (11168 / 12512), Elapsed time: 28.61 mins\n",
      "Enc Loss = 189.68, KL Divergence = 1218.69, Reconstruction Loss = 496.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.63 mins\n",
      "Epoch: 3 / 10, Batch: 349 (11200 / 12512), Elapsed time: 28.63 mins\n",
      "Enc Loss = 159.77, KL Divergence = 1144.58, Reconstruction Loss = 406.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.65 mins\n",
      "Epoch: 3 / 10, Batch: 350 (11232 / 12512), Elapsed time: 28.65 mins\n",
      "Enc Loss = 149.44, KL Divergence = 1205.95, Reconstruction Loss = 366.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.67 mins\n",
      "Epoch: 3 / 10, Batch: 351 (11264 / 12512), Elapsed time: 28.67 mins\n",
      "Enc Loss = 159.81, KL Divergence = 1158.41, Reconstruction Loss = 405.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.69 mins\n",
      "Epoch: 3 / 10, Batch: 352 (11296 / 12512), Elapsed time: 28.69 mins\n",
      "Enc Loss = 155.42, KL Divergence = 1186.77, Reconstruction Loss = 387.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.71 mins\n",
      "Epoch: 3 / 10, Batch: 353 (11328 / 12512), Elapsed time: 28.71 mins\n",
      "Enc Loss = 156.57, KL Divergence = 1255.22, Reconstruction Loss = 384.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.73 mins\n",
      "Epoch: 3 / 10, Batch: 354 (11360 / 12512), Elapsed time: 28.73 mins\n",
      "Enc Loss = 166.52, KL Divergence = 1286.63, Reconstruction Loss = 413.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.75 mins\n",
      "Epoch: 3 / 10, Batch: 355 (11392 / 12512), Elapsed time: 28.75 mins\n",
      "Enc Loss = 161.40, KL Divergence = 1299.85, Reconstruction Loss = 395.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.76 mins\n",
      "Epoch: 3 / 10, Batch: 356 (11424 / 12512), Elapsed time: 28.77 mins\n",
      "Enc Loss = 168.68, KL Divergence = 1338.29, Reconstruction Loss = 415.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.78 mins\n",
      "Epoch: 3 / 10, Batch: 357 (11456 / 12512), Elapsed time: 28.78 mins\n",
      "Enc Loss = 191.62, KL Divergence = 1424.24, Reconstruction Loss = 482.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.80 mins\n",
      "Epoch: 3 / 10, Batch: 358 (11488 / 12512), Elapsed time: 28.80 mins\n",
      "Enc Loss = 153.31, KL Divergence = 1102.13, Reconstruction Loss = 389.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.82 mins\n",
      "Epoch: 3 / 10, Batch: 359 (11520 / 12512), Elapsed time: 28.82 mins\n",
      "Enc Loss = 146.40, KL Divergence = 1109.31, Reconstruction Loss = 366.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.84 mins\n",
      "Epoch: 3 / 10, Batch: 360 (11552 / 12512), Elapsed time: 28.84 mins\n",
      "Enc Loss = 164.63, KL Divergence = 1303.96, Reconstruction Loss = 405.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.86 mins\n",
      "Epoch: 3 / 10, Batch: 361 (11584 / 12512), Elapsed time: 28.86 mins\n",
      "Enc Loss = 163.33, KL Divergence = 1196.89, Reconstruction Loss = 412.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.88 mins\n",
      "Epoch: 3 / 10, Batch: 362 (11616 / 12512), Elapsed time: 28.88 mins\n",
      "Enc Loss = 150.27, KL Divergence = 1245.63, Reconstruction Loss = 364.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.90 mins\n",
      "Epoch: 3 / 10, Batch: 363 (11648 / 12512), Elapsed time: 28.90 mins\n",
      "Enc Loss = 156.81, KL Divergence = 1286.78, Reconstruction Loss = 382.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.92 mins\n",
      "Epoch: 3 / 10, Batch: 364 (11680 / 12512), Elapsed time: 28.92 mins\n",
      "Enc Loss = 156.88, KL Divergence = 1248.19, Reconstruction Loss = 386.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.94 mins\n",
      "Epoch: 3 / 10, Batch: 365 (11712 / 12512), Elapsed time: 28.94 mins\n",
      "Enc Loss = 159.04, KL Divergence = 1328.90, Reconstruction Loss = 385.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.95 mins\n",
      "Epoch: 3 / 10, Batch: 366 (11744 / 12512), Elapsed time: 28.96 mins\n",
      "Enc Loss = 147.51, KL Divergence = 1218.02, Reconstruction Loss = 358.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.97 mins\n",
      "Epoch: 3 / 10, Batch: 367 (11776 / 12512), Elapsed time: 28.97 mins\n",
      "Enc Loss = 155.31, KL Divergence = 1237.14, Reconstruction Loss = 382.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 28.99 mins\n",
      "Epoch: 3 / 10, Batch: 368 (11808 / 12512), Elapsed time: 28.99 mins\n",
      "Enc Loss = 165.39, KL Divergence = 1321.61, Reconstruction Loss = 406.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.01 mins\n",
      "Epoch: 3 / 10, Batch: 369 (11840 / 12512), Elapsed time: 29.01 mins\n",
      "Enc Loss = 158.44, KL Divergence = 1225.59, Reconstruction Loss = 393.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.03 mins\n",
      "Epoch: 3 / 10, Batch: 370 (11872 / 12512), Elapsed time: 29.03 mins\n",
      "Enc Loss = 158.48, KL Divergence = 1291.80, Reconstruction Loss = 387.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.05 mins\n",
      "Epoch: 3 / 10, Batch: 371 (11904 / 12512), Elapsed time: 29.05 mins\n",
      "Enc Loss = 147.17, KL Divergence = 1152.19, Reconstruction Loss = 364.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.07 mins\n",
      "Epoch: 3 / 10, Batch: 372 (11936 / 12512), Elapsed time: 29.07 mins\n",
      "Enc Loss = 157.86, KL Divergence = 1274.86, Reconstruction Loss = 386.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.09 mins\n",
      "Epoch: 3 / 10, Batch: 373 (11968 / 12512), Elapsed time: 29.09 mins\n",
      "Enc Loss = 160.86, KL Divergence = 1266.80, Reconstruction Loss = 397.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.11 mins\n",
      "Epoch: 3 / 10, Batch: 374 (12000 / 12512), Elapsed time: 29.11 mins\n",
      "Enc Loss = 158.23, KL Divergence = 1210.31, Reconstruction Loss = 394.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.13 mins\n",
      "Epoch: 3 / 10, Batch: 375 (12032 / 12512), Elapsed time: 29.13 mins\n",
      "Enc Loss = 159.43, KL Divergence = 1128.56, Reconstruction Loss = 406.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.14 mins\n",
      "Epoch: 3 / 10, Batch: 376 (12064 / 12512), Elapsed time: 29.14 mins\n",
      "Enc Loss = 152.74, KL Divergence = 1157.81, Reconstruction Loss = 381.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.16 mins\n",
      "Epoch: 3 / 10, Batch: 377 (12096 / 12512), Elapsed time: 29.16 mins\n",
      "Enc Loss = 155.50, KL Divergence = 1243.79, Reconstruction Loss = 382.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.18 mins\n",
      "Epoch: 3 / 10, Batch: 378 (12128 / 12512), Elapsed time: 29.18 mins\n",
      "Enc Loss = 162.44, KL Divergence = 1020.29, Reconstruction Loss = 427.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.20 mins\n",
      "Epoch: 3 / 10, Batch: 379 (12160 / 12512), Elapsed time: 29.20 mins\n",
      "Enc Loss = 151.79, KL Divergence = 1159.09, Reconstruction Loss = 378.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.22 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 / 10, Batch: 380 (12192 / 12512), Elapsed time: 29.22 mins\n",
      "Enc Loss = 159.75, KL Divergence = 1158.89, Reconstruction Loss = 404.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.24 mins\n",
      "Epoch: 3 / 10, Batch: 381 (12224 / 12512), Elapsed time: 29.24 mins\n",
      "Enc Loss = 245.92, KL Divergence = 1209.70, Reconstruction Loss = 681.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.26 mins\n",
      "Epoch: 3 / 10, Batch: 382 (12256 / 12512), Elapsed time: 29.26 mins\n",
      "Enc Loss = 169.11, KL Divergence = 1255.05, Reconstruction Loss = 425.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.28 mins\n",
      "Epoch: 3 / 10, Batch: 383 (12288 / 12512), Elapsed time: 29.28 mins\n",
      "Enc Loss = 152.38, KL Divergence = 1126.84, Reconstruction Loss = 383.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.30 mins\n",
      "Epoch: 3 / 10, Batch: 384 (12320 / 12512), Elapsed time: 29.30 mins\n",
      "Enc Loss = 168.80, KL Divergence = 1270.04, Reconstruction Loss = 423.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.32 mins\n",
      "Epoch: 3 / 10, Batch: 385 (12352 / 12512), Elapsed time: 29.32 mins\n",
      "Enc Loss = 176.11, KL Divergence = 1333.62, Reconstruction Loss = 440.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.34 mins\n",
      "Epoch: 3 / 10, Batch: 386 (12384 / 12512), Elapsed time: 29.34 mins\n",
      "Enc Loss = 162.11, KL Divergence = 1335.83, Reconstruction Loss = 394.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.36 mins\n",
      "Epoch: 3 / 10, Batch: 387 (12416 / 12512), Elapsed time: 29.36 mins\n",
      "Enc Loss = 157.43, KL Divergence = 1323.99, Reconstruction Loss = 380.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.37 mins\n",
      "Epoch: 3 / 10, Batch: 388 (12448 / 12512), Elapsed time: 29.37 mins\n",
      "Enc Loss = 153.77, KL Divergence = 1338.93, Reconstruction Loss = 366.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.39 mins\n",
      "Epoch: 3 / 10, Batch: 389 (12480 / 12512), Elapsed time: 29.39 mins\n",
      "Enc Loss = 171.59, KL Divergence = 1280.09, Reconstruction Loss = 431.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.41 mins\n",
      "Epoch: 3 / 10, Batch: 390 (12512 / 12512), Elapsed time: 29.41 mins\n",
      "Enc Loss = 132.70, KL Divergence = 500.67, Reconstruction Loss = 383.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.43 mins\n",
      "Epoch: 4, Elapsed Time: 29.43\n",
      "Epoch: 4 / 10, Batch: 0 (32 / 12512), Elapsed time: 29.43 mins\n",
      "Enc Loss = 156.12, KL Divergence = 1291.72, Reconstruction Loss = 379.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.45 mins\n",
      "Epoch: 4 / 10, Batch: 1 (64 / 12512), Elapsed time: 29.45 mins\n",
      "Enc Loss = 168.23, KL Divergence = 1310.88, Reconstruction Loss = 417.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.47 mins\n",
      "Epoch: 4 / 10, Batch: 2 (96 / 12512), Elapsed time: 29.47 mins\n",
      "Enc Loss = 164.24, KL Divergence = 1272.44, Reconstruction Loss = 407.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.49 mins\n",
      "Epoch: 4 / 10, Batch: 3 (128 / 12512), Elapsed time: 29.49 mins\n",
      "Enc Loss = 186.39, KL Divergence = 1416.72, Reconstruction Loss = 465.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.51 mins\n",
      "Epoch: 4 / 10, Batch: 4 (160 / 12512), Elapsed time: 29.51 mins\n",
      "Enc Loss = 145.74, KL Divergence = 1260.23, Reconstruction Loss = 348.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.53 mins\n",
      "Epoch: 4 / 10, Batch: 5 (192 / 12512), Elapsed time: 29.53 mins\n",
      "Enc Loss = 146.18, KL Divergence = 1221.35, Reconstruction Loss = 353.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.54 mins\n",
      "Epoch: 4 / 10, Batch: 6 (224 / 12512), Elapsed time: 29.54 mins\n",
      "Enc Loss = 165.26, KL Divergence = 1250.27, Reconstruction Loss = 413.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.56 mins\n",
      "Epoch: 4 / 10, Batch: 7 (256 / 12512), Elapsed time: 29.56 mins\n",
      "Enc Loss = 152.80, KL Divergence = 1285.28, Reconstruction Loss = 369.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.58 mins\n",
      "Epoch: 4 / 10, Batch: 8 (288 / 12512), Elapsed time: 29.58 mins\n",
      "Enc Loss = 160.94, KL Divergence = 1293.52, Reconstruction Loss = 394.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.60 mins\n",
      "Epoch: 4 / 10, Batch: 9 (320 / 12512), Elapsed time: 29.60 mins\n",
      "Enc Loss = 152.78, KL Divergence = 1207.50, Reconstruction Loss = 376.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.62 mins\n",
      "Epoch: 4 / 10, Batch: 10 (352 / 12512), Elapsed time: 29.62 mins\n",
      "Enc Loss = 157.73, KL Divergence = 1264.69, Reconstruction Loss = 387.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.64 mins\n",
      "Epoch: 4 / 10, Batch: 11 (384 / 12512), Elapsed time: 29.64 mins\n",
      "Enc Loss = 182.43, KL Divergence = 1230.24, Reconstruction Loss = 471.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.66 mins\n",
      "Epoch: 4 / 10, Batch: 12 (416 / 12512), Elapsed time: 29.66 mins\n",
      "Enc Loss = 156.73, KL Divergence = 1282.96, Reconstruction Loss = 382.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.68 mins\n",
      "Epoch: 4 / 10, Batch: 13 (448 / 12512), Elapsed time: 29.68 mins\n",
      "Enc Loss = 191.81, KL Divergence = 1427.80, Reconstruction Loss = 482.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.70 mins\n",
      "Epoch: 4 / 10, Batch: 14 (480 / 12512), Elapsed time: 29.70 mins\n",
      "Enc Loss = 174.85, KL Divergence = 1324.35, Reconstruction Loss = 437.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.72 mins\n",
      "Epoch: 4 / 10, Batch: 15 (512 / 12512), Elapsed time: 29.72 mins\n",
      "Enc Loss = 151.11, KL Divergence = 1145.96, Reconstruction Loss = 377.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.73 mins\n",
      "Epoch: 4 / 10, Batch: 16 (544 / 12512), Elapsed time: 29.74 mins\n",
      "Enc Loss = 165.00, KL Divergence = 1268.89, Reconstruction Loss = 410.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.75 mins\n",
      "Epoch: 4 / 10, Batch: 17 (576 / 12512), Elapsed time: 29.75 mins\n",
      "Enc Loss = 168.85, KL Divergence = 1195.74, Reconstruction Loss = 430.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.77 mins\n",
      "Epoch: 4 / 10, Batch: 18 (608 / 12512), Elapsed time: 29.77 mins\n",
      "Enc Loss = 156.09, KL Divergence = 1168.27, Reconstruction Loss = 391.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.79 mins\n",
      "Epoch: 4 / 10, Batch: 19 (640 / 12512), Elapsed time: 29.79 mins\n",
      "Enc Loss = 181.21, KL Divergence = 1282.91, Reconstruction Loss = 462.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.81 mins\n",
      "Epoch: 4 / 10, Batch: 20 (672 / 12512), Elapsed time: 29.81 mins\n",
      "Enc Loss = 159.05, KL Divergence = 1131.43, Reconstruction Loss = 405.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.83 mins\n",
      "Epoch: 4 / 10, Batch: 21 (704 / 12512), Elapsed time: 29.83 mins\n",
      "Enc Loss = 154.13, KL Divergence = 1127.94, Reconstruction Loss = 389.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.85 mins\n",
      "Epoch: 4 / 10, Batch: 22 (736 / 12512), Elapsed time: 29.85 mins\n",
      "Enc Loss = 181.05, KL Divergence = 1397.16, Reconstruction Loss = 450.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.87 mins\n",
      "Epoch: 4 / 10, Batch: 23 (768 / 12512), Elapsed time: 29.87 mins\n",
      "Enc Loss = 175.34, KL Divergence = 1217.98, Reconstruction Loss = 449.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.89 mins\n",
      "Epoch: 4 / 10, Batch: 24 (800 / 12512), Elapsed time: 29.89 mins\n",
      "Enc Loss = 150.17, KL Divergence = 1178.04, Reconstruction Loss = 371.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.91 mins\n",
      "Epoch: 4 / 10, Batch: 25 (832 / 12512), Elapsed time: 29.91 mins\n",
      "Enc Loss = 191.90, KL Divergence = 1428.51, Reconstruction Loss = 482.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.92 mins\n",
      "Epoch: 4 / 10, Batch: 26 (864 / 12512), Elapsed time: 29.93 mins\n",
      "Enc Loss = 156.38, KL Divergence = 1169.23, Reconstruction Loss = 392.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.94 mins\n",
      "Epoch: 4 / 10, Batch: 27 (896 / 12512), Elapsed time: 29.94 mins\n",
      "Enc Loss = 150.43, KL Divergence = 1108.51, Reconstruction Loss = 379.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.96 mins\n",
      "Epoch: 4 / 10, Batch: 28 (928 / 12512), Elapsed time: 29.96 mins\n",
      "Enc Loss = 142.80, KL Divergence = 1164.84, Reconstruction Loss = 348.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 29.98 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 10, Batch: 29 (960 / 12512), Elapsed time: 29.98 mins\n",
      "Enc Loss = 167.61, KL Divergence = 1147.26, Reconstruction Loss = 431.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.00 mins\n",
      "Epoch: 4 / 10, Batch: 30 (992 / 12512), Elapsed time: 30.00 mins\n",
      "Enc Loss = 158.49, KL Divergence = 1293.27, Reconstruction Loss = 386.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.02 mins\n",
      "Epoch: 4 / 10, Batch: 31 (1024 / 12512), Elapsed time: 30.02 mins\n",
      "Enc Loss = 158.33, KL Divergence = 1222.72, Reconstruction Loss = 393.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.04 mins\n",
      "Epoch: 4 / 10, Batch: 32 (1056 / 12512), Elapsed time: 30.04 mins\n",
      "Enc Loss = 155.93, KL Divergence = 1200.22, Reconstruction Loss = 388.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.06 mins\n",
      "Epoch: 4 / 10, Batch: 33 (1088 / 12512), Elapsed time: 30.06 mins\n",
      "Enc Loss = 163.08, KL Divergence = 1236.22, Reconstruction Loss = 407.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.08 mins\n",
      "Epoch: 4 / 10, Batch: 34 (1120 / 12512), Elapsed time: 30.08 mins\n",
      "Enc Loss = 152.58, KL Divergence = 1104.37, Reconstruction Loss = 386.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.09 mins\n",
      "Epoch: 4 / 10, Batch: 35 (1152 / 12512), Elapsed time: 30.10 mins\n",
      "Enc Loss = 162.19, KL Divergence = 1216.58, Reconstruction Loss = 406.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.11 mins\n",
      "Epoch: 4 / 10, Batch: 36 (1184 / 12512), Elapsed time: 30.11 mins\n",
      "Enc Loss = 145.82, KL Divergence = 1161.80, Reconstruction Loss = 358.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.13 mins\n",
      "Epoch: 4 / 10, Batch: 37 (1216 / 12512), Elapsed time: 30.13 mins\n",
      "Enc Loss = 157.09, KL Divergence = 1130.17, Reconstruction Loss = 399.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.15 mins\n",
      "Epoch: 4 / 10, Batch: 38 (1248 / 12512), Elapsed time: 30.15 mins\n",
      "Enc Loss = 150.78, KL Divergence = 1143.00, Reconstruction Loss = 377.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.17 mins\n",
      "Epoch: 4 / 10, Batch: 39 (1280 / 12512), Elapsed time: 30.17 mins\n",
      "Enc Loss = 144.26, KL Divergence = 1052.88, Reconstruction Loss = 364.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.19 mins\n",
      "Epoch: 4 / 10, Batch: 40 (1312 / 12512), Elapsed time: 30.19 mins\n",
      "Enc Loss = 146.22, KL Divergence = 1145.70, Reconstruction Loss = 361.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.21 mins\n",
      "Epoch: 4 / 10, Batch: 41 (1344 / 12512), Elapsed time: 30.21 mins\n",
      "Enc Loss = 154.47, KL Divergence = 1171.67, Reconstruction Loss = 386.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.23 mins\n",
      "Epoch: 4 / 10, Batch: 42 (1376 / 12512), Elapsed time: 30.23 mins\n",
      "Enc Loss = 148.75, KL Divergence = 1069.92, Reconstruction Loss = 377.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.25 mins\n",
      "Epoch: 4 / 10, Batch: 43 (1408 / 12512), Elapsed time: 30.25 mins\n",
      "Enc Loss = 160.13, KL Divergence = 1123.57, Reconstruction Loss = 409.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.26 mins\n",
      "Epoch: 4 / 10, Batch: 44 (1440 / 12512), Elapsed time: 30.26 mins\n",
      "Enc Loss = 154.16, KL Divergence = 1068.15, Reconstruction Loss = 395.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.28 mins\n",
      "Epoch: 4 / 10, Batch: 45 (1472 / 12512), Elapsed time: 30.28 mins\n",
      "Enc Loss = 147.73, KL Divergence = 1073.91, Reconstruction Loss = 374.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.30 mins\n",
      "Epoch: 4 / 10, Batch: 46 (1504 / 12512), Elapsed time: 30.30 mins\n",
      "Enc Loss = 158.34, KL Divergence = 1192.30, Reconstruction Loss = 396.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.32 mins\n",
      "Epoch: 4 / 10, Batch: 47 (1536 / 12512), Elapsed time: 30.32 mins\n",
      "Enc Loss = 148.13, KL Divergence = 1100.74, Reconstruction Loss = 372.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.34 mins\n",
      "Epoch: 4 / 10, Batch: 48 (1568 / 12512), Elapsed time: 30.34 mins\n",
      "Enc Loss = 145.50, KL Divergence = 1026.74, Reconstruction Loss = 371.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.36 mins\n",
      "Epoch: 4 / 10, Batch: 49 (1600 / 12512), Elapsed time: 30.36 mins\n",
      "Enc Loss = 172.24, KL Divergence = 1290.12, Reconstruction Loss = 432.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.38 mins\n",
      "Epoch: 4 / 10, Batch: 50 (1632 / 12512), Elapsed time: 30.38 mins\n",
      "Enc Loss = 159.79, KL Divergence = 1165.53, Reconstruction Loss = 404.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.40 mins\n",
      "Epoch: 4 / 10, Batch: 51 (1664 / 12512), Elapsed time: 30.40 mins\n",
      "Enc Loss = 153.38, KL Divergence = 1164.52, Reconstruction Loss = 383.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.42 mins\n",
      "Epoch: 4 / 10, Batch: 52 (1696 / 12512), Elapsed time: 30.42 mins\n",
      "Enc Loss = 144.56, KL Divergence = 1090.41, Reconstruction Loss = 362.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.44 mins\n",
      "Epoch: 4 / 10, Batch: 53 (1728 / 12512), Elapsed time: 30.44 mins\n",
      "Enc Loss = 164.83, KL Divergence = 1122.31, Reconstruction Loss = 425.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.46 mins\n",
      "Epoch: 4 / 10, Batch: 54 (1760 / 12512), Elapsed time: 30.46 mins\n",
      "Enc Loss = 141.33, KL Divergence = 1071.03, Reconstruction Loss = 353.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.48 mins\n",
      "Epoch: 4 / 10, Batch: 55 (1792 / 12512), Elapsed time: 30.48 mins\n",
      "Enc Loss = 150.31, KL Divergence = 1141.71, Reconstruction Loss = 375.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.50 mins\n",
      "Epoch: 4 / 10, Batch: 56 (1824 / 12512), Elapsed time: 30.50 mins\n",
      "Enc Loss = 159.33, KL Divergence = 1200.86, Reconstruction Loss = 399.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.52 mins\n",
      "Epoch: 4 / 10, Batch: 57 (1856 / 12512), Elapsed time: 30.52 mins\n",
      "Enc Loss = 166.10, KL Divergence = 1293.96, Reconstruction Loss = 411.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.54 mins\n",
      "Epoch: 4 / 10, Batch: 58 (1888 / 12512), Elapsed time: 30.54 mins\n",
      "Enc Loss = 160.72, KL Divergence = 1358.97, Reconstruction Loss = 387.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.55 mins\n",
      "Epoch: 4 / 10, Batch: 59 (1920 / 12512), Elapsed time: 30.55 mins\n",
      "Enc Loss = 149.92, KL Divergence = 1122.10, Reconstruction Loss = 376.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.57 mins\n",
      "Epoch: 4 / 10, Batch: 60 (1952 / 12512), Elapsed time: 30.57 mins\n",
      "Enc Loss = 161.92, KL Divergence = 1267.34, Reconstruction Loss = 400.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.59 mins\n",
      "Epoch: 4 / 10, Batch: 61 (1984 / 12512), Elapsed time: 30.59 mins\n",
      "Enc Loss = 142.86, KL Divergence = 1104.02, Reconstruction Loss = 355.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.61 mins\n",
      "Epoch: 4 / 10, Batch: 62 (2016 / 12512), Elapsed time: 30.61 mins\n",
      "Enc Loss = 147.43, KL Divergence = 1160.22, Reconstruction Loss = 364.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.63 mins\n",
      "Epoch: 4 / 10, Batch: 63 (2048 / 12512), Elapsed time: 30.63 mins\n",
      "Enc Loss = 144.12, KL Divergence = 1125.44, Reconstruction Loss = 357.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.65 mins\n",
      "Epoch: 4 / 10, Batch: 64 (2080 / 12512), Elapsed time: 30.65 mins\n",
      "Enc Loss = 167.58, KL Divergence = 1235.67, Reconstruction Loss = 422.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.67 mins\n",
      "Epoch: 4 / 10, Batch: 65 (2112 / 12512), Elapsed time: 30.67 mins\n",
      "Enc Loss = 151.03, KL Divergence = 1238.36, Reconstruction Loss = 368.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.69 mins\n",
      "Epoch: 4 / 10, Batch: 66 (2144 / 12512), Elapsed time: 30.69 mins\n",
      "Enc Loss = 154.35, KL Divergence = 1197.44, Reconstruction Loss = 383.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.71 mins\n",
      "Epoch: 4 / 10, Batch: 67 (2176 / 12512), Elapsed time: 30.71 mins\n",
      "Enc Loss = 150.40, KL Divergence = 1081.52, Reconstruction Loss = 382.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.73 mins\n",
      "Epoch: 4 / 10, Batch: 68 (2208 / 12512), Elapsed time: 30.73 mins\n",
      "Enc Loss = 155.02, KL Divergence = 1187.35, Reconstruction Loss = 386.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.75 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 / 10, Batch: 69 (2240 / 12512), Elapsed time: 30.75 mins\n",
      "Enc Loss = 152.54, KL Divergence = 1141.97, Reconstruction Loss = 382.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.76 mins\n",
      "Epoch: 4 / 10, Batch: 70 (2272 / 12512), Elapsed time: 30.76 mins\n",
      "Enc Loss = 151.78, KL Divergence = 1168.27, Reconstruction Loss = 377.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.78 mins\n",
      "Epoch: 4 / 10, Batch: 71 (2304 / 12512), Elapsed time: 30.78 mins\n",
      "Enc Loss = 166.06, KL Divergence = 1233.64, Reconstruction Loss = 417.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.80 mins\n",
      "Epoch: 4 / 10, Batch: 72 (2336 / 12512), Elapsed time: 30.80 mins\n",
      "Enc Loss = 152.57, KL Divergence = 1175.24, Reconstruction Loss = 379.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.82 mins\n",
      "Epoch: 4 / 10, Batch: 73 (2368 / 12512), Elapsed time: 30.82 mins\n",
      "Enc Loss = 159.42, KL Divergence = 1190.92, Reconstruction Loss = 400.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.84 mins\n",
      "Epoch: 4 / 10, Batch: 74 (2400 / 12512), Elapsed time: 30.84 mins\n",
      "Enc Loss = 166.95, KL Divergence = 1286.99, Reconstruction Loss = 415.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.86 mins\n",
      "Epoch: 4 / 10, Batch: 75 (2432 / 12512), Elapsed time: 30.86 mins\n",
      "Enc Loss = 157.18, KL Divergence = 1215.45, Reconstruction Loss = 390.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.88 mins\n",
      "Epoch: 4 / 10, Batch: 76 (2464 / 12512), Elapsed time: 30.88 mins\n",
      "Enc Loss = 156.45, KL Divergence = 1258.12, Reconstruction Loss = 383.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.90 mins\n",
      "Epoch: 4 / 10, Batch: 77 (2496 / 12512), Elapsed time: 30.90 mins\n",
      "Enc Loss = 157.34, KL Divergence = 1364.48, Reconstruction Loss = 375.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.92 mins\n",
      "Epoch: 4 / 10, Batch: 78 (2528 / 12512), Elapsed time: 30.92 mins\n",
      "Enc Loss = 168.77, KL Divergence = 1357.72, Reconstruction Loss = 413.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.94 mins\n",
      "Epoch: 4 / 10, Batch: 79 (2560 / 12512), Elapsed time: 30.94 mins\n",
      "Enc Loss = 154.66, KL Divergence = 1210.23, Reconstruction Loss = 382.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.95 mins\n",
      "Epoch: 4 / 10, Batch: 80 (2592 / 12512), Elapsed time: 30.95 mins\n",
      "Enc Loss = 139.98, KL Divergence = 1211.68, Reconstruction Loss = 334.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.97 mins\n",
      "Epoch: 4 / 10, Batch: 81 (2624 / 12512), Elapsed time: 30.97 mins\n",
      "Enc Loss = 146.56, KL Divergence = 1143.00, Reconstruction Loss = 363.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 30.99 mins\n",
      "Epoch: 4 / 10, Batch: 82 (2656 / 12512), Elapsed time: 30.99 mins\n",
      "Enc Loss = 159.58, KL Divergence = 1186.99, Reconstruction Loss = 401.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.01 mins\n",
      "Epoch: 4 / 10, Batch: 83 (2688 / 12512), Elapsed time: 31.01 mins\n",
      "Enc Loss = 156.66, KL Divergence = 1216.09, Reconstruction Loss = 388.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.03 mins\n",
      "Epoch: 4 / 10, Batch: 84 (2720 / 12512), Elapsed time: 31.03 mins\n",
      "Enc Loss = 163.34, KL Divergence = 1188.96, Reconstruction Loss = 413.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.05 mins\n",
      "Epoch: 4 / 10, Batch: 85 (2752 / 12512), Elapsed time: 31.05 mins\n",
      "Enc Loss = 167.84, KL Divergence = 1187.74, Reconstruction Loss = 428.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.07 mins\n",
      "Epoch: 4 / 10, Batch: 86 (2784 / 12512), Elapsed time: 31.07 mins\n",
      "Enc Loss = 162.20, KL Divergence = 1233.90, Reconstruction Loss = 405.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.09 mins\n",
      "Epoch: 4 / 10, Batch: 87 (2816 / 12512), Elapsed time: 31.09 mins\n",
      "Enc Loss = 155.23, KL Divergence = 1140.09, Reconstruction Loss = 391.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.10 mins\n",
      "Epoch: 4 / 10, Batch: 88 (2848 / 12512), Elapsed time: 31.11 mins\n",
      "Enc Loss = 160.09, KL Divergence = 1087.04, Reconstruction Loss = 413.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.12 mins\n",
      "Epoch: 4 / 10, Batch: 89 (2880 / 12512), Elapsed time: 31.12 mins\n",
      "Enc Loss = 149.04, KL Divergence = 1216.13, Reconstruction Loss = 363.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.14 mins\n",
      "Epoch: 4 / 10, Batch: 90 (2912 / 12512), Elapsed time: 31.14 mins\n",
      "Enc Loss = 148.71, KL Divergence = 1218.95, Reconstruction Loss = 362.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.16 mins\n",
      "Epoch: 4 / 10, Batch: 91 (2944 / 12512), Elapsed time: 31.16 mins\n",
      "Enc Loss = 172.03, KL Divergence = 1219.41, Reconstruction Loss = 438.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.18 mins\n",
      "Epoch: 4 / 10, Batch: 92 (2976 / 12512), Elapsed time: 31.18 mins\n",
      "Enc Loss = 162.70, KL Divergence = 1265.30, Reconstruction Loss = 403.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.20 mins\n",
      "Epoch: 4 / 10, Batch: 93 (3008 / 12512), Elapsed time: 31.20 mins\n",
      "Enc Loss = 144.74, KL Divergence = 1055.06, Reconstruction Loss = 366.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 31.22 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 138.07, KL Divergence = 1063.16, Reconstruction Loss = 343.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.87 mins\n",
      "Epoch: 6 / 10, Batch: 176 (5664 / 12512), Elapsed time: 47.87 mins\n",
      "Enc Loss = 153.79, KL Divergence = 1197.64, Reconstruction Loss = 381.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.89 mins\n",
      "Epoch: 6 / 10, Batch: 177 (5696 / 12512), Elapsed time: 47.89 mins\n",
      "Enc Loss = 146.35, KL Divergence = 1135.00, Reconstruction Loss = 363.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.91 mins\n",
      "Epoch: 6 / 10, Batch: 178 (5728 / 12512), Elapsed time: 47.91 mins\n",
      "Enc Loss = 146.64, KL Divergence = 1153.14, Reconstruction Loss = 362.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.93 mins\n",
      "Epoch: 6 / 10, Batch: 179 (5760 / 12512), Elapsed time: 47.93 mins\n",
      "Enc Loss = 147.31, KL Divergence = 1109.73, Reconstruction Loss = 369.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.95 mins\n",
      "Epoch: 6 / 10, Batch: 180 (5792 / 12512), Elapsed time: 47.95 mins\n",
      "Enc Loss = 146.04, KL Divergence = 1160.21, Reconstruction Loss = 359.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.97 mins\n",
      "Epoch: 6 / 10, Batch: 181 (5824 / 12512), Elapsed time: 47.97 mins\n",
      "Enc Loss = 141.60, KL Divergence = 1108.33, Reconstruction Loss = 350.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 47.99 mins\n",
      "Epoch: 6 / 10, Batch: 182 (5856 / 12512), Elapsed time: 47.99 mins\n",
      "Enc Loss = 137.29, KL Divergence = 1142.20, Reconstruction Loss = 332.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.01 mins\n",
      "Epoch: 6 / 10, Batch: 183 (5888 / 12512), Elapsed time: 48.01 mins\n",
      "Enc Loss = 132.32, KL Divergence = 987.08, Reconstruction Loss = 332.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.03 mins\n",
      "Epoch: 6 / 10, Batch: 184 (5920 / 12512), Elapsed time: 48.03 mins\n",
      "Enc Loss = 175.60, KL Divergence = 1303.03, Reconstruction Loss = 441.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.05 mins\n",
      "Epoch: 6 / 10, Batch: 185 (5952 / 12512), Elapsed time: 48.05 mins\n",
      "Enc Loss = 131.63, KL Divergence = 1050.20, Reconstruction Loss = 323.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.07 mins\n",
      "Epoch: 6 / 10, Batch: 186 (5984 / 12512), Elapsed time: 48.07 mins\n",
      "Enc Loss = 142.14, KL Divergence = 1050.76, Reconstruction Loss = 358.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.09 mins\n",
      "Epoch: 6 / 10, Batch: 187 (6016 / 12512), Elapsed time: 48.09 mins\n",
      "Enc Loss = 157.85, KL Divergence = 1239.96, Reconstruction Loss = 390.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.11 mins\n",
      "Epoch: 6 / 10, Batch: 188 (6048 / 12512), Elapsed time: 48.11 mins\n",
      "Enc Loss = 136.88, KL Divergence = 1041.08, Reconstruction Loss = 341.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.13 mins\n",
      "Epoch: 6 / 10, Batch: 189 (6080 / 12512), Elapsed time: 48.13 mins\n",
      "Enc Loss = 138.82, KL Divergence = 1069.22, Reconstruction Loss = 345.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.15 mins\n",
      "Epoch: 6 / 10, Batch: 190 (6112 / 12512), Elapsed time: 48.15 mins\n",
      "Enc Loss = 154.11, KL Divergence = 1070.41, Reconstruction Loss = 395.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.17 mins\n",
      "Epoch: 6 / 10, Batch: 191 (6144 / 12512), Elapsed time: 48.17 mins\n",
      "Enc Loss = 142.96, KL Divergence = 1141.98, Reconstruction Loss = 351.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.19 mins\n",
      "Epoch: 6 / 10, Batch: 192 (6176 / 12512), Elapsed time: 48.19 mins\n",
      "Enc Loss = 144.87, KL Divergence = 1233.20, Reconstruction Loss = 348.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.21 mins\n",
      "Epoch: 6 / 10, Batch: 193 (6208 / 12512), Elapsed time: 48.21 mins\n",
      "Enc Loss = 141.58, KL Divergence = 1241.30, Reconstruction Loss = 336.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.23 mins\n",
      "Epoch: 6 / 10, Batch: 194 (6240 / 12512), Elapsed time: 48.23 mins\n",
      "Enc Loss = 149.08, KL Divergence = 1281.06, Reconstruction Loss = 357.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.24 mins\n",
      "Epoch: 6 / 10, Batch: 195 (6272 / 12512), Elapsed time: 48.24 mins\n",
      "Enc Loss = 142.82, KL Divergence = 1155.71, Reconstruction Loss = 349.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.26 mins\n",
      "Epoch: 6 / 10, Batch: 196 (6304 / 12512), Elapsed time: 48.26 mins\n",
      "Enc Loss = 142.35, KL Divergence = 1172.61, Reconstruction Loss = 346.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.28 mins\n",
      "Epoch: 6 / 10, Batch: 197 (6336 / 12512), Elapsed time: 48.28 mins\n",
      "Enc Loss = 140.54, KL Divergence = 1137.38, Reconstruction Loss = 344.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.30 mins\n",
      "Epoch: 6 / 10, Batch: 198 (6368 / 12512), Elapsed time: 48.30 mins\n",
      "Enc Loss = 142.45, KL Divergence = 1184.77, Reconstruction Loss = 345.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.32 mins\n",
      "Epoch: 6 / 10, Batch: 199 (6400 / 12512), Elapsed time: 48.32 mins\n",
      "Enc Loss = 157.02, KL Divergence = 1278.58, Reconstruction Loss = 383.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.34 mins\n",
      "Epoch: 6 / 10, Batch: 200 (6432 / 12512), Elapsed time: 48.34 mins\n",
      "Enc Loss = 140.30, KL Divergence = 1094.81, Reconstruction Loss = 347.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.36 mins\n",
      "Epoch: 6 / 10, Batch: 201 (6464 / 12512), Elapsed time: 48.36 mins\n",
      "Enc Loss = 147.52, KL Divergence = 1167.31, Reconstruction Loss = 363.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.38 mins\n",
      "Epoch: 6 / 10, Batch: 202 (6496 / 12512), Elapsed time: 48.38 mins\n",
      "Enc Loss = 138.38, KL Divergence = 1026.55, Reconstruction Loss = 348.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.40 mins\n",
      "Epoch: 6 / 10, Batch: 203 (6528 / 12512), Elapsed time: 48.40 mins\n",
      "Enc Loss = 134.16, KL Divergence = 1033.18, Reconstruction Loss = 333.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.42 mins\n",
      "Epoch: 6 / 10, Batch: 204 (6560 / 12512), Elapsed time: 48.42 mins\n",
      "Enc Loss = 130.38, KL Divergence = 897.45, Reconstruction Loss = 335.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.44 mins\n",
      "Epoch: 6 / 10, Batch: 205 (6592 / 12512), Elapsed time: 48.44 mins\n",
      "Enc Loss = 146.74, KL Divergence = 1060.80, Reconstruction Loss = 372.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.46 mins\n",
      "Epoch: 6 / 10, Batch: 206 (6624 / 12512), Elapsed time: 48.46 mins\n",
      "Enc Loss = 157.61, KL Divergence = 1159.85, Reconstruction Loss = 397.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.48 mins\n",
      "Epoch: 6 / 10, Batch: 207 (6656 / 12512), Elapsed time: 48.48 mins\n",
      "Enc Loss = 152.88, KL Divergence = 1111.36, Reconstruction Loss = 387.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.50 mins\n",
      "Epoch: 6 / 10, Batch: 208 (6688 / 12512), Elapsed time: 48.50 mins\n",
      "Enc Loss = 155.21, KL Divergence = 1075.50, Reconstruction Loss = 398.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.52 mins\n",
      "Epoch: 6 / 10, Batch: 209 (6720 / 12512), Elapsed time: 48.52 mins\n",
      "Enc Loss = 146.69, KL Divergence = 1178.30, Reconstruction Loss = 360.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.54 mins\n",
      "Epoch: 6 / 10, Batch: 210 (6752 / 12512), Elapsed time: 48.54 mins\n",
      "Enc Loss = 136.75, KL Divergence = 1121.64, Reconstruction Loss = 333.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.56 mins\n",
      "Epoch: 6 / 10, Batch: 211 (6784 / 12512), Elapsed time: 48.56 mins\n",
      "Enc Loss = 138.02, KL Divergence = 1090.93, Reconstruction Loss = 340.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.58 mins\n",
      "Epoch: 6 / 10, Batch: 212 (6816 / 12512), Elapsed time: 48.58 mins\n",
      "Enc Loss = 146.08, KL Divergence = 1187.00, Reconstruction Loss = 357.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.59 mins\n",
      "Epoch: 6 / 10, Batch: 213 (6848 / 12512), Elapsed time: 48.60 mins\n",
      "Enc Loss = 147.65, KL Divergence = 1265.53, Reconstruction Loss = 354.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.61 mins\n",
      "Epoch: 6 / 10, Batch: 214 (6880 / 12512), Elapsed time: 48.61 mins\n",
      "Enc Loss = 152.68, KL Divergence = 1173.84, Reconstruction Loss = 380.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.63 mins\n",
      "Epoch: 6 / 10, Batch: 215 (6912 / 12512), Elapsed time: 48.63 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 153.86, KL Divergence = 1146.25, Reconstruction Loss = 386.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.65 mins\n",
      "Epoch: 6 / 10, Batch: 216 (6944 / 12512), Elapsed time: 48.65 mins\n",
      "Enc Loss = 137.63, KL Divergence = 1172.30, Reconstruction Loss = 330.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.67 mins\n",
      "Epoch: 6 / 10, Batch: 217 (6976 / 12512), Elapsed time: 48.67 mins\n",
      "Enc Loss = 139.13, KL Divergence = 1216.38, Reconstruction Loss = 331.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.69 mins\n",
      "Epoch: 6 / 10, Batch: 218 (7008 / 12512), Elapsed time: 48.69 mins\n",
      "Enc Loss = 152.35, KL Divergence = 1346.64, Reconstruction Loss = 361.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.71 mins\n",
      "Epoch: 6 / 10, Batch: 219 (7040 / 12512), Elapsed time: 48.71 mins\n",
      "Enc Loss = 140.92, KL Divergence = 1298.35, Reconstruction Loss = 328.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.73 mins\n",
      "Epoch: 6 / 10, Batch: 220 (7072 / 12512), Elapsed time: 48.73 mins\n",
      "Enc Loss = 146.57, KL Divergence = 1277.74, Reconstruction Loss = 349.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.75 mins\n",
      "Epoch: 6 / 10, Batch: 221 (7104 / 12512), Elapsed time: 48.75 mins\n",
      "Enc Loss = 147.45, KL Divergence = 1227.12, Reconstruction Loss = 357.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.77 mins\n",
      "Epoch: 6 / 10, Batch: 222 (7136 / 12512), Elapsed time: 48.77 mins\n",
      "Enc Loss = 141.20, KL Divergence = 1230.28, Reconstruction Loss = 336.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.79 mins\n",
      "Epoch: 6 / 10, Batch: 223 (7168 / 12512), Elapsed time: 48.79 mins\n",
      "Enc Loss = 141.05, KL Divergence = 1165.61, Reconstruction Loss = 342.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.81 mins\n",
      "Epoch: 6 / 10, Batch: 224 (7200 / 12512), Elapsed time: 48.81 mins\n",
      "Enc Loss = 146.86, KL Divergence = 1112.97, Reconstruction Loss = 367.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.83 mins\n",
      "Epoch: 6 / 10, Batch: 225 (7232 / 12512), Elapsed time: 48.83 mins\n",
      "Enc Loss = 150.77, KL Divergence = 1185.38, Reconstruction Loss = 372.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.85 mins\n",
      "Epoch: 6 / 10, Batch: 226 (7264 / 12512), Elapsed time: 48.85 mins\n",
      "Enc Loss = 153.51, KL Divergence = 1228.57, Reconstruction Loss = 377.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.87 mins\n",
      "Epoch: 6 / 10, Batch: 227 (7296 / 12512), Elapsed time: 48.87 mins\n",
      "Enc Loss = 128.07, KL Divergence = 1067.13, Reconstruction Loss = 310.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.89 mins\n",
      "Epoch: 6 / 10, Batch: 228 (7328 / 12512), Elapsed time: 48.89 mins\n",
      "Enc Loss = 135.09, KL Divergence = 1156.55, Reconstruction Loss = 324.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.91 mins\n",
      "Epoch: 6 / 10, Batch: 229 (7360 / 12512), Elapsed time: 48.91 mins\n",
      "Enc Loss = 135.17, KL Divergence = 1127.55, Reconstruction Loss = 327.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.93 mins\n",
      "Epoch: 6 / 10, Batch: 230 (7392 / 12512), Elapsed time: 48.93 mins\n",
      "Enc Loss = 165.92, KL Divergence = 1201.71, Reconstruction Loss = 420.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.95 mins\n",
      "Epoch: 6 / 10, Batch: 231 (7424 / 12512), Elapsed time: 48.95 mins\n",
      "Enc Loss = 136.87, KL Divergence = 1081.53, Reconstruction Loss = 337.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.97 mins\n",
      "Epoch: 6 / 10, Batch: 232 (7456 / 12512), Elapsed time: 48.97 mins\n",
      "Enc Loss = 141.35, KL Divergence = 1089.16, Reconstruction Loss = 351.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 48.99 mins\n",
      "Epoch: 6 / 10, Batch: 233 (7488 / 12512), Elapsed time: 48.99 mins\n",
      "Enc Loss = 139.96, KL Divergence = 1053.66, Reconstruction Loss = 350.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.01 mins\n",
      "Epoch: 6 / 10, Batch: 234 (7520 / 12512), Elapsed time: 49.01 mins\n",
      "Enc Loss = 131.81, KL Divergence = 1064.28, Reconstruction Loss = 322.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.03 mins\n",
      "Epoch: 6 / 10, Batch: 235 (7552 / 12512), Elapsed time: 49.03 mins\n",
      "Enc Loss = 130.31, KL Divergence = 1066.61, Reconstruction Loss = 317.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.05 mins\n",
      "Epoch: 6 / 10, Batch: 236 (7584 / 12512), Elapsed time: 49.05 mins\n",
      "Enc Loss = 155.66, KL Divergence = 1148.96, Reconstruction Loss = 392.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.07 mins\n",
      "Epoch: 6 / 10, Batch: 237 (7616 / 12512), Elapsed time: 49.07 mins\n",
      "Enc Loss = 135.94, KL Divergence = 1043.90, Reconstruction Loss = 338.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.08 mins\n",
      "Epoch: 6 / 10, Batch: 238 (7648 / 12512), Elapsed time: 49.08 mins\n",
      "Enc Loss = 139.54, KL Divergence = 1063.79, Reconstruction Loss = 348.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.10 mins\n",
      "Epoch: 6 / 10, Batch: 239 (7680 / 12512), Elapsed time: 49.10 mins\n",
      "Enc Loss = 146.64, KL Divergence = 1153.36, Reconstruction Loss = 362.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.12 mins\n",
      "Epoch: 6 / 10, Batch: 240 (7712 / 12512), Elapsed time: 49.12 mins\n",
      "Enc Loss = 145.26, KL Divergence = 1223.01, Reconstruction Loss = 350.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.14 mins\n",
      "Epoch: 6 / 10, Batch: 241 (7744 / 12512), Elapsed time: 49.14 mins\n",
      "Enc Loss = 144.67, KL Divergence = 1076.18, Reconstruction Loss = 363.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.16 mins\n",
      "Epoch: 6 / 10, Batch: 242 (7776 / 12512), Elapsed time: 49.16 mins\n",
      "Enc Loss = 156.32, KL Divergence = 1191.33, Reconstruction Loss = 390.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.18 mins\n",
      "Epoch: 6 / 10, Batch: 243 (7808 / 12512), Elapsed time: 49.18 mins\n",
      "Enc Loss = 161.75, KL Divergence = 1314.26, Reconstruction Loss = 395.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.20 mins\n",
      "Epoch: 6 / 10, Batch: 244 (7840 / 12512), Elapsed time: 49.20 mins\n",
      "Enc Loss = 141.01, KL Divergence = 1083.03, Reconstruction Loss = 351.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.22 mins\n",
      "Epoch: 6 / 10, Batch: 245 (7872 / 12512), Elapsed time: 49.22 mins\n",
      "Enc Loss = 136.33, KL Divergence = 1112.10, Reconstruction Loss = 332.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.24 mins\n",
      "Epoch: 6 / 10, Batch: 246 (7904 / 12512), Elapsed time: 49.24 mins\n",
      "Enc Loss = 145.29, KL Divergence = 1190.21, Reconstruction Loss = 354.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.26 mins\n",
      "Epoch: 6 / 10, Batch: 247 (7936 / 12512), Elapsed time: 49.26 mins\n",
      "Enc Loss = 133.39, KL Divergence = 1042.79, Reconstruction Loss = 330.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.28 mins\n",
      "Epoch: 6 / 10, Batch: 248 (7968 / 12512), Elapsed time: 49.28 mins\n",
      "Enc Loss = 140.90, KL Divergence = 1192.07, Reconstruction Loss = 339.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.30 mins\n",
      "Epoch: 6 / 10, Batch: 249 (8000 / 12512), Elapsed time: 49.30 mins\n",
      "Enc Loss = 144.41, KL Divergence = 1280.61, Reconstruction Loss = 342.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.32 mins\n",
      "Epoch: 6 / 10, Batch: 250 (8032 / 12512), Elapsed time: 49.32 mins\n",
      "Enc Loss = 144.63, KL Divergence = 1157.61, Reconstruction Loss = 355.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.34 mins\n",
      "Epoch: 6 / 10, Batch: 251 (8064 / 12512), Elapsed time: 49.34 mins\n",
      "Enc Loss = 132.59, KL Divergence = 1102.82, Reconstruction Loss = 321.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.36 mins\n",
      "Epoch: 6 / 10, Batch: 252 (8096 / 12512), Elapsed time: 49.36 mins\n",
      "Enc Loss = 144.72, KL Divergence = 1104.49, Reconstruction Loss = 361.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.38 mins\n",
      "Epoch: 6 / 10, Batch: 253 (8128 / 12512), Elapsed time: 49.38 mins\n",
      "Enc Loss = 135.39, KL Divergence = 1119.01, Reconstruction Loss = 329.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.40 mins\n",
      "Epoch: 6 / 10, Batch: 254 (8160 / 12512), Elapsed time: 49.40 mins\n",
      "Enc Loss = 137.86, KL Divergence = 1029.23, Reconstruction Loss = 346.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.42 mins\n",
      "Epoch: 6 / 10, Batch: 255 (8192 / 12512), Elapsed time: 49.42 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 144.16, KL Divergence = 1072.66, Reconstruction Loss = 362.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.43 mins\n",
      "Epoch: 6 / 10, Batch: 256 (8224 / 12512), Elapsed time: 49.43 mins\n",
      "Enc Loss = 151.90, KL Divergence = 1203.89, Reconstruction Loss = 374.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.45 mins\n",
      "Epoch: 6 / 10, Batch: 257 (8256 / 12512), Elapsed time: 49.45 mins\n",
      "Enc Loss = 151.82, KL Divergence = 1145.71, Reconstruction Loss = 380.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.47 mins\n",
      "Epoch: 6 / 10, Batch: 258 (8288 / 12512), Elapsed time: 49.47 mins\n",
      "Enc Loss = 129.70, KL Divergence = 1089.53, Reconstruction Loss = 313.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.49 mins\n",
      "Epoch: 6 / 10, Batch: 259 (8320 / 12512), Elapsed time: 49.49 mins\n",
      "Enc Loss = 139.06, KL Divergence = 1015.16, Reconstruction Loss = 351.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.51 mins\n",
      "Epoch: 6 / 10, Batch: 260 (8352 / 12512), Elapsed time: 49.51 mins\n",
      "Enc Loss = 156.93, KL Divergence = 1261.40, Reconstruction Loss = 385.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.53 mins\n",
      "Epoch: 6 / 10, Batch: 261 (8384 / 12512), Elapsed time: 49.53 mins\n",
      "Enc Loss = 144.76, KL Divergence = 1040.44, Reconstruction Loss = 367.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.55 mins\n",
      "Epoch: 6 / 10, Batch: 262 (8416 / 12512), Elapsed time: 49.55 mins\n",
      "Enc Loss = 153.34, KL Divergence = 1255.51, Reconstruction Loss = 373.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.57 mins\n",
      "Epoch: 6 / 10, Batch: 263 (8448 / 12512), Elapsed time: 49.57 mins\n",
      "Enc Loss = 138.16, KL Divergence = 1121.37, Reconstruction Loss = 337.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.59 mins\n",
      "Epoch: 6 / 10, Batch: 264 (8480 / 12512), Elapsed time: 49.59 mins\n",
      "Enc Loss = 161.75, KL Divergence = 1140.20, Reconstruction Loss = 413.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.61 mins\n",
      "Epoch: 6 / 10, Batch: 265 (8512 / 12512), Elapsed time: 49.61 mins\n",
      "Enc Loss = 148.57, KL Divergence = 1188.61, Reconstruction Loss = 365.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.63 mins\n",
      "Epoch: 6 / 10, Batch: 266 (8544 / 12512), Elapsed time: 49.63 mins\n",
      "Enc Loss = 142.28, KL Divergence = 1121.80, Reconstruction Loss = 351.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.65 mins\n",
      "Epoch: 6 / 10, Batch: 267 (8576 / 12512), Elapsed time: 49.65 mins\n",
      "Enc Loss = 140.23, KL Divergence = 1163.63, Reconstruction Loss = 340.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.67 mins\n",
      "Epoch: 6 / 10, Batch: 268 (8608 / 12512), Elapsed time: 49.67 mins\n",
      "Enc Loss = 140.27, KL Divergence = 1255.58, Reconstruction Loss = 331.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.69 mins\n",
      "Epoch: 6 / 10, Batch: 269 (8640 / 12512), Elapsed time: 49.69 mins\n",
      "Enc Loss = 144.59, KL Divergence = 1189.89, Reconstruction Loss = 351.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.71 mins\n",
      "Epoch: 6 / 10, Batch: 270 (8672 / 12512), Elapsed time: 49.71 mins\n",
      "Enc Loss = 147.20, KL Divergence = 1267.97, Reconstruction Loss = 352.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.73 mins\n",
      "Epoch: 6 / 10, Batch: 271 (8704 / 12512), Elapsed time: 49.73 mins\n",
      "Enc Loss = 141.15, KL Divergence = 1179.50, Reconstruction Loss = 341.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.75 mins\n",
      "Epoch: 6 / 10, Batch: 272 (8736 / 12512), Elapsed time: 49.75 mins\n",
      "Enc Loss = 170.54, KL Divergence = 1264.73, Reconstruction Loss = 429.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.77 mins\n",
      "Epoch: 6 / 10, Batch: 273 (8768 / 12512), Elapsed time: 49.77 mins\n",
      "Enc Loss = 155.95, KL Divergence = 1229.02, Reconstruction Loss = 385.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.79 mins\n",
      "Epoch: 6 / 10, Batch: 274 (8800 / 12512), Elapsed time: 49.79 mins\n",
      "Enc Loss = 140.33, KL Divergence = 1088.07, Reconstruction Loss = 348.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.81 mins\n",
      "Epoch: 6 / 10, Batch: 275 (8832 / 12512), Elapsed time: 49.81 mins\n",
      "Enc Loss = 136.44, KL Divergence = 1184.41, Reconstruction Loss = 325.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.83 mins\n",
      "Epoch: 6 / 10, Batch: 276 (8864 / 12512), Elapsed time: 49.83 mins\n",
      "Enc Loss = 150.01, KL Divergence = 1274.53, Reconstruction Loss = 361.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.85 mins\n",
      "Epoch: 6 / 10, Batch: 277 (8896 / 12512), Elapsed time: 49.85 mins\n",
      "Enc Loss = 141.99, KL Divergence = 1164.75, Reconstruction Loss = 346.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.87 mins\n",
      "Epoch: 6 / 10, Batch: 278 (8928 / 12512), Elapsed time: 49.87 mins\n",
      "Enc Loss = 142.52, KL Divergence = 1203.09, Reconstruction Loss = 343.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.89 mins\n",
      "Epoch: 6 / 10, Batch: 279 (8960 / 12512), Elapsed time: 49.89 mins\n",
      "Enc Loss = 150.01, KL Divergence = 1310.77, Reconstruction Loss = 357.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.91 mins\n",
      "Epoch: 6 / 10, Batch: 280 (8992 / 12512), Elapsed time: 49.91 mins\n",
      "Enc Loss = 154.46, KL Divergence = 1248.40, Reconstruction Loss = 378.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.92 mins\n",
      "Epoch: 6 / 10, Batch: 281 (9024 / 12512), Elapsed time: 49.93 mins\n",
      "Enc Loss = 146.67, KL Divergence = 1172.11, Reconstruction Loss = 360.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.94 mins\n",
      "Epoch: 6 / 10, Batch: 282 (9056 / 12512), Elapsed time: 49.94 mins\n",
      "Enc Loss = 151.79, KL Divergence = 1157.03, Reconstruction Loss = 378.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.96 mins\n",
      "Epoch: 6 / 10, Batch: 283 (9088 / 12512), Elapsed time: 49.96 mins\n",
      "Enc Loss = 136.75, KL Divergence = 1115.29, Reconstruction Loss = 333.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 49.98 mins\n",
      "Epoch: 6 / 10, Batch: 284 (9120 / 12512), Elapsed time: 49.98 mins\n",
      "Enc Loss = 148.60, KL Divergence = 1245.37, Reconstruction Loss = 359.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.00 mins\n",
      "Epoch: 6 / 10, Batch: 285 (9152 / 12512), Elapsed time: 50.00 mins\n",
      "Enc Loss = 140.65, KL Divergence = 1094.38, Reconstruction Loss = 348.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.02 mins\n",
      "Epoch: 6 / 10, Batch: 286 (9184 / 12512), Elapsed time: 50.02 mins\n",
      "Enc Loss = 150.37, KL Divergence = 1155.57, Reconstruction Loss = 374.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.04 mins\n",
      "Epoch: 6 / 10, Batch: 287 (9216 / 12512), Elapsed time: 50.04 mins\n",
      "Enc Loss = 134.44, KL Divergence = 1031.66, Reconstruction Loss = 334.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.06 mins\n",
      "Epoch: 6 / 10, Batch: 288 (9248 / 12512), Elapsed time: 50.06 mins\n",
      "Enc Loss = 136.11, KL Divergence = 1007.92, Reconstruction Loss = 342.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.08 mins\n",
      "Epoch: 6 / 10, Batch: 289 (9280 / 12512), Elapsed time: 50.08 mins\n",
      "Enc Loss = 140.43, KL Divergence = 1081.64, Reconstruction Loss = 349.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.10 mins\n",
      "Epoch: 6 / 10, Batch: 290 (9312 / 12512), Elapsed time: 50.10 mins\n",
      "Enc Loss = 128.22, KL Divergence = 966.10, Reconstruction Loss = 321.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.12 mins\n",
      "Epoch: 6 / 10, Batch: 291 (9344 / 12512), Elapsed time: 50.12 mins\n",
      "Enc Loss = 148.33, KL Divergence = 1107.70, Reconstruction Loss = 372.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.14 mins\n",
      "Epoch: 6 / 10, Batch: 292 (9376 / 12512), Elapsed time: 50.14 mins\n",
      "Enc Loss = 148.49, KL Divergence = 1108.74, Reconstruction Loss = 373.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.16 mins\n",
      "Epoch: 6 / 10, Batch: 293 (9408 / 12512), Elapsed time: 50.16 mins\n",
      "Enc Loss = 134.66, KL Divergence = 1038.13, Reconstruction Loss = 334.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.18 mins\n",
      "Epoch: 6 / 10, Batch: 294 (9440 / 12512), Elapsed time: 50.18 mins\n",
      "Enc Loss = 146.94, KL Divergence = 1131.39, Reconstruction Loss = 365.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.20 mins\n",
      "Epoch: 6 / 10, Batch: 295 (9472 / 12512), Elapsed time: 50.20 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 141.09, KL Divergence = 1115.54, Reconstruction Loss = 348.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.22 mins\n",
      "Epoch: 6 / 10, Batch: 296 (9504 / 12512), Elapsed time: 50.22 mins\n",
      "Enc Loss = 137.65, KL Divergence = 1115.07, Reconstruction Loss = 336.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.24 mins\n",
      "Epoch: 6 / 10, Batch: 297 (9536 / 12512), Elapsed time: 50.24 mins\n",
      "Enc Loss = 166.49, KL Divergence = 1219.63, Reconstruction Loss = 420.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.26 mins\n",
      "Epoch: 6 / 10, Batch: 298 (9568 / 12512), Elapsed time: 50.26 mins\n",
      "Enc Loss = 156.07, KL Divergence = 1078.39, Reconstruction Loss = 400.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.28 mins\n",
      "Epoch: 6 / 10, Batch: 299 (9600 / 12512), Elapsed time: 50.28 mins\n",
      "Enc Loss = 153.18, KL Divergence = 1242.85, Reconstruction Loss = 374.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.30 mins\n",
      "Epoch: 6 / 10, Batch: 300 (9632 / 12512), Elapsed time: 50.30 mins\n",
      "Enc Loss = 138.49, KL Divergence = 1217.13, Reconstruction Loss = 329.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.32 mins\n",
      "Epoch: 6 / 10, Batch: 301 (9664 / 12512), Elapsed time: 50.32 mins\n",
      "Enc Loss = 149.58, KL Divergence = 1346.02, Reconstruction Loss = 352.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.34 mins\n",
      "Epoch: 6 / 10, Batch: 302 (9696 / 12512), Elapsed time: 50.34 mins\n",
      "Enc Loss = 149.99, KL Divergence = 1369.23, Reconstruction Loss = 351.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.36 mins\n",
      "Epoch: 6 / 10, Batch: 303 (9728 / 12512), Elapsed time: 50.36 mins\n",
      "Enc Loss = 145.27, KL Divergence = 1304.03, Reconstruction Loss = 342.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.38 mins\n",
      "Epoch: 6 / 10, Batch: 304 (9760 / 12512), Elapsed time: 50.38 mins\n",
      "Enc Loss = 142.71, KL Divergence = 1223.70, Reconstruction Loss = 342.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.40 mins\n",
      "Epoch: 6 / 10, Batch: 305 (9792 / 12512), Elapsed time: 50.40 mins\n",
      "Enc Loss = 141.59, KL Divergence = 1141.00, Reconstruction Loss = 347.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.42 mins\n",
      "Epoch: 6 / 10, Batch: 306 (9824 / 12512), Elapsed time: 50.42 mins\n",
      "Enc Loss = 144.17, KL Divergence = 1191.08, Reconstruction Loss = 350.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.44 mins\n",
      "Epoch: 6 / 10, Batch: 307 (9856 / 12512), Elapsed time: 50.44 mins\n",
      "Enc Loss = 142.31, KL Divergence = 1142.23, Reconstruction Loss = 349.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.46 mins\n",
      "Epoch: 6 / 10, Batch: 308 (9888 / 12512), Elapsed time: 50.46 mins\n",
      "Enc Loss = 135.30, KL Divergence = 1131.60, Reconstruction Loss = 327.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.48 mins\n",
      "Epoch: 6 / 10, Batch: 309 (9920 / 12512), Elapsed time: 50.48 mins\n",
      "Enc Loss = 154.06, KL Divergence = 1200.97, Reconstruction Loss = 381.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.50 mins\n",
      "Epoch: 6 / 10, Batch: 310 (9952 / 12512), Elapsed time: 50.50 mins\n",
      "Enc Loss = 137.85, KL Divergence = 1073.32, Reconstruction Loss = 341.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.52 mins\n",
      "Epoch: 6 / 10, Batch: 311 (9984 / 12512), Elapsed time: 50.52 mins\n",
      "Enc Loss = 149.30, KL Divergence = 1054.00, Reconstruction Loss = 381.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.54 mins\n",
      "Epoch: 6 / 10, Batch: 312 (10016 / 12512), Elapsed time: 50.54 mins\n",
      "Enc Loss = 138.80, KL Divergence = 1015.65, Reconstruction Loss = 350.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.56 mins\n",
      "Epoch: 6 / 10, Batch: 313 (10048 / 12512), Elapsed time: 50.56 mins\n",
      "Enc Loss = 139.03, KL Divergence = 1043.20, Reconstruction Loss = 348.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.58 mins\n",
      "Epoch: 6 / 10, Batch: 314 (10080 / 12512), Elapsed time: 50.58 mins\n",
      "Enc Loss = 152.41, KL Divergence = 1115.24, Reconstruction Loss = 385.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.60 mins\n",
      "Epoch: 6 / 10, Batch: 315 (10112 / 12512), Elapsed time: 50.60 mins\n",
      "Enc Loss = 144.67, KL Divergence = 1206.10, Reconstruction Loss = 350.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.62 mins\n",
      "Epoch: 6 / 10, Batch: 316 (10144 / 12512), Elapsed time: 50.62 mins\n",
      "Enc Loss = 148.22, KL Divergence = 1083.24, Reconstruction Loss = 374.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.64 mins\n",
      "Epoch: 6 / 10, Batch: 317 (10176 / 12512), Elapsed time: 50.64 mins\n",
      "Enc Loss = 139.70, KL Divergence = 1222.79, Reconstruction Loss = 332.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.66 mins\n",
      "Epoch: 6 / 10, Batch: 318 (10208 / 12512), Elapsed time: 50.66 mins\n",
      "Enc Loss = 143.86, KL Divergence = 1192.77, Reconstruction Loss = 349.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.68 mins\n",
      "Epoch: 6 / 10, Batch: 319 (10240 / 12512), Elapsed time: 50.68 mins\n",
      "Enc Loss = 133.03, KL Divergence = 1135.56, Reconstruction Loss = 319.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.70 mins\n",
      "Epoch: 6 / 10, Batch: 320 (10272 / 12512), Elapsed time: 50.70 mins\n",
      "Enc Loss = 149.00, KL Divergence = 1326.52, Reconstruction Loss = 352.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.72 mins\n",
      "Epoch: 6 / 10, Batch: 321 (10304 / 12512), Elapsed time: 50.72 mins\n",
      "Enc Loss = 149.87, KL Divergence = 1254.57, Reconstruction Loss = 362.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.73 mins\n",
      "Epoch: 6 / 10, Batch: 322 (10336 / 12512), Elapsed time: 50.73 mins\n",
      "Enc Loss = 154.28, KL Divergence = 1264.09, Reconstruction Loss = 376.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.75 mins\n",
      "Epoch: 6 / 10, Batch: 323 (10368 / 12512), Elapsed time: 50.75 mins\n",
      "Enc Loss = 150.91, KL Divergence = 1207.68, Reconstruction Loss = 370.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.77 mins\n",
      "Epoch: 6 / 10, Batch: 324 (10400 / 12512), Elapsed time: 50.77 mins\n",
      "Enc Loss = 178.88, KL Divergence = 1347.39, Reconstruction Loss = 448.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.79 mins\n",
      "Epoch: 6 / 10, Batch: 325 (10432 / 12512), Elapsed time: 50.79 mins\n",
      "Enc Loss = 142.12, KL Divergence = 1282.66, Reconstruction Loss = 334.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.81 mins\n",
      "Epoch: 6 / 10, Batch: 326 (10464 / 12512), Elapsed time: 50.81 mins\n",
      "Enc Loss = 140.77, KL Divergence = 1152.52, Reconstruction Loss = 343.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.83 mins\n",
      "Epoch: 6 / 10, Batch: 327 (10496 / 12512), Elapsed time: 50.83 mins\n",
      "Enc Loss = 151.06, KL Divergence = 1206.56, Reconstruction Loss = 371.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.85 mins\n",
      "Epoch: 6 / 10, Batch: 328 (10528 / 12512), Elapsed time: 50.85 mins\n",
      "Enc Loss = 158.65, KL Divergence = 1306.81, Reconstruction Loss = 386.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.87 mins\n",
      "Epoch: 6 / 10, Batch: 329 (10560 / 12512), Elapsed time: 50.87 mins\n",
      "Enc Loss = 141.69, KL Divergence = 1194.82, Reconstruction Loss = 341.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.89 mins\n",
      "Epoch: 6 / 10, Batch: 330 (10592 / 12512), Elapsed time: 50.89 mins\n",
      "Enc Loss = 150.10, KL Divergence = 1201.81, Reconstruction Loss = 368.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.91 mins\n",
      "Epoch: 6 / 10, Batch: 331 (10624 / 12512), Elapsed time: 50.91 mins\n",
      "Enc Loss = 146.13, KL Divergence = 1112.06, Reconstruction Loss = 364.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.93 mins\n",
      "Epoch: 6 / 10, Batch: 332 (10656 / 12512), Elapsed time: 50.93 mins\n",
      "Enc Loss = 138.23, KL Divergence = 1085.92, Reconstruction Loss = 341.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.95 mins\n",
      "Epoch: 6 / 10, Batch: 333 (10688 / 12512), Elapsed time: 50.95 mins\n",
      "Enc Loss = 153.68, KL Divergence = 1014.44, Reconstruction Loss = 399.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.97 mins\n",
      "Epoch: 6 / 10, Batch: 334 (10720 / 12512), Elapsed time: 50.97 mins\n",
      "Enc Loss = 165.83, KL Divergence = 1261.76, Reconstruction Loss = 414.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 50.99 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 10, Batch: 335 (10752 / 12512), Elapsed time: 50.99 mins\n",
      "Enc Loss = 143.94, KL Divergence = 1194.34, Reconstruction Loss = 349.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.01 mins\n",
      "Epoch: 6 / 10, Batch: 336 (10784 / 12512), Elapsed time: 51.01 mins\n",
      "Enc Loss = 129.85, KL Divergence = 1074.56, Reconstruction Loss = 315.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.03 mins\n",
      "Epoch: 6 / 10, Batch: 337 (10816 / 12512), Elapsed time: 51.03 mins\n",
      "Enc Loss = 137.36, KL Divergence = 1069.11, Reconstruction Loss = 340.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.05 mins\n",
      "Epoch: 6 / 10, Batch: 338 (10848 / 12512), Elapsed time: 51.05 mins\n",
      "Enc Loss = 136.59, KL Divergence = 1156.52, Reconstruction Loss = 329.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.07 mins\n",
      "Epoch: 6 / 10, Batch: 339 (10880 / 12512), Elapsed time: 51.07 mins\n",
      "Enc Loss = 149.24, KL Divergence = 1186.48, Reconstruction Loss = 367.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.09 mins\n",
      "Epoch: 6 / 10, Batch: 340 (10912 / 12512), Elapsed time: 51.09 mins\n",
      "Enc Loss = 134.93, KL Divergence = 1083.08, Reconstruction Loss = 331.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.11 mins\n",
      "Epoch: 6 / 10, Batch: 341 (10944 / 12512), Elapsed time: 51.11 mins\n",
      "Enc Loss = 149.31, KL Divergence = 1235.51, Reconstruction Loss = 362.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.13 mins\n",
      "Epoch: 6 / 10, Batch: 342 (10976 / 12512), Elapsed time: 51.13 mins\n",
      "Enc Loss = 139.05, KL Divergence = 1141.83, Reconstruction Loss = 338.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.14 mins\n",
      "Epoch: 6 / 10, Batch: 343 (11008 / 12512), Elapsed time: 51.15 mins\n",
      "Enc Loss = 150.19, KL Divergence = 1179.67, Reconstruction Loss = 371.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.16 mins\n",
      "Epoch: 6 / 10, Batch: 344 (11040 / 12512), Elapsed time: 51.16 mins\n",
      "Enc Loss = 144.20, KL Divergence = 1045.93, Reconstruction Loss = 365.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.18 mins\n",
      "Epoch: 6 / 10, Batch: 345 (11072 / 12512), Elapsed time: 51.18 mins\n",
      "Enc Loss = 141.46, KL Divergence = 1103.97, Reconstruction Loss = 350.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.20 mins\n",
      "Epoch: 6 / 10, Batch: 346 (11104 / 12512), Elapsed time: 51.20 mins\n",
      "Enc Loss = 148.14, KL Divergence = 1107.78, Reconstruction Loss = 371.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.22 mins\n",
      "Epoch: 6 / 10, Batch: 347 (11136 / 12512), Elapsed time: 51.22 mins\n",
      "Enc Loss = 135.34, KL Divergence = 1028.81, Reconstruction Loss = 338.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.24 mins\n",
      "Epoch: 6 / 10, Batch: 348 (11168 / 12512), Elapsed time: 51.24 mins\n",
      "Enc Loss = 168.49, KL Divergence = 1218.57, Reconstruction Loss = 427.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.26 mins\n",
      "Epoch: 6 / 10, Batch: 349 (11200 / 12512), Elapsed time: 51.26 mins\n",
      "Enc Loss = 144.10, KL Divergence = 1084.91, Reconstruction Loss = 361.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.28 mins\n",
      "Epoch: 6 / 10, Batch: 350 (11232 / 12512), Elapsed time: 51.28 mins\n",
      "Enc Loss = 136.44, KL Divergence = 1117.10, Reconstruction Loss = 332.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.30 mins\n",
      "Epoch: 6 / 10, Batch: 351 (11264 / 12512), Elapsed time: 51.30 mins\n",
      "Enc Loss = 139.09, KL Divergence = 1087.04, Reconstruction Loss = 344.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.32 mins\n",
      "Epoch: 6 / 10, Batch: 352 (11296 / 12512), Elapsed time: 51.32 mins\n",
      "Enc Loss = 142.10, KL Divergence = 1123.98, Reconstruction Loss = 350.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.34 mins\n",
      "Epoch: 6 / 10, Batch: 353 (11328 / 12512), Elapsed time: 51.34 mins\n",
      "Enc Loss = 145.02, KL Divergence = 1191.86, Reconstruction Loss = 353.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.36 mins\n",
      "Epoch: 6 / 10, Batch: 354 (11360 / 12512), Elapsed time: 51.36 mins\n",
      "Enc Loss = 147.96, KL Divergence = 1270.46, Reconstruction Loss = 354.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.38 mins\n",
      "Epoch: 6 / 10, Batch: 355 (11392 / 12512), Elapsed time: 51.38 mins\n",
      "Enc Loss = 143.06, KL Divergence = 1256.85, Reconstruction Loss = 340.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.40 mins\n",
      "Epoch: 6 / 10, Batch: 356 (11424 / 12512), Elapsed time: 51.40 mins\n",
      "Enc Loss = 152.06, KL Divergence = 1298.12, Reconstruction Loss = 365.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.42 mins\n",
      "Epoch: 6 / 10, Batch: 357 (11456 / 12512), Elapsed time: 51.42 mins\n",
      "Enc Loss = 162.45, KL Divergence = 1363.16, Reconstruction Loss = 392.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.44 mins\n",
      "Epoch: 6 / 10, Batch: 358 (11488 / 12512), Elapsed time: 51.44 mins\n",
      "Enc Loss = 134.79, KL Divergence = 1077.30, Reconstruction Loss = 331.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.46 mins\n",
      "Epoch: 6 / 10, Batch: 359 (11520 / 12512), Elapsed time: 51.46 mins\n",
      "Enc Loss = 130.15, KL Divergence = 1074.11, Reconstruction Loss = 316.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.48 mins\n",
      "Epoch: 6 / 10, Batch: 360 (11552 / 12512), Elapsed time: 51.48 mins\n",
      "Enc Loss = 146.43, KL Divergence = 1237.58, Reconstruction Loss = 353.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.50 mins\n",
      "Epoch: 6 / 10, Batch: 361 (11584 / 12512), Elapsed time: 51.50 mins\n",
      "Enc Loss = 133.49, KL Divergence = 1100.99, Reconstruction Loss = 324.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.52 mins\n",
      "Epoch: 6 / 10, Batch: 362 (11616 / 12512), Elapsed time: 51.52 mins\n",
      "Enc Loss = 139.33, KL Divergence = 1148.50, Reconstruction Loss = 338.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.54 mins\n",
      "Epoch: 6 / 10, Batch: 363 (11648 / 12512), Elapsed time: 51.54 mins\n",
      "Enc Loss = 131.44, KL Divergence = 1162.60, Reconstruction Loss = 311.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.56 mins\n",
      "Epoch: 6 / 10, Batch: 364 (11680 / 12512), Elapsed time: 51.56 mins\n",
      "Enc Loss = 143.64, KL Divergence = 1068.29, Reconstruction Loss = 361.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.58 mins\n",
      "Epoch: 6 / 10, Batch: 365 (11712 / 12512), Elapsed time: 51.58 mins\n",
      "Enc Loss = 142.83, KL Divergence = 1141.97, Reconstruction Loss = 351.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.60 mins\n",
      "Epoch: 6 / 10, Batch: 366 (11744 / 12512), Elapsed time: 51.60 mins\n",
      "Enc Loss = 133.58, KL Divergence = 1084.20, Reconstruction Loss = 326.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.62 mins\n",
      "Epoch: 6 / 10, Batch: 367 (11776 / 12512), Elapsed time: 51.62 mins\n",
      "Enc Loss = 136.01, KL Divergence = 1097.00, Reconstruction Loss = 333.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.64 mins\n",
      "Epoch: 6 / 10, Batch: 368 (11808 / 12512), Elapsed time: 51.64 mins\n",
      "Enc Loss = 149.33, KL Divergence = 1165.65, Reconstruction Loss = 369.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.66 mins\n",
      "Epoch: 6 / 10, Batch: 369 (11840 / 12512), Elapsed time: 51.66 mins\n",
      "Enc Loss = 142.33, KL Divergence = 1065.01, Reconstruction Loss = 357.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.68 mins\n",
      "Epoch: 6 / 10, Batch: 370 (11872 / 12512), Elapsed time: 51.68 mins\n",
      "Enc Loss = 138.61, KL Divergence = 1151.30, Reconstruction Loss = 336.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.70 mins\n",
      "Epoch: 6 / 10, Batch: 371 (11904 / 12512), Elapsed time: 51.70 mins\n",
      "Enc Loss = 130.28, KL Divergence = 1017.44, Reconstruction Loss = 322.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.72 mins\n",
      "Epoch: 6 / 10, Batch: 372 (11936 / 12512), Elapsed time: 51.72 mins\n",
      "Enc Loss = 135.42, KL Divergence = 1155.49, Reconstruction Loss = 325.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.73 mins\n",
      "Epoch: 6 / 10, Batch: 373 (11968 / 12512), Elapsed time: 51.73 mins\n",
      "Enc Loss = 141.44, KL Divergence = 1193.39, Reconstruction Loss = 341.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.75 mins\n",
      "Epoch: 6 / 10, Batch: 374 (12000 / 12512), Elapsed time: 51.76 mins\n",
      "Enc Loss = 136.05, KL Divergence = 1122.44, Reconstruction Loss = 330.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.77 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 / 10, Batch: 375 (12032 / 12512), Elapsed time: 51.77 mins\n",
      "Enc Loss = 142.22, KL Divergence = 1009.16, Reconstruction Loss = 362.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.79 mins\n",
      "Epoch: 6 / 10, Batch: 376 (12064 / 12512), Elapsed time: 51.79 mins\n",
      "Enc Loss = 140.28, KL Divergence = 1082.84, Reconstruction Loss = 348.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.81 mins\n",
      "Epoch: 6 / 10, Batch: 377 (12096 / 12512), Elapsed time: 51.81 mins\n",
      "Enc Loss = 149.34, KL Divergence = 1177.08, Reconstruction Loss = 368.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.83 mins\n",
      "Epoch: 6 / 10, Batch: 378 (12128 / 12512), Elapsed time: 51.83 mins\n",
      "Enc Loss = 139.11, KL Divergence = 1010.80, Reconstruction Loss = 352.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.85 mins\n",
      "Epoch: 6 / 10, Batch: 379 (12160 / 12512), Elapsed time: 51.85 mins\n",
      "Enc Loss = 140.17, KL Divergence = 1170.91, Reconstruction Loss = 339.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.87 mins\n",
      "Epoch: 6 / 10, Batch: 380 (12192 / 12512), Elapsed time: 51.87 mins\n",
      "Enc Loss = 143.47, KL Divergence = 1188.07, Reconstruction Loss = 348.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.89 mins\n",
      "Epoch: 6 / 10, Batch: 381 (12224 / 12512), Elapsed time: 51.89 mins\n",
      "Enc Loss = 193.27, KL Divergence = 1232.32, Reconstruction Loss = 507.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.91 mins\n",
      "Epoch: 6 / 10, Batch: 382 (12256 / 12512), Elapsed time: 51.91 mins\n",
      "Enc Loss = 164.41, KL Divergence = 1260.59, Reconstruction Loss = 409.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.93 mins\n",
      "Epoch: 6 / 10, Batch: 383 (12288 / 12512), Elapsed time: 51.93 mins\n",
      "Enc Loss = 138.32, KL Divergence = 1160.99, Reconstruction Loss = 334.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.95 mins\n",
      "Epoch: 6 / 10, Batch: 384 (12320 / 12512), Elapsed time: 51.95 mins\n",
      "Enc Loss = 146.82, KL Divergence = 1321.46, Reconstruction Loss = 345.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.97 mins\n",
      "Epoch: 6 / 10, Batch: 385 (12352 / 12512), Elapsed time: 51.97 mins\n",
      "Enc Loss = 157.54, KL Divergence = 1383.44, Reconstruction Loss = 374.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 51.99 mins\n",
      "Epoch: 6 / 10, Batch: 386 (12384 / 12512), Elapsed time: 51.99 mins\n",
      "Enc Loss = 148.17, KL Divergence = 1369.38, Reconstruction Loss = 345.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.01 mins\n",
      "Epoch: 6 / 10, Batch: 387 (12416 / 12512), Elapsed time: 52.01 mins\n",
      "Enc Loss = 137.93, KL Divergence = 1340.71, Reconstruction Loss = 314.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.03 mins\n",
      "Epoch: 6 / 10, Batch: 388 (12448 / 12512), Elapsed time: 52.03 mins\n",
      "Enc Loss = 139.40, KL Divergence = 1347.88, Reconstruction Loss = 318.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.05 mins\n",
      "Epoch: 6 / 10, Batch: 389 (12480 / 12512), Elapsed time: 52.05 mins\n",
      "Enc Loss = 146.83, KL Divergence = 1305.20, Reconstruction Loss = 347.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.07 mins\n",
      "Epoch: 6 / 10, Batch: 390 (12512 / 12512), Elapsed time: 52.07 mins\n",
      "Enc Loss = 119.01, KL Divergence = 544.65, Reconstruction Loss = 334.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.09 mins\n",
      "Epoch: 7, Elapsed Time: 52.09\n",
      "Epoch: 7 / 10, Batch: 0 (32 / 12512), Elapsed time: 52.09 mins\n",
      "Enc Loss = 139.98, KL Divergence = 1284.77, Reconstruction Loss = 327.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.11 mins\n",
      "Epoch: 7 / 10, Batch: 1 (64 / 12512), Elapsed time: 52.11 mins\n",
      "Enc Loss = 155.29, KL Divergence = 1282.29, Reconstruction Loss = 377.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.12 mins\n",
      "Epoch: 7 / 10, Batch: 2 (96 / 12512), Elapsed time: 52.13 mins\n",
      "Enc Loss = 147.20, KL Divergence = 1202.48, Reconstruction Loss = 359.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.14 mins\n",
      "Epoch: 7 / 10, Batch: 3 (128 / 12512), Elapsed time: 52.14 mins\n",
      "Enc Loss = 175.37, KL Divergence = 1361.18, Reconstruction Loss = 435.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.16 mins\n",
      "Epoch: 7 / 10, Batch: 4 (160 / 12512), Elapsed time: 52.16 mins\n",
      "Enc Loss = 135.84, KL Divergence = 1190.85, Reconstruction Loss = 323.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.18 mins\n",
      "Epoch: 7 / 10, Batch: 5 (192 / 12512), Elapsed time: 52.18 mins\n",
      "Enc Loss = 139.57, KL Divergence = 1134.91, Reconstruction Loss = 341.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.20 mins\n",
      "Epoch: 7 / 10, Batch: 6 (224 / 12512), Elapsed time: 52.20 mins\n",
      "Enc Loss = 142.92, KL Divergence = 1168.96, Reconstruction Loss = 348.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.22 mins\n",
      "Epoch: 7 / 10, Batch: 7 (256 / 12512), Elapsed time: 52.22 mins\n",
      "Enc Loss = 143.20, KL Divergence = 1204.50, Reconstruction Loss = 345.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.24 mins\n",
      "Epoch: 7 / 10, Batch: 8 (288 / 12512), Elapsed time: 52.24 mins\n",
      "Enc Loss = 143.14, KL Divergence = 1210.68, Reconstruction Loss = 345.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.26 mins\n",
      "Epoch: 7 / 10, Batch: 9 (320 / 12512), Elapsed time: 52.26 mins\n",
      "Enc Loss = 139.10, KL Divergence = 1154.98, Reconstruction Loss = 337.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.28 mins\n",
      "Epoch: 7 / 10, Batch: 10 (352 / 12512), Elapsed time: 52.28 mins\n",
      "Enc Loss = 137.31, KL Divergence = 1226.97, Reconstruction Loss = 324.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.30 mins\n",
      "Epoch: 7 / 10, Batch: 11 (384 / 12512), Elapsed time: 52.30 mins\n",
      "Enc Loss = 155.90, KL Divergence = 1146.55, Reconstruction Loss = 393.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.32 mins\n",
      "Epoch: 7 / 10, Batch: 12 (416 / 12512), Elapsed time: 52.32 mins\n",
      "Enc Loss = 141.82, KL Divergence = 1179.43, Reconstruction Loss = 343.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.34 mins\n",
      "Epoch: 7 / 10, Batch: 13 (448 / 12512), Elapsed time: 52.34 mins\n",
      "Enc Loss = 167.87, KL Divergence = 1355.67, Reconstruction Loss = 411.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.36 mins\n",
      "Epoch: 7 / 10, Batch: 14 (480 / 12512), Elapsed time: 52.36 mins\n",
      "Enc Loss = 158.38, KL Divergence = 1213.89, Reconstruction Loss = 394.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.38 mins\n",
      "Epoch: 7 / 10, Batch: 15 (512 / 12512), Elapsed time: 52.38 mins\n",
      "Enc Loss = 133.24, KL Divergence = 1041.27, Reconstruction Loss = 329.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.40 mins\n",
      "Epoch: 7 / 10, Batch: 16 (544 / 12512), Elapsed time: 52.40 mins\n",
      "Enc Loss = 142.67, KL Divergence = 1163.66, Reconstruction Loss = 348.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.42 mins\n",
      "Epoch: 7 / 10, Batch: 17 (576 / 12512), Elapsed time: 52.42 mins\n",
      "Enc Loss = 157.88, KL Divergence = 1110.33, Reconstruction Loss = 403.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.44 mins\n",
      "Epoch: 7 / 10, Batch: 18 (608 / 12512), Elapsed time: 52.44 mins\n",
      "Enc Loss = 137.44, KL Divergence = 1080.83, Reconstruction Loss = 339.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.46 mins\n",
      "Epoch: 7 / 10, Batch: 19 (640 / 12512), Elapsed time: 52.46 mins\n",
      "Enc Loss = 161.91, KL Divergence = 1251.90, Reconstruction Loss = 402.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.48 mins\n",
      "Epoch: 7 / 10, Batch: 20 (672 / 12512), Elapsed time: 52.48 mins\n",
      "Enc Loss = 154.22, KL Divergence = 1056.63, Reconstruction Loss = 397.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.50 mins\n",
      "Epoch: 7 / 10, Batch: 21 (704 / 12512), Elapsed time: 52.50 mins\n",
      "Enc Loss = 142.17, KL Divergence = 1031.13, Reconstruction Loss = 360.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.52 mins\n",
      "Epoch: 7 / 10, Batch: 22 (736 / 12512), Elapsed time: 52.52 mins\n",
      "Enc Loss = 162.59, KL Divergence = 1298.42, Reconstruction Loss = 399.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.54 mins\n",
      "Epoch: 7 / 10, Batch: 23 (768 / 12512), Elapsed time: 52.54 mins\n",
      "Enc Loss = 167.13, KL Divergence = 1170.17, Reconstruction Loss = 427.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.56 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 10, Batch: 24 (800 / 12512), Elapsed time: 52.56 mins\n",
      "Enc Loss = 141.92, KL Divergence = 1153.57, Reconstruction Loss = 346.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.58 mins\n",
      "Epoch: 7 / 10, Batch: 25 (832 / 12512), Elapsed time: 52.58 mins\n",
      "Enc Loss = 165.15, KL Divergence = 1460.98, Reconstruction Loss = 391.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.59 mins\n",
      "Epoch: 7 / 10, Batch: 26 (864 / 12512), Elapsed time: 52.60 mins\n",
      "Enc Loss = 144.53, KL Divergence = 1240.18, Reconstruction Loss = 346.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.61 mins\n",
      "Epoch: 7 / 10, Batch: 27 (896 / 12512), Elapsed time: 52.62 mins\n",
      "Enc Loss = 131.56, KL Divergence = 1113.79, Reconstruction Loss = 317.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.63 mins\n",
      "Epoch: 7 / 10, Batch: 28 (928 / 12512), Elapsed time: 52.64 mins\n",
      "Enc Loss = 137.22, KL Divergence = 1169.09, Reconstruction Loss = 329.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.65 mins\n",
      "Epoch: 7 / 10, Batch: 29 (960 / 12512), Elapsed time: 52.65 mins\n",
      "Enc Loss = 155.98, KL Divergence = 1155.84, Reconstruction Loss = 392.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.67 mins\n",
      "Epoch: 7 / 10, Batch: 30 (992 / 12512), Elapsed time: 52.67 mins\n",
      "Enc Loss = 153.17, KL Divergence = 1299.95, Reconstruction Loss = 368.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.69 mins\n",
      "Epoch: 7 / 10, Batch: 31 (1024 / 12512), Elapsed time: 52.69 mins\n",
      "Enc Loss = 148.73, KL Divergence = 1259.17, Reconstruction Loss = 358.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.71 mins\n",
      "Epoch: 7 / 10, Batch: 32 (1056 / 12512), Elapsed time: 52.71 mins\n",
      "Enc Loss = 137.60, KL Divergence = 1208.70, Reconstruction Loss = 327.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.73 mins\n",
      "Epoch: 7 / 10, Batch: 33 (1088 / 12512), Elapsed time: 52.73 mins\n",
      "Enc Loss = 146.39, KL Divergence = 1218.17, Reconstruction Loss = 354.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.75 mins\n",
      "Epoch: 7 / 10, Batch: 34 (1120 / 12512), Elapsed time: 52.75 mins\n",
      "Enc Loss = 139.57, KL Divergence = 1091.49, Reconstruction Loss = 345.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.77 mins\n",
      "Epoch: 7 / 10, Batch: 35 (1152 / 12512), Elapsed time: 52.77 mins\n",
      "Enc Loss = 143.75, KL Divergence = 1247.74, Reconstruction Loss = 343.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.79 mins\n",
      "Epoch: 7 / 10, Batch: 36 (1184 / 12512), Elapsed time: 52.79 mins\n",
      "Enc Loss = 135.66, KL Divergence = 1151.18, Reconstruction Loss = 326.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.81 mins\n",
      "Epoch: 7 / 10, Batch: 37 (1216 / 12512), Elapsed time: 52.81 mins\n",
      "Enc Loss = 138.92, KL Divergence = 1135.26, Reconstruction Loss = 338.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.83 mins\n",
      "Epoch: 7 / 10, Batch: 38 (1248 / 12512), Elapsed time: 52.83 mins\n",
      "Enc Loss = 141.96, KL Divergence = 1182.47, Reconstruction Loss = 344.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.85 mins\n",
      "Epoch: 7 / 10, Batch: 39 (1280 / 12512), Elapsed time: 52.85 mins\n",
      "Enc Loss = 140.32, KL Divergence = 1087.81, Reconstruction Loss = 348.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.87 mins\n",
      "Epoch: 7 / 10, Batch: 40 (1312 / 12512), Elapsed time: 52.87 mins\n",
      "Enc Loss = 136.59, KL Divergence = 1149.05, Reconstruction Loss = 329.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.89 mins\n",
      "Epoch: 7 / 10, Batch: 41 (1344 / 12512), Elapsed time: 52.89 mins\n",
      "Enc Loss = 143.63, KL Divergence = 1236.38, Reconstruction Loss = 344.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.91 mins\n",
      "Epoch: 7 / 10, Batch: 42 (1376 / 12512), Elapsed time: 52.91 mins\n",
      "Enc Loss = 138.32, KL Divergence = 1086.38, Reconstruction Loss = 341.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.93 mins\n",
      "Epoch: 7 / 10, Batch: 43 (1408 / 12512), Elapsed time: 52.93 mins\n",
      "Enc Loss = 141.42, KL Divergence = 1151.09, Reconstruction Loss = 345.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.95 mins\n",
      "Epoch: 7 / 10, Batch: 44 (1440 / 12512), Elapsed time: 52.95 mins\n",
      "Enc Loss = 137.30, KL Divergence = 1083.54, Reconstruction Loss = 338.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.97 mins\n",
      "Epoch: 7 / 10, Batch: 45 (1472 / 12512), Elapsed time: 52.97 mins\n",
      "Enc Loss = 137.82, KL Divergence = 1063.50, Reconstruction Loss = 342.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 52.99 mins\n",
      "Epoch: 7 / 10, Batch: 46 (1504 / 12512), Elapsed time: 52.99 mins\n",
      "Enc Loss = 149.26, KL Divergence = 1182.52, Reconstruction Loss = 368.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.01 mins\n",
      "Epoch: 7 / 10, Batch: 47 (1536 / 12512), Elapsed time: 53.01 mins\n",
      "Enc Loss = 134.25, KL Divergence = 1068.26, Reconstruction Loss = 330.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.03 mins\n",
      "Epoch: 7 / 10, Batch: 48 (1568 / 12512), Elapsed time: 53.03 mins\n",
      "Enc Loss = 131.86, KL Divergence = 980.24, Reconstruction Loss = 331.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.05 mins\n",
      "Epoch: 7 / 10, Batch: 49 (1600 / 12512), Elapsed time: 53.05 mins\n",
      "Enc Loss = 152.31, KL Divergence = 1275.04, Reconstruction Loss = 368.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.07 mins\n",
      "Epoch: 7 / 10, Batch: 50 (1632 / 12512), Elapsed time: 53.07 mins\n",
      "Enc Loss = 146.85, KL Divergence = 1112.15, Reconstruction Loss = 367.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.09 mins\n",
      "Epoch: 7 / 10, Batch: 51 (1664 / 12512), Elapsed time: 53.09 mins\n",
      "Enc Loss = 140.84, KL Divergence = 1087.41, Reconstruction Loss = 350.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.11 mins\n",
      "Epoch: 7 / 10, Batch: 52 (1696 / 12512), Elapsed time: 53.11 mins\n",
      "Enc Loss = 136.49, KL Divergence = 1000.49, Reconstruction Loss = 344.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.13 mins\n",
      "Epoch: 7 / 10, Batch: 53 (1728 / 12512), Elapsed time: 53.13 mins\n",
      "Enc Loss = 138.71, KL Divergence = 1052.60, Reconstruction Loss = 346.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.15 mins\n",
      "Epoch: 7 / 10, Batch: 54 (1760 / 12512), Elapsed time: 53.15 mins\n",
      "Enc Loss = 128.02, KL Divergence = 963.63, Reconstruction Loss = 320.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.17 mins\n",
      "Epoch: 7 / 10, Batch: 55 (1792 / 12512), Elapsed time: 53.17 mins\n",
      "Enc Loss = 131.00, KL Divergence = 1024.56, Reconstruction Loss = 324.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.19 mins\n",
      "Epoch: 7 / 10, Batch: 56 (1824 / 12512), Elapsed time: 53.19 mins\n",
      "Enc Loss = 146.45, KL Divergence = 1113.57, Reconstruction Loss = 365.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.21 mins\n",
      "Epoch: 7 / 10, Batch: 57 (1856 / 12512), Elapsed time: 53.21 mins\n",
      "Enc Loss = 145.53, KL Divergence = 1195.75, Reconstruction Loss = 354.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.23 mins\n",
      "Epoch: 7 / 10, Batch: 58 (1888 / 12512), Elapsed time: 53.23 mins\n",
      "Enc Loss = 148.70, KL Divergence = 1281.14, Reconstruction Loss = 356.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.25 mins\n",
      "Epoch: 7 / 10, Batch: 59 (1920 / 12512), Elapsed time: 53.25 mins\n",
      "Enc Loss = 132.10, KL Divergence = 1051.23, Reconstruction Loss = 325.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.27 mins\n",
      "Epoch: 7 / 10, Batch: 60 (1952 / 12512), Elapsed time: 53.27 mins\n",
      "Enc Loss = 146.71, KL Divergence = 1214.30, Reconstruction Loss = 356.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.29 mins\n",
      "Epoch: 7 / 10, Batch: 61 (1984 / 12512), Elapsed time: 53.29 mins\n",
      "Enc Loss = 134.52, KL Divergence = 1014.30, Reconstruction Loss = 336.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.31 mins\n",
      "Epoch: 7 / 10, Batch: 62 (2016 / 12512), Elapsed time: 53.31 mins\n",
      "Enc Loss = 136.31, KL Divergence = 1130.28, Reconstruction Loss = 330.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.33 mins\n",
      "Epoch: 7 / 10, Batch: 63 (2048 / 12512), Elapsed time: 53.33 mins\n",
      "Enc Loss = 133.21, KL Divergence = 1091.53, Reconstruction Loss = 324.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.35 mins\n",
      "Epoch: 7 / 10, Batch: 64 (2080 / 12512), Elapsed time: 53.35 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 147.94, KL Divergence = 1254.52, Reconstruction Loss = 356.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.37 mins\n",
      "Epoch: 7 / 10, Batch: 65 (2112 / 12512), Elapsed time: 53.37 mins\n",
      "Enc Loss = 141.88, KL Divergence = 1226.09, Reconstruction Loss = 339.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.39 mins\n",
      "Epoch: 7 / 10, Batch: 66 (2144 / 12512), Elapsed time: 53.39 mins\n",
      "Enc Loss = 144.04, KL Divergence = 1216.17, Reconstruction Loss = 347.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.41 mins\n",
      "Epoch: 7 / 10, Batch: 67 (2176 / 12512), Elapsed time: 53.41 mins\n",
      "Enc Loss = 131.96, KL Divergence = 1076.04, Reconstruction Loss = 322.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.43 mins\n",
      "Epoch: 7 / 10, Batch: 68 (2208 / 12512), Elapsed time: 53.43 mins\n",
      "Enc Loss = 140.83, KL Divergence = 1162.07, Reconstruction Loss = 342.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.45 mins\n",
      "Epoch: 7 / 10, Batch: 69 (2240 / 12512), Elapsed time: 53.45 mins\n",
      "Enc Loss = 142.84, KL Divergence = 1145.79, Reconstruction Loss = 350.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.47 mins\n",
      "Epoch: 7 / 10, Batch: 70 (2272 / 12512), Elapsed time: 53.47 mins\n",
      "Enc Loss = 136.05, KL Divergence = 1135.09, Reconstruction Loss = 329.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.49 mins\n",
      "Epoch: 7 / 10, Batch: 71 (2304 / 12512), Elapsed time: 53.49 mins\n",
      "Enc Loss = 144.39, KL Divergence = 1222.27, Reconstruction Loss = 347.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.51 mins\n",
      "Epoch: 7 / 10, Batch: 72 (2336 / 12512), Elapsed time: 53.51 mins\n",
      "Enc Loss = 133.76, KL Divergence = 1105.95, Reconstruction Loss = 325.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.53 mins\n",
      "Epoch: 7 / 10, Batch: 73 (2368 / 12512), Elapsed time: 53.53 mins\n",
      "Enc Loss = 149.42, KL Divergence = 1128.93, Reconstruction Loss = 374.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.55 mins\n",
      "Epoch: 7 / 10, Batch: 74 (2400 / 12512), Elapsed time: 53.55 mins\n",
      "Enc Loss = 154.24, KL Divergence = 1195.43, Reconstruction Loss = 382.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.57 mins\n",
      "Epoch: 7 / 10, Batch: 75 (2432 / 12512), Elapsed time: 53.57 mins\n",
      "Enc Loss = 141.33, KL Divergence = 1088.04, Reconstruction Loss = 351.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.59 mins\n",
      "Epoch: 7 / 10, Batch: 76 (2464 / 12512), Elapsed time: 53.59 mins\n",
      "Enc Loss = 140.50, KL Divergence = 1122.58, Reconstruction Loss = 345.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.60 mins\n",
      "Epoch: 7 / 10, Batch: 77 (2496 / 12512), Elapsed time: 53.60 mins\n",
      "Enc Loss = 142.32, KL Divergence = 1241.20, Reconstruction Loss = 339.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.62 mins\n",
      "Epoch: 7 / 10, Batch: 78 (2528 / 12512), Elapsed time: 53.63 mins\n",
      "Enc Loss = 150.46, KL Divergence = 1271.90, Reconstruction Loss = 362.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.65 mins\n",
      "Epoch: 7 / 10, Batch: 79 (2560 / 12512), Elapsed time: 53.65 mins\n",
      "Enc Loss = 139.78, KL Divergence = 1123.27, Reconstruction Loss = 343.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.67 mins\n",
      "Epoch: 7 / 10, Batch: 80 (2592 / 12512), Elapsed time: 53.67 mins\n",
      "Enc Loss = 129.22, KL Divergence = 1150.69, Reconstruction Loss = 305.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.69 mins\n",
      "Epoch: 7 / 10, Batch: 81 (2624 / 12512), Elapsed time: 53.69 mins\n",
      "Enc Loss = 135.02, KL Divergence = 1103.95, Reconstruction Loss = 329.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.71 mins\n",
      "Epoch: 7 / 10, Batch: 82 (2656 / 12512), Elapsed time: 53.71 mins\n",
      "Enc Loss = 147.70, KL Divergence = 1167.55, Reconstruction Loss = 364.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.73 mins\n",
      "Epoch: 7 / 10, Batch: 83 (2688 / 12512), Elapsed time: 53.73 mins\n",
      "Enc Loss = 146.27, KL Divergence = 1213.01, Reconstruction Loss = 355.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.75 mins\n",
      "Epoch: 7 / 10, Batch: 84 (2720 / 12512), Elapsed time: 53.75 mins\n",
      "Enc Loss = 150.69, KL Divergence = 1188.74, Reconstruction Loss = 372.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.77 mins\n",
      "Epoch: 7 / 10, Batch: 85 (2752 / 12512), Elapsed time: 53.77 mins\n",
      "Enc Loss = 145.83, KL Divergence = 1205.27, Reconstruction Loss = 354.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.79 mins\n",
      "Epoch: 7 / 10, Batch: 86 (2784 / 12512), Elapsed time: 53.79 mins\n",
      "Enc Loss = 145.35, KL Divergence = 1245.74, Reconstruction Loss = 348.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.81 mins\n",
      "Epoch: 7 / 10, Batch: 87 (2816 / 12512), Elapsed time: 53.81 mins\n",
      "Enc Loss = 135.30, KL Divergence = 1149.77, Reconstruction Loss = 325.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.83 mins\n",
      "Epoch: 7 / 10, Batch: 88 (2848 / 12512), Elapsed time: 53.83 mins\n",
      "Enc Loss = 145.97, KL Divergence = 1076.87, Reconstruction Loss = 368.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.85 mins\n",
      "Epoch: 7 / 10, Batch: 89 (2880 / 12512), Elapsed time: 53.85 mins\n",
      "Enc Loss = 139.64, KL Divergence = 1168.82, Reconstruction Loss = 337.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.87 mins\n",
      "Epoch: 7 / 10, Batch: 90 (2912 / 12512), Elapsed time: 53.87 mins\n",
      "Enc Loss = 137.45, KL Divergence = 1154.33, Reconstruction Loss = 332.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.89 mins\n",
      "Epoch: 7 / 10, Batch: 91 (2944 / 12512), Elapsed time: 53.89 mins\n",
      "Enc Loss = 169.54, KL Divergence = 1138.09, Reconstruction Loss = 439.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.91 mins\n",
      "Epoch: 7 / 10, Batch: 92 (2976 / 12512), Elapsed time: 53.91 mins\n",
      "Enc Loss = 144.31, KL Divergence = 1208.66, Reconstruction Loss = 349.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.93 mins\n",
      "Epoch: 7 / 10, Batch: 93 (3008 / 12512), Elapsed time: 53.93 mins\n",
      "Enc Loss = 131.83, KL Divergence = 1016.68, Reconstruction Loss = 327.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.95 mins\n",
      "Epoch: 7 / 10, Batch: 94 (3040 / 12512), Elapsed time: 53.95 mins\n",
      "Enc Loss = 134.03, KL Divergence = 1110.39, Reconstruction Loss = 325.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.97 mins\n",
      "Epoch: 7 / 10, Batch: 95 (3072 / 12512), Elapsed time: 53.97 mins\n",
      "Enc Loss = 142.13, KL Divergence = 1052.13, Reconstruction Loss = 357.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 53.99 mins\n",
      "Epoch: 7 / 10, Batch: 96 (3104 / 12512), Elapsed time: 53.99 mins\n",
      "Enc Loss = 158.10, KL Divergence = 1190.95, Reconstruction Loss = 396.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.01 mins\n",
      "Epoch: 7 / 10, Batch: 97 (3136 / 12512), Elapsed time: 54.01 mins\n",
      "Enc Loss = 144.16, KL Divergence = 1216.82, Reconstruction Loss = 347.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.03 mins\n",
      "Epoch: 7 / 10, Batch: 98 (3168 / 12512), Elapsed time: 54.03 mins\n",
      "Enc Loss = 151.52, KL Divergence = 1256.42, Reconstruction Loss = 367.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.05 mins\n",
      "Epoch: 7 / 10, Batch: 99 (3200 / 12512), Elapsed time: 54.05 mins\n",
      "Enc Loss = 133.99, KL Divergence = 1122.16, Reconstruction Loss = 324.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.07 mins\n",
      "Epoch: 7 / 10, Batch: 100 (3232 / 12512), Elapsed time: 54.07 mins\n",
      "Enc Loss = 133.27, KL Divergence = 1101.73, Reconstruction Loss = 323.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.09 mins\n",
      "Epoch: 7 / 10, Batch: 101 (3264 / 12512), Elapsed time: 54.09 mins\n",
      "Enc Loss = 128.58, KL Divergence = 1059.01, Reconstruction Loss = 312.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.11 mins\n",
      "Epoch: 7 / 10, Batch: 102 (3296 / 12512), Elapsed time: 54.11 mins\n",
      "Enc Loss = 136.72, KL Divergence = 1098.47, Reconstruction Loss = 335.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.13 mins\n",
      "Epoch: 7 / 10, Batch: 103 (3328 / 12512), Elapsed time: 54.13 mins\n",
      "Enc Loss = 144.57, KL Divergence = 1079.20, Reconstruction Loss = 363.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.15 mins\n",
      "Epoch: 7 / 10, Batch: 104 (3360 / 12512), Elapsed time: 54.15 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 143.14, KL Divergence = 1132.46, Reconstruction Loss = 353.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.17 mins\n",
      "Epoch: 7 / 10, Batch: 105 (3392 / 12512), Elapsed time: 54.17 mins\n",
      "Enc Loss = 138.67, KL Divergence = 1117.98, Reconstruction Loss = 339.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.19 mins\n",
      "Epoch: 7 / 10, Batch: 106 (3424 / 12512), Elapsed time: 54.19 mins\n",
      "Enc Loss = 147.56, KL Divergence = 1194.14, Reconstruction Loss = 361.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.21 mins\n",
      "Epoch: 7 / 10, Batch: 107 (3456 / 12512), Elapsed time: 54.21 mins\n",
      "Enc Loss = 132.46, KL Divergence = 1039.62, Reconstruction Loss = 327.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.23 mins\n",
      "Epoch: 7 / 10, Batch: 108 (3488 / 12512), Elapsed time: 54.23 mins\n",
      "Enc Loss = 153.23, KL Divergence = 1125.90, Reconstruction Loss = 386.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.25 mins\n",
      "Epoch: 7 / 10, Batch: 109 (3520 / 12512), Elapsed time: 54.25 mins\n",
      "Enc Loss = 144.00, KL Divergence = 1165.16, Reconstruction Loss = 352.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.27 mins\n",
      "Epoch: 7 / 10, Batch: 110 (3552 / 12512), Elapsed time: 54.27 mins\n",
      "Enc Loss = 138.95, KL Divergence = 1165.70, Reconstruction Loss = 335.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.29 mins\n",
      "Epoch: 7 / 10, Batch: 111 (3584 / 12512), Elapsed time: 54.29 mins\n",
      "Enc Loss = 140.31, KL Divergence = 1203.46, Reconstruction Loss = 336.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.31 mins\n",
      "Epoch: 7 / 10, Batch: 112 (3616 / 12512), Elapsed time: 54.31 mins\n",
      "Enc Loss = 136.56, KL Divergence = 1156.92, Reconstruction Loss = 329.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.33 mins\n",
      "Epoch: 7 / 10, Batch: 113 (3648 / 12512), Elapsed time: 54.33 mins\n",
      "Enc Loss = 140.88, KL Divergence = 1167.31, Reconstruction Loss = 342.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.35 mins\n",
      "Epoch: 7 / 10, Batch: 114 (3680 / 12512), Elapsed time: 54.35 mins\n",
      "Enc Loss = 139.85, KL Divergence = 1140.80, Reconstruction Loss = 341.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.37 mins\n",
      "Epoch: 7 / 10, Batch: 115 (3712 / 12512), Elapsed time: 54.37 mins\n",
      "Enc Loss = 147.50, KL Divergence = 1278.25, Reconstruction Loss = 352.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.39 mins\n",
      "Epoch: 7 / 10, Batch: 116 (3744 / 12512), Elapsed time: 54.39 mins\n",
      "Enc Loss = 143.43, KL Divergence = 1184.35, Reconstruction Loss = 348.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.41 mins\n",
      "Epoch: 7 / 10, Batch: 117 (3776 / 12512), Elapsed time: 54.41 mins\n",
      "Enc Loss = 144.50, KL Divergence = 1206.23, Reconstruction Loss = 349.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.43 mins\n",
      "Epoch: 7 / 10, Batch: 118 (3808 / 12512), Elapsed time: 54.43 mins\n",
      "Enc Loss = 140.70, KL Divergence = 1143.21, Reconstruction Loss = 343.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.45 mins\n",
      "Epoch: 7 / 10, Batch: 119 (3840 / 12512), Elapsed time: 54.45 mins\n",
      "Enc Loss = 140.03, KL Divergence = 1115.41, Reconstruction Loss = 344.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.47 mins\n",
      "Epoch: 7 / 10, Batch: 120 (3872 / 12512), Elapsed time: 54.47 mins\n",
      "Enc Loss = 143.26, KL Divergence = 1145.11, Reconstruction Loss = 352.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.49 mins\n",
      "Epoch: 7 / 10, Batch: 121 (3904 / 12512), Elapsed time: 54.49 mins\n",
      "Enc Loss = 149.14, KL Divergence = 1255.66, Reconstruction Loss = 360.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.50 mins\n",
      "Epoch: 7 / 10, Batch: 122 (3936 / 12512), Elapsed time: 54.50 mins\n",
      "Enc Loss = 142.92, KL Divergence = 1117.71, Reconstruction Loss = 353.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.52 mins\n",
      "Epoch: 7 / 10, Batch: 123 (3968 / 12512), Elapsed time: 54.52 mins\n",
      "Enc Loss = 139.34, KL Divergence = 1214.08, Reconstruction Loss = 332.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.54 mins\n",
      "Epoch: 7 / 10, Batch: 124 (4000 / 12512), Elapsed time: 54.55 mins\n",
      "Enc Loss = 132.90, KL Divergence = 1082.87, Reconstruction Loss = 324.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.56 mins\n",
      "Epoch: 7 / 10, Batch: 125 (4032 / 12512), Elapsed time: 54.56 mins\n",
      "Enc Loss = 136.18, KL Divergence = 1163.47, Reconstruction Loss = 327.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.58 mins\n",
      "Epoch: 7 / 10, Batch: 126 (4064 / 12512), Elapsed time: 54.59 mins\n",
      "Enc Loss = 138.09, KL Divergence = 1077.17, Reconstruction Loss = 342.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.61 mins\n",
      "Epoch: 7 / 10, Batch: 127 (4096 / 12512), Elapsed time: 54.61 mins\n",
      "Enc Loss = 131.92, KL Divergence = 1048.89, Reconstruction Loss = 324.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.63 mins\n",
      "Epoch: 7 / 10, Batch: 128 (4128 / 12512), Elapsed time: 54.63 mins\n",
      "Enc Loss = 136.36, KL Divergence = 982.16, Reconstruction Loss = 346.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.65 mins\n",
      "Epoch: 7 / 10, Batch: 129 (4160 / 12512), Elapsed time: 54.65 mins\n",
      "Enc Loss = 143.89, KL Divergence = 1062.12, Reconstruction Loss = 362.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.67 mins\n",
      "Epoch: 7 / 10, Batch: 130 (4192 / 12512), Elapsed time: 54.67 mins\n",
      "Enc Loss = 133.94, KL Divergence = 1059.09, Reconstruction Loss = 330.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.68 mins\n",
      "Epoch: 7 / 10, Batch: 131 (4224 / 12512), Elapsed time: 54.68 mins\n",
      "Enc Loss = 141.35, KL Divergence = 1072.18, Reconstruction Loss = 353.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.70 mins\n",
      "Epoch: 7 / 10, Batch: 132 (4256 / 12512), Elapsed time: 54.70 mins\n",
      "Enc Loss = 128.71, KL Divergence = 1008.53, Reconstruction Loss = 318.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.72 mins\n",
      "Epoch: 7 / 10, Batch: 133 (4288 / 12512), Elapsed time: 54.72 mins\n",
      "Enc Loss = 140.40, KL Divergence = 1102.03, Reconstruction Loss = 347.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.74 mins\n",
      "Epoch: 7 / 10, Batch: 134 (4320 / 12512), Elapsed time: 54.74 mins\n",
      "Enc Loss = 145.18, KL Divergence = 1102.88, Reconstruction Loss = 362.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.76 mins\n",
      "Epoch: 7 / 10, Batch: 135 (4352 / 12512), Elapsed time: 54.76 mins\n",
      "Enc Loss = 153.74, KL Divergence = 1150.59, Reconstruction Loss = 385.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.78 mins\n",
      "Epoch: 7 / 10, Batch: 136 (4384 / 12512), Elapsed time: 54.78 mins\n",
      "Enc Loss = 165.44, KL Divergence = 1307.54, Reconstruction Loss = 408.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.80 mins\n",
      "Epoch: 7 / 10, Batch: 137 (4416 / 12512), Elapsed time: 54.80 mins\n",
      "Enc Loss = 138.00, KL Divergence = 1106.85, Reconstruction Loss = 338.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.82 mins\n",
      "Epoch: 7 / 10, Batch: 138 (4448 / 12512), Elapsed time: 54.82 mins\n",
      "Enc Loss = 139.58, KL Divergence = 1093.82, Reconstruction Loss = 345.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.84 mins\n",
      "Epoch: 7 / 10, Batch: 139 (4480 / 12512), Elapsed time: 54.84 mins\n",
      "Enc Loss = 151.74, KL Divergence = 1326.62, Reconstruction Loss = 361.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.86 mins\n",
      "Epoch: 7 / 10, Batch: 140 (4512 / 12512), Elapsed time: 54.86 mins\n",
      "Enc Loss = 144.16, KL Divergence = 1154.46, Reconstruction Loss = 354.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.88 mins\n",
      "Epoch: 7 / 10, Batch: 141 (4544 / 12512), Elapsed time: 54.88 mins\n",
      "Enc Loss = 150.67, KL Divergence = 1270.42, Reconstruction Loss = 363.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.90 mins\n",
      "Epoch: 7 / 10, Batch: 142 (4576 / 12512), Elapsed time: 54.90 mins\n",
      "Enc Loss = 149.81, KL Divergence = 1254.61, Reconstruction Loss = 362.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.92 mins\n",
      "Epoch: 7 / 10, Batch: 143 (4608 / 12512), Elapsed time: 54.92 mins\n",
      "Enc Loss = 145.74, KL Divergence = 1212.03, Reconstruction Loss = 353.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.94 mins\n",
      "Epoch: 7 / 10, Batch: 144 (4640 / 12512), Elapsed time: 54.94 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 141.95, KL Divergence = 1211.71, Reconstruction Loss = 341.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.96 mins\n",
      "Epoch: 7 / 10, Batch: 145 (4672 / 12512), Elapsed time: 54.96 mins\n",
      "Enc Loss = 141.98, KL Divergence = 1211.57, Reconstruction Loss = 341.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 54.98 mins\n",
      "Epoch: 7 / 10, Batch: 146 (4704 / 12512), Elapsed time: 54.98 mins\n",
      "Enc Loss = 142.32, KL Divergence = 1166.05, Reconstruction Loss = 346.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.00 mins\n",
      "Epoch: 7 / 10, Batch: 147 (4736 / 12512), Elapsed time: 55.00 mins\n",
      "Enc Loss = 134.78, KL Divergence = 1195.93, Reconstruction Loss = 319.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.02 mins\n",
      "Epoch: 7 / 10, Batch: 148 (4768 / 12512), Elapsed time: 55.02 mins\n",
      "Enc Loss = 128.47, KL Divergence = 1048.98, Reconstruction Loss = 313.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.04 mins\n",
      "Epoch: 7 / 10, Batch: 149 (4800 / 12512), Elapsed time: 55.04 mins\n",
      "Enc Loss = 140.90, KL Divergence = 1120.22, Reconstruction Loss = 346.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.06 mins\n",
      "Epoch: 7 / 10, Batch: 150 (4832 / 12512), Elapsed time: 55.06 mins\n",
      "Enc Loss = 134.51, KL Divergence = 996.65, Reconstruction Loss = 338.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.08 mins\n",
      "Epoch: 7 / 10, Batch: 151 (4864 / 12512), Elapsed time: 55.08 mins\n",
      "Enc Loss = 131.06, KL Divergence = 1045.50, Reconstruction Loss = 322.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.10 mins\n",
      "Epoch: 7 / 10, Batch: 152 (4896 / 12512), Elapsed time: 55.10 mins\n",
      "Enc Loss = 154.45, KL Divergence = 1148.70, Reconstruction Loss = 388.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.12 mins\n",
      "Epoch: 7 / 10, Batch: 153 (4928 / 12512), Elapsed time: 55.12 mins\n",
      "Enc Loss = 150.91, KL Divergence = 1117.02, Reconstruction Loss = 380.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.14 mins\n",
      "Epoch: 7 / 10, Batch: 154 (4960 / 12512), Elapsed time: 55.14 mins\n",
      "Enc Loss = 128.72, KL Divergence = 986.63, Reconstruction Loss = 320.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.15 mins\n",
      "Epoch: 7 / 10, Batch: 155 (4992 / 12512), Elapsed time: 55.16 mins\n",
      "Enc Loss = 139.17, KL Divergence = 1111.41, Reconstruction Loss = 342.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.17 mins\n",
      "Epoch: 7 / 10, Batch: 156 (5024 / 12512), Elapsed time: 55.18 mins\n",
      "Enc Loss = 132.43, KL Divergence = 1027.63, Reconstruction Loss = 328.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.20 mins\n",
      "Epoch: 7 / 10, Batch: 157 (5056 / 12512), Elapsed time: 55.20 mins\n",
      "Enc Loss = 135.74, KL Divergence = 1069.64, Reconstruction Loss = 335.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.22 mins\n",
      "Epoch: 7 / 10, Batch: 158 (5088 / 12512), Elapsed time: 55.22 mins\n",
      "Enc Loss = 145.69, KL Divergence = 1130.25, Reconstruction Loss = 361.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.23 mins\n",
      "Epoch: 7 / 10, Batch: 159 (5120 / 12512), Elapsed time: 55.24 mins\n",
      "Enc Loss = 161.56, KL Divergence = 1124.50, Reconstruction Loss = 414.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.25 mins\n",
      "Epoch: 7 / 10, Batch: 160 (5152 / 12512), Elapsed time: 55.25 mins\n",
      "Enc Loss = 137.12, KL Divergence = 1165.25, Reconstruction Loss = 330.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.27 mins\n",
      "Epoch: 7 / 10, Batch: 161 (5184 / 12512), Elapsed time: 55.27 mins\n",
      "Enc Loss = 141.87, KL Divergence = 1226.97, Reconstruction Loss = 339.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.29 mins\n",
      "Epoch: 7 / 10, Batch: 162 (5216 / 12512), Elapsed time: 55.29 mins\n",
      "Enc Loss = 130.99, KL Divergence = 1110.68, Reconstruction Loss = 315.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.31 mins\n",
      "Epoch: 7 / 10, Batch: 163 (5248 / 12512), Elapsed time: 55.31 mins\n",
      "Enc Loss = 145.58, KL Divergence = 1292.05, Reconstruction Loss = 344.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.33 mins\n",
      "Epoch: 7 / 10, Batch: 164 (5280 / 12512), Elapsed time: 55.33 mins\n",
      "Enc Loss = 157.12, KL Divergence = 1382.02, Reconstruction Loss = 373.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.35 mins\n",
      "Epoch: 7 / 10, Batch: 165 (5312 / 12512), Elapsed time: 55.35 mins\n",
      "Enc Loss = 134.22, KL Divergence = 1135.23, Reconstruction Loss = 323.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.37 mins\n",
      "Epoch: 7 / 10, Batch: 166 (5344 / 12512), Elapsed time: 55.37 mins\n",
      "Enc Loss = 137.22, KL Divergence = 1140.80, Reconstruction Loss = 332.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.39 mins\n",
      "Epoch: 7 / 10, Batch: 167 (5376 / 12512), Elapsed time: 55.39 mins\n",
      "Enc Loss = 128.49, KL Divergence = 989.38, Reconstruction Loss = 319.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.41 mins\n",
      "Epoch: 7 / 10, Batch: 168 (5408 / 12512), Elapsed time: 55.41 mins\n",
      "Enc Loss = 168.53, KL Divergence = 1255.82, Reconstruction Loss = 423.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.43 mins\n",
      "Epoch: 7 / 10, Batch: 169 (5440 / 12512), Elapsed time: 55.43 mins\n",
      "Enc Loss = 128.75, KL Divergence = 1034.20, Reconstruction Loss = 316.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.45 mins\n",
      "Epoch: 7 / 10, Batch: 170 (5472 / 12512), Elapsed time: 55.45 mins\n",
      "Enc Loss = 132.10, KL Divergence = 1036.61, Reconstruction Loss = 326.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.47 mins\n",
      "Epoch: 7 / 10, Batch: 171 (5504 / 12512), Elapsed time: 55.47 mins\n",
      "Enc Loss = 159.48, KL Divergence = 1130.93, Reconstruction Loss = 406.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.49 mins\n",
      "Epoch: 7 / 10, Batch: 172 (5536 / 12512), Elapsed time: 55.49 mins\n",
      "Enc Loss = 151.81, KL Divergence = 1222.60, Reconstruction Loss = 372.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.51 mins\n",
      "Epoch: 7 / 10, Batch: 173 (5568 / 12512), Elapsed time: 55.51 mins\n",
      "Enc Loss = 139.62, KL Divergence = 1120.95, Reconstruction Loss = 342.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.53 mins\n",
      "Epoch: 7 / 10, Batch: 174 (5600 / 12512), Elapsed time: 55.53 mins\n",
      "Enc Loss = 152.40, KL Divergence = 1179.72, Reconstruction Loss = 378.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.55 mins\n",
      "Epoch: 7 / 10, Batch: 175 (5632 / 12512), Elapsed time: 55.55 mins\n",
      "Enc Loss = 138.16, KL Divergence = 1054.74, Reconstruction Loss = 344.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.57 mins\n",
      "Epoch: 7 / 10, Batch: 176 (5664 / 12512), Elapsed time: 55.57 mins\n",
      "Enc Loss = 146.01, KL Divergence = 1184.67, Reconstruction Loss = 357.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.59 mins\n",
      "Epoch: 7 / 10, Batch: 177 (5696 / 12512), Elapsed time: 55.59 mins\n",
      "Enc Loss = 141.48, KL Divergence = 1117.19, Reconstruction Loss = 349.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.61 mins\n",
      "Epoch: 7 / 10, Batch: 178 (5728 / 12512), Elapsed time: 55.61 mins\n",
      "Enc Loss = 138.76, KL Divergence = 1137.27, Reconstruction Loss = 338.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.63 mins\n",
      "Epoch: 7 / 10, Batch: 179 (5760 / 12512), Elapsed time: 55.63 mins\n",
      "Enc Loss = 136.07, KL Divergence = 1102.39, Reconstruction Loss = 332.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.65 mins\n",
      "Epoch: 7 / 10, Batch: 180 (5792 / 12512), Elapsed time: 55.65 mins\n",
      "Enc Loss = 141.71, KL Divergence = 1144.93, Reconstruction Loss = 347.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.67 mins\n",
      "Epoch: 7 / 10, Batch: 181 (5824 / 12512), Elapsed time: 55.67 mins\n",
      "Enc Loss = 135.13, KL Divergence = 1095.29, Reconstruction Loss = 330.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.69 mins\n",
      "Epoch: 7 / 10, Batch: 182 (5856 / 12512), Elapsed time: 55.69 mins\n",
      "Enc Loss = 133.99, KL Divergence = 1113.20, Reconstruction Loss = 325.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.71 mins\n",
      "Epoch: 7 / 10, Batch: 183 (5888 / 12512), Elapsed time: 55.71 mins\n",
      "Enc Loss = 127.36, KL Divergence = 967.99, Reconstruction Loss = 318.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.73 mins\n",
      "Epoch: 7 / 10, Batch: 184 (5920 / 12512), Elapsed time: 55.73 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 170.37, KL Divergence = 1283.33, Reconstruction Loss = 426.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.75 mins\n",
      "Epoch: 7 / 10, Batch: 185 (5952 / 12512), Elapsed time: 55.75 mins\n",
      "Enc Loss = 126.31, KL Divergence = 1019.17, Reconstruction Loss = 309.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.77 mins\n",
      "Epoch: 7 / 10, Batch: 186 (5984 / 12512), Elapsed time: 55.77 mins\n",
      "Enc Loss = 141.92, KL Divergence = 1024.99, Reconstruction Loss = 360.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.79 mins\n",
      "Epoch: 7 / 10, Batch: 187 (6016 / 12512), Elapsed time: 55.79 mins\n",
      "Enc Loss = 145.59, KL Divergence = 1231.82, Reconstruction Loss = 350.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.81 mins\n",
      "Epoch: 7 / 10, Batch: 188 (6048 / 12512), Elapsed time: 55.81 mins\n",
      "Enc Loss = 138.85, KL Divergence = 1018.43, Reconstruction Loss = 350.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.83 mins\n",
      "Epoch: 7 / 10, Batch: 189 (6080 / 12512), Elapsed time: 55.83 mins\n",
      "Enc Loss = 138.45, KL Divergence = 1030.63, Reconstruction Loss = 348.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.84 mins\n",
      "Epoch: 7 / 10, Batch: 190 (6112 / 12512), Elapsed time: 55.85 mins\n",
      "Enc Loss = 142.15, KL Divergence = 1051.04, Reconstruction Loss = 358.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.86 mins\n",
      "Epoch: 7 / 10, Batch: 191 (6144 / 12512), Elapsed time: 55.86 mins\n",
      "Enc Loss = 139.62, KL Divergence = 1139.24, Reconstruction Loss = 340.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.88 mins\n",
      "Epoch: 7 / 10, Batch: 192 (6176 / 12512), Elapsed time: 55.88 mins\n",
      "Enc Loss = 141.65, KL Divergence = 1210.51, Reconstruction Loss = 340.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.90 mins\n",
      "Epoch: 7 / 10, Batch: 193 (6208 / 12512), Elapsed time: 55.91 mins\n",
      "Enc Loss = 136.50, KL Divergence = 1194.97, Reconstruction Loss = 324.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.93 mins\n",
      "Epoch: 7 / 10, Batch: 194 (6240 / 12512), Elapsed time: 55.93 mins\n",
      "Enc Loss = 150.91, KL Divergence = 1256.77, Reconstruction Loss = 365.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.94 mins\n",
      "Epoch: 7 / 10, Batch: 195 (6272 / 12512), Elapsed time: 55.95 mins\n",
      "Enc Loss = 138.82, KL Divergence = 1123.56, Reconstruction Loss = 339.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.96 mins\n",
      "Epoch: 7 / 10, Batch: 196 (6304 / 12512), Elapsed time: 55.96 mins\n",
      "Enc Loss = 133.09, KL Divergence = 1161.73, Reconstruction Loss = 317.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 55.98 mins\n",
      "Epoch: 7 / 10, Batch: 197 (6336 / 12512), Elapsed time: 55.98 mins\n",
      "Enc Loss = 138.90, KL Divergence = 1110.93, Reconstruction Loss = 341.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.00 mins\n",
      "Epoch: 7 / 10, Batch: 198 (6368 / 12512), Elapsed time: 56.00 mins\n",
      "Enc Loss = 133.94, KL Divergence = 1160.12, Reconstruction Loss = 320.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.02 mins\n",
      "Epoch: 7 / 10, Batch: 199 (6400 / 12512), Elapsed time: 56.02 mins\n",
      "Enc Loss = 165.74, KL Divergence = 1232.93, Reconstruction Loss = 416.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.04 mins\n",
      "Epoch: 7 / 10, Batch: 200 (6432 / 12512), Elapsed time: 56.04 mins\n",
      "Enc Loss = 137.40, KL Divergence = 1086.88, Reconstruction Loss = 338.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.06 mins\n",
      "Epoch: 7 / 10, Batch: 201 (6464 / 12512), Elapsed time: 56.06 mins\n",
      "Enc Loss = 144.01, KL Divergence = 1160.32, Reconstruction Loss = 353.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.08 mins\n",
      "Epoch: 7 / 10, Batch: 202 (6496 / 12512), Elapsed time: 56.08 mins\n",
      "Enc Loss = 130.84, KL Divergence = 1027.36, Reconstruction Loss = 323.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.10 mins\n",
      "Epoch: 7 / 10, Batch: 203 (6528 / 12512), Elapsed time: 56.10 mins\n",
      "Enc Loss = 128.76, KL Divergence = 1030.25, Reconstruction Loss = 316.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.12 mins\n",
      "Epoch: 7 / 10, Batch: 204 (6560 / 12512), Elapsed time: 56.12 mins\n",
      "Enc Loss = 137.03, KL Divergence = 885.67, Reconstruction Loss = 358.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.14 mins\n",
      "Epoch: 7 / 10, Batch: 205 (6592 / 12512), Elapsed time: 56.14 mins\n",
      "Enc Loss = 133.62, KL Divergence = 1072.24, Reconstruction Loss = 328.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.16 mins\n",
      "Epoch: 7 / 10, Batch: 206 (6624 / 12512), Elapsed time: 56.16 mins\n",
      "Enc Loss = 159.42, KL Divergence = 1166.22, Reconstruction Loss = 402.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.18 mins\n",
      "Epoch: 7 / 10, Batch: 207 (6656 / 12512), Elapsed time: 56.18 mins\n",
      "Enc Loss = 145.26, KL Divergence = 1125.00, Reconstruction Loss = 360.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.20 mins\n",
      "Epoch: 7 / 10, Batch: 208 (6688 / 12512), Elapsed time: 56.20 mins\n",
      "Enc Loss = 143.49, KL Divergence = 1069.17, Reconstruction Loss = 360.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.22 mins\n",
      "Epoch: 7 / 10, Batch: 209 (6720 / 12512), Elapsed time: 56.22 mins\n",
      "Enc Loss = 145.19, KL Divergence = 1164.21, Reconstruction Loss = 356.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.24 mins\n",
      "Epoch: 7 / 10, Batch: 210 (6752 / 12512), Elapsed time: 56.24 mins\n",
      "Enc Loss = 139.95, KL Divergence = 1096.26, Reconstruction Loss = 346.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.26 mins\n",
      "Epoch: 7 / 10, Batch: 211 (6784 / 12512), Elapsed time: 56.26 mins\n",
      "Enc Loss = 136.14, KL Divergence = 1076.83, Reconstruction Loss = 335.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.28 mins\n",
      "Epoch: 7 / 10, Batch: 212 (6816 / 12512), Elapsed time: 56.28 mins\n",
      "Enc Loss = 140.04, KL Divergence = 1150.96, Reconstruction Loss = 341.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.30 mins\n",
      "Epoch: 7 / 10, Batch: 213 (6848 / 12512), Elapsed time: 56.30 mins\n",
      "Enc Loss = 141.97, KL Divergence = 1236.09, Reconstruction Loss = 338.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.32 mins\n",
      "Epoch: 7 / 10, Batch: 214 (6880 / 12512), Elapsed time: 56.32 mins\n",
      "Enc Loss = 144.68, KL Divergence = 1147.37, Reconstruction Loss = 356.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.34 mins\n",
      "Epoch: 7 / 10, Batch: 215 (6912 / 12512), Elapsed time: 56.34 mins\n",
      "Enc Loss = 139.71, KL Divergence = 1118.01, Reconstruction Loss = 343.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.36 mins\n",
      "Epoch: 7 / 10, Batch: 216 (6944 / 12512), Elapsed time: 56.36 mins\n",
      "Enc Loss = 136.70, KL Divergence = 1159.00, Reconstruction Loss = 329.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.38 mins\n",
      "Epoch: 7 / 10, Batch: 217 (6976 / 12512), Elapsed time: 56.38 mins\n",
      "Enc Loss = 136.37, KL Divergence = 1173.01, Reconstruction Loss = 326.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.40 mins\n",
      "Epoch: 7 / 10, Batch: 218 (7008 / 12512), Elapsed time: 56.40 mins\n",
      "Enc Loss = 154.86, KL Divergence = 1323.03, Reconstruction Loss = 371.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.42 mins\n",
      "Epoch: 7 / 10, Batch: 219 (7040 / 12512), Elapsed time: 56.42 mins\n",
      "Enc Loss = 138.49, KL Divergence = 1262.33, Reconstruction Loss = 324.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.44 mins\n",
      "Epoch: 7 / 10, Batch: 220 (7072 / 12512), Elapsed time: 56.44 mins\n",
      "Enc Loss = 143.34, KL Divergence = 1248.18, Reconstruction Loss = 341.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.46 mins\n",
      "Epoch: 7 / 10, Batch: 221 (7104 / 12512), Elapsed time: 56.46 mins\n",
      "Enc Loss = 141.93, KL Divergence = 1181.24, Reconstruction Loss = 344.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.48 mins\n",
      "Epoch: 7 / 10, Batch: 222 (7136 / 12512), Elapsed time: 56.48 mins\n",
      "Enc Loss = 136.15, KL Divergence = 1190.71, Reconstruction Loss = 324.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.50 mins\n",
      "Epoch: 7 / 10, Batch: 223 (7168 / 12512), Elapsed time: 56.50 mins\n",
      "Enc Loss = 131.58, KL Divergence = 1122.14, Reconstruction Loss = 316.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.52 mins\n",
      "Epoch: 7 / 10, Batch: 224 (7200 / 12512), Elapsed time: 56.52 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 138.13, KL Divergence = 1075.59, Reconstruction Loss = 342.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.54 mins\n",
      "Epoch: 7 / 10, Batch: 225 (7232 / 12512), Elapsed time: 56.54 mins\n",
      "Enc Loss = 145.46, KL Divergence = 1148.50, Reconstruction Loss = 359.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.56 mins\n",
      "Epoch: 7 / 10, Batch: 226 (7264 / 12512), Elapsed time: 56.56 mins\n",
      "Enc Loss = 154.75, KL Divergence = 1206.76, Reconstruction Loss = 383.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.58 mins\n",
      "Epoch: 7 / 10, Batch: 227 (7296 / 12512), Elapsed time: 56.58 mins\n",
      "Enc Loss = 125.08, KL Divergence = 1018.47, Reconstruction Loss = 305.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.60 mins\n",
      "Epoch: 7 / 10, Batch: 228 (7328 / 12512), Elapsed time: 56.60 mins\n",
      "Enc Loss = 135.14, KL Divergence = 1135.93, Reconstruction Loss = 326.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.62 mins\n",
      "Epoch: 7 / 10, Batch: 229 (7360 / 12512), Elapsed time: 56.62 mins\n",
      "Enc Loss = 135.68, KL Divergence = 1123.65, Reconstruction Loss = 329.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.63 mins\n",
      "Epoch: 7 / 10, Batch: 230 (7392 / 12512), Elapsed time: 56.63 mins\n",
      "Enc Loss = 147.14, KL Divergence = 1204.05, Reconstruction Loss = 358.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.65 mins\n",
      "Epoch: 7 / 10, Batch: 231 (7424 / 12512), Elapsed time: 56.66 mins\n",
      "Enc Loss = 131.72, KL Divergence = 1104.62, Reconstruction Loss = 318.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.67 mins\n",
      "Epoch: 7 / 10, Batch: 232 (7456 / 12512), Elapsed time: 56.68 mins\n",
      "Enc Loss = 136.61, KL Divergence = 1109.72, Reconstruction Loss = 334.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.69 mins\n",
      "Epoch: 7 / 10, Batch: 233 (7488 / 12512), Elapsed time: 56.69 mins\n",
      "Enc Loss = 143.01, KL Divergence = 1067.38, Reconstruction Loss = 359.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.71 mins\n",
      "Epoch: 7 / 10, Batch: 234 (7520 / 12512), Elapsed time: 56.71 mins\n",
      "Enc Loss = 127.63, KL Divergence = 1077.01, Reconstruction Loss = 307.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.73 mins\n",
      "Epoch: 7 / 10, Batch: 235 (7552 / 12512), Elapsed time: 56.73 mins\n",
      "Enc Loss = 130.99, KL Divergence = 1083.57, Reconstruction Loss = 318.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.75 mins\n",
      "Epoch: 7 / 10, Batch: 236 (7584 / 12512), Elapsed time: 56.75 mins\n",
      "Enc Loss = 147.74, KL Divergence = 1160.57, Reconstruction Loss = 365.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.77 mins\n",
      "Epoch: 7 / 10, Batch: 237 (7616 / 12512), Elapsed time: 56.77 mins\n",
      "Enc Loss = 131.70, KL Divergence = 1045.48, Reconstruction Loss = 324.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.79 mins\n",
      "Epoch: 7 / 10, Batch: 238 (7648 / 12512), Elapsed time: 56.79 mins\n",
      "Enc Loss = 136.52, KL Divergence = 1046.88, Reconstruction Loss = 340.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.81 mins\n",
      "Epoch: 7 / 10, Batch: 239 (7680 / 12512), Elapsed time: 56.81 mins\n",
      "Enc Loss = 143.16, KL Divergence = 1128.94, Reconstruction Loss = 353.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.83 mins\n",
      "Epoch: 7 / 10, Batch: 240 (7712 / 12512), Elapsed time: 56.83 mins\n",
      "Enc Loss = 138.41, KL Divergence = 1177.31, Reconstruction Loss = 332.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.85 mins\n",
      "Epoch: 7 / 10, Batch: 241 (7744 / 12512), Elapsed time: 56.85 mins\n",
      "Enc Loss = 132.20, KL Divergence = 1033.22, Reconstruction Loss = 327.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.87 mins\n",
      "Epoch: 7 / 10, Batch: 242 (7776 / 12512), Elapsed time: 56.87 mins\n",
      "Enc Loss = 158.50, KL Divergence = 1148.56, Reconstruction Loss = 401.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.89 mins\n",
      "Epoch: 7 / 10, Batch: 243 (7808 / 12512), Elapsed time: 56.89 mins\n",
      "Enc Loss = 153.70, KL Divergence = 1226.34, Reconstruction Loss = 378.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.91 mins\n",
      "Epoch: 7 / 10, Batch: 244 (7840 / 12512), Elapsed time: 56.91 mins\n",
      "Enc Loss = 136.35, KL Divergence = 1013.37, Reconstruction Loss = 343.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.92 mins\n",
      "Epoch: 7 / 10, Batch: 245 (7872 / 12512), Elapsed time: 56.93 mins\n",
      "Enc Loss = 128.84, KL Divergence = 1030.16, Reconstruction Loss = 316.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.95 mins\n",
      "Epoch: 7 / 10, Batch: 246 (7904 / 12512), Elapsed time: 56.95 mins\n",
      "Enc Loss = 134.67, KL Divergence = 1099.60, Reconstruction Loss = 328.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.97 mins\n",
      "Epoch: 7 / 10, Batch: 247 (7936 / 12512), Elapsed time: 56.97 mins\n",
      "Enc Loss = 125.57, KL Divergence = 969.46, Reconstruction Loss = 312.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 56.99 mins\n",
      "Epoch: 7 / 10, Batch: 248 (7968 / 12512), Elapsed time: 56.99 mins\n",
      "Enc Loss = 139.76, KL Divergence = 1136.38, Reconstruction Loss = 341.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.01 mins\n",
      "Epoch: 7 / 10, Batch: 249 (8000 / 12512), Elapsed time: 57.01 mins\n",
      "Enc Loss = 146.63, KL Divergence = 1203.35, Reconstruction Loss = 357.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.03 mins\n",
      "Epoch: 7 / 10, Batch: 250 (8032 / 12512), Elapsed time: 57.03 mins\n",
      "Enc Loss = 144.59, KL Divergence = 1099.95, Reconstruction Loss = 361.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.05 mins\n",
      "Epoch: 7 / 10, Batch: 251 (8064 / 12512), Elapsed time: 57.05 mins\n",
      "Enc Loss = 128.06, KL Divergence = 1072.71, Reconstruction Loss = 309.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.07 mins\n",
      "Epoch: 7 / 10, Batch: 252 (8096 / 12512), Elapsed time: 57.07 mins\n",
      "Enc Loss = 139.74, KL Divergence = 1095.82, Reconstruction Loss = 345.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.08 mins\n",
      "Epoch: 7 / 10, Batch: 253 (8128 / 12512), Elapsed time: 57.08 mins\n",
      "Enc Loss = 132.40, KL Divergence = 1104.57, Reconstruction Loss = 320.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.10 mins\n",
      "Epoch: 7 / 10, Batch: 254 (8160 / 12512), Elapsed time: 57.10 mins\n",
      "Enc Loss = 137.42, KL Divergence = 1024.64, Reconstruction Loss = 345.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.12 mins\n",
      "Epoch: 7 / 10, Batch: 255 (8192 / 12512), Elapsed time: 57.12 mins\n",
      "Enc Loss = 147.43, KL Divergence = 1091.47, Reconstruction Loss = 371.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.14 mins\n",
      "Epoch: 7 / 10, Batch: 256 (8224 / 12512), Elapsed time: 57.14 mins\n",
      "Enc Loss = 153.08, KL Divergence = 1238.08, Reconstruction Loss = 374.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.16 mins\n",
      "Epoch: 7 / 10, Batch: 257 (8256 / 12512), Elapsed time: 57.16 mins\n",
      "Enc Loss = 148.70, KL Divergence = 1182.80, Reconstruction Loss = 366.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.18 mins\n",
      "Epoch: 7 / 10, Batch: 258 (8288 / 12512), Elapsed time: 57.18 mins\n",
      "Enc Loss = 133.74, KL Divergence = 1148.26, Reconstruction Loss = 320.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.20 mins\n",
      "Epoch: 7 / 10, Batch: 259 (8320 / 12512), Elapsed time: 57.20 mins\n",
      "Enc Loss = 130.19, KL Divergence = 1110.13, Reconstruction Loss = 312.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.22 mins\n",
      "Epoch: 7 / 10, Batch: 260 (8352 / 12512), Elapsed time: 57.22 mins\n",
      "Enc Loss = 148.54, KL Divergence = 1359.00, Reconstruction Loss = 347.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.24 mins\n",
      "Epoch: 7 / 10, Batch: 261 (8384 / 12512), Elapsed time: 57.24 mins\n",
      "Enc Loss = 137.94, KL Divergence = 1124.13, Reconstruction Loss = 336.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.26 mins\n",
      "Epoch: 7 / 10, Batch: 262 (8416 / 12512), Elapsed time: 57.26 mins\n",
      "Enc Loss = 151.05, KL Divergence = 1312.43, Reconstruction Loss = 360.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.28 mins\n",
      "Epoch: 7 / 10, Batch: 263 (8448 / 12512), Elapsed time: 57.28 mins\n",
      "Enc Loss = 132.52, KL Divergence = 1165.60, Reconstruction Loss = 314.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.30 mins\n",
      "Epoch: 7 / 10, Batch: 264 (8480 / 12512), Elapsed time: 57.30 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 143.46, KL Divergence = 1188.83, Reconstruction Loss = 348.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.32 mins\n",
      "Epoch: 7 / 10, Batch: 265 (8512 / 12512), Elapsed time: 57.32 mins\n",
      "Enc Loss = 140.98, KL Divergence = 1208.08, Reconstruction Loss = 338.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.34 mins\n",
      "Epoch: 7 / 10, Batch: 266 (8544 / 12512), Elapsed time: 57.34 mins\n",
      "Enc Loss = 136.36, KL Divergence = 1095.10, Reconstruction Loss = 334.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.36 mins\n",
      "Epoch: 7 / 10, Batch: 267 (8576 / 12512), Elapsed time: 57.36 mins\n",
      "Enc Loss = 137.15, KL Divergence = 1113.25, Reconstruction Loss = 335.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.38 mins\n",
      "Epoch: 7 / 10, Batch: 268 (8608 / 12512), Elapsed time: 57.38 mins\n",
      "Enc Loss = 132.84, KL Divergence = 1167.46, Reconstruction Loss = 315.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.40 mins\n",
      "Epoch: 7 / 10, Batch: 269 (8640 / 12512), Elapsed time: 57.40 mins\n",
      "Enc Loss = 140.88, KL Divergence = 1074.41, Reconstruction Loss = 351.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.42 mins\n",
      "Epoch: 7 / 10, Batch: 270 (8672 / 12512), Elapsed time: 57.42 mins\n",
      "Enc Loss = 137.60, KL Divergence = 1147.92, Reconstruction Loss = 333.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.44 mins\n",
      "Epoch: 7 / 10, Batch: 271 (8704 / 12512), Elapsed time: 57.44 mins\n",
      "Enc Loss = 139.33, KL Divergence = 1064.10, Reconstruction Loss = 347.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.46 mins\n",
      "Epoch: 7 / 10, Batch: 272 (8736 / 12512), Elapsed time: 57.46 mins\n",
      "Enc Loss = 161.59, KL Divergence = 1137.97, Reconstruction Loss = 412.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.48 mins\n",
      "Epoch: 7 / 10, Batch: 273 (8768 / 12512), Elapsed time: 57.48 mins\n",
      "Enc Loss = 150.44, KL Divergence = 1106.01, Reconstruction Loss = 379.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.50 mins\n",
      "Epoch: 7 / 10, Batch: 274 (8800 / 12512), Elapsed time: 57.50 mins\n",
      "Enc Loss = 132.80, KL Divergence = 1016.47, Reconstruction Loss = 331.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.52 mins\n",
      "Epoch: 7 / 10, Batch: 275 (8832 / 12512), Elapsed time: 57.52 mins\n",
      "Enc Loss = 139.78, KL Divergence = 1094.63, Reconstruction Loss = 345.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.54 mins\n",
      "Epoch: 7 / 10, Batch: 276 (8864 / 12512), Elapsed time: 57.54 mins\n",
      "Enc Loss = 142.43, KL Divergence = 1194.81, Reconstruction Loss = 344.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.55 mins\n",
      "Epoch: 7 / 10, Batch: 277 (8896 / 12512), Elapsed time: 57.56 mins\n",
      "Enc Loss = 133.05, KL Divergence = 1111.85, Reconstruction Loss = 322.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.57 mins\n",
      "Epoch: 7 / 10, Batch: 278 (8928 / 12512), Elapsed time: 57.57 mins\n",
      "Enc Loss = 135.27, KL Divergence = 1138.18, Reconstruction Loss = 326.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.59 mins\n",
      "Epoch: 7 / 10, Batch: 279 (8960 / 12512), Elapsed time: 57.59 mins\n",
      "Enc Loss = 143.98, KL Divergence = 1232.95, Reconstruction Loss = 345.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.61 mins\n",
      "Epoch: 7 / 10, Batch: 280 (8992 / 12512), Elapsed time: 57.61 mins\n",
      "Enc Loss = 151.98, KL Divergence = 1173.18, Reconstruction Loss = 377.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.63 mins\n",
      "Epoch: 7 / 10, Batch: 281 (9024 / 12512), Elapsed time: 57.63 mins\n",
      "Enc Loss = 139.58, KL Divergence = 1119.11, Reconstruction Loss = 342.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.65 mins\n",
      "Epoch: 7 / 10, Batch: 282 (9056 / 12512), Elapsed time: 57.65 mins\n",
      "Enc Loss = 145.34, KL Divergence = 1076.39, Reconstruction Loss = 366.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.67 mins\n",
      "Epoch: 7 / 10, Batch: 283 (9088 / 12512), Elapsed time: 57.67 mins\n",
      "Enc Loss = 131.64, KL Divergence = 1054.71, Reconstruction Loss = 323.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.69 mins\n",
      "Epoch: 7 / 10, Batch: 284 (9120 / 12512), Elapsed time: 57.69 mins\n",
      "Enc Loss = 158.28, KL Divergence = 1162.24, Reconstruction Loss = 399.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.71 mins\n",
      "Epoch: 7 / 10, Batch: 285 (9152 / 12512), Elapsed time: 57.71 mins\n",
      "Enc Loss = 136.34, KL Divergence = 1064.43, Reconstruction Loss = 337.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.73 mins\n",
      "Epoch: 7 / 10, Batch: 286 (9184 / 12512), Elapsed time: 57.73 mins\n",
      "Enc Loss = 142.68, KL Divergence = 1152.92, Reconstruction Loss = 349.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.75 mins\n",
      "Epoch: 7 / 10, Batch: 287 (9216 / 12512), Elapsed time: 57.75 mins\n",
      "Enc Loss = 131.76, KL Divergence = 1046.61, Reconstruction Loss = 324.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.77 mins\n",
      "Epoch: 7 / 10, Batch: 288 (9248 / 12512), Elapsed time: 57.77 mins\n",
      "Enc Loss = 129.16, KL Divergence = 1051.47, Reconstruction Loss = 315.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.79 mins\n",
      "Epoch: 7 / 10, Batch: 289 (9280 / 12512), Elapsed time: 57.79 mins\n",
      "Enc Loss = 138.08, KL Divergence = 1145.11, Reconstruction Loss = 335.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.81 mins\n",
      "Epoch: 7 / 10, Batch: 290 (9312 / 12512), Elapsed time: 57.81 mins\n",
      "Enc Loss = 120.75, KL Divergence = 1041.17, Reconstruction Loss = 289.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.83 mins\n",
      "Epoch: 7 / 10, Batch: 291 (9344 / 12512), Elapsed time: 57.83 mins\n",
      "Enc Loss = 141.79, KL Divergence = 1164.81, Reconstruction Loss = 345.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.85 mins\n",
      "Epoch: 7 / 10, Batch: 292 (9376 / 12512), Elapsed time: 57.85 mins\n",
      "Enc Loss = 141.94, KL Divergence = 1170.83, Reconstruction Loss = 345.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.87 mins\n",
      "Epoch: 7 / 10, Batch: 293 (9408 / 12512), Elapsed time: 57.87 mins\n",
      "Enc Loss = 131.27, KL Divergence = 1070.01, Reconstruction Loss = 320.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.89 mins\n",
      "Epoch: 7 / 10, Batch: 294 (9440 / 12512), Elapsed time: 57.89 mins\n",
      "Enc Loss = 145.63, KL Divergence = 1167.01, Reconstruction Loss = 357.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.91 mins\n",
      "Epoch: 7 / 10, Batch: 295 (9472 / 12512), Elapsed time: 57.91 mins\n",
      "Enc Loss = 143.41, KL Divergence = 1128.23, Reconstruction Loss = 354.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.93 mins\n",
      "Epoch: 7 / 10, Batch: 296 (9504 / 12512), Elapsed time: 57.93 mins\n",
      "Enc Loss = 136.96, KL Divergence = 1123.33, Reconstruction Loss = 333.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.95 mins\n",
      "Epoch: 7 / 10, Batch: 297 (9536 / 12512), Elapsed time: 57.95 mins\n",
      "Enc Loss = 161.79, KL Divergence = 1245.70, Reconstruction Loss = 402.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.97 mins\n",
      "Epoch: 7 / 10, Batch: 298 (9568 / 12512), Elapsed time: 57.97 mins\n",
      "Enc Loss = 150.05, KL Divergence = 1077.36, Reconstruction Loss = 381.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 57.98 mins\n",
      "Epoch: 7 / 10, Batch: 299 (9600 / 12512), Elapsed time: 57.98 mins\n",
      "Enc Loss = 157.23, KL Divergence = 1233.08, Reconstruction Loss = 388.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.00 mins\n",
      "Epoch: 7 / 10, Batch: 300 (9632 / 12512), Elapsed time: 58.00 mins\n",
      "Enc Loss = 138.42, KL Divergence = 1219.92, Reconstruction Loss = 328.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.02 mins\n",
      "Epoch: 7 / 10, Batch: 301 (9664 / 12512), Elapsed time: 58.02 mins\n",
      "Enc Loss = 150.23, KL Divergence = 1354.86, Reconstruction Loss = 353.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.04 mins\n",
      "Epoch: 7 / 10, Batch: 302 (9696 / 12512), Elapsed time: 58.04 mins\n",
      "Enc Loss = 148.57, KL Divergence = 1385.87, Reconstruction Loss = 344.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.06 mins\n",
      "Epoch: 7 / 10, Batch: 303 (9728 / 12512), Elapsed time: 58.06 mins\n",
      "Enc Loss = 145.29, KL Divergence = 1315.56, Reconstruction Loss = 341.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.08 mins\n",
      "Epoch: 7 / 10, Batch: 304 (9760 / 12512), Elapsed time: 58.08 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 142.47, KL Divergence = 1236.85, Reconstruction Loss = 340.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.10 mins\n",
      "Epoch: 7 / 10, Batch: 305 (9792 / 12512), Elapsed time: 58.10 mins\n",
      "Enc Loss = 140.75, KL Divergence = 1167.49, Reconstruction Loss = 341.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.12 mins\n",
      "Epoch: 7 / 10, Batch: 306 (9824 / 12512), Elapsed time: 58.12 mins\n",
      "Enc Loss = 138.42, KL Divergence = 1196.15, Reconstruction Loss = 331.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.14 mins\n",
      "Epoch: 7 / 10, Batch: 307 (9856 / 12512), Elapsed time: 58.14 mins\n",
      "Enc Loss = 139.13, KL Divergence = 1160.16, Reconstruction Loss = 337.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.16 mins\n",
      "Epoch: 7 / 10, Batch: 308 (9888 / 12512), Elapsed time: 58.16 mins\n",
      "Enc Loss = 129.16, KL Divergence = 1113.76, Reconstruction Loss = 309.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.18 mins\n",
      "Epoch: 7 / 10, Batch: 309 (9920 / 12512), Elapsed time: 58.18 mins\n",
      "Enc Loss = 145.25, KL Divergence = 1189.09, Reconstruction Loss = 354.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.20 mins\n",
      "Epoch: 7 / 10, Batch: 310 (9952 / 12512), Elapsed time: 58.20 mins\n",
      "Enc Loss = 132.30, KL Divergence = 1046.06, Reconstruction Loss = 326.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.22 mins\n",
      "Epoch: 7 / 10, Batch: 311 (9984 / 12512), Elapsed time: 58.22 mins\n",
      "Enc Loss = 137.90, KL Divergence = 1005.88, Reconstruction Loss = 348.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.24 mins\n",
      "Epoch: 7 / 10, Batch: 312 (10016 / 12512), Elapsed time: 58.24 mins\n",
      "Enc Loss = 131.29, KL Divergence = 962.67, Reconstruction Loss = 331.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.26 mins\n",
      "Epoch: 7 / 10, Batch: 313 (10048 / 12512), Elapsed time: 58.26 mins\n",
      "Enc Loss = 136.74, KL Divergence = 977.05, Reconstruction Loss = 348.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.28 mins\n",
      "Epoch: 7 / 10, Batch: 314 (10080 / 12512), Elapsed time: 58.28 mins\n",
      "Enc Loss = 150.81, KL Divergence = 1027.12, Reconstruction Loss = 389.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.30 mins\n",
      "Epoch: 7 / 10, Batch: 315 (10112 / 12512), Elapsed time: 58.30 mins\n",
      "Enc Loss = 154.83, KL Divergence = 1099.03, Reconstruction Loss = 394.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.32 mins\n",
      "Epoch: 7 / 10, Batch: 316 (10144 / 12512), Elapsed time: 58.32 mins\n",
      "Enc Loss = 133.05, KL Divergence = 1005.95, Reconstruction Loss = 332.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.34 mins\n",
      "Epoch: 7 / 10, Batch: 317 (10176 / 12512), Elapsed time: 58.34 mins\n",
      "Enc Loss = 135.06, KL Divergence = 1128.93, Reconstruction Loss = 326.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.35 mins\n",
      "Epoch: 7 / 10, Batch: 318 (10208 / 12512), Elapsed time: 58.35 mins\n",
      "Enc Loss = 139.31, KL Divergence = 1098.89, Reconstruction Loss = 343.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.37 mins\n",
      "Epoch: 7 / 10, Batch: 319 (10240 / 12512), Elapsed time: 58.37 mins\n",
      "Enc Loss = 130.78, KL Divergence = 1085.29, Reconstruction Loss = 317.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.39 mins\n",
      "Epoch: 7 / 10, Batch: 320 (10272 / 12512), Elapsed time: 58.39 mins\n",
      "Enc Loss = 148.97, KL Divergence = 1300.18, Reconstruction Loss = 355.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.41 mins\n",
      "Epoch: 7 / 10, Batch: 321 (10304 / 12512), Elapsed time: 58.42 mins\n",
      "Enc Loss = 153.33, KL Divergence = 1222.89, Reconstruction Loss = 377.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.43 mins\n",
      "Epoch: 7 / 10, Batch: 322 (10336 / 12512), Elapsed time: 58.43 mins\n",
      "Enc Loss = 150.08, KL Divergence = 1256.14, Reconstruction Loss = 363.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.45 mins\n",
      "Epoch: 7 / 10, Batch: 323 (10368 / 12512), Elapsed time: 58.45 mins\n",
      "Enc Loss = 146.80, KL Divergence = 1194.86, Reconstruction Loss = 358.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.47 mins\n",
      "Epoch: 7 / 10, Batch: 324 (10400 / 12512), Elapsed time: 58.47 mins\n",
      "Enc Loss = 162.81, KL Divergence = 1354.24, Reconstruction Loss = 394.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.49 mins\n",
      "Epoch: 7 / 10, Batch: 325 (10432 / 12512), Elapsed time: 58.49 mins\n",
      "Enc Loss = 142.01, KL Divergence = 1269.45, Reconstruction Loss = 335.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.51 mins\n",
      "Epoch: 7 / 10, Batch: 326 (10464 / 12512), Elapsed time: 58.51 mins\n",
      "Enc Loss = 134.65, KL Divergence = 1117.10, Reconstruction Loss = 326.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.53 mins\n",
      "Epoch: 7 / 10, Batch: 327 (10496 / 12512), Elapsed time: 58.53 mins\n",
      "Enc Loss = 152.51, KL Divergence = 1119.99, Reconstruction Loss = 385.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.55 mins\n",
      "Epoch: 7 / 10, Batch: 328 (10528 / 12512), Elapsed time: 58.55 mins\n",
      "Enc Loss = 156.16, KL Divergence = 1261.46, Reconstruction Loss = 382.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.57 mins\n",
      "Epoch: 7 / 10, Batch: 329 (10560 / 12512), Elapsed time: 58.57 mins\n",
      "Enc Loss = 139.25, KL Divergence = 1132.18, Reconstruction Loss = 340.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.59 mins\n",
      "Epoch: 7 / 10, Batch: 330 (10592 / 12512), Elapsed time: 58.59 mins\n",
      "Enc Loss = 142.92, KL Divergence = 1157.15, Reconstruction Loss = 349.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.61 mins\n",
      "Epoch: 7 / 10, Batch: 331 (10624 / 12512), Elapsed time: 58.61 mins\n",
      "Enc Loss = 143.01, KL Divergence = 1070.62, Reconstruction Loss = 358.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.63 mins\n",
      "Epoch: 7 / 10, Batch: 332 (10656 / 12512), Elapsed time: 58.63 mins\n",
      "Enc Loss = 140.04, KL Divergence = 1069.60, Reconstruction Loss = 349.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.65 mins\n",
      "Epoch: 7 / 10, Batch: 333 (10688 / 12512), Elapsed time: 58.65 mins\n",
      "Enc Loss = 150.49, KL Divergence = 1021.06, Reconstruction Loss = 388.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.67 mins\n",
      "Epoch: 7 / 10, Batch: 334 (10720 / 12512), Elapsed time: 58.67 mins\n",
      "Enc Loss = 160.97, KL Divergence = 1304.96, Reconstruction Loss = 393.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.69 mins\n",
      "Epoch: 7 / 10, Batch: 335 (10752 / 12512), Elapsed time: 58.69 mins\n",
      "Enc Loss = 145.84, KL Divergence = 1245.09, Reconstruction Loss = 350.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.71 mins\n",
      "Epoch: 7 / 10, Batch: 336 (10784 / 12512), Elapsed time: 58.71 mins\n",
      "Enc Loss = 129.08, KL Divergence = 1116.61, Reconstruction Loss = 308.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.73 mins\n",
      "Epoch: 7 / 10, Batch: 337 (10816 / 12512), Elapsed time: 58.73 mins\n",
      "Enc Loss = 136.97, KL Divergence = 1137.25, Reconstruction Loss = 332.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.75 mins\n",
      "Epoch: 7 / 10, Batch: 338 (10848 / 12512), Elapsed time: 58.75 mins\n",
      "Enc Loss = 140.56, KL Divergence = 1223.11, Reconstruction Loss = 335.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.77 mins\n",
      "Epoch: 7 / 10, Batch: 339 (10880 / 12512), Elapsed time: 58.77 mins\n",
      "Enc Loss = 151.20, KL Divergence = 1250.32, Reconstruction Loss = 367.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.79 mins\n",
      "Epoch: 7 / 10, Batch: 340 (10912 / 12512), Elapsed time: 58.79 mins\n",
      "Enc Loss = 131.53, KL Divergence = 1167.27, Reconstruction Loss = 311.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.81 mins\n",
      "Epoch: 7 / 10, Batch: 341 (10944 / 12512), Elapsed time: 58.81 mins\n",
      "Enc Loss = 149.99, KL Divergence = 1323.36, Reconstruction Loss = 355.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.83 mins\n",
      "Epoch: 7 / 10, Batch: 342 (10976 / 12512), Elapsed time: 58.83 mins\n",
      "Enc Loss = 140.62, KL Divergence = 1210.78, Reconstruction Loss = 336.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.85 mins\n",
      "Epoch: 7 / 10, Batch: 343 (11008 / 12512), Elapsed time: 58.85 mins\n",
      "Enc Loss = 147.12, KL Divergence = 1273.96, Reconstruction Loss = 351.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.86 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 10, Batch: 344 (11040 / 12512), Elapsed time: 58.87 mins\n",
      "Enc Loss = 141.77, KL Divergence = 1097.44, Reconstruction Loss = 352.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.88 mins\n",
      "Epoch: 7 / 10, Batch: 345 (11072 / 12512), Elapsed time: 58.89 mins\n",
      "Enc Loss = 135.06, KL Divergence = 1174.91, Reconstruction Loss = 322.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.90 mins\n",
      "Epoch: 7 / 10, Batch: 346 (11104 / 12512), Elapsed time: 58.91 mins\n",
      "Enc Loss = 140.69, KL Divergence = 1157.85, Reconstruction Loss = 342.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.92 mins\n",
      "Epoch: 7 / 10, Batch: 347 (11136 / 12512), Elapsed time: 58.93 mins\n",
      "Enc Loss = 132.51, KL Divergence = 1054.44, Reconstruction Loss = 326.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.94 mins\n",
      "Epoch: 7 / 10, Batch: 348 (11168 / 12512), Elapsed time: 58.94 mins\n",
      "Enc Loss = 167.07, KL Divergence = 1223.49, Reconstruction Loss = 422.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.96 mins\n",
      "Epoch: 7 / 10, Batch: 349 (11200 / 12512), Elapsed time: 58.97 mins\n",
      "Enc Loss = 136.10, KL Divergence = 1087.20, Reconstruction Loss = 334.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 58.98 mins\n",
      "Epoch: 7 / 10, Batch: 350 (11232 / 12512), Elapsed time: 58.99 mins\n",
      "Enc Loss = 127.60, KL Divergence = 1051.73, Reconstruction Loss = 310.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.00 mins\n",
      "Epoch: 7 / 10, Batch: 351 (11264 / 12512), Elapsed time: 59.00 mins\n",
      "Enc Loss = 136.97, KL Divergence = 1004.52, Reconstruction Loss = 345.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.02 mins\n",
      "Epoch: 7 / 10, Batch: 352 (11296 / 12512), Elapsed time: 59.02 mins\n",
      "Enc Loss = 136.37, KL Divergence = 1045.57, Reconstruction Loss = 339.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.04 mins\n",
      "Epoch: 7 / 10, Batch: 353 (11328 / 12512), Elapsed time: 59.04 mins\n",
      "Enc Loss = 140.40, KL Divergence = 1088.95, Reconstruction Loss = 348.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.06 mins\n",
      "Epoch: 7 / 10, Batch: 354 (11360 / 12512), Elapsed time: 59.06 mins\n",
      "Enc Loss = 153.55, KL Divergence = 1141.06, Reconstruction Loss = 386.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.08 mins\n",
      "Epoch: 7 / 10, Batch: 355 (11392 / 12512), Elapsed time: 59.08 mins\n",
      "Enc Loss = 145.54, KL Divergence = 1164.05, Reconstruction Loss = 357.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.10 mins\n",
      "Epoch: 7 / 10, Batch: 356 (11424 / 12512), Elapsed time: 59.10 mins\n",
      "Enc Loss = 141.50, KL Divergence = 1200.96, Reconstruction Loss = 340.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.12 mins\n",
      "Epoch: 7 / 10, Batch: 357 (11456 / 12512), Elapsed time: 59.12 mins\n",
      "Enc Loss = 151.37, KL Divergence = 1316.80, Reconstruction Loss = 361.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.14 mins\n",
      "Epoch: 7 / 10, Batch: 358 (11488 / 12512), Elapsed time: 59.14 mins\n",
      "Enc Loss = 138.61, KL Divergence = 1025.80, Reconstruction Loss = 349.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.16 mins\n",
      "Epoch: 7 / 10, Batch: 359 (11520 / 12512), Elapsed time: 59.16 mins\n",
      "Enc Loss = 133.33, KL Divergence = 1057.00, Reconstruction Loss = 328.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.18 mins\n",
      "Epoch: 7 / 10, Batch: 360 (11552 / 12512), Elapsed time: 59.18 mins\n",
      "Enc Loss = 147.35, KL Divergence = 1241.86, Reconstruction Loss = 355.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.20 mins\n",
      "Epoch: 7 / 10, Batch: 361 (11584 / 12512), Elapsed time: 59.20 mins\n",
      "Enc Loss = 132.06, KL Divergence = 1115.37, Reconstruction Loss = 318.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.22 mins\n",
      "Epoch: 7 / 10, Batch: 362 (11616 / 12512), Elapsed time: 59.22 mins\n",
      "Enc Loss = 140.23, KL Divergence = 1164.09, Reconstruction Loss = 340.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.24 mins\n",
      "Epoch: 7 / 10, Batch: 363 (11648 / 12512), Elapsed time: 59.24 mins\n",
      "Enc Loss = 126.83, KL Divergence = 1188.49, Reconstruction Loss = 293.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.26 mins\n",
      "Epoch: 7 / 10, Batch: 364 (11680 / 12512), Elapsed time: 59.26 mins\n",
      "Enc Loss = 130.92, KL Divergence = 1119.64, Reconstruction Loss = 314.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.28 mins\n",
      "Epoch: 7 / 10, Batch: 365 (11712 / 12512), Elapsed time: 59.28 mins\n",
      "Enc Loss = 147.26, KL Divergence = 1168.83, Reconstruction Loss = 362.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.30 mins\n",
      "Epoch: 7 / 10, Batch: 366 (11744 / 12512), Elapsed time: 59.30 mins\n",
      "Enc Loss = 138.97, KL Divergence = 1097.55, Reconstruction Loss = 342.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.32 mins\n",
      "Epoch: 7 / 10, Batch: 367 (11776 / 12512), Elapsed time: 59.32 mins\n",
      "Enc Loss = 136.80, KL Divergence = 1125.25, Reconstruction Loss = 333.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.34 mins\n",
      "Epoch: 7 / 10, Batch: 368 (11808 / 12512), Elapsed time: 59.34 mins\n",
      "Enc Loss = 157.54, KL Divergence = 1235.89, Reconstruction Loss = 389.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.36 mins\n",
      "Epoch: 7 / 10, Batch: 369 (11840 / 12512), Elapsed time: 59.36 mins\n",
      "Enc Loss = 134.78, KL Divergence = 1145.08, Reconstruction Loss = 324.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.38 mins\n",
      "Epoch: 7 / 10, Batch: 370 (11872 / 12512), Elapsed time: 59.38 mins\n",
      "Enc Loss = 146.86, KL Divergence = 1231.12, Reconstruction Loss = 355.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.40 mins\n",
      "Epoch: 7 / 10, Batch: 371 (11904 / 12512), Elapsed time: 59.40 mins\n",
      "Enc Loss = 127.93, KL Divergence = 1100.68, Reconstruction Loss = 306.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.42 mins\n",
      "Epoch: 7 / 10, Batch: 372 (11936 / 12512), Elapsed time: 59.42 mins\n",
      "Enc Loss = 141.84, KL Divergence = 1248.25, Reconstruction Loss = 336.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.44 mins\n",
      "Epoch: 7 / 10, Batch: 373 (11968 / 12512), Elapsed time: 59.44 mins\n",
      "Enc Loss = 143.79, KL Divergence = 1293.52, Reconstruction Loss = 338.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.46 mins\n",
      "Epoch: 7 / 10, Batch: 374 (12000 / 12512), Elapsed time: 59.46 mins\n",
      "Enc Loss = 139.91, KL Divergence = 1221.14, Reconstruction Loss = 333.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.48 mins\n",
      "Epoch: 7 / 10, Batch: 375 (12032 / 12512), Elapsed time: 59.48 mins\n",
      "Enc Loss = 140.33, KL Divergence = 1139.72, Reconstruction Loss = 343.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.50 mins\n",
      "Epoch: 7 / 10, Batch: 376 (12064 / 12512), Elapsed time: 59.50 mins\n",
      "Enc Loss = 137.91, KL Divergence = 1191.52, Reconstruction Loss = 329.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.52 mins\n",
      "Epoch: 7 / 10, Batch: 377 (12096 / 12512), Elapsed time: 59.52 mins\n",
      "Enc Loss = 147.55, KL Divergence = 1292.92, Reconstruction Loss = 351.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.54 mins\n",
      "Epoch: 7 / 10, Batch: 378 (12128 / 12512), Elapsed time: 59.54 mins\n",
      "Enc Loss = 135.43, KL Divergence = 1069.94, Reconstruction Loss = 334.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.56 mins\n",
      "Epoch: 7 / 10, Batch: 379 (12160 / 12512), Elapsed time: 59.56 mins\n",
      "Enc Loss = 136.55, KL Divergence = 1174.31, Reconstruction Loss = 327.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.58 mins\n",
      "Epoch: 7 / 10, Batch: 380 (12192 / 12512), Elapsed time: 59.58 mins\n",
      "Enc Loss = 137.48, KL Divergence = 1197.23, Reconstruction Loss = 327.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.60 mins\n",
      "Epoch: 7 / 10, Batch: 381 (12224 / 12512), Elapsed time: 59.60 mins\n",
      "Enc Loss = 182.17, KL Divergence = 1217.21, Reconstruction Loss = 472.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.62 mins\n",
      "Epoch: 7 / 10, Batch: 382 (12256 / 12512), Elapsed time: 59.62 mins\n",
      "Enc Loss = 155.64, KL Divergence = 1180.17, Reconstruction Loss = 389.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.64 mins\n",
      "Epoch: 7 / 10, Batch: 383 (12288 / 12512), Elapsed time: 59.64 mins\n",
      "Enc Loss = 129.77, KL Divergence = 1063.99, Reconstruction Loss = 316.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.66 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 / 10, Batch: 384 (12320 / 12512), Elapsed time: 59.66 mins\n",
      "Enc Loss = 139.62, KL Divergence = 1161.28, Reconstruction Loss = 338.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.68 mins\n",
      "Epoch: 7 / 10, Batch: 385 (12352 / 12512), Elapsed time: 59.68 mins\n",
      "Enc Loss = 147.33, KL Divergence = 1169.09, Reconstruction Loss = 363.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.69 mins\n",
      "Epoch: 7 / 10, Batch: 386 (12384 / 12512), Elapsed time: 59.70 mins\n",
      "Enc Loss = 140.87, KL Divergence = 1154.87, Reconstruction Loss = 343.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.71 mins\n",
      "Epoch: 7 / 10, Batch: 387 (12416 / 12512), Elapsed time: 59.71 mins\n",
      "Enc Loss = 132.31, KL Divergence = 1097.12, Reconstruction Loss = 321.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.73 mins\n",
      "Epoch: 7 / 10, Batch: 388 (12448 / 12512), Elapsed time: 59.73 mins\n",
      "Enc Loss = 134.05, KL Divergence = 1125.14, Reconstruction Loss = 324.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.75 mins\n",
      "Epoch: 7 / 10, Batch: 389 (12480 / 12512), Elapsed time: 59.75 mins\n",
      "Enc Loss = 140.28, KL Divergence = 1096.32, Reconstruction Loss = 347.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.77 mins\n",
      "Epoch: 7 / 10, Batch: 390 (12512 / 12512), Elapsed time: 59.77 mins\n",
      "Enc Loss = 119.60, KL Divergence = 482.54, Reconstruction Loss = 342.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.79 mins\n",
      "Epoch: 8, Elapsed Time: 59.79\n",
      "Epoch: 8 / 10, Batch: 0 (32 / 12512), Elapsed time: 59.79 mins\n",
      "Enc Loss = 137.66, KL Divergence = 1086.43, Reconstruction Loss = 339.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.81 mins\n",
      "Epoch: 8 / 10, Batch: 1 (64 / 12512), Elapsed time: 59.81 mins\n",
      "Enc Loss = 143.44, KL Divergence = 1110.09, Reconstruction Loss = 356.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.83 mins\n",
      "Epoch: 8 / 10, Batch: 2 (96 / 12512), Elapsed time: 59.83 mins\n",
      "Enc Loss = 141.51, KL Divergence = 1083.09, Reconstruction Loss = 352.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.85 mins\n",
      "Epoch: 8 / 10, Batch: 3 (128 / 12512), Elapsed time: 59.85 mins\n",
      "Enc Loss = 155.85, KL Divergence = 1240.19, Reconstruction Loss = 383.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.87 mins\n",
      "Epoch: 8 / 10, Batch: 4 (160 / 12512), Elapsed time: 59.87 mins\n",
      "Enc Loss = 133.98, KL Divergence = 1128.00, Reconstruction Loss = 323.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.89 mins\n",
      "Epoch: 8 / 10, Batch: 5 (192 / 12512), Elapsed time: 59.89 mins\n",
      "Enc Loss = 124.57, KL Divergence = 1075.20, Reconstruction Loss = 298.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.91 mins\n",
      "Epoch: 8 / 10, Batch: 6 (224 / 12512), Elapsed time: 59.91 mins\n",
      "Enc Loss = 143.28, KL Divergence = 1113.63, Reconstruction Loss = 355.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.93 mins\n",
      "Epoch: 8 / 10, Batch: 7 (256 / 12512), Elapsed time: 59.93 mins\n",
      "Enc Loss = 138.28, KL Divergence = 1178.96, Reconstruction Loss = 332.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.95 mins\n",
      "Epoch: 8 / 10, Batch: 8 (288 / 12512), Elapsed time: 59.95 mins\n",
      "Enc Loss = 136.46, KL Divergence = 1180.00, Reconstruction Loss = 326.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.97 mins\n",
      "Epoch: 8 / 10, Batch: 9 (320 / 12512), Elapsed time: 59.97 mins\n",
      "Enc Loss = 135.08, KL Divergence = 1114.02, Reconstruction Loss = 328.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 59.99 mins\n",
      "Epoch: 8 / 10, Batch: 10 (352 / 12512), Elapsed time: 59.99 mins\n",
      "Enc Loss = 141.20, KL Divergence = 1188.69, Reconstruction Loss = 340.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.01 mins\n",
      "Epoch: 8 / 10, Batch: 11 (384 / 12512), Elapsed time: 60.01 mins\n",
      "Enc Loss = 154.29, KL Divergence = 1154.15, Reconstruction Loss = 387.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.03 mins\n",
      "Epoch: 8 / 10, Batch: 12 (416 / 12512), Elapsed time: 60.03 mins\n",
      "Enc Loss = 135.84, KL Divergence = 1175.76, Reconstruction Loss = 324.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.05 mins\n",
      "Epoch: 8 / 10, Batch: 13 (448 / 12512), Elapsed time: 60.05 mins\n",
      "Enc Loss = 165.40, KL Divergence = 1400.32, Reconstruction Loss = 398.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.07 mins\n",
      "Epoch: 8 / 10, Batch: 14 (480 / 12512), Elapsed time: 60.07 mins\n",
      "Enc Loss = 150.52, KL Divergence = 1287.45, Reconstruction Loss = 361.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.09 mins\n",
      "Epoch: 8 / 10, Batch: 15 (512 / 12512), Elapsed time: 60.09 mins\n",
      "Enc Loss = 133.37, KL Divergence = 1068.70, Reconstruction Loss = 327.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.11 mins\n",
      "Epoch: 8 / 10, Batch: 16 (544 / 12512), Elapsed time: 60.11 mins\n",
      "Enc Loss = 148.42, KL Divergence = 1204.08, Reconstruction Loss = 363.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.13 mins\n",
      "Epoch: 8 / 10, Batch: 17 (576 / 12512), Elapsed time: 60.13 mins\n",
      "Enc Loss = 145.44, KL Divergence = 1158.53, Reconstruction Loss = 357.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.15 mins\n",
      "Epoch: 8 / 10, Batch: 18 (608 / 12512), Elapsed time: 60.15 mins\n",
      "Enc Loss = 137.31, KL Divergence = 1089.10, Reconstruction Loss = 338.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.17 mins\n",
      "Epoch: 8 / 10, Batch: 19 (640 / 12512), Elapsed time: 60.17 mins\n",
      "Enc Loss = 156.65, KL Divergence = 1250.75, Reconstruction Loss = 385.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.19 mins\n",
      "Epoch: 8 / 10, Batch: 20 (672 / 12512), Elapsed time: 60.19 mins\n",
      "Enc Loss = 152.74, KL Divergence = 1073.99, Reconstruction Loss = 390.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.21 mins\n",
      "Epoch: 8 / 10, Batch: 21 (704 / 12512), Elapsed time: 60.21 mins\n",
      "Enc Loss = 132.65, KL Divergence = 1029.19, Reconstruction Loss = 329.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.23 mins\n",
      "Epoch: 8 / 10, Batch: 22 (736 / 12512), Elapsed time: 60.23 mins\n",
      "Enc Loss = 172.70, KL Divergence = 1256.19, Reconstruction Loss = 437.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.25 mins\n",
      "Epoch: 8 / 10, Batch: 23 (768 / 12512), Elapsed time: 60.25 mins\n",
      "Enc Loss = 177.51, KL Divergence = 1144.34, Reconstruction Loss = 464.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.27 mins\n",
      "Epoch: 8 / 10, Batch: 24 (800 / 12512), Elapsed time: 60.27 mins\n",
      "Enc Loss = 139.01, KL Divergence = 1131.91, Reconstruction Loss = 339.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.29 mins\n",
      "Epoch: 8 / 10, Batch: 25 (832 / 12512), Elapsed time: 60.29 mins\n",
      "Enc Loss = 155.68, KL Divergence = 1419.17, Reconstruction Loss = 364.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.31 mins\n",
      "Epoch: 8 / 10, Batch: 26 (864 / 12512), Elapsed time: 60.31 mins\n",
      "Enc Loss = 145.02, KL Divergence = 1195.12, Reconstruction Loss = 352.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.33 mins\n",
      "Epoch: 8 / 10, Batch: 27 (896 / 12512), Elapsed time: 60.33 mins\n",
      "Enc Loss = 128.15, KL Divergence = 1109.54, Reconstruction Loss = 306.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.35 mins\n",
      "Epoch: 8 / 10, Batch: 28 (928 / 12512), Elapsed time: 60.35 mins\n",
      "Enc Loss = 130.30, KL Divergence = 1182.11, Reconstruction Loss = 305.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.37 mins\n",
      "Epoch: 8 / 10, Batch: 29 (960 / 12512), Elapsed time: 60.37 mins\n",
      "Enc Loss = 143.71, KL Divergence = 1173.31, Reconstruction Loss = 350.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.39 mins\n",
      "Epoch: 8 / 10, Batch: 30 (992 / 12512), Elapsed time: 60.39 mins\n",
      "Enc Loss = 147.94, KL Divergence = 1286.42, Reconstruction Loss = 353.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.41 mins\n",
      "Epoch: 8 / 10, Batch: 31 (1024 / 12512), Elapsed time: 60.41 mins\n",
      "Enc Loss = 139.41, KL Divergence = 1217.39, Reconstruction Loss = 332.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.43 mins\n",
      "Epoch: 8 / 10, Batch: 32 (1056 / 12512), Elapsed time: 60.43 mins\n",
      "Enc Loss = 138.78, KL Divergence = 1175.13, Reconstruction Loss = 334.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.45 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 33 (1088 / 12512), Elapsed time: 60.45 mins\n",
      "Enc Loss = 132.85, KL Divergence = 1189.50, Reconstruction Loss = 313.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.46 mins\n",
      "Epoch: 8 / 10, Batch: 34 (1120 / 12512), Elapsed time: 60.47 mins\n",
      "Enc Loss = 135.72, KL Divergence = 1045.34, Reconstruction Loss = 337.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.48 mins\n",
      "Epoch: 8 / 10, Batch: 35 (1152 / 12512), Elapsed time: 60.48 mins\n",
      "Enc Loss = 139.03, KL Divergence = 1196.84, Reconstruction Loss = 333.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.50 mins\n",
      "Epoch: 8 / 10, Batch: 36 (1184 / 12512), Elapsed time: 60.50 mins\n",
      "Enc Loss = 134.20, KL Divergence = 1062.01, Reconstruction Loss = 331.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.52 mins\n",
      "Epoch: 8 / 10, Batch: 37 (1216 / 12512), Elapsed time: 60.52 mins\n",
      "Enc Loss = 144.94, KL Divergence = 1036.59, Reconstruction Loss = 368.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.54 mins\n",
      "Epoch: 8 / 10, Batch: 38 (1248 / 12512), Elapsed time: 60.54 mins\n",
      "Enc Loss = 137.73, KL Divergence = 1086.88, Reconstruction Loss = 340.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.56 mins\n",
      "Epoch: 8 / 10, Batch: 39 (1280 / 12512), Elapsed time: 60.57 mins\n",
      "Enc Loss = 125.58, KL Divergence = 1012.17, Reconstruction Loss = 307.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.58 mins\n",
      "Epoch: 8 / 10, Batch: 40 (1312 / 12512), Elapsed time: 60.58 mins\n",
      "Enc Loss = 130.45, KL Divergence = 1063.97, Reconstruction Loss = 318.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.60 mins\n",
      "Epoch: 8 / 10, Batch: 41 (1344 / 12512), Elapsed time: 60.60 mins\n",
      "Enc Loss = 144.24, KL Divergence = 1133.27, Reconstruction Loss = 356.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.62 mins\n",
      "Epoch: 8 / 10, Batch: 42 (1376 / 12512), Elapsed time: 60.62 mins\n",
      "Enc Loss = 131.56, KL Divergence = 1010.13, Reconstruction Loss = 327.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.64 mins\n",
      "Epoch: 8 / 10, Batch: 43 (1408 / 12512), Elapsed time: 60.64 mins\n",
      "Enc Loss = 140.88, KL Divergence = 1094.28, Reconstruction Loss = 349.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.66 mins\n",
      "Epoch: 8 / 10, Batch: 44 (1440 / 12512), Elapsed time: 60.66 mins\n",
      "Enc Loss = 131.32, KL Divergence = 1049.42, Reconstruction Loss = 322.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.68 mins\n",
      "Epoch: 8 / 10, Batch: 45 (1472 / 12512), Elapsed time: 60.68 mins\n",
      "Enc Loss = 136.68, KL Divergence = 1054.17, Reconstruction Loss = 339.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.70 mins\n",
      "Epoch: 8 / 10, Batch: 46 (1504 / 12512), Elapsed time: 60.70 mins\n",
      "Enc Loss = 144.38, KL Divergence = 1174.34, Reconstruction Loss = 352.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.72 mins\n",
      "Epoch: 8 / 10, Batch: 47 (1536 / 12512), Elapsed time: 60.73 mins\n",
      "Enc Loss = 130.19, KL Divergence = 1056.88, Reconstruction Loss = 318.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.75 mins\n",
      "Epoch: 8 / 10, Batch: 48 (1568 / 12512), Elapsed time: 60.75 mins\n",
      "Enc Loss = 133.28, KL Divergence = 983.82, Reconstruction Loss = 335.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.76 mins\n",
      "Epoch: 8 / 10, Batch: 49 (1600 / 12512), Elapsed time: 60.77 mins\n",
      "Enc Loss = 147.56, KL Divergence = 1260.88, Reconstruction Loss = 354.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.78 mins\n",
      "Epoch: 8 / 10, Batch: 50 (1632 / 12512), Elapsed time: 60.78 mins\n",
      "Enc Loss = 144.17, KL Divergence = 1141.33, Reconstruction Loss = 355.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.80 mins\n",
      "Epoch: 8 / 10, Batch: 51 (1664 / 12512), Elapsed time: 60.81 mins\n",
      "Enc Loss = 135.73, KL Divergence = 1128.63, Reconstruction Loss = 329.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.82 mins\n",
      "Epoch: 8 / 10, Batch: 52 (1696 / 12512), Elapsed time: 60.82 mins\n",
      "Enc Loss = 131.07, KL Divergence = 1035.15, Reconstruction Loss = 323.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.84 mins\n",
      "Epoch: 8 / 10, Batch: 53 (1728 / 12512), Elapsed time: 60.84 mins\n",
      "Enc Loss = 133.41, KL Divergence = 1081.19, Reconstruction Loss = 326.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.86 mins\n",
      "Epoch: 8 / 10, Batch: 54 (1760 / 12512), Elapsed time: 60.86 mins\n",
      "Enc Loss = 131.33, KL Divergence = 1011.64, Reconstruction Loss = 326.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.88 mins\n",
      "Epoch: 8 / 10, Batch: 55 (1792 / 12512), Elapsed time: 60.88 mins\n",
      "Enc Loss = 142.62, KL Divergence = 1037.70, Reconstruction Loss = 361.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.90 mins\n",
      "Epoch: 8 / 10, Batch: 56 (1824 / 12512), Elapsed time: 60.90 mins\n",
      "Enc Loss = 135.95, KL Divergence = 1137.22, Reconstruction Loss = 329.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.92 mins\n",
      "Epoch: 8 / 10, Batch: 57 (1856 / 12512), Elapsed time: 60.92 mins\n",
      "Enc Loss = 144.66, KL Divergence = 1212.07, Reconstruction Loss = 349.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.94 mins\n",
      "Epoch: 8 / 10, Batch: 58 (1888 / 12512), Elapsed time: 60.94 mins\n",
      "Enc Loss = 152.74, KL Divergence = 1269.41, Reconstruction Loss = 370.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.96 mins\n",
      "Epoch: 8 / 10, Batch: 59 (1920 / 12512), Elapsed time: 60.96 mins\n",
      "Enc Loss = 132.58, KL Divergence = 1057.56, Reconstruction Loss = 326.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 60.98 mins\n",
      "Epoch: 8 / 10, Batch: 60 (1952 / 12512), Elapsed time: 60.98 mins\n",
      "Enc Loss = 146.98, KL Divergence = 1227.94, Reconstruction Loss = 355.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.00 mins\n",
      "Epoch: 8 / 10, Batch: 61 (1984 / 12512), Elapsed time: 61.00 mins\n",
      "Enc Loss = 126.86, KL Divergence = 1042.47, Reconstruction Loss = 308.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.02 mins\n",
      "Epoch: 8 / 10, Batch: 62 (2016 / 12512), Elapsed time: 61.02 mins\n",
      "Enc Loss = 134.75, KL Divergence = 1153.49, Reconstruction Loss = 323.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.04 mins\n",
      "Epoch: 8 / 10, Batch: 63 (2048 / 12512), Elapsed time: 61.04 mins\n",
      "Enc Loss = 129.83, KL Divergence = 1117.28, Reconstruction Loss = 311.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.06 mins\n",
      "Epoch: 8 / 10, Batch: 64 (2080 / 12512), Elapsed time: 61.06 mins\n",
      "Enc Loss = 145.08, KL Divergence = 1254.91, Reconstruction Loss = 346.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.08 mins\n",
      "Epoch: 8 / 10, Batch: 65 (2112 / 12512), Elapsed time: 61.08 mins\n",
      "Enc Loss = 141.66, KL Divergence = 1245.86, Reconstruction Loss = 336.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.10 mins\n",
      "Epoch: 8 / 10, Batch: 66 (2144 / 12512), Elapsed time: 61.10 mins\n",
      "Enc Loss = 141.96, KL Divergence = 1223.57, Reconstruction Loss = 339.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.12 mins\n",
      "Epoch: 8 / 10, Batch: 67 (2176 / 12512), Elapsed time: 61.12 mins\n",
      "Enc Loss = 135.98, KL Divergence = 1080.33, Reconstruction Loss = 334.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.14 mins\n",
      "Epoch: 8 / 10, Batch: 68 (2208 / 12512), Elapsed time: 61.14 mins\n",
      "Enc Loss = 135.37, KL Divergence = 1165.37, Reconstruction Loss = 324.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.16 mins\n",
      "Epoch: 8 / 10, Batch: 69 (2240 / 12512), Elapsed time: 61.16 mins\n",
      "Enc Loss = 135.63, KL Divergence = 1159.94, Reconstruction Loss = 325.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.18 mins\n",
      "Epoch: 8 / 10, Batch: 70 (2272 / 12512), Elapsed time: 61.18 mins\n",
      "Enc Loss = 137.91, KL Divergence = 1131.56, Reconstruction Loss = 336.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.20 mins\n",
      "Epoch: 8 / 10, Batch: 71 (2304 / 12512), Elapsed time: 61.20 mins\n",
      "Enc Loss = 140.20, KL Divergence = 1216.93, Reconstruction Loss = 334.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.22 mins\n",
      "Epoch: 8 / 10, Batch: 72 (2336 / 12512), Elapsed time: 61.22 mins\n",
      "Enc Loss = 133.82, KL Divergence = 1107.86, Reconstruction Loss = 325.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.24 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 73 (2368 / 12512), Elapsed time: 61.24 mins\n",
      "Enc Loss = 142.62, KL Divergence = 1139.87, Reconstruction Loss = 350.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.26 mins\n",
      "Epoch: 8 / 10, Batch: 74 (2400 / 12512), Elapsed time: 61.26 mins\n",
      "Enc Loss = 153.45, KL Divergence = 1197.05, Reconstruction Loss = 380.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.28 mins\n",
      "Epoch: 8 / 10, Batch: 75 (2432 / 12512), Elapsed time: 61.28 mins\n",
      "Enc Loss = 144.30, KL Divergence = 1094.42, Reconstruction Loss = 360.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.30 mins\n",
      "Epoch: 8 / 10, Batch: 76 (2464 / 12512), Elapsed time: 61.30 mins\n",
      "Enc Loss = 135.37, KL Divergence = 1141.83, Reconstruction Loss = 326.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.32 mins\n",
      "Epoch: 8 / 10, Batch: 77 (2496 / 12512), Elapsed time: 61.32 mins\n",
      "Enc Loss = 141.69, KL Divergence = 1217.21, Reconstruction Loss = 339.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.34 mins\n",
      "Epoch: 8 / 10, Batch: 78 (2528 / 12512), Elapsed time: 61.34 mins\n",
      "Enc Loss = 152.32, KL Divergence = 1272.15, Reconstruction Loss = 368.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.36 mins\n",
      "Epoch: 8 / 10, Batch: 79 (2560 / 12512), Elapsed time: 61.36 mins\n",
      "Enc Loss = 132.09, KL Divergence = 1109.65, Reconstruction Loss = 319.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.38 mins\n",
      "Epoch: 8 / 10, Batch: 80 (2592 / 12512), Elapsed time: 61.38 mins\n",
      "Enc Loss = 124.37, KL Divergence = 1106.46, Reconstruction Loss = 294.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.40 mins\n",
      "Epoch: 8 / 10, Batch: 81 (2624 / 12512), Elapsed time: 61.40 mins\n",
      "Enc Loss = 132.68, KL Divergence = 1070.15, Reconstruction Loss = 325.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.42 mins\n",
      "Epoch: 8 / 10, Batch: 82 (2656 / 12512), Elapsed time: 61.42 mins\n",
      "Enc Loss = 146.17, KL Divergence = 1116.15, Reconstruction Loss = 364.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.44 mins\n",
      "Epoch: 8 / 10, Batch: 83 (2688 / 12512), Elapsed time: 61.44 mins\n",
      "Enc Loss = 135.11, KL Divergence = 1150.98, Reconstruction Loss = 324.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.46 mins\n",
      "Epoch: 8 / 10, Batch: 84 (2720 / 12512), Elapsed time: 61.46 mins\n",
      "Enc Loss = 142.84, KL Divergence = 1091.79, Reconstruction Loss = 356.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.48 mins\n",
      "Epoch: 8 / 10, Batch: 85 (2752 / 12512), Elapsed time: 61.48 mins\n",
      "Enc Loss = 144.13, KL Divergence = 1114.08, Reconstruction Loss = 358.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.50 mins\n",
      "Epoch: 8 / 10, Batch: 86 (2784 / 12512), Elapsed time: 61.50 mins\n",
      "Enc Loss = 138.90, KL Divergence = 1137.95, Reconstruction Loss = 338.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.52 mins\n",
      "Epoch: 8 / 10, Batch: 87 (2816 / 12512), Elapsed time: 61.52 mins\n",
      "Enc Loss = 136.37, KL Divergence = 1050.05, Reconstruction Loss = 339.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.54 mins\n",
      "Epoch: 8 / 10, Batch: 88 (2848 / 12512), Elapsed time: 61.54 mins\n",
      "Enc Loss = 141.30, KL Divergence = 987.76, Reconstruction Loss = 361.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.56 mins\n",
      "Epoch: 8 / 10, Batch: 89 (2880 / 12512), Elapsed time: 61.56 mins\n",
      "Enc Loss = 131.56, KL Divergence = 1104.10, Reconstruction Loss = 318.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.58 mins\n",
      "Epoch: 8 / 10, Batch: 90 (2912 / 12512), Elapsed time: 61.58 mins\n",
      "Enc Loss = 133.91, KL Divergence = 1087.89, Reconstruction Loss = 327.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.60 mins\n",
      "Epoch: 8 / 10, Batch: 91 (2944 / 12512), Elapsed time: 61.60 mins\n",
      "Enc Loss = 157.16, KL Divergence = 1125.48, Reconstruction Loss = 399.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.61 mins\n",
      "Epoch: 8 / 10, Batch: 92 (2976 / 12512), Elapsed time: 61.62 mins\n",
      "Enc Loss = 140.59, KL Divergence = 1187.08, Reconstruction Loss = 339.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.63 mins\n",
      "Epoch: 8 / 10, Batch: 93 (3008 / 12512), Elapsed time: 61.63 mins\n",
      "Enc Loss = 128.44, KL Divergence = 1002.34, Reconstruction Loss = 318.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.65 mins\n",
      "Epoch: 8 / 10, Batch: 94 (3040 / 12512), Elapsed time: 61.65 mins\n",
      "Enc Loss = 142.10, KL Divergence = 1112.33, Reconstruction Loss = 351.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.67 mins\n",
      "Epoch: 8 / 10, Batch: 95 (3072 / 12512), Elapsed time: 61.67 mins\n",
      "Enc Loss = 142.19, KL Divergence = 1043.66, Reconstruction Loss = 359.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.69 mins\n",
      "Epoch: 8 / 10, Batch: 96 (3104 / 12512), Elapsed time: 61.69 mins\n",
      "Enc Loss = 156.81, KL Divergence = 1188.94, Reconstruction Loss = 392.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.71 mins\n",
      "Epoch: 8 / 10, Batch: 97 (3136 / 12512), Elapsed time: 61.71 mins\n",
      "Enc Loss = 144.28, KL Divergence = 1253.01, Reconstruction Loss = 344.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.73 mins\n",
      "Epoch: 8 / 10, Batch: 98 (3168 / 12512), Elapsed time: 61.73 mins\n",
      "Enc Loss = 142.64, KL Divergence = 1292.44, Reconstruction Loss = 335.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.75 mins\n",
      "Epoch: 8 / 10, Batch: 99 (3200 / 12512), Elapsed time: 61.75 mins\n",
      "Enc Loss = 131.28, KL Divergence = 1180.77, Reconstruction Loss = 309.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.77 mins\n",
      "Epoch: 8 / 10, Batch: 100 (3232 / 12512), Elapsed time: 61.77 mins\n",
      "Enc Loss = 133.28, KL Divergence = 1159.12, Reconstruction Loss = 318.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.79 mins\n",
      "Epoch: 8 / 10, Batch: 101 (3264 / 12512), Elapsed time: 61.79 mins\n",
      "Enc Loss = 128.60, KL Divergence = 1127.19, Reconstruction Loss = 305.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.81 mins\n",
      "Epoch: 8 / 10, Batch: 102 (3296 / 12512), Elapsed time: 61.81 mins\n",
      "Enc Loss = 134.76, KL Divergence = 1164.91, Reconstruction Loss = 322.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.83 mins\n",
      "Epoch: 8 / 10, Batch: 103 (3328 / 12512), Elapsed time: 61.83 mins\n",
      "Enc Loss = 137.07, KL Divergence = 1120.98, Reconstruction Loss = 334.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.85 mins\n",
      "Epoch: 8 / 10, Batch: 104 (3360 / 12512), Elapsed time: 61.85 mins\n",
      "Enc Loss = 140.80, KL Divergence = 1183.48, Reconstruction Loss = 340.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.87 mins\n",
      "Epoch: 8 / 10, Batch: 105 (3392 / 12512), Elapsed time: 61.87 mins\n",
      "Enc Loss = 132.89, KL Divergence = 1143.26, Reconstruction Loss = 318.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.89 mins\n",
      "Epoch: 8 / 10, Batch: 106 (3424 / 12512), Elapsed time: 61.89 mins\n",
      "Enc Loss = 149.60, KL Divergence = 1190.31, Reconstruction Loss = 368.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.91 mins\n",
      "Epoch: 8 / 10, Batch: 107 (3456 / 12512), Elapsed time: 61.91 mins\n",
      "Enc Loss = 126.40, KL Divergence = 1033.64, Reconstruction Loss = 308.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.93 mins\n",
      "Epoch: 8 / 10, Batch: 108 (3488 / 12512), Elapsed time: 61.93 mins\n",
      "Enc Loss = 142.57, KL Divergence = 1127.80, Reconstruction Loss = 351.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.95 mins\n",
      "Epoch: 8 / 10, Batch: 109 (3520 / 12512), Elapsed time: 61.95 mins\n",
      "Enc Loss = 133.53, KL Divergence = 1138.34, Reconstruction Loss = 320.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.97 mins\n",
      "Epoch: 8 / 10, Batch: 110 (3552 / 12512), Elapsed time: 61.97 mins\n",
      "Enc Loss = 136.81, KL Divergence = 1125.45, Reconstruction Loss = 333.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 61.99 mins\n",
      "Epoch: 8 / 10, Batch: 111 (3584 / 12512), Elapsed time: 61.99 mins\n",
      "Enc Loss = 136.42, KL Divergence = 1134.62, Reconstruction Loss = 330.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.01 mins\n",
      "Epoch: 8 / 10, Batch: 112 (3616 / 12512), Elapsed time: 62.01 mins\n",
      "Enc Loss = 133.53, KL Divergence = 1072.68, Reconstruction Loss = 327.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.03 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 113 (3648 / 12512), Elapsed time: 62.03 mins\n",
      "Enc Loss = 135.26, KL Divergence = 1080.59, Reconstruction Loss = 332.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.05 mins\n",
      "Epoch: 8 / 10, Batch: 114 (3680 / 12512), Elapsed time: 62.05 mins\n",
      "Enc Loss = 141.53, KL Divergence = 1044.18, Reconstruction Loss = 356.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.07 mins\n",
      "Epoch: 8 / 10, Batch: 115 (3712 / 12512), Elapsed time: 62.07 mins\n",
      "Enc Loss = 149.26, KL Divergence = 1199.00, Reconstruction Loss = 366.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.09 mins\n",
      "Epoch: 8 / 10, Batch: 116 (3744 / 12512), Elapsed time: 62.09 mins\n",
      "Enc Loss = 141.44, KL Divergence = 1104.77, Reconstruction Loss = 350.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.11 mins\n",
      "Epoch: 8 / 10, Batch: 117 (3776 / 12512), Elapsed time: 62.11 mins\n",
      "Enc Loss = 141.81, KL Divergence = 1148.65, Reconstruction Loss = 347.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.13 mins\n",
      "Epoch: 8 / 10, Batch: 118 (3808 / 12512), Elapsed time: 62.13 mins\n",
      "Enc Loss = 136.59, KL Divergence = 1100.96, Reconstruction Loss = 334.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.15 mins\n",
      "Epoch: 8 / 10, Batch: 119 (3840 / 12512), Elapsed time: 62.15 mins\n",
      "Enc Loss = 138.79, KL Divergence = 1105.08, Reconstruction Loss = 341.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.17 mins\n",
      "Epoch: 8 / 10, Batch: 120 (3872 / 12512), Elapsed time: 62.17 mins\n",
      "Enc Loss = 145.27, KL Divergence = 1134.51, Reconstruction Loss = 359.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.19 mins\n",
      "Epoch: 8 / 10, Batch: 121 (3904 / 12512), Elapsed time: 62.19 mins\n",
      "Enc Loss = 154.47, KL Divergence = 1254.30, Reconstruction Loss = 377.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.21 mins\n",
      "Epoch: 8 / 10, Batch: 122 (3936 / 12512), Elapsed time: 62.21 mins\n",
      "Enc Loss = 141.02, KL Divergence = 1143.28, Reconstruction Loss = 345.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.23 mins\n",
      "Epoch: 8 / 10, Batch: 123 (3968 / 12512), Elapsed time: 62.23 mins\n",
      "Enc Loss = 138.34, KL Divergence = 1259.29, Reconstruction Loss = 324.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.25 mins\n",
      "Epoch: 8 / 10, Batch: 124 (4000 / 12512), Elapsed time: 62.25 mins\n",
      "Enc Loss = 134.95, KL Divergence = 1127.24, Reconstruction Loss = 326.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.27 mins\n",
      "Epoch: 8 / 10, Batch: 125 (4032 / 12512), Elapsed time: 62.27 mins\n",
      "Enc Loss = 134.70, KL Divergence = 1206.57, Reconstruction Loss = 317.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.29 mins\n",
      "Epoch: 8 / 10, Batch: 126 (4064 / 12512), Elapsed time: 62.29 mins\n",
      "Enc Loss = 134.76, KL Divergence = 1146.81, Reconstruction Loss = 324.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.31 mins\n",
      "Epoch: 8 / 10, Batch: 127 (4096 / 12512), Elapsed time: 62.31 mins\n",
      "Enc Loss = 130.73, KL Divergence = 1116.31, Reconstruction Loss = 314.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.33 mins\n",
      "Epoch: 8 / 10, Batch: 128 (4128 / 12512), Elapsed time: 62.33 mins\n",
      "Enc Loss = 138.18, KL Divergence = 1032.84, Reconstruction Loss = 347.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.35 mins\n",
      "Epoch: 8 / 10, Batch: 129 (4160 / 12512), Elapsed time: 62.35 mins\n",
      "Enc Loss = 135.36, KL Divergence = 1125.61, Reconstruction Loss = 328.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.37 mins\n",
      "Epoch: 8 / 10, Batch: 130 (4192 / 12512), Elapsed time: 62.37 mins\n",
      "Enc Loss = 131.84, KL Divergence = 1112.94, Reconstruction Loss = 318.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.39 mins\n",
      "Epoch: 8 / 10, Batch: 131 (4224 / 12512), Elapsed time: 62.39 mins\n",
      "Enc Loss = 139.76, KL Divergence = 1105.01, Reconstruction Loss = 344.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.41 mins\n",
      "Epoch: 8 / 10, Batch: 132 (4256 / 12512), Elapsed time: 62.41 mins\n",
      "Enc Loss = 123.93, KL Divergence = 1055.21, Reconstruction Loss = 298.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.42 mins\n",
      "Epoch: 8 / 10, Batch: 133 (4288 / 12512), Elapsed time: 62.43 mins\n",
      "Enc Loss = 144.68, KL Divergence = 1124.38, Reconstruction Loss = 358.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.44 mins\n",
      "Epoch: 8 / 10, Batch: 134 (4320 / 12512), Elapsed time: 62.45 mins\n",
      "Enc Loss = 136.06, KL Divergence = 1124.91, Reconstruction Loss = 330.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.46 mins\n",
      "Epoch: 8 / 10, Batch: 135 (4352 / 12512), Elapsed time: 62.46 mins\n",
      "Enc Loss = 153.55, KL Divergence = 1170.59, Reconstruction Loss = 383.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.48 mins\n",
      "Epoch: 8 / 10, Batch: 136 (4384 / 12512), Elapsed time: 62.48 mins\n",
      "Enc Loss = 167.14, KL Divergence = 1320.69, Reconstruction Loss = 412.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.50 mins\n",
      "Epoch: 8 / 10, Batch: 137 (4416 / 12512), Elapsed time: 62.50 mins\n",
      "Enc Loss = 137.58, KL Divergence = 1130.25, Reconstruction Loss = 335.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.52 mins\n",
      "Epoch: 8 / 10, Batch: 138 (4448 / 12512), Elapsed time: 62.52 mins\n",
      "Enc Loss = 135.64, KL Divergence = 1106.12, Reconstruction Loss = 331.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.54 mins\n",
      "Epoch: 8 / 10, Batch: 139 (4480 / 12512), Elapsed time: 62.54 mins\n",
      "Enc Loss = 147.06, KL Divergence = 1353.71, Reconstruction Loss = 343.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.56 mins\n",
      "Epoch: 8 / 10, Batch: 140 (4512 / 12512), Elapsed time: 62.56 mins\n",
      "Enc Loss = 144.29, KL Divergence = 1199.69, Reconstruction Loss = 349.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.58 mins\n",
      "Epoch: 8 / 10, Batch: 141 (4544 / 12512), Elapsed time: 62.58 mins\n",
      "Enc Loss = 151.66, KL Divergence = 1279.31, Reconstruction Loss = 365.97, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.60 mins\n",
      "Epoch: 8 / 10, Batch: 142 (4576 / 12512), Elapsed time: 62.60 mins\n",
      "Enc Loss = 147.48, KL Divergence = 1261.15, Reconstruction Loss = 354.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.62 mins\n",
      "Epoch: 8 / 10, Batch: 143 (4608 / 12512), Elapsed time: 62.62 mins\n",
      "Enc Loss = 140.37, KL Divergence = 1199.01, Reconstruction Loss = 337.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.64 mins\n",
      "Epoch: 8 / 10, Batch: 144 (4640 / 12512), Elapsed time: 62.64 mins\n",
      "Enc Loss = 137.92, KL Divergence = 1172.28, Reconstruction Loss = 331.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.66 mins\n",
      "Epoch: 8 / 10, Batch: 145 (4672 / 12512), Elapsed time: 62.66 mins\n",
      "Enc Loss = 138.98, KL Divergence = 1151.23, Reconstruction Loss = 337.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.68 mins\n",
      "Epoch: 8 / 10, Batch: 146 (4704 / 12512), Elapsed time: 62.68 mins\n",
      "Enc Loss = 133.49, KL Divergence = 1115.66, Reconstruction Loss = 323.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.70 mins\n",
      "Epoch: 8 / 10, Batch: 147 (4736 / 12512), Elapsed time: 62.70 mins\n",
      "Enc Loss = 134.55, KL Divergence = 1119.84, Reconstruction Loss = 326.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.72 mins\n",
      "Epoch: 8 / 10, Batch: 148 (4768 / 12512), Elapsed time: 62.72 mins\n",
      "Enc Loss = 125.37, KL Divergence = 970.72, Reconstruction Loss = 311.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.74 mins\n",
      "Epoch: 8 / 10, Batch: 149 (4800 / 12512), Elapsed time: 62.74 mins\n",
      "Enc Loss = 136.17, KL Divergence = 1050.07, Reconstruction Loss = 338.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.76 mins\n",
      "Epoch: 8 / 10, Batch: 150 (4832 / 12512), Elapsed time: 62.76 mins\n",
      "Enc Loss = 133.52, KL Divergence = 935.56, Reconstruction Loss = 341.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.78 mins\n",
      "Epoch: 8 / 10, Batch: 151 (4864 / 12512), Elapsed time: 62.78 mins\n",
      "Enc Loss = 133.42, KL Divergence = 971.31, Reconstruction Loss = 337.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.80 mins\n",
      "Epoch: 8 / 10, Batch: 152 (4896 / 12512), Elapsed time: 62.80 mins\n",
      "Enc Loss = 138.20, KL Divergence = 1106.28, Reconstruction Loss = 339.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.82 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 153 (4928 / 12512), Elapsed time: 62.82 mins\n",
      "Enc Loss = 151.88, KL Divergence = 1082.42, Reconstruction Loss = 386.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.84 mins\n",
      "Epoch: 8 / 10, Batch: 154 (4960 / 12512), Elapsed time: 62.84 mins\n",
      "Enc Loss = 127.62, KL Divergence = 944.90, Reconstruction Loss = 321.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.86 mins\n",
      "Epoch: 8 / 10, Batch: 155 (4992 / 12512), Elapsed time: 62.86 mins\n",
      "Enc Loss = 138.00, KL Divergence = 1081.65, Reconstruction Loss = 341.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.88 mins\n",
      "Epoch: 8 / 10, Batch: 156 (5024 / 12512), Elapsed time: 62.88 mins\n",
      "Enc Loss = 124.37, KL Divergence = 1011.34, Reconstruction Loss = 303.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.90 mins\n",
      "Epoch: 8 / 10, Batch: 157 (5056 / 12512), Elapsed time: 62.90 mins\n",
      "Enc Loss = 139.02, KL Divergence = 1047.76, Reconstruction Loss = 348.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.92 mins\n",
      "Epoch: 8 / 10, Batch: 158 (5088 / 12512), Elapsed time: 62.92 mins\n",
      "Enc Loss = 141.81, KL Divergence = 1128.92, Reconstruction Loss = 349.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.94 mins\n",
      "Epoch: 8 / 10, Batch: 159 (5120 / 12512), Elapsed time: 62.94 mins\n",
      "Enc Loss = 152.73, KL Divergence = 1127.18, Reconstruction Loss = 385.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.96 mins\n",
      "Epoch: 8 / 10, Batch: 160 (5152 / 12512), Elapsed time: 62.96 mins\n",
      "Enc Loss = 132.83, KL Divergence = 1132.99, Reconstruction Loss = 319.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 62.98 mins\n",
      "Epoch: 8 / 10, Batch: 161 (5184 / 12512), Elapsed time: 62.98 mins\n",
      "Enc Loss = 136.42, KL Divergence = 1186.03, Reconstruction Loss = 325.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.00 mins\n",
      "Epoch: 8 / 10, Batch: 162 (5216 / 12512), Elapsed time: 63.00 mins\n",
      "Enc Loss = 126.88, KL Divergence = 1076.51, Reconstruction Loss = 305.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.02 mins\n",
      "Epoch: 8 / 10, Batch: 163 (5248 / 12512), Elapsed time: 63.02 mins\n",
      "Enc Loss = 143.99, KL Divergence = 1245.92, Reconstruction Loss = 344.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.04 mins\n",
      "Epoch: 8 / 10, Batch: 164 (5280 / 12512), Elapsed time: 63.04 mins\n",
      "Enc Loss = 158.75, KL Divergence = 1329.93, Reconstruction Loss = 384.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.06 mins\n",
      "Epoch: 8 / 10, Batch: 165 (5312 / 12512), Elapsed time: 63.06 mins\n",
      "Enc Loss = 134.26, KL Divergence = 1100.22, Reconstruction Loss = 327.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.08 mins\n",
      "Epoch: 8 / 10, Batch: 166 (5344 / 12512), Elapsed time: 63.08 mins\n",
      "Enc Loss = 132.87, KL Divergence = 1116.88, Reconstruction Loss = 321.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.10 mins\n",
      "Epoch: 8 / 10, Batch: 167 (5376 / 12512), Elapsed time: 63.10 mins\n",
      "Enc Loss = 123.37, KL Divergence = 977.17, Reconstruction Loss = 304.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.12 mins\n",
      "Epoch: 8 / 10, Batch: 168 (5408 / 12512), Elapsed time: 63.12 mins\n",
      "Enc Loss = 155.21, KL Divergence = 1260.10, Reconstruction Loss = 379.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.14 mins\n",
      "Epoch: 8 / 10, Batch: 169 (5440 / 12512), Elapsed time: 63.14 mins\n",
      "Enc Loss = 127.74, KL Divergence = 1030.98, Reconstruction Loss = 312.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.16 mins\n",
      "Epoch: 8 / 10, Batch: 170 (5472 / 12512), Elapsed time: 63.16 mins\n",
      "Enc Loss = 134.87, KL Divergence = 1050.54, Reconstruction Loss = 334.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.18 mins\n",
      "Epoch: 8 / 10, Batch: 171 (5504 / 12512), Elapsed time: 63.18 mins\n",
      "Enc Loss = 162.32, KL Divergence = 1113.66, Reconstruction Loss = 417.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.20 mins\n",
      "Epoch: 8 / 10, Batch: 172 (5536 / 12512), Elapsed time: 63.20 mins\n",
      "Enc Loss = 151.84, KL Divergence = 1229.35, Reconstruction Loss = 371.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.22 mins\n",
      "Epoch: 8 / 10, Batch: 173 (5568 / 12512), Elapsed time: 63.22 mins\n",
      "Enc Loss = 139.45, KL Divergence = 1096.25, Reconstruction Loss = 344.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.24 mins\n",
      "Epoch: 8 / 10, Batch: 174 (5600 / 12512), Elapsed time: 63.24 mins\n",
      "Enc Loss = 151.80, KL Divergence = 1157.46, Reconstruction Loss = 378.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.26 mins\n",
      "Epoch: 8 / 10, Batch: 175 (5632 / 12512), Elapsed time: 63.26 mins\n",
      "Enc Loss = 132.58, KL Divergence = 1047.20, Reconstruction Loss = 327.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.28 mins\n",
      "Epoch: 8 / 10, Batch: 176 (5664 / 12512), Elapsed time: 63.28 mins\n",
      "Enc Loss = 142.26, KL Divergence = 1174.70, Reconstruction Loss = 345.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.30 mins\n",
      "Epoch: 8 / 10, Batch: 177 (5696 / 12512), Elapsed time: 63.30 mins\n",
      "Enc Loss = 138.20, KL Divergence = 1087.37, Reconstruction Loss = 341.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.32 mins\n",
      "Epoch: 8 / 10, Batch: 178 (5728 / 12512), Elapsed time: 63.32 mins\n",
      "Enc Loss = 136.05, KL Divergence = 1116.28, Reconstruction Loss = 331.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.34 mins\n",
      "Epoch: 8 / 10, Batch: 179 (5760 / 12512), Elapsed time: 63.34 mins\n",
      "Enc Loss = 136.55, KL Divergence = 1055.53, Reconstruction Loss = 339.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.36 mins\n",
      "Epoch: 8 / 10, Batch: 180 (5792 / 12512), Elapsed time: 63.36 mins\n",
      "Enc Loss = 147.59, KL Divergence = 1115.52, Reconstruction Loss = 369.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.38 mins\n",
      "Epoch: 8 / 10, Batch: 181 (5824 / 12512), Elapsed time: 63.38 mins\n",
      "Enc Loss = 132.29, KL Divergence = 1097.34, Reconstruction Loss = 321.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.40 mins\n",
      "Epoch: 8 / 10, Batch: 182 (5856 / 12512), Elapsed time: 63.40 mins\n",
      "Enc Loss = 131.86, KL Divergence = 1100.79, Reconstruction Loss = 319.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.42 mins\n",
      "Epoch: 8 / 10, Batch: 183 (5888 / 12512), Elapsed time: 63.42 mins\n",
      "Enc Loss = 123.03, KL Divergence = 978.09, Reconstruction Loss = 302.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.44 mins\n",
      "Epoch: 8 / 10, Batch: 184 (5920 / 12512), Elapsed time: 63.44 mins\n",
      "Enc Loss = 161.16, KL Divergence = 1320.21, Reconstruction Loss = 392.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.45 mins\n",
      "Epoch: 8 / 10, Batch: 185 (5952 / 12512), Elapsed time: 63.46 mins\n",
      "Enc Loss = 128.32, KL Divergence = 1060.43, Reconstruction Loss = 311.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.47 mins\n",
      "Epoch: 8 / 10, Batch: 186 (5984 / 12512), Elapsed time: 63.48 mins\n",
      "Enc Loss = 132.72, KL Divergence = 1095.40, Reconstruction Loss = 322.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.49 mins\n",
      "Epoch: 8 / 10, Batch: 187 (6016 / 12512), Elapsed time: 63.49 mins\n",
      "Enc Loss = 146.01, KL Divergence = 1276.80, Reconstruction Loss = 347.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.51 mins\n",
      "Epoch: 8 / 10, Batch: 188 (6048 / 12512), Elapsed time: 63.51 mins\n",
      "Enc Loss = 129.90, KL Divergence = 1072.27, Reconstruction Loss = 315.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.53 mins\n",
      "Epoch: 8 / 10, Batch: 189 (6080 / 12512), Elapsed time: 63.53 mins\n",
      "Enc Loss = 129.44, KL Divergence = 1071.83, Reconstruction Loss = 314.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.55 mins\n",
      "Epoch: 8 / 10, Batch: 190 (6112 / 12512), Elapsed time: 63.55 mins\n",
      "Enc Loss = 139.07, KL Divergence = 1043.12, Reconstruction Loss = 348.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.57 mins\n",
      "Epoch: 8 / 10, Batch: 191 (6144 / 12512), Elapsed time: 63.57 mins\n",
      "Enc Loss = 135.53, KL Divergence = 1122.67, Reconstruction Loss = 329.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.59 mins\n",
      "Epoch: 8 / 10, Batch: 192 (6176 / 12512), Elapsed time: 63.59 mins\n",
      "Enc Loss = 135.63, KL Divergence = 1172.34, Reconstruction Loss = 324.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.61 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 193 (6208 / 12512), Elapsed time: 63.61 mins\n",
      "Enc Loss = 136.54, KL Divergence = 1149.79, Reconstruction Loss = 329.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.63 mins\n",
      "Epoch: 8 / 10, Batch: 194 (6240 / 12512), Elapsed time: 63.63 mins\n",
      "Enc Loss = 146.01, KL Divergence = 1209.35, Reconstruction Loss = 354.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.65 mins\n",
      "Epoch: 8 / 10, Batch: 195 (6272 / 12512), Elapsed time: 63.65 mins\n",
      "Enc Loss = 134.13, KL Divergence = 1088.30, Reconstruction Loss = 328.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.67 mins\n",
      "Epoch: 8 / 10, Batch: 196 (6304 / 12512), Elapsed time: 63.67 mins\n",
      "Enc Loss = 140.65, KL Divergence = 1119.68, Reconstruction Loss = 346.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.69 mins\n",
      "Epoch: 8 / 10, Batch: 197 (6336 / 12512), Elapsed time: 63.69 mins\n",
      "Enc Loss = 137.71, KL Divergence = 1101.51, Reconstruction Loss = 338.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.71 mins\n",
      "Epoch: 8 / 10, Batch: 198 (6368 / 12512), Elapsed time: 63.71 mins\n",
      "Enc Loss = 135.43, KL Divergence = 1154.06, Reconstruction Loss = 325.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.73 mins\n",
      "Epoch: 8 / 10, Batch: 199 (6400 / 12512), Elapsed time: 63.73 mins\n",
      "Enc Loss = 149.81, KL Divergence = 1248.13, Reconstruction Loss = 363.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.75 mins\n",
      "Epoch: 8 / 10, Batch: 200 (6432 / 12512), Elapsed time: 63.75 mins\n",
      "Enc Loss = 130.15, KL Divergence = 1110.54, Reconstruction Loss = 312.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.77 mins\n",
      "Epoch: 8 / 10, Batch: 201 (6464 / 12512), Elapsed time: 63.77 mins\n",
      "Enc Loss = 141.50, KL Divergence = 1202.47, Reconstruction Loss = 340.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.79 mins\n",
      "Epoch: 8 / 10, Batch: 202 (6496 / 12512), Elapsed time: 63.79 mins\n",
      "Enc Loss = 128.65, KL Divergence = 1053.90, Reconstruction Loss = 313.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.81 mins\n",
      "Epoch: 8 / 10, Batch: 203 (6528 / 12512), Elapsed time: 63.81 mins\n",
      "Enc Loss = 128.81, KL Divergence = 1051.50, Reconstruction Loss = 314.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.83 mins\n",
      "Epoch: 8 / 10, Batch: 204 (6560 / 12512), Elapsed time: 63.83 mins\n",
      "Enc Loss = 123.33, KL Divergence = 907.89, Reconstruction Loss = 311.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.85 mins\n",
      "Epoch: 8 / 10, Batch: 205 (6592 / 12512), Elapsed time: 63.85 mins\n",
      "Enc Loss = 136.39, KL Divergence = 1080.76, Reconstruction Loss = 336.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.87 mins\n",
      "Epoch: 8 / 10, Batch: 206 (6624 / 12512), Elapsed time: 63.87 mins\n",
      "Enc Loss = 144.83, KL Divergence = 1178.12, Reconstruction Loss = 353.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.89 mins\n",
      "Epoch: 8 / 10, Batch: 207 (6656 / 12512), Elapsed time: 63.89 mins\n",
      "Enc Loss = 149.17, KL Divergence = 1106.91, Reconstruction Loss = 375.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.91 mins\n",
      "Epoch: 8 / 10, Batch: 208 (6688 / 12512), Elapsed time: 63.91 mins\n",
      "Enc Loss = 136.68, KL Divergence = 1054.33, Reconstruction Loss = 339.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.93 mins\n",
      "Epoch: 8 / 10, Batch: 209 (6720 / 12512), Elapsed time: 63.93 mins\n",
      "Enc Loss = 139.47, KL Divergence = 1140.86, Reconstruction Loss = 340.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.95 mins\n",
      "Epoch: 8 / 10, Batch: 210 (6752 / 12512), Elapsed time: 63.95 mins\n",
      "Enc Loss = 133.32, KL Divergence = 1060.54, Reconstruction Loss = 328.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.97 mins\n",
      "Epoch: 8 / 10, Batch: 211 (6784 / 12512), Elapsed time: 63.97 mins\n",
      "Enc Loss = 127.79, KL Divergence = 1020.30, Reconstruction Loss = 314.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 63.99 mins\n",
      "Epoch: 8 / 10, Batch: 212 (6816 / 12512), Elapsed time: 63.99 mins\n",
      "Enc Loss = 132.78, KL Divergence = 1087.69, Reconstruction Loss = 323.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.01 mins\n",
      "Epoch: 8 / 10, Batch: 213 (6848 / 12512), Elapsed time: 64.01 mins\n",
      "Enc Loss = 145.71, KL Divergence = 1171.10, Reconstruction Loss = 357.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.03 mins\n",
      "Epoch: 8 / 10, Batch: 214 (6880 / 12512), Elapsed time: 64.03 mins\n",
      "Enc Loss = 139.38, KL Divergence = 1090.80, Reconstruction Loss = 345.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.05 mins\n",
      "Epoch: 8 / 10, Batch: 215 (6912 / 12512), Elapsed time: 64.05 mins\n",
      "Enc Loss = 131.06, KL Divergence = 1077.81, Reconstruction Loss = 319.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.07 mins\n",
      "Epoch: 8 / 10, Batch: 216 (6944 / 12512), Elapsed time: 64.07 mins\n",
      "Enc Loss = 131.42, KL Divergence = 1094.90, Reconstruction Loss = 318.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.09 mins\n",
      "Epoch: 8 / 10, Batch: 217 (6976 / 12512), Elapsed time: 64.09 mins\n",
      "Enc Loss = 128.52, KL Divergence = 1117.76, Reconstruction Loss = 306.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.11 mins\n",
      "Epoch: 8 / 10, Batch: 218 (7008 / 12512), Elapsed time: 64.11 mins\n",
      "Enc Loss = 151.88, KL Divergence = 1273.80, Reconstruction Loss = 367.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.13 mins\n",
      "Epoch: 8 / 10, Batch: 219 (7040 / 12512), Elapsed time: 64.13 mins\n",
      "Enc Loss = 131.62, KL Divergence = 1209.26, Reconstruction Loss = 307.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.15 mins\n",
      "Epoch: 8 / 10, Batch: 220 (7072 / 12512), Elapsed time: 64.15 mins\n",
      "Enc Loss = 137.90, KL Divergence = 1154.90, Reconstruction Loss = 333.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.17 mins\n",
      "Epoch: 8 / 10, Batch: 221 (7104 / 12512), Elapsed time: 64.17 mins\n",
      "Enc Loss = 135.70, KL Divergence = 1116.61, Reconstruction Loss = 330.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.19 mins\n",
      "Epoch: 8 / 10, Batch: 222 (7136 / 12512), Elapsed time: 64.19 mins\n",
      "Enc Loss = 134.00, KL Divergence = 1125.50, Reconstruction Loss = 323.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.21 mins\n",
      "Epoch: 8 / 10, Batch: 223 (7168 / 12512), Elapsed time: 64.21 mins\n",
      "Enc Loss = 131.28, KL Divergence = 1061.08, Reconstruction Loss = 321.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.23 mins\n",
      "Epoch: 8 / 10, Batch: 224 (7200 / 12512), Elapsed time: 64.23 mins\n",
      "Enc Loss = 142.19, KL Divergence = 1020.98, Reconstruction Loss = 361.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.25 mins\n",
      "Epoch: 8 / 10, Batch: 225 (7232 / 12512), Elapsed time: 64.25 mins\n",
      "Enc Loss = 145.10, KL Divergence = 1110.22, Reconstruction Loss = 361.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.27 mins\n",
      "Epoch: 8 / 10, Batch: 226 (7264 / 12512), Elapsed time: 64.27 mins\n",
      "Enc Loss = 147.24, KL Divergence = 1192.47, Reconstruction Loss = 360.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.29 mins\n",
      "Epoch: 8 / 10, Batch: 227 (7296 / 12512), Elapsed time: 64.29 mins\n",
      "Enc Loss = 122.34, KL Divergence = 985.25, Reconstruction Loss = 300.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.31 mins\n",
      "Epoch: 8 / 10, Batch: 228 (7328 / 12512), Elapsed time: 64.31 mins\n",
      "Enc Loss = 128.36, KL Divergence = 1115.19, Reconstruction Loss = 306.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.33 mins\n",
      "Epoch: 8 / 10, Batch: 229 (7360 / 12512), Elapsed time: 64.33 mins\n",
      "Enc Loss = 134.36, KL Divergence = 1096.83, Reconstruction Loss = 327.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.35 mins\n",
      "Epoch: 8 / 10, Batch: 230 (7392 / 12512), Elapsed time: 64.35 mins\n",
      "Enc Loss = 146.53, KL Divergence = 1168.81, Reconstruction Loss = 360.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.37 mins\n",
      "Epoch: 8 / 10, Batch: 231 (7424 / 12512), Elapsed time: 64.37 mins\n",
      "Enc Loss = 132.96, KL Divergence = 1091.33, Reconstruction Loss = 323.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.39 mins\n",
      "Epoch: 8 / 10, Batch: 232 (7456 / 12512), Elapsed time: 64.39 mins\n",
      "Enc Loss = 132.54, KL Divergence = 1089.39, Reconstruction Loss = 322.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.41 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 233 (7488 / 12512), Elapsed time: 64.41 mins\n",
      "Enc Loss = 134.27, KL Divergence = 1057.82, Reconstruction Loss = 331.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.43 mins\n",
      "Epoch: 8 / 10, Batch: 234 (7520 / 12512), Elapsed time: 64.43 mins\n",
      "Enc Loss = 128.49, KL Divergence = 1044.00, Reconstruction Loss = 314.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.45 mins\n",
      "Epoch: 8 / 10, Batch: 235 (7552 / 12512), Elapsed time: 64.45 mins\n",
      "Enc Loss = 128.77, KL Divergence = 1066.28, Reconstruction Loss = 312.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.47 mins\n",
      "Epoch: 8 / 10, Batch: 236 (7584 / 12512), Elapsed time: 64.47 mins\n",
      "Enc Loss = 135.13, KL Divergence = 1148.34, Reconstruction Loss = 325.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.49 mins\n",
      "Epoch: 8 / 10, Batch: 237 (7616 / 12512), Elapsed time: 64.49 mins\n",
      "Enc Loss = 131.23, KL Divergence = 1039.14, Reconstruction Loss = 323.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.51 mins\n",
      "Epoch: 8 / 10, Batch: 238 (7648 / 12512), Elapsed time: 64.51 mins\n",
      "Enc Loss = 146.22, KL Divergence = 1049.90, Reconstruction Loss = 371.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.53 mins\n",
      "Epoch: 8 / 10, Batch: 239 (7680 / 12512), Elapsed time: 64.53 mins\n",
      "Enc Loss = 143.44, KL Divergence = 1132.93, Reconstruction Loss = 354.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.54 mins\n",
      "Epoch: 8 / 10, Batch: 240 (7712 / 12512), Elapsed time: 64.55 mins\n",
      "Enc Loss = 138.08, KL Divergence = 1210.29, Reconstruction Loss = 328.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.56 mins\n",
      "Epoch: 8 / 10, Batch: 241 (7744 / 12512), Elapsed time: 64.56 mins\n",
      "Enc Loss = 138.12, KL Divergence = 1081.39, Reconstruction Loss = 341.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.58 mins\n",
      "Epoch: 8 / 10, Batch: 242 (7776 / 12512), Elapsed time: 64.58 mins\n",
      "Enc Loss = 153.99, KL Divergence = 1203.52, Reconstruction Loss = 381.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.60 mins\n",
      "Epoch: 8 / 10, Batch: 243 (7808 / 12512), Elapsed time: 64.60 mins\n",
      "Enc Loss = 145.81, KL Divergence = 1310.20, Reconstruction Loss = 343.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.62 mins\n",
      "Epoch: 8 / 10, Batch: 244 (7840 / 12512), Elapsed time: 64.62 mins\n",
      "Enc Loss = 132.80, KL Divergence = 1110.65, Reconstruction Loss = 321.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.64 mins\n",
      "Epoch: 8 / 10, Batch: 245 (7872 / 12512), Elapsed time: 64.64 mins\n",
      "Enc Loss = 130.90, KL Divergence = 1098.03, Reconstruction Loss = 316.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.66 mins\n",
      "Epoch: 8 / 10, Batch: 246 (7904 / 12512), Elapsed time: 64.66 mins\n",
      "Enc Loss = 136.59, KL Divergence = 1184.78, Reconstruction Loss = 326.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.68 mins\n",
      "Epoch: 8 / 10, Batch: 247 (7936 / 12512), Elapsed time: 64.68 mins\n",
      "Enc Loss = 125.28, KL Divergence = 1026.27, Reconstruction Loss = 305.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.70 mins\n",
      "Epoch: 8 / 10, Batch: 248 (7968 / 12512), Elapsed time: 64.70 mins\n",
      "Enc Loss = 139.49, KL Divergence = 1203.66, Reconstruction Loss = 333.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.72 mins\n",
      "Epoch: 8 / 10, Batch: 249 (8000 / 12512), Elapsed time: 64.72 mins\n",
      "Enc Loss = 142.77, KL Divergence = 1268.65, Reconstruction Loss = 337.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.74 mins\n",
      "Epoch: 8 / 10, Batch: 250 (8032 / 12512), Elapsed time: 64.75 mins\n",
      "Enc Loss = 134.92, KL Divergence = 1168.02, Reconstruction Loss = 322.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.77 mins\n",
      "Epoch: 8 / 10, Batch: 251 (8064 / 12512), Elapsed time: 64.77 mins\n",
      "Enc Loss = 125.22, KL Divergence = 1095.55, Reconstruction Loss = 298.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.79 mins\n",
      "Epoch: 8 / 10, Batch: 252 (8096 / 12512), Elapsed time: 64.79 mins\n",
      "Enc Loss = 143.47, KL Divergence = 1110.41, Reconstruction Loss = 356.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.81 mins\n",
      "Epoch: 8 / 10, Batch: 253 (8128 / 12512), Elapsed time: 64.81 mins\n",
      "Enc Loss = 136.56, KL Divergence = 1095.30, Reconstruction Loss = 335.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.83 mins\n",
      "Epoch: 8 / 10, Batch: 254 (8160 / 12512), Elapsed time: 64.83 mins\n",
      "Enc Loss = 137.49, KL Divergence = 1037.80, Reconstruction Loss = 344.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.85 mins\n",
      "Epoch: 8 / 10, Batch: 255 (8192 / 12512), Elapsed time: 64.85 mins\n",
      "Enc Loss = 140.13, KL Divergence = 1099.95, Reconstruction Loss = 346.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.87 mins\n",
      "Epoch: 8 / 10, Batch: 256 (8224 / 12512), Elapsed time: 64.87 mins\n",
      "Enc Loss = 137.29, KL Divergence = 1235.51, Reconstruction Loss = 323.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.89 mins\n",
      "Epoch: 8 / 10, Batch: 257 (8256 / 12512), Elapsed time: 64.89 mins\n",
      "Enc Loss = 143.49, KL Divergence = 1169.83, Reconstruction Loss = 350.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.91 mins\n",
      "Epoch: 8 / 10, Batch: 258 (8288 / 12512), Elapsed time: 64.91 mins\n",
      "Enc Loss = 134.33, KL Divergence = 1100.39, Reconstruction Loss = 327.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.93 mins\n",
      "Epoch: 8 / 10, Batch: 259 (8320 / 12512), Elapsed time: 64.93 mins\n",
      "Enc Loss = 131.30, KL Divergence = 1031.74, Reconstruction Loss = 324.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.95 mins\n",
      "Epoch: 8 / 10, Batch: 260 (8352 / 12512), Elapsed time: 64.95 mins\n",
      "Enc Loss = 145.21, KL Divergence = 1279.04, Reconstruction Loss = 344.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.97 mins\n",
      "Epoch: 8 / 10, Batch: 261 (8384 / 12512), Elapsed time: 64.97 mins\n",
      "Enc Loss = 137.57, KL Divergence = 1031.11, Reconstruction Loss = 345.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 64.99 mins\n",
      "Epoch: 8 / 10, Batch: 262 (8416 / 12512), Elapsed time: 64.99 mins\n",
      "Enc Loss = 155.60, KL Divergence = 1222.21, Reconstruction Loss = 384.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.01 mins\n",
      "Epoch: 8 / 10, Batch: 263 (8448 / 12512), Elapsed time: 65.01 mins\n",
      "Enc Loss = 129.97, KL Divergence = 1102.40, Reconstruction Loss = 312.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.03 mins\n",
      "Epoch: 8 / 10, Batch: 264 (8480 / 12512), Elapsed time: 65.03 mins\n",
      "Enc Loss = 138.98, KL Divergence = 1112.15, Reconstruction Loss = 341.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.05 mins\n",
      "Epoch: 8 / 10, Batch: 265 (8512 / 12512), Elapsed time: 65.05 mins\n",
      "Enc Loss = 136.57, KL Divergence = 1160.85, Reconstruction Loss = 328.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.07 mins\n",
      "Epoch: 8 / 10, Batch: 266 (8544 / 12512), Elapsed time: 65.07 mins\n",
      "Enc Loss = 136.22, KL Divergence = 1060.57, Reconstruction Loss = 337.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.09 mins\n",
      "Epoch: 8 / 10, Batch: 267 (8576 / 12512), Elapsed time: 65.09 mins\n",
      "Enc Loss = 138.12, KL Divergence = 1086.32, Reconstruction Loss = 341.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.11 mins\n",
      "Epoch: 8 / 10, Batch: 268 (8608 / 12512), Elapsed time: 65.11 mins\n",
      "Enc Loss = 136.48, KL Divergence = 1163.86, Reconstruction Loss = 328.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.12 mins\n",
      "Epoch: 8 / 10, Batch: 269 (8640 / 12512), Elapsed time: 65.13 mins\n",
      "Enc Loss = 144.23, KL Divergence = 1085.04, Reconstruction Loss = 361.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.14 mins\n",
      "Epoch: 8 / 10, Batch: 270 (8672 / 12512), Elapsed time: 65.15 mins\n",
      "Enc Loss = 139.25, KL Divergence = 1185.53, Reconstruction Loss = 334.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.16 mins\n",
      "Epoch: 8 / 10, Batch: 271 (8704 / 12512), Elapsed time: 65.17 mins\n",
      "Enc Loss = 138.33, KL Divergence = 1143.04, Reconstruction Loss = 336.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.18 mins\n",
      "Epoch: 8 / 10, Batch: 272 (8736 / 12512), Elapsed time: 65.19 mins\n",
      "Enc Loss = 157.44, KL Divergence = 1223.32, Reconstruction Loss = 390.62, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.20 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 273 (8768 / 12512), Elapsed time: 65.20 mins\n",
      "Enc Loss = 149.43, KL Divergence = 1218.01, Reconstruction Loss = 364.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.22 mins\n",
      "Epoch: 8 / 10, Batch: 274 (8800 / 12512), Elapsed time: 65.22 mins\n",
      "Enc Loss = 139.16, KL Divergence = 1114.75, Reconstruction Loss = 341.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.24 mins\n",
      "Epoch: 8 / 10, Batch: 275 (8832 / 12512), Elapsed time: 65.24 mins\n",
      "Enc Loss = 141.11, KL Divergence = 1206.38, Reconstruction Loss = 338.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.26 mins\n",
      "Epoch: 8 / 10, Batch: 276 (8864 / 12512), Elapsed time: 65.26 mins\n",
      "Enc Loss = 145.12, KL Divergence = 1319.63, Reconstruction Loss = 340.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.28 mins\n",
      "Epoch: 8 / 10, Batch: 277 (8896 / 12512), Elapsed time: 65.28 mins\n",
      "Enc Loss = 134.93, KL Divergence = 1230.67, Reconstruction Loss = 316.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.30 mins\n",
      "Epoch: 8 / 10, Batch: 278 (8928 / 12512), Elapsed time: 65.31 mins\n",
      "Enc Loss = 131.47, KL Divergence = 1243.10, Reconstruction Loss = 303.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.32 mins\n",
      "Epoch: 8 / 10, Batch: 279 (8960 / 12512), Elapsed time: 65.33 mins\n",
      "Enc Loss = 145.93, KL Divergence = 1338.85, Reconstruction Loss = 341.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.35 mins\n",
      "Epoch: 8 / 10, Batch: 280 (8992 / 12512), Elapsed time: 65.35 mins\n",
      "Enc Loss = 155.28, KL Divergence = 1280.39, Reconstruction Loss = 377.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.37 mins\n",
      "Epoch: 8 / 10, Batch: 281 (9024 / 12512), Elapsed time: 65.37 mins\n",
      "Enc Loss = 145.60, KL Divergence = 1207.90, Reconstruction Loss = 353.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.39 mins\n",
      "Epoch: 8 / 10, Batch: 282 (9056 / 12512), Elapsed time: 65.39 mins\n",
      "Enc Loss = 140.97, KL Divergence = 1166.01, Reconstruction Loss = 342.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.41 mins\n",
      "Epoch: 8 / 10, Batch: 283 (9088 / 12512), Elapsed time: 65.41 mins\n",
      "Enc Loss = 129.24, KL Divergence = 1138.36, Reconstruction Loss = 306.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.43 mins\n",
      "Epoch: 8 / 10, Batch: 284 (9120 / 12512), Elapsed time: 65.43 mins\n",
      "Enc Loss = 148.51, KL Divergence = 1260.65, Reconstruction Loss = 357.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.45 mins\n",
      "Epoch: 8 / 10, Batch: 285 (9152 / 12512), Elapsed time: 65.45 mins\n",
      "Enc Loss = 134.84, KL Divergence = 1109.42, Reconstruction Loss = 328.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.47 mins\n",
      "Epoch: 8 / 10, Batch: 286 (9184 / 12512), Elapsed time: 65.47 mins\n",
      "Enc Loss = 139.45, KL Divergence = 1202.79, Reconstruction Loss = 333.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.49 mins\n",
      "Epoch: 8 / 10, Batch: 287 (9216 / 12512), Elapsed time: 65.49 mins\n",
      "Enc Loss = 130.32, KL Divergence = 1067.89, Reconstruction Loss = 317.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.51 mins\n",
      "Epoch: 8 / 10, Batch: 288 (9248 / 12512), Elapsed time: 65.51 mins\n",
      "Enc Loss = 127.74, KL Divergence = 1030.32, Reconstruction Loss = 313.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.53 mins\n",
      "Epoch: 8 / 10, Batch: 289 (9280 / 12512), Elapsed time: 65.53 mins\n",
      "Enc Loss = 140.91, KL Divergence = 1107.93, Reconstruction Loss = 348.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.55 mins\n",
      "Epoch: 8 / 10, Batch: 290 (9312 / 12512), Elapsed time: 65.55 mins\n",
      "Enc Loss = 122.08, KL Divergence = 984.48, Reconstruction Loss = 299.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.57 mins\n",
      "Epoch: 8 / 10, Batch: 291 (9344 / 12512), Elapsed time: 65.57 mins\n",
      "Enc Loss = 139.57, KL Divergence = 1121.31, Reconstruction Loss = 342.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.59 mins\n",
      "Epoch: 8 / 10, Batch: 292 (9376 / 12512), Elapsed time: 65.59 mins\n",
      "Enc Loss = 139.00, KL Divergence = 1155.75, Reconstruction Loss = 337.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.61 mins\n",
      "Epoch: 8 / 10, Batch: 293 (9408 / 12512), Elapsed time: 65.61 mins\n",
      "Enc Loss = 124.84, KL Divergence = 1062.82, Reconstruction Loss = 300.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.63 mins\n",
      "Epoch: 8 / 10, Batch: 294 (9440 / 12512), Elapsed time: 65.63 mins\n",
      "Enc Loss = 137.59, KL Divergence = 1165.08, Reconstruction Loss = 331.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.65 mins\n",
      "Epoch: 8 / 10, Batch: 295 (9472 / 12512), Elapsed time: 65.65 mins\n",
      "Enc Loss = 136.58, KL Divergence = 1113.33, Reconstruction Loss = 333.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.67 mins\n",
      "Epoch: 8 / 10, Batch: 296 (9504 / 12512), Elapsed time: 65.67 mins\n",
      "Enc Loss = 133.65, KL Divergence = 1114.24, Reconstruction Loss = 323.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.69 mins\n",
      "Epoch: 8 / 10, Batch: 297 (9536 / 12512), Elapsed time: 65.69 mins\n",
      "Enc Loss = 158.73, KL Divergence = 1216.28, Reconstruction Loss = 395.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.71 mins\n",
      "Epoch: 8 / 10, Batch: 298 (9568 / 12512), Elapsed time: 65.71 mins\n",
      "Enc Loss = 141.00, KL Divergence = 1063.27, Reconstruction Loss = 353.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.73 mins\n",
      "Epoch: 8 / 10, Batch: 299 (9600 / 12512), Elapsed time: 65.73 mins\n",
      "Enc Loss = 147.73, KL Divergence = 1232.94, Reconstruction Loss = 357.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.75 mins\n",
      "Epoch: 8 / 10, Batch: 300 (9632 / 12512), Elapsed time: 65.75 mins\n",
      "Enc Loss = 134.69, KL Divergence = 1154.71, Reconstruction Loss = 323.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.77 mins\n",
      "Epoch: 8 / 10, Batch: 301 (9664 / 12512), Elapsed time: 65.77 mins\n",
      "Enc Loss = 141.19, KL Divergence = 1297.86, Reconstruction Loss = 329.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.79 mins\n",
      "Epoch: 8 / 10, Batch: 302 (9696 / 12512), Elapsed time: 65.79 mins\n",
      "Enc Loss = 148.29, KL Divergence = 1300.34, Reconstruction Loss = 352.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.81 mins\n",
      "Epoch: 8 / 10, Batch: 303 (9728 / 12512), Elapsed time: 65.81 mins\n",
      "Enc Loss = 138.11, KL Divergence = 1240.91, Reconstruction Loss = 325.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.83 mins\n",
      "Epoch: 8 / 10, Batch: 304 (9760 / 12512), Elapsed time: 65.83 mins\n",
      "Enc Loss = 134.94, KL Divergence = 1161.58, Reconstruction Loss = 323.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.85 mins\n",
      "Epoch: 8 / 10, Batch: 305 (9792 / 12512), Elapsed time: 65.85 mins\n",
      "Enc Loss = 138.44, KL Divergence = 1113.18, Reconstruction Loss = 339.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.87 mins\n",
      "Epoch: 8 / 10, Batch: 306 (9824 / 12512), Elapsed time: 65.87 mins\n",
      "Enc Loss = 138.38, KL Divergence = 1121.51, Reconstruction Loss = 338.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.89 mins\n",
      "Epoch: 8 / 10, Batch: 307 (9856 / 12512), Elapsed time: 65.89 mins\n",
      "Enc Loss = 138.11, KL Divergence = 1115.84, Reconstruction Loss = 338.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.91 mins\n",
      "Epoch: 8 / 10, Batch: 308 (9888 / 12512), Elapsed time: 65.91 mins\n",
      "Enc Loss = 127.46, KL Divergence = 1095.49, Reconstruction Loss = 305.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.93 mins\n",
      "Epoch: 8 / 10, Batch: 309 (9920 / 12512), Elapsed time: 65.93 mins\n",
      "Enc Loss = 145.36, KL Divergence = 1165.36, Reconstruction Loss = 356.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.95 mins\n",
      "Epoch: 8 / 10, Batch: 310 (9952 / 12512), Elapsed time: 65.95 mins\n",
      "Enc Loss = 134.09, KL Divergence = 1068.32, Reconstruction Loss = 330.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.97 mins\n",
      "Epoch: 8 / 10, Batch: 311 (9984 / 12512), Elapsed time: 65.97 mins\n",
      "Enc Loss = 140.69, KL Divergence = 1042.30, Reconstruction Loss = 354.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 65.99 mins\n",
      "Epoch: 8 / 10, Batch: 312 (10016 / 12512), Elapsed time: 65.99 mins\n",
      "Enc Loss = 123.98, KL Divergence = 1008.43, Reconstruction Loss = 302.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.01 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 313 (10048 / 12512), Elapsed time: 66.01 mins\n",
      "Enc Loss = 128.03, KL Divergence = 1043.73, Reconstruction Loss = 312.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.03 mins\n",
      "Epoch: 8 / 10, Batch: 314 (10080 / 12512), Elapsed time: 66.03 mins\n",
      "Enc Loss = 136.30, KL Divergence = 1097.61, Reconstruction Loss = 334.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.05 mins\n",
      "Epoch: 8 / 10, Batch: 315 (10112 / 12512), Elapsed time: 66.05 mins\n",
      "Enc Loss = 147.23, KL Divergence = 1186.33, Reconstruction Loss = 360.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.07 mins\n",
      "Epoch: 8 / 10, Batch: 316 (10144 / 12512), Elapsed time: 66.07 mins\n",
      "Enc Loss = 135.15, KL Divergence = 1036.50, Reconstruction Loss = 336.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.08 mins\n",
      "Epoch: 8 / 10, Batch: 317 (10176 / 12512), Elapsed time: 66.09 mins\n",
      "Enc Loss = 134.68, KL Divergence = 1154.73, Reconstruction Loss = 323.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.10 mins\n",
      "Epoch: 8 / 10, Batch: 318 (10208 / 12512), Elapsed time: 66.11 mins\n",
      "Enc Loss = 135.66, KL Divergence = 1120.32, Reconstruction Loss = 329.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.12 mins\n",
      "Epoch: 8 / 10, Batch: 319 (10240 / 12512), Elapsed time: 66.13 mins\n",
      "Enc Loss = 127.58, KL Divergence = 1063.23, Reconstruction Loss = 309.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.15 mins\n",
      "Epoch: 8 / 10, Batch: 320 (10272 / 12512), Elapsed time: 66.15 mins\n",
      "Enc Loss = 144.80, KL Divergence = 1254.37, Reconstruction Loss = 346.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.17 mins\n",
      "Epoch: 8 / 10, Batch: 321 (10304 / 12512), Elapsed time: 66.17 mins\n",
      "Enc Loss = 153.24, KL Divergence = 1163.59, Reconstruction Loss = 382.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.18 mins\n",
      "Epoch: 8 / 10, Batch: 322 (10336 / 12512), Elapsed time: 66.19 mins\n",
      "Enc Loss = 148.87, KL Divergence = 1227.08, Reconstruction Loss = 362.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.20 mins\n",
      "Epoch: 8 / 10, Batch: 323 (10368 / 12512), Elapsed time: 66.20 mins\n",
      "Enc Loss = 143.15, KL Divergence = 1195.80, Reconstruction Loss = 346.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.22 mins\n",
      "Epoch: 8 / 10, Batch: 324 (10400 / 12512), Elapsed time: 66.22 mins\n",
      "Enc Loss = 167.11, KL Divergence = 1359.65, Reconstruction Loss = 408.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.24 mins\n",
      "Epoch: 8 / 10, Batch: 325 (10432 / 12512), Elapsed time: 66.24 mins\n",
      "Enc Loss = 138.44, KL Divergence = 1299.49, Reconstruction Loss = 320.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.26 mins\n",
      "Epoch: 8 / 10, Batch: 326 (10464 / 12512), Elapsed time: 66.26 mins\n",
      "Enc Loss = 138.71, KL Divergence = 1193.18, Reconstruction Loss = 332.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.28 mins\n",
      "Epoch: 8 / 10, Batch: 327 (10496 / 12512), Elapsed time: 66.28 mins\n",
      "Enc Loss = 140.23, KL Divergence = 1235.80, Reconstruction Loss = 332.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.30 mins\n",
      "Epoch: 8 / 10, Batch: 328 (10528 / 12512), Elapsed time: 66.30 mins\n",
      "Enc Loss = 151.33, KL Divergence = 1328.55, Reconstruction Loss = 359.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.32 mins\n",
      "Epoch: 8 / 10, Batch: 329 (10560 / 12512), Elapsed time: 66.32 mins\n",
      "Enc Loss = 138.16, KL Divergence = 1184.82, Reconstruction Loss = 331.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.34 mins\n",
      "Epoch: 8 / 10, Batch: 330 (10592 / 12512), Elapsed time: 66.35 mins\n",
      "Enc Loss = 137.04, KL Divergence = 1216.24, Reconstruction Loss = 324.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.37 mins\n",
      "Epoch: 8 / 10, Batch: 331 (10624 / 12512), Elapsed time: 66.37 mins\n",
      "Enc Loss = 132.88, KL Divergence = 1107.04, Reconstruction Loss = 322.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.39 mins\n",
      "Epoch: 8 / 10, Batch: 332 (10656 / 12512), Elapsed time: 66.39 mins\n",
      "Enc Loss = 135.36, KL Divergence = 1077.70, Reconstruction Loss = 333.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.41 mins\n",
      "Epoch: 8 / 10, Batch: 333 (10688 / 12512), Elapsed time: 66.41 mins\n",
      "Enc Loss = 148.91, KL Divergence = 1005.07, Reconstruction Loss = 385.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.43 mins\n",
      "Epoch: 8 / 10, Batch: 334 (10720 / 12512), Elapsed time: 66.43 mins\n",
      "Enc Loss = 157.68, KL Divergence = 1234.08, Reconstruction Loss = 390.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.44 mins\n",
      "Epoch: 8 / 10, Batch: 335 (10752 / 12512), Elapsed time: 66.44 mins\n",
      "Enc Loss = 140.54, KL Divergence = 1138.79, Reconstruction Loss = 343.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.46 mins\n",
      "Epoch: 8 / 10, Batch: 336 (10784 / 12512), Elapsed time: 66.46 mins\n",
      "Enc Loss = 126.04, KL Divergence = 1013.26, Reconstruction Loss = 309.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.48 mins\n",
      "Epoch: 8 / 10, Batch: 337 (10816 / 12512), Elapsed time: 66.48 mins\n",
      "Enc Loss = 130.02, KL Divergence = 1026.45, Reconstruction Loss = 320.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.51 mins\n",
      "Epoch: 8 / 10, Batch: 338 (10848 / 12512), Elapsed time: 66.51 mins\n",
      "Enc Loss = 134.51, KL Divergence = 1107.12, Reconstruction Loss = 327.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.52 mins\n",
      "Epoch: 8 / 10, Batch: 339 (10880 / 12512), Elapsed time: 66.53 mins\n",
      "Enc Loss = 147.96, KL Divergence = 1118.32, Reconstruction Loss = 370.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.55 mins\n",
      "Epoch: 8 / 10, Batch: 340 (10912 / 12512), Elapsed time: 66.55 mins\n",
      "Enc Loss = 126.22, KL Divergence = 1037.70, Reconstruction Loss = 307.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.57 mins\n",
      "Epoch: 8 / 10, Batch: 341 (10944 / 12512), Elapsed time: 66.57 mins\n",
      "Enc Loss = 142.56, KL Divergence = 1214.73, Reconstruction Loss = 342.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.59 mins\n",
      "Epoch: 8 / 10, Batch: 342 (10976 / 12512), Elapsed time: 66.59 mins\n",
      "Enc Loss = 140.70, KL Divergence = 1110.59, Reconstruction Loss = 347.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.60 mins\n",
      "Epoch: 8 / 10, Batch: 343 (11008 / 12512), Elapsed time: 66.61 mins\n",
      "Enc Loss = 144.97, KL Divergence = 1177.15, Reconstruction Loss = 354.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.63 mins\n",
      "Epoch: 8 / 10, Batch: 344 (11040 / 12512), Elapsed time: 66.63 mins\n",
      "Enc Loss = 133.30, KL Divergence = 1059.74, Reconstruction Loss = 328.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.65 mins\n",
      "Epoch: 8 / 10, Batch: 345 (11072 / 12512), Elapsed time: 66.65 mins\n",
      "Enc Loss = 138.50, KL Divergence = 1142.94, Reconstruction Loss = 336.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.66 mins\n",
      "Epoch: 8 / 10, Batch: 346 (11104 / 12512), Elapsed time: 66.66 mins\n",
      "Enc Loss = 139.71, KL Divergence = 1129.64, Reconstruction Loss = 342.12, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.68 mins\n",
      "Epoch: 8 / 10, Batch: 347 (11136 / 12512), Elapsed time: 66.68 mins\n",
      "Enc Loss = 130.20, KL Divergence = 1037.56, Reconstruction Loss = 320.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.70 mins\n",
      "Epoch: 8 / 10, Batch: 348 (11168 / 12512), Elapsed time: 66.70 mins\n",
      "Enc Loss = 167.27, KL Divergence = 1185.27, Reconstruction Loss = 426.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.72 mins\n",
      "Epoch: 8 / 10, Batch: 349 (11200 / 12512), Elapsed time: 66.72 mins\n",
      "Enc Loss = 137.69, KL Divergence = 1095.77, Reconstruction Loss = 338.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.74 mins\n",
      "Epoch: 8 / 10, Batch: 350 (11232 / 12512), Elapsed time: 66.74 mins\n",
      "Enc Loss = 129.20, KL Divergence = 1099.36, Reconstruction Loss = 310.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.76 mins\n",
      "Epoch: 8 / 10, Batch: 351 (11264 / 12512), Elapsed time: 66.76 mins\n",
      "Enc Loss = 133.19, KL Divergence = 1082.54, Reconstruction Loss = 325.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.78 mins\n",
      "Epoch: 8 / 10, Batch: 352 (11296 / 12512), Elapsed time: 66.78 mins\n",
      "Enc Loss = 136.89, KL Divergence = 1131.03, Reconstruction Loss = 332.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.80 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 / 10, Batch: 353 (11328 / 12512), Elapsed time: 66.80 mins\n",
      "Enc Loss = 137.34, KL Divergence = 1181.58, Reconstruction Loss = 329.03, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.82 mins\n",
      "Epoch: 8 / 10, Batch: 354 (11360 / 12512), Elapsed time: 66.82 mins\n",
      "Enc Loss = 139.78, KL Divergence = 1210.03, Reconstruction Loss = 334.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.84 mins\n",
      "Epoch: 8 / 10, Batch: 355 (11392 / 12512), Elapsed time: 66.84 mins\n",
      "Enc Loss = 136.98, KL Divergence = 1233.20, Reconstruction Loss = 322.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.86 mins\n",
      "Epoch: 8 / 10, Batch: 356 (11424 / 12512), Elapsed time: 66.86 mins\n",
      "Enc Loss = 144.34, KL Divergence = 1242.02, Reconstruction Loss = 345.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.88 mins\n",
      "Epoch: 8 / 10, Batch: 357 (11456 / 12512), Elapsed time: 66.88 mins\n",
      "Enc Loss = 155.60, KL Divergence = 1310.94, Reconstruction Loss = 375.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.90 mins\n",
      "Epoch: 8 / 10, Batch: 358 (11488 / 12512), Elapsed time: 66.90 mins\n",
      "Enc Loss = 126.24, KL Divergence = 1033.07, Reconstruction Loss = 307.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.92 mins\n",
      "Epoch: 8 / 10, Batch: 359 (11520 / 12512), Elapsed time: 66.92 mins\n",
      "Enc Loss = 126.97, KL Divergence = 1023.09, Reconstruction Loss = 311.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.94 mins\n",
      "Epoch: 8 / 10, Batch: 360 (11552 / 12512), Elapsed time: 66.94 mins\n",
      "Enc Loss = 139.45, KL Divergence = 1167.13, Reconstruction Loss = 337.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.96 mins\n",
      "Epoch: 8 / 10, Batch: 361 (11584 / 12512), Elapsed time: 66.96 mins\n",
      "Enc Loss = 132.11, KL Divergence = 1058.18, Reconstruction Loss = 324.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 66.98 mins\n",
      "Epoch: 8 / 10, Batch: 362 (11616 / 12512), Elapsed time: 66.98 mins\n",
      "Enc Loss = 133.20, KL Divergence = 1107.56, Reconstruction Loss = 323.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.00 mins\n",
      "Epoch: 8 / 10, Batch: 363 (11648 / 12512), Elapsed time: 67.00 mins\n",
      "Enc Loss = 132.86, KL Divergence = 1124.79, Reconstruction Loss = 320.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.02 mins\n",
      "Epoch: 8 / 10, Batch: 364 (11680 / 12512), Elapsed time: 67.02 mins\n",
      "Enc Loss = 131.14, KL Divergence = 1074.65, Reconstruction Loss = 319.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.04 mins\n",
      "Epoch: 8 / 10, Batch: 365 (11712 / 12512), Elapsed time: 67.04 mins\n",
      "Enc Loss = 140.74, KL Divergence = 1155.80, Reconstruction Loss = 342.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.06 mins\n",
      "Epoch: 8 / 10, Batch: 366 (11744 / 12512), Elapsed time: 67.06 mins\n",
      "Enc Loss = 129.92, KL Divergence = 1088.04, Reconstruction Loss = 314.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.08 mins\n",
      "Epoch: 8 / 10, Batch: 367 (11776 / 12512), Elapsed time: 67.08 mins\n",
      "Enc Loss = 132.87, KL Divergence = 1118.21, Reconstruction Loss = 320.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.10 mins\n",
      "Epoch: 8 / 10, Batch: 368 (11808 / 12512), Elapsed time: 67.10 mins\n",
      "Enc Loss = 154.19, KL Divergence = 1217.83, Reconstruction Loss = 380.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.12 mins\n",
      "Epoch: 8 / 10, Batch: 369 (11840 / 12512), Elapsed time: 67.12 mins\n",
      "Enc Loss = 136.03, KL Divergence = 1135.26, Reconstruction Loss = 329.51, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.14 mins\n",
      "Epoch: 8 / 10, Batch: 370 (11872 / 12512), Elapsed time: 67.14 mins\n",
      "Enc Loss = 139.74, KL Divergence = 1232.94, Reconstruction Loss = 331.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.16 mins\n",
      "Epoch: 8 / 10, Batch: 371 (11904 / 12512), Elapsed time: 67.16 mins\n",
      "Enc Loss = 122.61, KL Divergence = 1108.53, Reconstruction Loss = 288.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.18 mins\n",
      "Epoch: 8 / 10, Batch: 372 (11936 / 12512), Elapsed time: 67.18 mins\n",
      "Enc Loss = 136.65, KL Divergence = 1261.12, Reconstruction Loss = 318.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.20 mins\n",
      "Epoch: 8 / 10, Batch: 373 (11968 / 12512), Elapsed time: 67.20 mins\n",
      "Enc Loss = 140.29, KL Divergence = 1264.49, Reconstruction Loss = 330.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.22 mins\n",
      "Epoch: 8 / 10, Batch: 374 (12000 / 12512), Elapsed time: 67.22 mins\n",
      "Enc Loss = 133.63, KL Divergence = 1187.44, Reconstruction Loss = 316.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.24 mins\n",
      "Epoch: 8 / 10, Batch: 375 (12032 / 12512), Elapsed time: 67.24 mins\n",
      "Enc Loss = 129.84, KL Divergence = 1093.06, Reconstruction Loss = 313.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.26 mins\n",
      "Epoch: 8 / 10, Batch: 376 (12064 / 12512), Elapsed time: 67.26 mins\n",
      "Enc Loss = 128.28, KL Divergence = 1148.59, Reconstruction Loss = 302.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.28 mins\n",
      "Epoch: 8 / 10, Batch: 377 (12096 / 12512), Elapsed time: 67.28 mins\n",
      "Enc Loss = 139.30, KL Divergence = 1217.93, Reconstruction Loss = 331.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.30 mins\n",
      "Epoch: 8 / 10, Batch: 378 (12128 / 12512), Elapsed time: 67.30 mins\n",
      "Enc Loss = 138.36, KL Divergence = 1000.99, Reconstruction Loss = 350.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.32 mins\n",
      "Epoch: 8 / 10, Batch: 379 (12160 / 12512), Elapsed time: 67.32 mins\n",
      "Enc Loss = 133.83, KL Divergence = 1121.86, Reconstruction Loss = 323.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.34 mins\n",
      "Epoch: 8 / 10, Batch: 380 (12192 / 12512), Elapsed time: 67.34 mins\n",
      "Enc Loss = 140.30, KL Divergence = 1110.14, Reconstruction Loss = 346.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.36 mins\n",
      "Epoch: 8 / 10, Batch: 381 (12224 / 12512), Elapsed time: 67.36 mins\n",
      "Enc Loss = 177.67, KL Divergence = 1135.80, Reconstruction Loss = 465.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.38 mins\n",
      "Epoch: 8 / 10, Batch: 382 (12256 / 12512), Elapsed time: 67.38 mins\n",
      "Enc Loss = 158.73, KL Divergence = 1128.31, Reconstruction Loss = 404.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.40 mins\n",
      "Epoch: 8 / 10, Batch: 383 (12288 / 12512), Elapsed time: 67.40 mins\n",
      "Enc Loss = 130.02, KL Divergence = 1045.97, Reconstruction Loss = 318.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.42 mins\n",
      "Epoch: 8 / 10, Batch: 384 (12320 / 12512), Elapsed time: 67.42 mins\n",
      "Enc Loss = 143.85, KL Divergence = 1212.50, Reconstruction Loss = 347.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.44 mins\n",
      "Epoch: 8 / 10, Batch: 385 (12352 / 12512), Elapsed time: 67.44 mins\n",
      "Enc Loss = 141.23, KL Divergence = 1194.91, Reconstruction Loss = 340.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.46 mins\n",
      "Epoch: 8 / 10, Batch: 386 (12384 / 12512), Elapsed time: 67.46 mins\n",
      "Enc Loss = 142.24, KL Divergence = 1223.23, Reconstruction Loss = 340.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.48 mins\n",
      "Epoch: 8 / 10, Batch: 387 (12416 / 12512), Elapsed time: 67.48 mins\n",
      "Enc Loss = 131.50, KL Divergence = 1171.49, Reconstruction Loss = 310.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.50 mins\n",
      "Epoch: 8 / 10, Batch: 388 (12448 / 12512), Elapsed time: 67.50 mins\n",
      "Enc Loss = 137.76, KL Divergence = 1176.25, Reconstruction Loss = 330.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.52 mins\n",
      "Epoch: 8 / 10, Batch: 389 (12480 / 12512), Elapsed time: 67.52 mins\n",
      "Enc Loss = 146.81, KL Divergence = 1116.11, Reconstruction Loss = 366.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.54 mins\n",
      "Epoch: 8 / 10, Batch: 390 (12512 / 12512), Elapsed time: 67.54 mins\n",
      "Enc Loss = 127.26, KL Divergence = 505.99, Reconstruction Loss = 365.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.56 mins\n",
      "Epoch: 9, Elapsed Time: 67.56\n",
      "Epoch: 9 / 10, Batch: 0 (32 / 12512), Elapsed time: 67.56 mins\n",
      "Enc Loss = 138.30, KL Divergence = 1132.20, Reconstruction Loss = 337.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.58 mins\n",
      "Epoch: 9 / 10, Batch: 1 (64 / 12512), Elapsed time: 67.58 mins\n",
      "Enc Loss = 145.00, KL Divergence = 1135.38, Reconstruction Loss = 358.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.60 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / 10, Batch: 2 (96 / 12512), Elapsed time: 67.60 mins\n",
      "Enc Loss = 147.18, KL Divergence = 1099.45, Reconstruction Loss = 369.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.62 mins\n",
      "Epoch: 9 / 10, Batch: 3 (128 / 12512), Elapsed time: 67.62 mins\n",
      "Enc Loss = 150.45, KL Divergence = 1256.78, Reconstruction Loss = 364.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.64 mins\n",
      "Epoch: 9 / 10, Batch: 4 (160 / 12512), Elapsed time: 67.64 mins\n",
      "Enc Loss = 132.70, KL Divergence = 1146.85, Reconstruction Loss = 317.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.66 mins\n",
      "Epoch: 9 / 10, Batch: 5 (192 / 12512), Elapsed time: 67.66 mins\n",
      "Enc Loss = 126.03, KL Divergence = 1094.54, Reconstruction Loss = 300.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.68 mins\n",
      "Epoch: 9 / 10, Batch: 6 (224 / 12512), Elapsed time: 67.68 mins\n",
      "Enc Loss = 141.79, KL Divergence = 1118.60, Reconstruction Loss = 350.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.70 mins\n",
      "Epoch: 9 / 10, Batch: 7 (256 / 12512), Elapsed time: 67.70 mins\n",
      "Enc Loss = 129.24, KL Divergence = 1169.38, Reconstruction Loss = 303.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.72 mins\n",
      "Epoch: 9 / 10, Batch: 8 (288 / 12512), Elapsed time: 67.72 mins\n",
      "Enc Loss = 136.02, KL Divergence = 1181.16, Reconstruction Loss = 324.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.74 mins\n",
      "Epoch: 9 / 10, Batch: 9 (320 / 12512), Elapsed time: 67.74 mins\n",
      "Enc Loss = 129.89, KL Divergence = 1102.10, Reconstruction Loss = 312.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.76 mins\n",
      "Epoch: 9 / 10, Batch: 10 (352 / 12512), Elapsed time: 67.76 mins\n",
      "Enc Loss = 133.01, KL Divergence = 1162.83, Reconstruction Loss = 316.77, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.78 mins\n",
      "Epoch: 9 / 10, Batch: 11 (384 / 12512), Elapsed time: 67.78 mins\n",
      "Enc Loss = 144.62, KL Divergence = 1099.73, Reconstruction Loss = 361.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.80 mins\n",
      "Epoch: 9 / 10, Batch: 12 (416 / 12512), Elapsed time: 67.80 mins\n",
      "Enc Loss = 130.44, KL Divergence = 1128.06, Reconstruction Loss = 311.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.82 mins\n",
      "Epoch: 9 / 10, Batch: 13 (448 / 12512), Elapsed time: 67.82 mins\n",
      "Enc Loss = 165.26, KL Divergence = 1325.70, Reconstruction Loss = 405.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.84 mins\n",
      "Epoch: 9 / 10, Batch: 14 (480 / 12512), Elapsed time: 67.84 mins\n",
      "Enc Loss = 159.03, KL Divergence = 1189.80, Reconstruction Loss = 399.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.86 mins\n",
      "Epoch: 9 / 10, Batch: 15 (512 / 12512), Elapsed time: 67.86 mins\n",
      "Enc Loss = 125.62, KL Divergence = 1023.63, Reconstruction Loss = 306.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.88 mins\n",
      "Epoch: 9 / 10, Batch: 16 (544 / 12512), Elapsed time: 67.88 mins\n",
      "Enc Loss = 143.10, KL Divergence = 1157.62, Reconstruction Loss = 350.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.90 mins\n",
      "Epoch: 9 / 10, Batch: 17 (576 / 12512), Elapsed time: 67.90 mins\n",
      "Enc Loss = 146.45, KL Divergence = 1130.48, Reconstruction Loss = 364.11, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.92 mins\n",
      "Epoch: 9 / 10, Batch: 18 (608 / 12512), Elapsed time: 67.92 mins\n",
      "Enc Loss = 140.80, KL Divergence = 1059.84, Reconstruction Loss = 352.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.94 mins\n",
      "Epoch: 9 / 10, Batch: 19 (640 / 12512), Elapsed time: 67.94 mins\n",
      "Enc Loss = 155.67, KL Divergence = 1272.31, Reconstruction Loss = 379.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.96 mins\n",
      "Epoch: 9 / 10, Batch: 20 (672 / 12512), Elapsed time: 67.96 mins\n",
      "Enc Loss = 143.10, KL Divergence = 1109.74, Reconstruction Loss = 355.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 67.98 mins\n",
      "Epoch: 9 / 10, Batch: 21 (704 / 12512), Elapsed time: 67.99 mins\n",
      "Enc Loss = 133.08, KL Divergence = 1069.92, Reconstruction Loss = 326.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.00 mins\n",
      "Epoch: 9 / 10, Batch: 22 (736 / 12512), Elapsed time: 68.01 mins\n",
      "Enc Loss = 167.95, KL Divergence = 1311.55, Reconstruction Loss = 416.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.02 mins\n",
      "Epoch: 9 / 10, Batch: 23 (768 / 12512), Elapsed time: 68.02 mins\n",
      "Enc Loss = 157.49, KL Divergence = 1202.82, Reconstruction Loss = 392.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.04 mins\n",
      "Epoch: 9 / 10, Batch: 24 (800 / 12512), Elapsed time: 68.04 mins\n",
      "Enc Loss = 135.62, KL Divergence = 1183.40, Reconstruction Loss = 323.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.07 mins\n",
      "Epoch: 9 / 10, Batch: 25 (832 / 12512), Elapsed time: 68.07 mins\n",
      "Enc Loss = 156.18, KL Divergence = 1443.13, Reconstruction Loss = 364.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.08 mins\n",
      "Epoch: 9 / 10, Batch: 26 (864 / 12512), Elapsed time: 68.09 mins\n",
      "Enc Loss = 138.98, KL Divergence = 1225.95, Reconstruction Loss = 329.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.10 mins\n",
      "Epoch: 9 / 10, Batch: 27 (896 / 12512), Elapsed time: 68.10 mins\n",
      "Enc Loss = 126.62, KL Divergence = 1097.32, Reconstruction Loss = 302.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.12 mins\n",
      "Epoch: 9 / 10, Batch: 28 (928 / 12512), Elapsed time: 68.12 mins\n",
      "Enc Loss = 125.66, KL Divergence = 1147.45, Reconstruction Loss = 294.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.14 mins\n",
      "Epoch: 9 / 10, Batch: 29 (960 / 12512), Elapsed time: 68.14 mins\n",
      "Enc Loss = 145.54, KL Divergence = 1148.68, Reconstruction Loss = 359.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.16 mins\n",
      "Epoch: 9 / 10, Batch: 30 (992 / 12512), Elapsed time: 68.16 mins\n",
      "Enc Loss = 138.90, KL Divergence = 1250.17, Reconstruction Loss = 327.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.18 mins\n",
      "Epoch: 9 / 10, Batch: 31 (1024 / 12512), Elapsed time: 68.18 mins\n",
      "Enc Loss = 140.42, KL Divergence = 1170.71, Reconstruction Loss = 340.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.20 mins\n",
      "Epoch: 9 / 10, Batch: 32 (1056 / 12512), Elapsed time: 68.20 mins\n",
      "Enc Loss = 131.11, KL Divergence = 1120.39, Reconstruction Loss = 314.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.22 mins\n",
      "Epoch: 9 / 10, Batch: 33 (1088 / 12512), Elapsed time: 68.22 mins\n",
      "Enc Loss = 132.15, KL Divergence = 1125.02, Reconstruction Loss = 317.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.24 mins\n",
      "Epoch: 9 / 10, Batch: 34 (1120 / 12512), Elapsed time: 68.24 mins\n",
      "Enc Loss = 131.56, KL Divergence = 994.39, Reconstruction Loss = 329.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.26 mins\n",
      "Epoch: 9 / 10, Batch: 35 (1152 / 12512), Elapsed time: 68.26 mins\n",
      "Enc Loss = 141.37, KL Divergence = 1121.96, Reconstruction Loss = 348.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.28 mins\n",
      "Epoch: 9 / 10, Batch: 36 (1184 / 12512), Elapsed time: 68.28 mins\n",
      "Enc Loss = 133.72, KL Divergence = 1046.12, Reconstruction Loss = 331.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.30 mins\n",
      "Epoch: 9 / 10, Batch: 37 (1216 / 12512), Elapsed time: 68.30 mins\n",
      "Enc Loss = 130.31, KL Divergence = 1043.21, Reconstruction Loss = 320.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.32 mins\n",
      "Epoch: 9 / 10, Batch: 38 (1248 / 12512), Elapsed time: 68.32 mins\n",
      "Enc Loss = 138.61, KL Divergence = 1093.45, Reconstruction Loss = 342.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.34 mins\n",
      "Epoch: 9 / 10, Batch: 39 (1280 / 12512), Elapsed time: 68.34 mins\n",
      "Enc Loss = 125.77, KL Divergence = 1011.50, Reconstruction Loss = 308.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.36 mins\n",
      "Epoch: 9 / 10, Batch: 40 (1312 / 12512), Elapsed time: 68.36 mins\n",
      "Enc Loss = 129.41, KL Divergence = 1100.07, Reconstruction Loss = 311.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.38 mins\n",
      "Epoch: 9 / 10, Batch: 41 (1344 / 12512), Elapsed time: 68.38 mins\n",
      "Enc Loss = 138.92, KL Divergence = 1162.36, Reconstruction Loss = 336.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.40 mins\n",
      "Epoch: 9 / 10, Batch: 42 (1376 / 12512), Elapsed time: 68.40 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 134.55, KL Divergence = 1028.09, Reconstruction Loss = 335.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.42 mins\n",
      "Epoch: 9 / 10, Batch: 43 (1408 / 12512), Elapsed time: 68.42 mins\n",
      "Enc Loss = 136.11, KL Divergence = 1101.77, Reconstruction Loss = 333.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.44 mins\n",
      "Epoch: 9 / 10, Batch: 44 (1440 / 12512), Elapsed time: 68.44 mins\n",
      "Enc Loss = 131.51, KL Divergence = 1043.72, Reconstruction Loss = 324.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.46 mins\n",
      "Epoch: 9 / 10, Batch: 45 (1472 / 12512), Elapsed time: 68.46 mins\n",
      "Enc Loss = 131.10, KL Divergence = 1035.07, Reconstruction Loss = 323.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.48 mins\n",
      "Epoch: 9 / 10, Batch: 46 (1504 / 12512), Elapsed time: 68.48 mins\n",
      "Enc Loss = 138.91, KL Divergence = 1141.42, Reconstruction Loss = 338.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.50 mins\n",
      "Epoch: 9 / 10, Batch: 47 (1536 / 12512), Elapsed time: 68.50 mins\n",
      "Enc Loss = 138.22, KL Divergence = 1000.49, Reconstruction Loss = 350.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.52 mins\n",
      "Epoch: 9 / 10, Batch: 48 (1568 / 12512), Elapsed time: 68.52 mins\n",
      "Enc Loss = 131.10, KL Divergence = 964.06, Reconstruction Loss = 330.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.54 mins\n",
      "Epoch: 9 / 10, Batch: 49 (1600 / 12512), Elapsed time: 68.54 mins\n",
      "Enc Loss = 147.58, KL Divergence = 1237.33, Reconstruction Loss = 356.90, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.56 mins\n",
      "Epoch: 9 / 10, Batch: 50 (1632 / 12512), Elapsed time: 68.56 mins\n",
      "Enc Loss = 139.74, KL Divergence = 1137.91, Reconstruction Loss = 341.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.58 mins\n",
      "Epoch: 9 / 10, Batch: 51 (1664 / 12512), Elapsed time: 68.58 mins\n",
      "Enc Loss = 133.27, KL Divergence = 1127.47, Reconstruction Loss = 321.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.60 mins\n",
      "Epoch: 9 / 10, Batch: 52 (1696 / 12512), Elapsed time: 68.60 mins\n",
      "Enc Loss = 139.91, KL Divergence = 1051.52, Reconstruction Loss = 350.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.62 mins\n",
      "Epoch: 9 / 10, Batch: 53 (1728 / 12512), Elapsed time: 68.62 mins\n",
      "Enc Loss = 143.69, KL Divergence = 1133.00, Reconstruction Loss = 354.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.64 mins\n",
      "Epoch: 9 / 10, Batch: 54 (1760 / 12512), Elapsed time: 68.64 mins\n",
      "Enc Loss = 127.24, KL Divergence = 1086.64, Reconstruction Loss = 305.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.66 mins\n",
      "Epoch: 9 / 10, Batch: 55 (1792 / 12512), Elapsed time: 68.66 mins\n",
      "Enc Loss = 123.80, KL Divergence = 1167.58, Reconstruction Loss = 286.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.68 mins\n",
      "Epoch: 9 / 10, Batch: 56 (1824 / 12512), Elapsed time: 68.68 mins\n",
      "Enc Loss = 136.03, KL Divergence = 1267.56, Reconstruction Loss = 315.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.70 mins\n",
      "Epoch: 9 / 10, Batch: 57 (1856 / 12512), Elapsed time: 68.70 mins\n",
      "Enc Loss = 145.34, KL Divergence = 1337.44, Reconstruction Loss = 339.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.72 mins\n",
      "Epoch: 9 / 10, Batch: 58 (1888 / 12512), Elapsed time: 68.72 mins\n",
      "Enc Loss = 150.12, KL Divergence = 1400.34, Reconstruction Loss = 348.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.74 mins\n",
      "Epoch: 9 / 10, Batch: 59 (1920 / 12512), Elapsed time: 68.74 mins\n",
      "Enc Loss = 133.91, KL Divergence = 1163.38, Reconstruction Loss = 319.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.76 mins\n",
      "Epoch: 9 / 10, Batch: 60 (1952 / 12512), Elapsed time: 68.76 mins\n",
      "Enc Loss = 139.30, KL Divergence = 1336.08, Reconstruction Loss = 319.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.78 mins\n",
      "Epoch: 9 / 10, Batch: 61 (1984 / 12512), Elapsed time: 68.78 mins\n",
      "Enc Loss = 128.44, KL Divergence = 1111.67, Reconstruction Loss = 307.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.80 mins\n",
      "Epoch: 9 / 10, Batch: 62 (2016 / 12512), Elapsed time: 68.80 mins\n",
      "Enc Loss = 127.80, KL Divergence = 1177.52, Reconstruction Loss = 298.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.82 mins\n",
      "Epoch: 9 / 10, Batch: 63 (2048 / 12512), Elapsed time: 68.82 mins\n",
      "Enc Loss = 126.32, KL Divergence = 1120.60, Reconstruction Loss = 299.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.84 mins\n",
      "Epoch: 9 / 10, Batch: 64 (2080 / 12512), Elapsed time: 68.84 mins\n",
      "Enc Loss = 141.99, KL Divergence = 1249.81, Reconstruction Loss = 337.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.86 mins\n",
      "Epoch: 9 / 10, Batch: 65 (2112 / 12512), Elapsed time: 68.86 mins\n",
      "Enc Loss = 141.29, KL Divergence = 1180.80, Reconstruction Loss = 342.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.88 mins\n",
      "Epoch: 9 / 10, Batch: 66 (2144 / 12512), Elapsed time: 68.88 mins\n",
      "Enc Loss = 139.25, KL Divergence = 1173.64, Reconstruction Loss = 336.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.90 mins\n",
      "Epoch: 9 / 10, Batch: 67 (2176 / 12512), Elapsed time: 68.90 mins\n",
      "Enc Loss = 125.74, KL Divergence = 1023.32, Reconstruction Loss = 307.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.92 mins\n",
      "Epoch: 9 / 10, Batch: 68 (2208 / 12512), Elapsed time: 68.92 mins\n",
      "Enc Loss = 132.95, KL Divergence = 1098.47, Reconstruction Loss = 323.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.94 mins\n",
      "Epoch: 9 / 10, Batch: 69 (2240 / 12512), Elapsed time: 68.94 mins\n",
      "Enc Loss = 142.09, KL Divergence = 1102.25, Reconstruction Loss = 352.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.96 mins\n",
      "Epoch: 9 / 10, Batch: 70 (2272 / 12512), Elapsed time: 68.96 mins\n",
      "Enc Loss = 130.37, KL Divergence = 1099.61, Reconstruction Loss = 314.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 68.98 mins\n",
      "Epoch: 9 / 10, Batch: 71 (2304 / 12512), Elapsed time: 68.98 mins\n",
      "Enc Loss = 136.47, KL Divergence = 1185.99, Reconstruction Loss = 325.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.00 mins\n",
      "Epoch: 9 / 10, Batch: 72 (2336 / 12512), Elapsed time: 69.00 mins\n",
      "Enc Loss = 128.40, KL Divergence = 1078.57, Reconstruction Loss = 310.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.02 mins\n",
      "Epoch: 9 / 10, Batch: 73 (2368 / 12512), Elapsed time: 69.02 mins\n",
      "Enc Loss = 140.31, KL Divergence = 1111.68, Reconstruction Loss = 345.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.04 mins\n",
      "Epoch: 9 / 10, Batch: 74 (2400 / 12512), Elapsed time: 69.04 mins\n",
      "Enc Loss = 143.30, KL Divergence = 1182.99, Reconstruction Loss = 348.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.06 mins\n",
      "Epoch: 9 / 10, Batch: 75 (2432 / 12512), Elapsed time: 69.06 mins\n",
      "Enc Loss = 137.42, KL Divergence = 1073.20, Reconstruction Loss = 340.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.08 mins\n",
      "Epoch: 9 / 10, Batch: 76 (2464 / 12512), Elapsed time: 69.08 mins\n",
      "Enc Loss = 133.57, KL Divergence = 1088.52, Reconstruction Loss = 326.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.10 mins\n",
      "Epoch: 9 / 10, Batch: 77 (2496 / 12512), Elapsed time: 69.10 mins\n",
      "Enc Loss = 139.80, KL Divergence = 1196.58, Reconstruction Loss = 335.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.12 mins\n",
      "Epoch: 9 / 10, Batch: 78 (2528 / 12512), Elapsed time: 69.12 mins\n",
      "Enc Loss = 153.15, KL Divergence = 1237.31, Reconstruction Loss = 375.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.14 mins\n",
      "Epoch: 9 / 10, Batch: 79 (2560 / 12512), Elapsed time: 69.14 mins\n",
      "Enc Loss = 133.99, KL Divergence = 1100.39, Reconstruction Loss = 326.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.16 mins\n",
      "Epoch: 9 / 10, Batch: 80 (2592 / 12512), Elapsed time: 69.16 mins\n",
      "Enc Loss = 126.95, KL Divergence = 1119.98, Reconstruction Loss = 301.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.18 mins\n",
      "Epoch: 9 / 10, Batch: 81 (2624 / 12512), Elapsed time: 69.18 mins\n",
      "Enc Loss = 130.98, KL Divergence = 1099.02, Reconstruction Loss = 316.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.20 mins\n",
      "Epoch: 9 / 10, Batch: 82 (2656 / 12512), Elapsed time: 69.20 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 140.07, KL Divergence = 1147.67, Reconstruction Loss = 341.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.22 mins\n",
      "Epoch: 9 / 10, Batch: 83 (2688 / 12512), Elapsed time: 69.22 mins\n",
      "Enc Loss = 131.98, KL Divergence = 1196.30, Reconstruction Loss = 309.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.24 mins\n",
      "Epoch: 9 / 10, Batch: 84 (2720 / 12512), Elapsed time: 69.24 mins\n",
      "Enc Loss = 143.58, KL Divergence = 1152.47, Reconstruction Loss = 352.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.26 mins\n",
      "Epoch: 9 / 10, Batch: 85 (2752 / 12512), Elapsed time: 69.26 mins\n",
      "Enc Loss = 140.48, KL Divergence = 1166.25, Reconstruction Loss = 340.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.28 mins\n",
      "Epoch: 9 / 10, Batch: 86 (2784 / 12512), Elapsed time: 69.28 mins\n",
      "Enc Loss = 145.09, KL Divergence = 1191.21, Reconstruction Loss = 353.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.30 mins\n",
      "Epoch: 9 / 10, Batch: 87 (2816 / 12512), Elapsed time: 69.30 mins\n",
      "Enc Loss = 126.75, KL Divergence = 1110.45, Reconstruction Loss = 301.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.32 mins\n",
      "Epoch: 9 / 10, Batch: 88 (2848 / 12512), Elapsed time: 69.32 mins\n",
      "Enc Loss = 147.70, KL Divergence = 1030.81, Reconstruction Loss = 378.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.34 mins\n",
      "Epoch: 9 / 10, Batch: 89 (2880 / 12512), Elapsed time: 69.34 mins\n",
      "Enc Loss = 131.16, KL Divergence = 1164.65, Reconstruction Loss = 310.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.36 mins\n",
      "Epoch: 9 / 10, Batch: 90 (2912 / 12512), Elapsed time: 69.36 mins\n",
      "Enc Loss = 133.39, KL Divergence = 1117.66, Reconstruction Loss = 322.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.38 mins\n",
      "Epoch: 9 / 10, Batch: 91 (2944 / 12512), Elapsed time: 69.38 mins\n",
      "Enc Loss = 143.08, KL Divergence = 1147.47, Reconstruction Loss = 351.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.40 mins\n",
      "Epoch: 9 / 10, Batch: 92 (2976 / 12512), Elapsed time: 69.40 mins\n",
      "Enc Loss = 137.52, KL Divergence = 1198.18, Reconstruction Loss = 327.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.42 mins\n",
      "Epoch: 9 / 10, Batch: 93 (3008 / 12512), Elapsed time: 69.42 mins\n",
      "Enc Loss = 126.74, KL Divergence = 998.20, Reconstruction Loss = 313.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.44 mins\n",
      "Epoch: 9 / 10, Batch: 94 (3040 / 12512), Elapsed time: 69.44 mins\n",
      "Enc Loss = 135.42, KL Divergence = 1097.96, Reconstruction Loss = 331.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.46 mins\n",
      "Epoch: 9 / 10, Batch: 95 (3072 / 12512), Elapsed time: 69.46 mins\n",
      "Enc Loss = 136.88, KL Divergence = 1041.35, Reconstruction Loss = 341.89, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.48 mins\n",
      "Epoch: 9 / 10, Batch: 96 (3104 / 12512), Elapsed time: 69.48 mins\n",
      "Enc Loss = 155.83, KL Divergence = 1189.63, Reconstruction Loss = 388.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.50 mins\n",
      "Epoch: 9 / 10, Batch: 97 (3136 / 12512), Elapsed time: 69.50 mins\n",
      "Enc Loss = 143.15, KL Divergence = 1198.61, Reconstruction Loss = 346.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.52 mins\n",
      "Epoch: 9 / 10, Batch: 98 (3168 / 12512), Elapsed time: 69.52 mins\n",
      "Enc Loss = 144.54, KL Divergence = 1255.15, Reconstruction Loss = 345.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.54 mins\n",
      "Epoch: 9 / 10, Batch: 99 (3200 / 12512), Elapsed time: 69.54 mins\n",
      "Enc Loss = 128.28, KL Divergence = 1136.42, Reconstruction Loss = 303.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.56 mins\n",
      "Epoch: 9 / 10, Batch: 100 (3232 / 12512), Elapsed time: 69.56 mins\n",
      "Enc Loss = 128.48, KL Divergence = 1111.30, Reconstruction Loss = 307.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.58 mins\n",
      "Epoch: 9 / 10, Batch: 101 (3264 / 12512), Elapsed time: 69.58 mins\n",
      "Enc Loss = 128.92, KL Divergence = 1101.79, Reconstruction Loss = 309.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.60 mins\n",
      "Epoch: 9 / 10, Batch: 102 (3296 / 12512), Elapsed time: 69.60 mins\n",
      "Enc Loss = 133.75, KL Divergence = 1133.44, Reconstruction Loss = 322.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.62 mins\n",
      "Epoch: 9 / 10, Batch: 103 (3328 / 12512), Elapsed time: 69.62 mins\n",
      "Enc Loss = 131.63, KL Divergence = 1120.03, Reconstruction Loss = 316.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.64 mins\n",
      "Epoch: 9 / 10, Batch: 104 (3360 / 12512), Elapsed time: 69.64 mins\n",
      "Enc Loss = 140.20, KL Divergence = 1186.69, Reconstruction Loss = 337.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.66 mins\n",
      "Epoch: 9 / 10, Batch: 105 (3392 / 12512), Elapsed time: 69.66 mins\n",
      "Enc Loss = 134.60, KL Divergence = 1148.34, Reconstruction Loss = 323.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.68 mins\n",
      "Epoch: 9 / 10, Batch: 106 (3424 / 12512), Elapsed time: 69.68 mins\n",
      "Enc Loss = 139.57, KL Divergence = 1251.54, Reconstruction Loss = 329.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.70 mins\n",
      "Epoch: 9 / 10, Batch: 107 (3456 / 12512), Elapsed time: 69.70 mins\n",
      "Enc Loss = 122.99, KL Divergence = 1074.68, Reconstruction Loss = 292.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.72 mins\n",
      "Epoch: 9 / 10, Batch: 108 (3488 / 12512), Elapsed time: 69.72 mins\n",
      "Enc Loss = 138.44, KL Divergence = 1153.84, Reconstruction Loss = 335.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.74 mins\n",
      "Epoch: 9 / 10, Batch: 109 (3520 / 12512), Elapsed time: 69.74 mins\n",
      "Enc Loss = 134.23, KL Divergence = 1139.33, Reconstruction Loss = 323.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.76 mins\n",
      "Epoch: 9 / 10, Batch: 110 (3552 / 12512), Elapsed time: 69.76 mins\n",
      "Enc Loss = 139.35, KL Divergence = 1127.78, Reconstruction Loss = 341.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.78 mins\n",
      "Epoch: 9 / 10, Batch: 111 (3584 / 12512), Elapsed time: 69.78 mins\n",
      "Enc Loss = 134.03, KL Divergence = 1136.34, Reconstruction Loss = 322.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.80 mins\n",
      "Epoch: 9 / 10, Batch: 112 (3616 / 12512), Elapsed time: 69.80 mins\n",
      "Enc Loss = 128.73, KL Divergence = 1081.86, Reconstruction Loss = 311.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.82 mins\n",
      "Epoch: 9 / 10, Batch: 113 (3648 / 12512), Elapsed time: 69.82 mins\n",
      "Enc Loss = 131.36, KL Divergence = 1069.42, Reconstruction Loss = 320.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.84 mins\n",
      "Epoch: 9 / 10, Batch: 114 (3680 / 12512), Elapsed time: 69.84 mins\n",
      "Enc Loss = 138.54, KL Divergence = 1060.27, Reconstruction Loss = 345.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.86 mins\n",
      "Epoch: 9 / 10, Batch: 115 (3712 / 12512), Elapsed time: 69.86 mins\n",
      "Enc Loss = 145.72, KL Divergence = 1189.65, Reconstruction Loss = 355.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.88 mins\n",
      "Epoch: 9 / 10, Batch: 116 (3744 / 12512), Elapsed time: 69.88 mins\n",
      "Enc Loss = 133.28, KL Divergence = 1088.90, Reconstruction Loss = 325.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.90 mins\n",
      "Epoch: 9 / 10, Batch: 117 (3776 / 12512), Elapsed time: 69.90 mins\n",
      "Enc Loss = 135.74, KL Divergence = 1130.67, Reconstruction Loss = 329.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.92 mins\n",
      "Epoch: 9 / 10, Batch: 118 (3808 / 12512), Elapsed time: 69.92 mins\n",
      "Enc Loss = 139.33, KL Divergence = 1087.09, Reconstruction Loss = 345.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.94 mins\n",
      "Epoch: 9 / 10, Batch: 119 (3840 / 12512), Elapsed time: 69.94 mins\n",
      "Enc Loss = 132.34, KL Divergence = 1063.69, Reconstruction Loss = 324.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.96 mins\n",
      "Epoch: 9 / 10, Batch: 120 (3872 / 12512), Elapsed time: 69.96 mins\n",
      "Enc Loss = 134.06, KL Divergence = 1108.32, Reconstruction Loss = 325.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 69.98 mins\n",
      "Epoch: 9 / 10, Batch: 121 (3904 / 12512), Elapsed time: 69.98 mins\n",
      "Enc Loss = 148.42, KL Divergence = 1201.50, Reconstruction Loss = 363.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.00 mins\n",
      "Epoch: 9 / 10, Batch: 122 (3936 / 12512), Elapsed time: 70.00 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 143.57, KL Divergence = 1085.13, Reconstruction Loss = 359.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.02 mins\n",
      "Epoch: 9 / 10, Batch: 123 (3968 / 12512), Elapsed time: 70.02 mins\n",
      "Enc Loss = 136.44, KL Divergence = 1188.89, Reconstruction Loss = 325.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.04 mins\n",
      "Epoch: 9 / 10, Batch: 124 (4000 / 12512), Elapsed time: 70.04 mins\n",
      "Enc Loss = 134.62, KL Divergence = 1053.94, Reconstruction Loss = 333.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.06 mins\n",
      "Epoch: 9 / 10, Batch: 125 (4032 / 12512), Elapsed time: 70.06 mins\n",
      "Enc Loss = 139.31, KL Divergence = 1109.82, Reconstruction Loss = 342.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.08 mins\n",
      "Epoch: 9 / 10, Batch: 126 (4064 / 12512), Elapsed time: 70.08 mins\n",
      "Enc Loss = 129.53, KL Divergence = 1065.49, Reconstruction Loss = 315.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.10 mins\n",
      "Epoch: 9 / 10, Batch: 127 (4096 / 12512), Elapsed time: 70.10 mins\n",
      "Enc Loss = 128.34, KL Divergence = 1036.85, Reconstruction Loss = 314.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.12 mins\n",
      "Epoch: 9 / 10, Batch: 128 (4128 / 12512), Elapsed time: 70.12 mins\n",
      "Enc Loss = 129.63, KL Divergence = 984.08, Reconstruction Loss = 323.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.14 mins\n",
      "Epoch: 9 / 10, Batch: 129 (4160 / 12512), Elapsed time: 70.14 mins\n",
      "Enc Loss = 131.06, KL Divergence = 1062.08, Reconstruction Loss = 320.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.16 mins\n",
      "Epoch: 9 / 10, Batch: 130 (4192 / 12512), Elapsed time: 70.16 mins\n",
      "Enc Loss = 126.27, KL Divergence = 1066.77, Reconstruction Loss = 304.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.18 mins\n",
      "Epoch: 9 / 10, Batch: 131 (4224 / 12512), Elapsed time: 70.18 mins\n",
      "Enc Loss = 135.43, KL Divergence = 1060.19, Reconstruction Loss = 335.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.20 mins\n",
      "Epoch: 9 / 10, Batch: 132 (4256 / 12512), Elapsed time: 70.20 mins\n",
      "Enc Loss = 130.93, KL Divergence = 1019.37, Reconstruction Loss = 324.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.22 mins\n",
      "Epoch: 9 / 10, Batch: 133 (4288 / 12512), Elapsed time: 70.22 mins\n",
      "Enc Loss = 140.71, KL Divergence = 1114.92, Reconstruction Loss = 346.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.24 mins\n",
      "Epoch: 9 / 10, Batch: 134 (4320 / 12512), Elapsed time: 70.24 mins\n",
      "Enc Loss = 150.35, KL Divergence = 1111.06, Reconstruction Loss = 378.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.26 mins\n",
      "Epoch: 9 / 10, Batch: 135 (4352 / 12512), Elapsed time: 70.26 mins\n",
      "Enc Loss = 147.06, KL Divergence = 1198.09, Reconstruction Loss = 359.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.28 mins\n",
      "Epoch: 9 / 10, Batch: 136 (4384 / 12512), Elapsed time: 70.28 mins\n",
      "Enc Loss = 166.34, KL Divergence = 1336.72, Reconstruction Loss = 408.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.30 mins\n",
      "Epoch: 9 / 10, Batch: 137 (4416 / 12512), Elapsed time: 70.30 mins\n",
      "Enc Loss = 129.94, KL Divergence = 1137.80, Reconstruction Loss = 309.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.32 mins\n",
      "Epoch: 9 / 10, Batch: 138 (4448 / 12512), Elapsed time: 70.33 mins\n",
      "Enc Loss = 135.35, KL Divergence = 1126.87, Reconstruction Loss = 328.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.35 mins\n",
      "Epoch: 9 / 10, Batch: 139 (4480 / 12512), Elapsed time: 70.35 mins\n",
      "Enc Loss = 145.28, KL Divergence = 1361.71, Reconstruction Loss = 336.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.37 mins\n",
      "Epoch: 9 / 10, Batch: 140 (4512 / 12512), Elapsed time: 70.37 mins\n",
      "Enc Loss = 138.52, KL Divergence = 1208.51, Reconstruction Loss = 330.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.39 mins\n",
      "Epoch: 9 / 10, Batch: 141 (4544 / 12512), Elapsed time: 70.39 mins\n",
      "Enc Loss = 145.05, KL Divergence = 1289.33, Reconstruction Loss = 343.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.41 mins\n",
      "Epoch: 9 / 10, Batch: 142 (4576 / 12512), Elapsed time: 70.41 mins\n",
      "Enc Loss = 144.72, KL Divergence = 1262.46, Reconstruction Loss = 344.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.43 mins\n",
      "Epoch: 9 / 10, Batch: 143 (4608 / 12512), Elapsed time: 70.43 mins\n",
      "Enc Loss = 139.08, KL Divergence = 1196.31, Reconstruction Loss = 333.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.45 mins\n",
      "Epoch: 9 / 10, Batch: 144 (4640 / 12512), Elapsed time: 70.45 mins\n",
      "Enc Loss = 133.95, KL Divergence = 1155.78, Reconstruction Loss = 320.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.47 mins\n",
      "Epoch: 9 / 10, Batch: 145 (4672 / 12512), Elapsed time: 70.47 mins\n",
      "Enc Loss = 134.84, KL Divergence = 1136.54, Reconstruction Loss = 325.48, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.49 mins\n",
      "Epoch: 9 / 10, Batch: 146 (4704 / 12512), Elapsed time: 70.49 mins\n",
      "Enc Loss = 131.56, KL Divergence = 1077.63, Reconstruction Loss = 320.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.51 mins\n",
      "Epoch: 9 / 10, Batch: 147 (4736 / 12512), Elapsed time: 70.51 mins\n",
      "Enc Loss = 131.93, KL Divergence = 1088.59, Reconstruction Loss = 320.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.53 mins\n",
      "Epoch: 9 / 10, Batch: 148 (4768 / 12512), Elapsed time: 70.53 mins\n",
      "Enc Loss = 128.02, KL Divergence = 954.10, Reconstruction Loss = 321.79, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.55 mins\n",
      "Epoch: 9 / 10, Batch: 149 (4800 / 12512), Elapsed time: 70.55 mins\n",
      "Enc Loss = 137.46, KL Divergence = 1016.39, Reconstruction Loss = 346.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.57 mins\n",
      "Epoch: 9 / 10, Batch: 150 (4832 / 12512), Elapsed time: 70.57 mins\n",
      "Enc Loss = 130.25, KL Divergence = 943.47, Reconstruction Loss = 330.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.59 mins\n",
      "Epoch: 9 / 10, Batch: 151 (4864 / 12512), Elapsed time: 70.59 mins\n",
      "Enc Loss = 130.98, KL Divergence = 1000.82, Reconstruction Loss = 326.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.61 mins\n",
      "Epoch: 9 / 10, Batch: 152 (4896 / 12512), Elapsed time: 70.61 mins\n",
      "Enc Loss = 141.12, KL Divergence = 1108.65, Reconstruction Loss = 348.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.63 mins\n",
      "Epoch: 9 / 10, Batch: 153 (4928 / 12512), Elapsed time: 70.63 mins\n",
      "Enc Loss = 145.50, KL Divergence = 1107.05, Reconstruction Loss = 363.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.65 mins\n",
      "Epoch: 9 / 10, Batch: 154 (4960 / 12512), Elapsed time: 70.65 mins\n",
      "Enc Loss = 120.46, KL Divergence = 976.27, Reconstruction Loss = 294.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.67 mins\n",
      "Epoch: 9 / 10, Batch: 155 (4992 / 12512), Elapsed time: 70.67 mins\n",
      "Enc Loss = 135.20, KL Divergence = 1134.17, Reconstruction Loss = 326.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.69 mins\n",
      "Epoch: 9 / 10, Batch: 156 (5024 / 12512), Elapsed time: 70.69 mins\n",
      "Enc Loss = 119.97, KL Divergence = 1034.89, Reconstruction Loss = 287.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.71 mins\n",
      "Epoch: 9 / 10, Batch: 157 (5056 / 12512), Elapsed time: 70.71 mins\n",
      "Enc Loss = 132.83, KL Divergence = 1076.38, Reconstruction Loss = 325.01, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.73 mins\n",
      "Epoch: 9 / 10, Batch: 158 (5088 / 12512), Elapsed time: 70.73 mins\n",
      "Enc Loss = 140.37, KL Divergence = 1143.57, Reconstruction Loss = 342.86, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.75 mins\n",
      "Epoch: 9 / 10, Batch: 159 (5120 / 12512), Elapsed time: 70.75 mins\n",
      "Enc Loss = 146.52, KL Divergence = 1142.80, Reconstruction Loss = 363.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.77 mins\n",
      "Epoch: 9 / 10, Batch: 160 (5152 / 12512), Elapsed time: 70.77 mins\n",
      "Enc Loss = 128.96, KL Divergence = 1155.71, Reconstruction Loss = 304.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.79 mins\n",
      "Epoch: 9 / 10, Batch: 161 (5184 / 12512), Elapsed time: 70.79 mins\n",
      "Enc Loss = 133.36, KL Divergence = 1216.49, Reconstruction Loss = 312.42, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.81 mins\n",
      "Epoch: 9 / 10, Batch: 162 (5216 / 12512), Elapsed time: 70.81 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 124.44, KL Divergence = 1078.60, Reconstruction Loss = 297.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.83 mins\n",
      "Epoch: 9 / 10, Batch: 163 (5248 / 12512), Elapsed time: 70.83 mins\n",
      "Enc Loss = 136.22, KL Divergence = 1270.57, Reconstruction Loss = 316.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.85 mins\n",
      "Epoch: 9 / 10, Batch: 164 (5280 / 12512), Elapsed time: 70.85 mins\n",
      "Enc Loss = 151.25, KL Divergence = 1324.65, Reconstruction Loss = 359.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.87 mins\n",
      "Epoch: 9 / 10, Batch: 165 (5312 / 12512), Elapsed time: 70.87 mins\n",
      "Enc Loss = 130.10, KL Divergence = 1074.20, Reconstruction Loss = 316.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.89 mins\n",
      "Epoch: 9 / 10, Batch: 166 (5344 / 12512), Elapsed time: 70.89 mins\n",
      "Enc Loss = 131.42, KL Divergence = 1068.00, Reconstruction Loss = 321.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.91 mins\n",
      "Epoch: 9 / 10, Batch: 167 (5376 / 12512), Elapsed time: 70.91 mins\n",
      "Enc Loss = 121.16, KL Divergence = 926.21, Reconstruction Loss = 302.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.93 mins\n",
      "Epoch: 9 / 10, Batch: 168 (5408 / 12512), Elapsed time: 70.93 mins\n",
      "Enc Loss = 159.29, KL Divergence = 1190.71, Reconstruction Loss = 400.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.95 mins\n",
      "Epoch: 9 / 10, Batch: 169 (5440 / 12512), Elapsed time: 70.95 mins\n",
      "Enc Loss = 123.48, KL Divergence = 972.52, Reconstruction Loss = 305.04, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.97 mins\n",
      "Epoch: 9 / 10, Batch: 170 (5472 / 12512), Elapsed time: 70.97 mins\n",
      "Enc Loss = 133.24, KL Divergence = 990.71, Reconstruction Loss = 335.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 70.99 mins\n",
      "Epoch: 9 / 10, Batch: 171 (5504 / 12512), Elapsed time: 70.99 mins\n",
      "Enc Loss = 152.96, KL Divergence = 1088.10, Reconstruction Loss = 389.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.01 mins\n",
      "Epoch: 9 / 10, Batch: 172 (5536 / 12512), Elapsed time: 71.01 mins\n",
      "Enc Loss = 144.14, KL Divergence = 1185.01, Reconstruction Loss = 350.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.03 mins\n",
      "Epoch: 9 / 10, Batch: 173 (5568 / 12512), Elapsed time: 71.03 mins\n",
      "Enc Loss = 137.69, KL Divergence = 1069.56, Reconstruction Loss = 341.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.05 mins\n",
      "Epoch: 9 / 10, Batch: 174 (5600 / 12512), Elapsed time: 71.05 mins\n",
      "Enc Loss = 140.47, KL Divergence = 1136.43, Reconstruction Loss = 343.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.07 mins\n",
      "Epoch: 9 / 10, Batch: 175 (5632 / 12512), Elapsed time: 71.07 mins\n",
      "Enc Loss = 131.97, KL Divergence = 1025.99, Reconstruction Loss = 327.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.09 mins\n",
      "Epoch: 9 / 10, Batch: 176 (5664 / 12512), Elapsed time: 71.09 mins\n",
      "Enc Loss = 139.96, KL Divergence = 1179.35, Reconstruction Loss = 337.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.11 mins\n",
      "Epoch: 9 / 10, Batch: 177 (5696 / 12512), Elapsed time: 71.11 mins\n",
      "Enc Loss = 133.51, KL Divergence = 1082.84, Reconstruction Loss = 326.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.13 mins\n",
      "Epoch: 9 / 10, Batch: 178 (5728 / 12512), Elapsed time: 71.13 mins\n",
      "Enc Loss = 132.43, KL Divergence = 1098.15, Reconstruction Loss = 321.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.15 mins\n",
      "Epoch: 9 / 10, Batch: 179 (5760 / 12512), Elapsed time: 71.15 mins\n",
      "Enc Loss = 132.61, KL Divergence = 1051.90, Reconstruction Loss = 326.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.17 mins\n",
      "Epoch: 9 / 10, Batch: 180 (5792 / 12512), Elapsed time: 71.17 mins\n",
      "Enc Loss = 133.49, KL Divergence = 1095.34, Reconstruction Loss = 325.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.19 mins\n",
      "Epoch: 9 / 10, Batch: 181 (5824 / 12512), Elapsed time: 71.19 mins\n",
      "Enc Loss = 128.60, KL Divergence = 1036.22, Reconstruction Loss = 315.29, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.21 mins\n",
      "Epoch: 9 / 10, Batch: 182 (5856 / 12512), Elapsed time: 71.21 mins\n",
      "Enc Loss = 129.46, KL Divergence = 1044.86, Reconstruction Loss = 317.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.23 mins\n",
      "Epoch: 9 / 10, Batch: 183 (5888 / 12512), Elapsed time: 71.23 mins\n",
      "Enc Loss = 120.41, KL Divergence = 921.68, Reconstruction Loss = 300.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.25 mins\n",
      "Epoch: 9 / 10, Batch: 184 (5920 / 12512), Elapsed time: 71.25 mins\n",
      "Enc Loss = 160.66, KL Divergence = 1225.41, Reconstruction Loss = 401.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.27 mins\n",
      "Epoch: 9 / 10, Batch: 185 (5952 / 12512), Elapsed time: 71.27 mins\n",
      "Enc Loss = 123.57, KL Divergence = 993.38, Reconstruction Loss = 303.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.29 mins\n",
      "Epoch: 9 / 10, Batch: 186 (5984 / 12512), Elapsed time: 71.29 mins\n",
      "Enc Loss = 133.87, KL Divergence = 1011.20, Reconstruction Loss = 335.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.31 mins\n",
      "Epoch: 9 / 10, Batch: 187 (6016 / 12512), Elapsed time: 71.31 mins\n",
      "Enc Loss = 143.00, KL Divergence = 1217.35, Reconstruction Loss = 343.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.33 mins\n",
      "Epoch: 9 / 10, Batch: 188 (6048 / 12512), Elapsed time: 71.33 mins\n",
      "Enc Loss = 131.71, KL Divergence = 1024.84, Reconstruction Loss = 326.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.35 mins\n",
      "Epoch: 9 / 10, Batch: 189 (6080 / 12512), Elapsed time: 71.35 mins\n",
      "Enc Loss = 123.74, KL Divergence = 1056.57, Reconstruction Loss = 297.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.37 mins\n",
      "Epoch: 9 / 10, Batch: 190 (6112 / 12512), Elapsed time: 71.37 mins\n",
      "Enc Loss = 132.53, KL Divergence = 1023.24, Reconstruction Loss = 329.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.39 mins\n",
      "Epoch: 9 / 10, Batch: 191 (6144 / 12512), Elapsed time: 71.39 mins\n",
      "Enc Loss = 135.11, KL Divergence = 1107.96, Reconstruction Loss = 329.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.41 mins\n",
      "Epoch: 9 / 10, Batch: 192 (6176 / 12512), Elapsed time: 71.41 mins\n",
      "Enc Loss = 134.16, KL Divergence = 1168.00, Reconstruction Loss = 320.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.43 mins\n",
      "Epoch: 9 / 10, Batch: 193 (6208 / 12512), Elapsed time: 71.43 mins\n",
      "Enc Loss = 135.12, KL Divergence = 1154.95, Reconstruction Loss = 324.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.45 mins\n",
      "Epoch: 9 / 10, Batch: 194 (6240 / 12512), Elapsed time: 71.45 mins\n",
      "Enc Loss = 139.14, KL Divergence = 1203.83, Reconstruction Loss = 332.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.47 mins\n",
      "Epoch: 9 / 10, Batch: 195 (6272 / 12512), Elapsed time: 71.47 mins\n",
      "Enc Loss = 127.30, KL Divergence = 1065.32, Reconstruction Loss = 308.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.49 mins\n",
      "Epoch: 9 / 10, Batch: 196 (6304 / 12512), Elapsed time: 71.49 mins\n",
      "Enc Loss = 134.63, KL Divergence = 1083.08, Reconstruction Loss = 330.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.51 mins\n",
      "Epoch: 9 / 10, Batch: 197 (6336 / 12512), Elapsed time: 71.51 mins\n",
      "Enc Loss = 134.37, KL Divergence = 1056.14, Reconstruction Loss = 332.16, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.53 mins\n",
      "Epoch: 9 / 10, Batch: 198 (6368 / 12512), Elapsed time: 71.53 mins\n",
      "Enc Loss = 133.74, KL Divergence = 1104.33, Reconstruction Loss = 325.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.55 mins\n",
      "Epoch: 9 / 10, Batch: 199 (6400 / 12512), Elapsed time: 71.55 mins\n",
      "Enc Loss = 152.77, KL Divergence = 1213.25, Reconstruction Loss = 376.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.57 mins\n",
      "Epoch: 9 / 10, Batch: 200 (6432 / 12512), Elapsed time: 71.57 mins\n",
      "Enc Loss = 125.75, KL Divergence = 1061.08, Reconstruction Loss = 303.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.59 mins\n",
      "Epoch: 9 / 10, Batch: 201 (6464 / 12512), Elapsed time: 71.59 mins\n",
      "Enc Loss = 141.61, KL Divergence = 1159.56, Reconstruction Loss = 345.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.61 mins\n",
      "Epoch: 9 / 10, Batch: 202 (6496 / 12512), Elapsed time: 71.61 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 127.69, KL Divergence = 1028.02, Reconstruction Loss = 313.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.63 mins\n",
      "Epoch: 9 / 10, Batch: 203 (6528 / 12512), Elapsed time: 71.63 mins\n",
      "Enc Loss = 126.94, KL Divergence = 1051.51, Reconstruction Loss = 308.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.65 mins\n",
      "Epoch: 9 / 10, Batch: 204 (6560 / 12512), Elapsed time: 71.65 mins\n",
      "Enc Loss = 126.71, KL Divergence = 920.82, Reconstruction Loss = 320.95, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.67 mins\n",
      "Epoch: 9 / 10, Batch: 205 (6592 / 12512), Elapsed time: 71.67 mins\n",
      "Enc Loss = 132.91, KL Divergence = 1120.62, Reconstruction Loss = 320.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.69 mins\n",
      "Epoch: 9 / 10, Batch: 206 (6624 / 12512), Elapsed time: 71.69 mins\n",
      "Enc Loss = 142.42, KL Divergence = 1224.79, Reconstruction Loss = 341.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.71 mins\n",
      "Epoch: 9 / 10, Batch: 207 (6656 / 12512), Elapsed time: 71.71 mins\n",
      "Enc Loss = 149.13, KL Divergence = 1167.12, Reconstruction Loss = 369.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.73 mins\n",
      "Epoch: 9 / 10, Batch: 208 (6688 / 12512), Elapsed time: 71.73 mins\n",
      "Enc Loss = 151.04, KL Divergence = 1107.03, Reconstruction Loss = 381.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.75 mins\n",
      "Epoch: 9 / 10, Batch: 209 (6720 / 12512), Elapsed time: 71.75 mins\n",
      "Enc Loss = 138.64, KL Divergence = 1238.90, Reconstruction Loss = 327.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.77 mins\n",
      "Epoch: 9 / 10, Batch: 210 (6752 / 12512), Elapsed time: 71.77 mins\n",
      "Enc Loss = 130.14, KL Divergence = 1159.30, Reconstruction Loss = 307.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.79 mins\n",
      "Epoch: 9 / 10, Batch: 211 (6784 / 12512), Elapsed time: 71.79 mins\n",
      "Enc Loss = 129.74, KL Divergence = 1138.27, Reconstruction Loss = 308.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.81 mins\n",
      "Epoch: 9 / 10, Batch: 212 (6816 / 12512), Elapsed time: 71.81 mins\n",
      "Enc Loss = 134.89, KL Divergence = 1219.91, Reconstruction Loss = 317.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.83 mins\n",
      "Epoch: 9 / 10, Batch: 213 (6848 / 12512), Elapsed time: 71.83 mins\n",
      "Enc Loss = 138.17, KL Divergence = 1332.49, Reconstruction Loss = 316.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.85 mins\n",
      "Epoch: 9 / 10, Batch: 214 (6880 / 12512), Elapsed time: 71.85 mins\n",
      "Enc Loss = 138.02, KL Divergence = 1194.20, Reconstruction Loss = 329.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.87 mins\n",
      "Epoch: 9 / 10, Batch: 215 (6912 / 12512), Elapsed time: 71.87 mins\n",
      "Enc Loss = 131.40, KL Divergence = 1164.35, Reconstruction Loss = 311.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.89 mins\n",
      "Epoch: 9 / 10, Batch: 216 (6944 / 12512), Elapsed time: 71.89 mins\n",
      "Enc Loss = 133.50, KL Divergence = 1156.04, Reconstruction Loss = 319.07, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.91 mins\n",
      "Epoch: 9 / 10, Batch: 217 (6976 / 12512), Elapsed time: 71.91 mins\n",
      "Enc Loss = 125.09, KL Divergence = 1181.79, Reconstruction Loss = 288.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.93 mins\n",
      "Epoch: 9 / 10, Batch: 218 (7008 / 12512), Elapsed time: 71.93 mins\n",
      "Enc Loss = 147.41, KL Divergence = 1320.24, Reconstruction Loss = 347.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.95 mins\n",
      "Epoch: 9 / 10, Batch: 219 (7040 / 12512), Elapsed time: 71.95 mins\n",
      "Enc Loss = 139.59, KL Divergence = 1238.83, Reconstruction Loss = 330.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.97 mins\n",
      "Epoch: 9 / 10, Batch: 220 (7072 / 12512), Elapsed time: 71.97 mins\n",
      "Enc Loss = 136.45, KL Divergence = 1227.42, Reconstruction Loss = 321.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 71.99 mins\n",
      "Epoch: 9 / 10, Batch: 221 (7104 / 12512), Elapsed time: 71.99 mins\n",
      "Enc Loss = 133.74, KL Divergence = 1132.97, Reconstruction Loss = 322.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.01 mins\n",
      "Epoch: 9 / 10, Batch: 222 (7136 / 12512), Elapsed time: 72.01 mins\n",
      "Enc Loss = 128.39, KL Divergence = 1160.59, Reconstruction Loss = 301.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.03 mins\n",
      "Epoch: 9 / 10, Batch: 223 (7168 / 12512), Elapsed time: 72.03 mins\n",
      "Enc Loss = 130.47, KL Divergence = 1090.52, Reconstruction Loss = 315.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.05 mins\n",
      "Epoch: 9 / 10, Batch: 224 (7200 / 12512), Elapsed time: 72.05 mins\n",
      "Enc Loss = 133.44, KL Divergence = 1049.95, Reconstruction Loss = 329.76, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.07 mins\n",
      "Epoch: 9 / 10, Batch: 225 (7232 / 12512), Elapsed time: 72.07 mins\n",
      "Enc Loss = 148.95, KL Divergence = 1118.63, Reconstruction Loss = 373.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.09 mins\n",
      "Epoch: 9 / 10, Batch: 226 (7264 / 12512), Elapsed time: 72.09 mins\n",
      "Enc Loss = 142.09, KL Divergence = 1199.78, Reconstruction Loss = 342.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.11 mins\n",
      "Epoch: 9 / 10, Batch: 227 (7296 / 12512), Elapsed time: 72.11 mins\n",
      "Enc Loss = 123.11, KL Divergence = 1001.95, Reconstruction Loss = 300.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.13 mins\n",
      "Epoch: 9 / 10, Batch: 228 (7328 / 12512), Elapsed time: 72.13 mins\n",
      "Enc Loss = 126.16, KL Divergence = 1125.33, Reconstruction Loss = 298.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.15 mins\n",
      "Epoch: 9 / 10, Batch: 229 (7360 / 12512), Elapsed time: 72.15 mins\n",
      "Enc Loss = 128.19, KL Divergence = 1111.04, Reconstruction Loss = 306.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.17 mins\n",
      "Epoch: 9 / 10, Batch: 230 (7392 / 12512), Elapsed time: 72.17 mins\n",
      "Enc Loss = 139.91, KL Divergence = 1177.57, Reconstruction Loss = 337.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.19 mins\n",
      "Epoch: 9 / 10, Batch: 231 (7424 / 12512), Elapsed time: 72.19 mins\n",
      "Enc Loss = 136.48, KL Divergence = 1083.46, Reconstruction Loss = 336.24, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.21 mins\n",
      "Epoch: 9 / 10, Batch: 232 (7456 / 12512), Elapsed time: 72.21 mins\n",
      "Enc Loss = 135.76, KL Divergence = 1078.88, Reconstruction Loss = 334.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.23 mins\n",
      "Epoch: 9 / 10, Batch: 233 (7488 / 12512), Elapsed time: 72.23 mins\n",
      "Enc Loss = 133.29, KL Divergence = 1036.98, Reconstruction Loss = 330.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.25 mins\n",
      "Epoch: 9 / 10, Batch: 234 (7520 / 12512), Elapsed time: 72.25 mins\n",
      "Enc Loss = 121.73, KL Divergence = 1044.42, Reconstruction Loss = 291.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.27 mins\n",
      "Epoch: 9 / 10, Batch: 235 (7552 / 12512), Elapsed time: 72.27 mins\n",
      "Enc Loss = 128.98, KL Divergence = 1072.18, Reconstruction Loss = 312.84, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.29 mins\n",
      "Epoch: 9 / 10, Batch: 236 (7584 / 12512), Elapsed time: 72.29 mins\n",
      "Enc Loss = 142.63, KL Divergence = 1131.99, Reconstruction Loss = 351.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.31 mins\n",
      "Epoch: 9 / 10, Batch: 237 (7616 / 12512), Elapsed time: 72.31 mins\n",
      "Enc Loss = 124.69, KL Divergence = 1028.91, Reconstruction Loss = 303.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.33 mins\n",
      "Epoch: 9 / 10, Batch: 238 (7648 / 12512), Elapsed time: 72.33 mins\n",
      "Enc Loss = 134.14, KL Divergence = 1053.13, Reconstruction Loss = 331.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.35 mins\n",
      "Epoch: 9 / 10, Batch: 239 (7680 / 12512), Elapsed time: 72.35 mins\n",
      "Enc Loss = 142.17, KL Divergence = 1126.53, Reconstruction Loss = 350.50, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.37 mins\n",
      "Epoch: 9 / 10, Batch: 240 (7712 / 12512), Elapsed time: 72.37 mins\n",
      "Enc Loss = 139.42, KL Divergence = 1180.28, Reconstruction Loss = 335.99, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.39 mins\n",
      "Epoch: 9 / 10, Batch: 241 (7744 / 12512), Elapsed time: 72.39 mins\n",
      "Enc Loss = 135.33, KL Divergence = 1034.47, Reconstruction Loss = 337.53, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.41 mins\n",
      "Epoch: 9 / 10, Batch: 242 (7776 / 12512), Elapsed time: 72.41 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 144.02, KL Divergence = 1147.21, Reconstruction Loss = 354.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.43 mins\n",
      "Epoch: 9 / 10, Batch: 243 (7808 / 12512), Elapsed time: 72.43 mins\n",
      "Enc Loss = 142.78, KL Divergence = 1238.14, Reconstruction Loss = 341.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.45 mins\n",
      "Epoch: 9 / 10, Batch: 244 (7840 / 12512), Elapsed time: 72.45 mins\n",
      "Enc Loss = 126.33, KL Divergence = 1036.43, Reconstruction Loss = 307.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.47 mins\n",
      "Epoch: 9 / 10, Batch: 245 (7872 / 12512), Elapsed time: 72.47 mins\n",
      "Enc Loss = 125.86, KL Divergence = 1014.00, Reconstruction Loss = 308.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.49 mins\n",
      "Epoch: 9 / 10, Batch: 246 (7904 / 12512), Elapsed time: 72.49 mins\n",
      "Enc Loss = 132.15, KL Divergence = 1085.77, Reconstruction Loss = 321.82, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.51 mins\n",
      "Epoch: 9 / 10, Batch: 247 (7936 / 12512), Elapsed time: 72.51 mins\n",
      "Enc Loss = 116.49, KL Divergence = 935.60, Reconstruction Loss = 285.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.53 mins\n",
      "Epoch: 9 / 10, Batch: 248 (7968 / 12512), Elapsed time: 72.53 mins\n",
      "Enc Loss = 128.97, KL Divergence = 1082.40, Reconstruction Loss = 311.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.55 mins\n",
      "Epoch: 9 / 10, Batch: 249 (8000 / 12512), Elapsed time: 72.55 mins\n",
      "Enc Loss = 138.65, KL Divergence = 1154.31, Reconstruction Loss = 336.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.57 mins\n",
      "Epoch: 9 / 10, Batch: 250 (8032 / 12512), Elapsed time: 72.57 mins\n",
      "Enc Loss = 135.17, KL Divergence = 1042.46, Reconstruction Loss = 336.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.59 mins\n",
      "Epoch: 9 / 10, Batch: 251 (8064 / 12512), Elapsed time: 72.59 mins\n",
      "Enc Loss = 120.78, KL Divergence = 985.79, Reconstruction Loss = 294.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.61 mins\n",
      "Epoch: 9 / 10, Batch: 252 (8096 / 12512), Elapsed time: 72.61 mins\n",
      "Enc Loss = 134.47, KL Divergence = 1007.40, Reconstruction Loss = 337.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.63 mins\n",
      "Epoch: 9 / 10, Batch: 253 (8128 / 12512), Elapsed time: 72.63 mins\n",
      "Enc Loss = 131.52, KL Divergence = 1016.94, Reconstruction Loss = 326.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.65 mins\n",
      "Epoch: 9 / 10, Batch: 254 (8160 / 12512), Elapsed time: 72.65 mins\n",
      "Enc Loss = 133.67, KL Divergence = 959.27, Reconstruction Loss = 339.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.67 mins\n",
      "Epoch: 9 / 10, Batch: 255 (8192 / 12512), Elapsed time: 72.67 mins\n",
      "Enc Loss = 139.89, KL Divergence = 1025.96, Reconstruction Loss = 353.33, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.69 mins\n",
      "Epoch: 9 / 10, Batch: 256 (8224 / 12512), Elapsed time: 72.69 mins\n",
      "Enc Loss = 144.82, KL Divergence = 1205.79, Reconstruction Loss = 351.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.71 mins\n",
      "Epoch: 9 / 10, Batch: 257 (8256 / 12512), Elapsed time: 72.72 mins\n",
      "Enc Loss = 138.63, KL Divergence = 1170.64, Reconstruction Loss = 334.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.74 mins\n",
      "Epoch: 9 / 10, Batch: 258 (8288 / 12512), Elapsed time: 72.74 mins\n",
      "Enc Loss = 132.37, KL Divergence = 1116.62, Reconstruction Loss = 319.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.76 mins\n",
      "Epoch: 9 / 10, Batch: 259 (8320 / 12512), Elapsed time: 72.76 mins\n",
      "Enc Loss = 129.56, KL Divergence = 1075.97, Reconstruction Loss = 314.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.78 mins\n",
      "Epoch: 9 / 10, Batch: 260 (8352 / 12512), Elapsed time: 72.78 mins\n",
      "Enc Loss = 151.17, KL Divergence = 1368.87, Reconstruction Loss = 355.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.80 mins\n",
      "Epoch: 9 / 10, Batch: 261 (8384 / 12512), Elapsed time: 72.80 mins\n",
      "Enc Loss = 133.33, KL Divergence = 1135.29, Reconstruction Loss = 320.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.82 mins\n",
      "Epoch: 9 / 10, Batch: 262 (8416 / 12512), Elapsed time: 72.82 mins\n",
      "Enc Loss = 152.60, KL Divergence = 1350.82, Reconstruction Loss = 361.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.84 mins\n",
      "Epoch: 9 / 10, Batch: 263 (8448 / 12512), Elapsed time: 72.84 mins\n",
      "Enc Loss = 127.36, KL Divergence = 1216.69, Reconstruction Loss = 292.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.86 mins\n",
      "Epoch: 9 / 10, Batch: 264 (8480 / 12512), Elapsed time: 72.86 mins\n",
      "Enc Loss = 140.61, KL Divergence = 1209.99, Reconstruction Loss = 336.87, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.88 mins\n",
      "Epoch: 9 / 10, Batch: 265 (8512 / 12512), Elapsed time: 72.88 mins\n",
      "Enc Loss = 141.47, KL Divergence = 1251.69, Reconstruction Loss = 335.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.90 mins\n",
      "Epoch: 9 / 10, Batch: 266 (8544 / 12512), Elapsed time: 72.90 mins\n",
      "Enc Loss = 131.57, KL Divergence = 1133.01, Reconstruction Loss = 315.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.92 mins\n",
      "Epoch: 9 / 10, Batch: 267 (8576 / 12512), Elapsed time: 72.92 mins\n",
      "Enc Loss = 128.06, KL Divergence = 1164.50, Reconstruction Loss = 300.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.94 mins\n",
      "Epoch: 9 / 10, Batch: 268 (8608 / 12512), Elapsed time: 72.94 mins\n",
      "Enc Loss = 128.13, KL Divergence = 1222.59, Reconstruction Loss = 294.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.96 mins\n",
      "Epoch: 9 / 10, Batch: 269 (8640 / 12512), Elapsed time: 72.96 mins\n",
      "Enc Loss = 136.08, KL Divergence = 1118.68, Reconstruction Loss = 331.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 72.98 mins\n",
      "Epoch: 9 / 10, Batch: 270 (8672 / 12512), Elapsed time: 72.98 mins\n",
      "Enc Loss = 136.12, KL Divergence = 1192.33, Reconstruction Loss = 323.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.00 mins\n",
      "Epoch: 9 / 10, Batch: 271 (8704 / 12512), Elapsed time: 73.00 mins\n",
      "Enc Loss = 135.08, KL Divergence = 1085.84, Reconstruction Loss = 331.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.02 mins\n",
      "Epoch: 9 / 10, Batch: 272 (8736 / 12512), Elapsed time: 73.02 mins\n",
      "Enc Loss = 153.39, KL Divergence = 1166.22, Reconstruction Loss = 383.22, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.04 mins\n",
      "Epoch: 9 / 10, Batch: 273 (8768 / 12512), Elapsed time: 73.04 mins\n",
      "Enc Loss = 140.77, KL Divergence = 1107.20, Reconstruction Loss = 347.88, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.06 mins\n",
      "Epoch: 9 / 10, Batch: 274 (8800 / 12512), Elapsed time: 73.06 mins\n",
      "Enc Loss = 136.82, KL Divergence = 992.68, Reconstruction Loss = 346.70, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.08 mins\n",
      "Epoch: 9 / 10, Batch: 275 (8832 / 12512), Elapsed time: 73.08 mins\n",
      "Enc Loss = 132.14, KL Divergence = 1068.15, Reconstruction Loss = 323.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.10 mins\n",
      "Epoch: 9 / 10, Batch: 276 (8864 / 12512), Elapsed time: 73.10 mins\n",
      "Enc Loss = 140.45, KL Divergence = 1188.99, Reconstruction Loss = 338.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.12 mins\n",
      "Epoch: 9 / 10, Batch: 277 (8896 / 12512), Elapsed time: 73.12 mins\n",
      "Enc Loss = 136.39, KL Divergence = 1091.99, Reconstruction Loss = 335.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.14 mins\n",
      "Epoch: 9 / 10, Batch: 278 (8928 / 12512), Elapsed time: 73.14 mins\n",
      "Enc Loss = 130.26, KL Divergence = 1137.29, Reconstruction Loss = 310.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.16 mins\n",
      "Epoch: 9 / 10, Batch: 279 (8960 / 12512), Elapsed time: 73.16 mins\n",
      "Enc Loss = 143.45, KL Divergence = 1262.52, Reconstruction Loss = 340.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.18 mins\n",
      "Epoch: 9 / 10, Batch: 280 (8992 / 12512), Elapsed time: 73.18 mins\n",
      "Enc Loss = 144.22, KL Divergence = 1213.18, Reconstruction Loss = 348.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.20 mins\n",
      "Epoch: 9 / 10, Batch: 281 (9024 / 12512), Elapsed time: 73.20 mins\n",
      "Enc Loss = 141.34, KL Divergence = 1157.74, Reconstruction Loss = 344.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.22 mins\n",
      "Epoch: 9 / 10, Batch: 282 (9056 / 12512), Elapsed time: 73.22 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 139.89, KL Divergence = 1122.97, Reconstruction Loss = 343.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.24 mins\n",
      "Epoch: 9 / 10, Batch: 283 (9088 / 12512), Elapsed time: 73.24 mins\n",
      "Enc Loss = 125.41, KL Divergence = 1090.67, Reconstruction Loss = 299.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.26 mins\n",
      "Epoch: 9 / 10, Batch: 284 (9120 / 12512), Elapsed time: 73.26 mins\n",
      "Enc Loss = 137.02, KL Divergence = 1218.76, Reconstruction Loss = 324.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.28 mins\n",
      "Epoch: 9 / 10, Batch: 285 (9152 / 12512), Elapsed time: 73.28 mins\n",
      "Enc Loss = 128.50, KL Divergence = 1064.99, Reconstruction Loss = 312.00, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.30 mins\n",
      "Epoch: 9 / 10, Batch: 286 (9184 / 12512), Elapsed time: 73.30 mins\n",
      "Enc Loss = 133.38, KL Divergence = 1139.69, Reconstruction Loss = 320.36, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.32 mins\n",
      "Epoch: 9 / 10, Batch: 287 (9216 / 12512), Elapsed time: 73.32 mins\n",
      "Enc Loss = 128.83, KL Divergence = 1022.03, Reconstruction Loss = 317.52, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.34 mins\n",
      "Epoch: 9 / 10, Batch: 288 (9248 / 12512), Elapsed time: 73.34 mins\n",
      "Enc Loss = 127.04, KL Divergence = 976.87, Reconstruction Loss = 316.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.36 mins\n",
      "Epoch: 9 / 10, Batch: 289 (9280 / 12512), Elapsed time: 73.36 mins\n",
      "Enc Loss = 129.63, KL Divergence = 1068.71, Reconstruction Loss = 315.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.38 mins\n",
      "Epoch: 9 / 10, Batch: 290 (9312 / 12512), Elapsed time: 73.38 mins\n",
      "Enc Loss = 117.54, KL Divergence = 941.99, Reconstruction Loss = 288.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.40 mins\n",
      "Epoch: 9 / 10, Batch: 291 (9344 / 12512), Elapsed time: 73.40 mins\n",
      "Enc Loss = 133.57, KL Divergence = 1049.54, Reconstruction Loss = 330.23, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.42 mins\n",
      "Epoch: 9 / 10, Batch: 292 (9376 / 12512), Elapsed time: 73.42 mins\n",
      "Enc Loss = 140.37, KL Divergence = 1068.61, Reconstruction Loss = 350.54, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.44 mins\n",
      "Epoch: 9 / 10, Batch: 293 (9408 / 12512), Elapsed time: 73.44 mins\n",
      "Enc Loss = 123.13, KL Divergence = 984.22, Reconstruction Loss = 302.67, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.46 mins\n",
      "Epoch: 9 / 10, Batch: 294 (9440 / 12512), Elapsed time: 73.46 mins\n",
      "Enc Loss = 143.69, KL Divergence = 1074.10, Reconstruction Loss = 360.85, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.48 mins\n",
      "Epoch: 9 / 10, Batch: 295 (9472 / 12512), Elapsed time: 73.48 mins\n",
      "Enc Loss = 135.78, KL Divergence = 1067.88, Reconstruction Loss = 335.57, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.50 mins\n",
      "Epoch: 9 / 10, Batch: 296 (9504 / 12512), Elapsed time: 73.50 mins\n",
      "Enc Loss = 128.51, KL Divergence = 1068.71, Reconstruction Loss = 311.66, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.52 mins\n",
      "Epoch: 9 / 10, Batch: 297 (9536 / 12512), Elapsed time: 73.52 mins\n",
      "Enc Loss = 162.40, KL Divergence = 1188.28, Reconstruction Loss = 410.46, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.54 mins\n",
      "Epoch: 9 / 10, Batch: 298 (9568 / 12512), Elapsed time: 73.54 mins\n",
      "Enc Loss = 144.65, KL Divergence = 1053.77, Reconstruction Loss = 366.08, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.56 mins\n",
      "Epoch: 9 / 10, Batch: 299 (9600 / 12512), Elapsed time: 73.56 mins\n",
      "Enc Loss = 141.65, KL Divergence = 1236.17, Reconstruction Loss = 337.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.58 mins\n",
      "Epoch: 9 / 10, Batch: 300 (9632 / 12512), Elapsed time: 73.58 mins\n",
      "Enc Loss = 128.56, KL Divergence = 1194.47, Reconstruction Loss = 298.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.60 mins\n",
      "Epoch: 9 / 10, Batch: 301 (9664 / 12512), Elapsed time: 73.60 mins\n",
      "Enc Loss = 142.50, KL Divergence = 1320.68, Reconstruction Loss = 331.71, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.62 mins\n",
      "Epoch: 9 / 10, Batch: 302 (9696 / 12512), Elapsed time: 73.62 mins\n",
      "Enc Loss = 140.93, KL Divergence = 1341.15, Reconstruction Loss = 324.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.64 mins\n",
      "Epoch: 9 / 10, Batch: 303 (9728 / 12512), Elapsed time: 73.64 mins\n",
      "Enc Loss = 135.79, KL Divergence = 1271.53, Reconstruction Loss = 314.78, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.66 mins\n",
      "Epoch: 9 / 10, Batch: 304 (9760 / 12512), Elapsed time: 73.67 mins\n",
      "Enc Loss = 133.79, KL Divergence = 1193.85, Reconstruction Loss = 316.17, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.68 mins\n",
      "Epoch: 9 / 10, Batch: 305 (9792 / 12512), Elapsed time: 73.69 mins\n",
      "Enc Loss = 126.98, KL Divergence = 1124.66, Reconstruction Loss = 300.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.71 mins\n",
      "Epoch: 9 / 10, Batch: 306 (9824 / 12512), Elapsed time: 73.71 mins\n",
      "Enc Loss = 134.69, KL Divergence = 1135.29, Reconstruction Loss = 325.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.73 mins\n",
      "Epoch: 9 / 10, Batch: 307 (9856 / 12512), Elapsed time: 73.73 mins\n",
      "Enc Loss = 132.42, KL Divergence = 1089.57, Reconstruction Loss = 322.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.75 mins\n",
      "Epoch: 9 / 10, Batch: 308 (9888 / 12512), Elapsed time: 73.75 mins\n",
      "Enc Loss = 122.56, KL Divergence = 1061.23, Reconstruction Loss = 292.94, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.77 mins\n",
      "Epoch: 9 / 10, Batch: 309 (9920 / 12512), Elapsed time: 73.77 mins\n",
      "Enc Loss = 151.42, KL Divergence = 1139.95, Reconstruction Loss = 379.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.79 mins\n",
      "Epoch: 9 / 10, Batch: 310 (9952 / 12512), Elapsed time: 73.79 mins\n",
      "Enc Loss = 128.46, KL Divergence = 1029.17, Reconstruction Loss = 315.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.81 mins\n",
      "Epoch: 9 / 10, Batch: 311 (9984 / 12512), Elapsed time: 73.81 mins\n",
      "Enc Loss = 134.73, KL Divergence = 1034.46, Reconstruction Loss = 335.55, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.83 mins\n",
      "Epoch: 9 / 10, Batch: 312 (10016 / 12512), Elapsed time: 73.83 mins\n",
      "Enc Loss = 123.05, KL Divergence = 985.36, Reconstruction Loss = 302.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.85 mins\n",
      "Epoch: 9 / 10, Batch: 313 (10048 / 12512), Elapsed time: 73.85 mins\n",
      "Enc Loss = 125.08, KL Divergence = 1008.73, Reconstruction Loss = 306.56, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.87 mins\n",
      "Epoch: 9 / 10, Batch: 314 (10080 / 12512), Elapsed time: 73.87 mins\n",
      "Enc Loss = 136.32, KL Divergence = 1058.54, Reconstruction Loss = 338.30, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.89 mins\n",
      "Epoch: 9 / 10, Batch: 315 (10112 / 12512), Elapsed time: 73.89 mins\n",
      "Enc Loss = 137.78, KL Divergence = 1136.88, Reconstruction Loss = 335.05, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.91 mins\n",
      "Epoch: 9 / 10, Batch: 316 (10144 / 12512), Elapsed time: 73.91 mins\n",
      "Enc Loss = 130.59, KL Divergence = 1008.30, Reconstruction Loss = 324.65, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.93 mins\n",
      "Epoch: 9 / 10, Batch: 317 (10176 / 12512), Elapsed time: 73.93 mins\n",
      "Enc Loss = 127.30, KL Divergence = 1124.27, Reconstruction Loss = 302.02, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.95 mins\n",
      "Epoch: 9 / 10, Batch: 318 (10208 / 12512), Elapsed time: 73.95 mins\n",
      "Enc Loss = 134.06, KL Divergence = 1083.43, Reconstruction Loss = 328.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.97 mins\n",
      "Epoch: 9 / 10, Batch: 319 (10240 / 12512), Elapsed time: 73.97 mins\n",
      "Enc Loss = 128.91, KL Divergence = 1035.18, Reconstruction Loss = 316.41, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 73.99 mins\n",
      "Epoch: 9 / 10, Batch: 320 (10272 / 12512), Elapsed time: 73.99 mins\n",
      "Enc Loss = 135.48, KL Divergence = 1208.11, Reconstruction Loss = 320.25, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.01 mins\n",
      "Epoch: 9 / 10, Batch: 321 (10304 / 12512), Elapsed time: 74.01 mins\n",
      "Enc Loss = 144.57, KL Divergence = 1111.38, Reconstruction Loss = 359.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.03 mins\n",
      "Epoch: 9 / 10, Batch: 322 (10336 / 12512), Elapsed time: 74.03 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc Loss = 146.33, KL Divergence = 1140.96, Reconstruction Loss = 362.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.05 mins\n",
      "Epoch: 9 / 10, Batch: 323 (10368 / 12512), Elapsed time: 74.05 mins\n",
      "Enc Loss = 139.47, KL Divergence = 1114.22, Reconstruction Loss = 342.91, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.07 mins\n",
      "Epoch: 9 / 10, Batch: 324 (10400 / 12512), Elapsed time: 74.07 mins\n",
      "Enc Loss = 181.85, KL Divergence = 1259.18, Reconstruction Loss = 466.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.09 mins\n",
      "Epoch: 9 / 10, Batch: 325 (10432 / 12512), Elapsed time: 74.09 mins\n",
      "Enc Loss = 133.48, KL Divergence = 1249.49, Reconstruction Loss = 309.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.11 mins\n",
      "Epoch: 9 / 10, Batch: 326 (10464 / 12512), Elapsed time: 74.11 mins\n",
      "Enc Loss = 134.87, KL Divergence = 1152.16, Reconstruction Loss = 323.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.13 mins\n",
      "Epoch: 9 / 10, Batch: 327 (10496 / 12512), Elapsed time: 74.13 mins\n",
      "Enc Loss = 142.12, KL Divergence = 1208.67, Reconstruction Loss = 341.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.15 mins\n",
      "Epoch: 9 / 10, Batch: 328 (10528 / 12512), Elapsed time: 74.15 mins\n",
      "Enc Loss = 142.06, KL Divergence = 1342.04, Reconstruction Loss = 328.09, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.17 mins\n",
      "Epoch: 9 / 10, Batch: 329 (10560 / 12512), Elapsed time: 74.17 mins\n",
      "Enc Loss = 131.39, KL Divergence = 1228.61, Reconstruction Loss = 304.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.19 mins\n",
      "Epoch: 9 / 10, Batch: 330 (10592 / 12512), Elapsed time: 74.19 mins\n",
      "Enc Loss = 136.72, KL Divergence = 1257.90, Reconstruction Loss = 319.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.21 mins\n",
      "Epoch: 9 / 10, Batch: 331 (10624 / 12512), Elapsed time: 74.21 mins\n",
      "Enc Loss = 131.54, KL Divergence = 1151.36, Reconstruction Loss = 313.13, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.23 mins\n",
      "Epoch: 9 / 10, Batch: 332 (10656 / 12512), Elapsed time: 74.23 mins\n",
      "Enc Loss = 133.98, KL Divergence = 1114.33, Reconstruction Loss = 324.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.25 mins\n",
      "Epoch: 9 / 10, Batch: 333 (10688 / 12512), Elapsed time: 74.25 mins\n",
      "Enc Loss = 154.78, KL Divergence = 1038.70, Reconstruction Loss = 400.83, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.27 mins\n",
      "Epoch: 9 / 10, Batch: 334 (10720 / 12512), Elapsed time: 74.27 mins\n",
      "Enc Loss = 153.22, KL Divergence = 1304.99, Reconstruction Loss = 368.44, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.29 mins\n",
      "Epoch: 9 / 10, Batch: 335 (10752 / 12512), Elapsed time: 74.29 mins\n",
      "Enc Loss = 135.50, KL Divergence = 1184.28, Reconstruction Loss = 322.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.31 mins\n",
      "Epoch: 9 / 10, Batch: 336 (10784 / 12512), Elapsed time: 74.31 mins\n",
      "Enc Loss = 120.90, KL Divergence = 1075.24, Reconstruction Loss = 286.06, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.33 mins\n",
      "Epoch: 9 / 10, Batch: 337 (10816 / 12512), Elapsed time: 74.33 mins\n",
      "Enc Loss = 125.97, KL Divergence = 1058.70, Reconstruction Loss = 304.37, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.35 mins\n",
      "Epoch: 9 / 10, Batch: 338 (10848 / 12512), Elapsed time: 74.35 mins\n",
      "Enc Loss = 131.07, KL Divergence = 1135.35, Reconstruction Loss = 313.21, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.37 mins\n",
      "Epoch: 9 / 10, Batch: 339 (10880 / 12512), Elapsed time: 74.37 mins\n",
      "Enc Loss = 141.78, KL Divergence = 1140.42, Reconstruction Loss = 347.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.39 mins\n",
      "Epoch: 9 / 10, Batch: 340 (10912 / 12512), Elapsed time: 74.39 mins\n",
      "Enc Loss = 126.35, KL Divergence = 1045.36, Reconstruction Loss = 306.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.41 mins\n",
      "Epoch: 9 / 10, Batch: 341 (10944 / 12512), Elapsed time: 74.41 mins\n",
      "Enc Loss = 148.56, KL Divergence = 1215.50, Reconstruction Loss = 362.35, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.43 mins\n",
      "Epoch: 9 / 10, Batch: 342 (10976 / 12512), Elapsed time: 74.43 mins\n",
      "Enc Loss = 133.08, KL Divergence = 1109.51, Reconstruction Loss = 322.45, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.45 mins\n",
      "Epoch: 9 / 10, Batch: 343 (11008 / 12512), Elapsed time: 74.45 mins\n",
      "Enc Loss = 139.03, KL Divergence = 1164.43, Reconstruction Loss = 336.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.47 mins\n",
      "Epoch: 9 / 10, Batch: 344 (11040 / 12512), Elapsed time: 74.47 mins\n",
      "Enc Loss = 134.61, KL Divergence = 1034.39, Reconstruction Loss = 335.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.49 mins\n",
      "Epoch: 9 / 10, Batch: 345 (11072 / 12512), Elapsed time: 74.49 mins\n",
      "Enc Loss = 130.36, KL Divergence = 1109.18, Reconstruction Loss = 313.58, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.51 mins\n",
      "Epoch: 9 / 10, Batch: 346 (11104 / 12512), Elapsed time: 74.51 mins\n",
      "Enc Loss = 139.70, KL Divergence = 1080.81, Reconstruction Loss = 347.10, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.53 mins\n",
      "Epoch: 9 / 10, Batch: 347 (11136 / 12512), Elapsed time: 74.53 mins\n",
      "Enc Loss = 127.28, KL Divergence = 983.87, Reconstruction Loss = 316.31, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.55 mins\n",
      "Epoch: 9 / 10, Batch: 348 (11168 / 12512), Elapsed time: 74.56 mins\n",
      "Enc Loss = 161.23, KL Divergence = 1160.29, Reconstruction Loss = 409.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.57 mins\n",
      "Epoch: 9 / 10, Batch: 349 (11200 / 12512), Elapsed time: 74.57 mins\n",
      "Enc Loss = 127.84, KL Divergence = 1063.94, Reconstruction Loss = 309.96, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.59 mins\n",
      "Epoch: 9 / 10, Batch: 350 (11232 / 12512), Elapsed time: 74.59 mins\n",
      "Enc Loss = 124.02, KL Divergence = 1044.85, Reconstruction Loss = 299.38, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.61 mins\n",
      "Epoch: 9 / 10, Batch: 351 (11264 / 12512), Elapsed time: 74.61 mins\n",
      "Enc Loss = 129.23, KL Divergence = 1007.47, Reconstruction Loss = 320.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.63 mins\n",
      "Epoch: 9 / 10, Batch: 352 (11296 / 12512), Elapsed time: 74.63 mins\n",
      "Enc Loss = 127.34, KL Divergence = 1029.93, Reconstruction Loss = 311.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.65 mins\n",
      "Epoch: 9 / 10, Batch: 353 (11328 / 12512), Elapsed time: 74.65 mins\n",
      "Enc Loss = 132.09, KL Divergence = 1070.69, Reconstruction Loss = 323.18, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.67 mins\n",
      "Epoch: 9 / 10, Batch: 354 (11360 / 12512), Elapsed time: 74.67 mins\n",
      "Enc Loss = 137.82, KL Divergence = 1124.58, Reconstruction Loss = 336.47, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.69 mins\n",
      "Epoch: 9 / 10, Batch: 355 (11392 / 12512), Elapsed time: 74.69 mins\n",
      "Enc Loss = 137.71, KL Divergence = 1118.51, Reconstruction Loss = 336.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.71 mins\n",
      "Epoch: 9 / 10, Batch: 356 (11424 / 12512), Elapsed time: 74.71 mins\n",
      "Enc Loss = 136.95, KL Divergence = 1114.04, Reconstruction Loss = 334.68, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.73 mins\n",
      "Epoch: 9 / 10, Batch: 357 (11456 / 12512), Elapsed time: 74.73 mins\n",
      "Enc Loss = 148.54, KL Divergence = 1179.18, Reconstruction Loss = 365.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.75 mins\n",
      "Epoch: 9 / 10, Batch: 358 (11488 / 12512), Elapsed time: 74.75 mins\n",
      "Enc Loss = 124.46, KL Divergence = 948.87, Reconstruction Loss = 310.69, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.77 mins\n",
      "Epoch: 9 / 10, Batch: 359 (11520 / 12512), Elapsed time: 74.77 mins\n",
      "Enc Loss = 123.15, KL Divergence = 966.17, Reconstruction Loss = 304.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.79 mins\n",
      "Epoch: 9 / 10, Batch: 360 (11552 / 12512), Elapsed time: 74.79 mins\n",
      "Enc Loss = 145.87, KL Divergence = 1109.81, Reconstruction Loss = 364.34, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.81 mins\n",
      "Epoch: 9 / 10, Batch: 361 (11584 / 12512), Elapsed time: 74.81 mins\n",
      "Enc Loss = 126.30, KL Divergence = 1012.95, Reconstruction Loss = 310.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.83 mins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 / 10, Batch: 362 (11616 / 12512), Elapsed time: 74.83 mins\n",
      "Enc Loss = 128.77, KL Divergence = 1082.03, Reconstruction Loss = 311.14, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.85 mins\n",
      "Epoch: 9 / 10, Batch: 363 (11648 / 12512), Elapsed time: 74.85 mins\n",
      "Enc Loss = 125.87, KL Divergence = 1109.74, Reconstruction Loss = 298.80, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.87 mins\n",
      "Epoch: 9 / 10, Batch: 364 (11680 / 12512), Elapsed time: 74.87 mins\n",
      "Enc Loss = 123.60, KL Divergence = 1048.70, Reconstruction Loss = 297.64, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.90 mins\n",
      "Epoch: 9 / 10, Batch: 365 (11712 / 12512), Elapsed time: 74.90 mins\n",
      "Enc Loss = 132.15, KL Divergence = 1146.72, Reconstruction Loss = 315.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.92 mins\n",
      "Epoch: 9 / 10, Batch: 366 (11744 / 12512), Elapsed time: 74.92 mins\n",
      "Enc Loss = 123.97, KL Divergence = 1071.90, Reconstruction Loss = 296.49, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.93 mins\n",
      "Epoch: 9 / 10, Batch: 367 (11776 / 12512), Elapsed time: 74.94 mins\n",
      "Enc Loss = 127.96, KL Divergence = 1102.41, Reconstruction Loss = 306.39, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.95 mins\n",
      "Epoch: 9 / 10, Batch: 368 (11808 / 12512), Elapsed time: 74.95 mins\n",
      "Enc Loss = 140.87, KL Divergence = 1168.89, Reconstruction Loss = 341.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 74.97 mins\n",
      "Epoch: 9 / 10, Batch: 369 (11840 / 12512), Elapsed time: 74.98 mins\n",
      "Enc Loss = 133.24, KL Divergence = 1063.47, Reconstruction Loss = 327.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.00 mins\n",
      "Epoch: 9 / 10, Batch: 370 (11872 / 12512), Elapsed time: 75.00 mins\n",
      "Enc Loss = 137.05, KL Divergence = 1126.72, Reconstruction Loss = 333.72, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.02 mins\n",
      "Epoch: 9 / 10, Batch: 371 (11904 / 12512), Elapsed time: 75.02 mins\n",
      "Enc Loss = 119.51, KL Divergence = 1012.53, Reconstruction Loss = 287.93, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.04 mins\n",
      "Epoch: 9 / 10, Batch: 372 (11936 / 12512), Elapsed time: 75.04 mins\n",
      "Enc Loss = 131.93, KL Divergence = 1127.93, Reconstruction Loss = 316.81, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.06 mins\n",
      "Epoch: 9 / 10, Batch: 373 (11968 / 12512), Elapsed time: 75.06 mins\n",
      "Enc Loss = 134.41, KL Divergence = 1166.74, Reconstruction Loss = 320.98, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.08 mins\n",
      "Epoch: 9 / 10, Batch: 374 (12000 / 12512), Elapsed time: 75.08 mins\n",
      "Enc Loss = 132.90, KL Divergence = 1095.80, Reconstruction Loss = 323.28, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.10 mins\n",
      "Epoch: 9 / 10, Batch: 375 (12032 / 12512), Elapsed time: 75.10 mins\n",
      "Enc Loss = 129.67, KL Divergence = 1007.21, Reconstruction Loss = 321.75, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.12 mins\n",
      "Epoch: 9 / 10, Batch: 376 (12064 / 12512), Elapsed time: 75.12 mins\n",
      "Enc Loss = 133.02, KL Divergence = 1086.67, Reconstruction Loss = 324.59, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.14 mins\n",
      "Epoch: 9 / 10, Batch: 377 (12096 / 12512), Elapsed time: 75.14 mins\n",
      "Enc Loss = 138.38, KL Divergence = 1192.53, Reconstruction Loss = 331.32, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.16 mins\n",
      "Epoch: 9 / 10, Batch: 378 (12128 / 12512), Elapsed time: 75.16 mins\n",
      "Enc Loss = 125.82, KL Divergence = 981.90, Reconstruction Loss = 311.74, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.18 mins\n",
      "Epoch: 9 / 10, Batch: 379 (12160 / 12512), Elapsed time: 75.18 mins\n",
      "Enc Loss = 133.30, KL Divergence = 1105.55, Reconstruction Loss = 323.60, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.20 mins\n",
      "Epoch: 9 / 10, Batch: 380 (12192 / 12512), Elapsed time: 75.20 mins\n",
      "Enc Loss = 133.46, KL Divergence = 1127.03, Reconstruction Loss = 321.92, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.22 mins\n",
      "Epoch: 9 / 10, Batch: 381 (12224 / 12512), Elapsed time: 75.22 mins\n",
      "Enc Loss = 183.83, KL Divergence = 1151.66, Reconstruction Loss = 484.43, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.24 mins\n",
      "Epoch: 9 / 10, Batch: 382 (12256 / 12512), Elapsed time: 75.24 mins\n",
      "Enc Loss = 139.20, KL Divergence = 1169.32, Reconstruction Loss = 336.40, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.26 mins\n",
      "Epoch: 9 / 10, Batch: 383 (12288 / 12512), Elapsed time: 75.26 mins\n",
      "Enc Loss = 132.41, KL Divergence = 1047.68, Reconstruction Loss = 326.61, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.28 mins\n",
      "Epoch: 9 / 10, Batch: 384 (12320 / 12512), Elapsed time: 75.28 mins\n",
      "Enc Loss = 137.35, KL Divergence = 1199.99, Reconstruction Loss = 327.19, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.30 mins\n",
      "Epoch: 9 / 10, Batch: 385 (12352 / 12512), Elapsed time: 75.30 mins\n",
      "Enc Loss = 144.51, KL Divergence = 1223.92, Reconstruction Loss = 348.20, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.32 mins\n",
      "Epoch: 9 / 10, Batch: 386 (12384 / 12512), Elapsed time: 75.32 mins\n",
      "Enc Loss = 139.88, KL Divergence = 1227.80, Reconstruction Loss = 332.63, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.34 mins\n",
      "Epoch: 9 / 10, Batch: 387 (12416 / 12512), Elapsed time: 75.34 mins\n",
      "Enc Loss = 126.40, KL Divergence = 1180.71, Reconstruction Loss = 293.27, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.36 mins\n",
      "Epoch: 9 / 10, Batch: 388 (12448 / 12512), Elapsed time: 75.36 mins\n",
      "Enc Loss = 128.96, KL Divergence = 1215.00, Reconstruction Loss = 298.15, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.38 mins\n",
      "Epoch: 9 / 10, Batch: 389 (12480 / 12512), Elapsed time: 75.38 mins\n",
      "Enc Loss = 138.48, KL Divergence = 1167.33, Reconstruction Loss = 334.26, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.40 mins\n",
      "Epoch: 9 / 10, Batch: 390 (12512 / 12512), Elapsed time: 75.40 mins\n",
      "Enc Loss = 123.40, KL Divergence = 504.19, Reconstruction Loss = 352.73, -dis_Loss = 999.00, dec_Loss = -999.00, Elapsed time: 75.42 mins\n",
      "Model saved in path: /home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/model_epoch-9.ckpt\n",
      "Metrics saved in path: /home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/metrics.json\n",
      "Did not save experiment metrics\n",
      "Done train_vaegan.py main\n",
      "Finished after 1:15:28.\n",
      "Completed after 1:15:28\n",
      "Stopping Heartbeat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sacred.run.Run at 0x7fd65b8dc588>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if last_model_dir == model_dir:\n",
    "    print('dont overwrite!')\n",
    "    assert False\n",
    "else:\n",
    "    last_model_dir = model_dir\n",
    "\n",
    "ex.run(config_updates=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructions\n",
    "\n",
    "Here we can reload a model and experiment with reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models.voxel_vaegan import VoxelVaegan\n",
    "from data.voxels import plot_voxels\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 500 epochs, just bird\n",
    "#model = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_09-30-02/model_epoch-499.ckpt'\n",
    "# 500 epochs, just bird, increased recon weight\n",
    "#model = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_09-38-41/model_epoch-499.ckpt'\n",
    "# 500 epochs, just bird, dropout 0.8\n",
    "# early stop\n",
    "#model = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_09-44-48/model_epoch-199.ckpt'\n",
    "# later stop\n",
    "#model = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_09-44-48/model_epoch-499.ckpt'\n",
    "#model = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_10-22-19/model_epoch-49.ckpt'\n",
    "\n",
    "# first run with modelnet10\n",
    "# {'reconstruction_loss': 808.4996337890625, 'dis_loss': -999.0, 'kl_divergence': 488.078369140625, 'dec_loss': -999.0, 'elapsed_time': 43.02408063411713, 'enc_loss': 261.9851379394531}\n",
    "best_toilet = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/2019-03-12_16-36-25/model_epoch-9.ckpt'\n",
    "best_sofa = '/home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/model_epoch-9.ckpt'\n",
    "model = best_sofa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/model_epoch-9.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jcworkma/jack/3d-form/src/../models/voxel_vaegan1/modelnet10/2019-03-15_10-33-37/model_epoch-9.ckpt\n"
     ]
    }
   ],
   "source": [
    "# restore the model from ckpt\n",
    "vaegan = VoxelVaegan.initFromCfg(cfg.get('cfg'))\n",
    "vaegan.restore(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DATASET_CLASS == 'Thingi10k':\n",
    "    # get an stl example\n",
    "    thingi = Thingi10k.init10k()\n",
    "    stl_example = thingi.get_stl_path(stl_id=126660)\n",
    "    training_example = thingi.get_voxels(32, stl_file=stl_example)\n",
    "elif DATASET_CLASS == 'ModelNet10':\n",
    "    modelnet = ModelNet10.initFromIndex(INDEX)\n",
    "    training_example = modelnet.get_random_voxels(32)\n",
    "\n",
    "plot_voxels(training_example)\n",
    "training_example = np.reshape(training_example, (-1, 32, 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  0.997077\n",
      "min:  6.4268085e-10\n",
      "mean:  0.14747371\n"
     ]
    }
   ],
   "source": [
    "recon = vaegan.reconstruct(training_example)\n",
    "recon = np.reshape(recon, [32, 32, 32])\n",
    "print('max: ', np.max(recon))\n",
    "print('min: ', np.min(recon))\n",
    "print('mean: ', np.mean(recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "recon_threshold = recon > 0.7\n",
    "plot_voxels(recon_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3d-form",
   "language": "python",
   "name": ".3d-form"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
