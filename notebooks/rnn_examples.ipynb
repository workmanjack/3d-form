{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Examples\n",
    "\n",
    "An alternative to VAEs for generating STL objects is an RNN or LSTM. The thought is that RNNs generate data sequentially, and this might improve the connectedness of our STL triangles. In other words, an RNN will generate triangle 2 based on triangle 1's vertices whereas a VAE generates each singularly.\n",
    "\n",
    "## I. Andrej Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks\n",
    "\n",
    "From https://www.tensorflow.org/tutorials/sequences/text_generation\n",
    "\n",
    "Uses an RNN to generate Shakespeare-esque text on the character level (not whole words).\n",
    "\n",
    "### I. A. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. B. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. C. Process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'C' :  15,\n",
      "  ' ' :   1,\n",
      "  '$' :   3,\n",
      "  'I' :  21,\n",
      "  ':' :  10,\n",
      "  'Z' :  38,\n",
      "  'G' :  19,\n",
      "  'r' :  56,\n",
      "  'p' :  54,\n",
      "  'f' :  44,\n",
      "  'i' :  47,\n",
      "  'B' :  14,\n",
      "  't' :  58,\n",
      "  'V' :  34,\n",
      "  'N' :  26,\n",
      "  'R' :  30,\n",
      "  '-' :   7,\n",
      "  'x' :  62,\n",
      "  'X' :  36,\n",
      "  'U' :  33,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen' ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(text[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. D. Create Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    print(chunk.shape)\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('F')\n",
      "  expected output: 47 ('i')\n",
      "Step    1\n",
      "  input: 47 ('i')\n",
      "  expected output: 56 ('r')\n",
      "Step    2\n",
      "  input: 56 ('r')\n",
      "  expected output: 57 ('s')\n",
      "Step    3\n",
      "  input: 57 ('s')\n",
      "  expected output: 58 ('t')\n",
      "Step    4\n",
      "  input: 58 ('t')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. E. Create Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size \n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences, \n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead, \n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "    import functools\n",
    "    rnn = functools.partial(\n",
    "      tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        rnn(rnn_units,\n",
    "            return_sequences=True, \n",
    "            recurrent_initializer='glorot_uniform',\n",
    "            stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3935232   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed categorical to multinomial according to https://github.com/tensorflow/tensorflow/issues/24949\n",
    "#sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.random.multinomial(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 44, 56, 50, 39, 43,  1,  0, 41, 39, 61, 56, 41,  1, 46, 39, 42,\n",
       "        1,  1, 54,  1, 56, 49, 51, 24, 43, 35, 43,  8, 58, 53, 58, 39, 57,\n",
       "       59, 56, 41, 43, 58, 39, 46, 43,  6, 57, 39, 34, 43, 57,  1,  1,  1,\n",
       "       50,  1,  1, 57,  1, 47, 39, 46, 52,  1, 43, 58, 57, 59, 53, 43, 19,\n",
       "       56, 30, 58, 41, 59, 57, 53, 57,  5, 44, 39, 58, 41, 58, 58, 43, 58,\n",
       "       56, 58, 51, 50, 44, 40,  1, 58, 43, 59,  0,  1,  1, 50, 57])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \"time heard lions roar?\\nHave I not heard the sea puff'd up with winds\\nRage like an angry boar chafed \"\n",
      "\n",
      "Next Char Predictions: \n",
      " \"efrlae \\ncawrc had  p rkmLeWe.totasurcetahe,saVes   l  s iahn etsuoeGrRtcusos'fatcttetrtmlfb teu\\n  ls\"\n"
     ]
    }
   ],
   "source": [
    "# untrained model - low expectations\n",
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. F. Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       2.8963306\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    # changed to backend thanks to the kind folks at https://github.com/tensorflow/tensorflow/blob/r1.12/tensorflow/python/keras/losses.py\n",
    "    #return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "    return tf.keras.backend.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. G. Configure Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './_output/training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. H. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "174/174 [==============================] - 397s 2s/step - loss: 2.1839\n",
      "Epoch 2/3\n",
      "174/174 [==============================] - 396s 2s/step - loss: 1.7289\n",
      "Epoch 3/3\n",
      "174/174 [==============================] - 396s 2s/step - loss: 1.5371\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. I. Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./_output/training_checkpoints'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 4,018,497\n",
      "Trainable params: 4,018,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing) \n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperatures results in more predictable text.\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # using a multinomial distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: go dost I so, were that?\n",
      "\n",
      "SAMPSOG:\n",
      "The norst intently wholuny;\n",
      "Fau, you appaired, who?\n",
      "\n",
      "MENENIUS:\n",
      "The presset my lebst:\n",
      "Veater words not for Furlo, and now for me, night, hose\n",
      "Wonder's naturn hither fither call our ghart cau\n",
      "Wo she would not\n",
      "Extone endroation, in the is fall'd with a do\n",
      "Answle vere in his heart.\n",
      "\n",
      "LEONTES:\n",
      "Alas! I have, for my liverd;\n",
      "I have you fush any that I am hows but door\n",
      "Can can be rique'dlease of his land:\n",
      "The foot of whice: I am,.\n",
      "\n",
      "Pitizens:\n",
      "Sweet arms, I surply to see. What's wishes in distransmen forgot:\n",
      "We thank you genlet him's son.\n",
      "\n",
      "PETRUCHIO:\n",
      "'Tis tomens of guttlemen and wlitted thee with what\n",
      "I fiald should root Peasen call for thy socrep of like\n",
      "And Croble in Edward Beholding some, and so father;\n",
      "Trumsful by thee instarter.\n",
      "And if you will.\n",
      "\n",
      "FERDI VONGENThey health, out doth kill do his father\n",
      "Now wixes my be a capoler, where is it break do proy her son.\n",
      "\n",
      "MENENIUS:\n",
      "The father Praming rame\n",
      "To the Bosh; gentleme:\n",
      "For it is like law, E wnock fos longers:-I\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. J. Advanced: Customized Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.1738\n",
      "Epoch 1 Batch 100 Loss 2.3267\n",
      "Epoch 1 Loss 2.1012\n",
      "Time taken for 1 epoch 392.35351943969727 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training step\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    # initializing the hidden state at the start of every epoch\n",
    "    # initally hidden is None\n",
    "    hidden = model.reset_states()\n",
    "    \n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # feeding the hidden state back into the model\n",
    "            # This is the interesting step\n",
    "            predictions = model(inp)\n",
    "            loss = tf.losses.sparse_softmax_cross_entropy(target, predictions)\n",
    "              \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            template = 'Epoch {} Batch {} Loss {:.4f}'\n",
    "            print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. K. Tutorial Complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Time-Series RNN/LSTM\n",
    "\n",
    "From: https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8\n",
    "\n",
    "Code: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/timeseries/rnn_cloudmle.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# import the tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/seaborn/timeseries.py:183: UserWarning: The `tsplot` function is deprecated and will be removed in a future release. Please update your code to use the new `lineplot` function.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD9CAYAAABUS3cAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4VNXWh98zmfROek+AVAgJpFBFAQGpKiJFuiDY9bNdr/1eu16716vSe0fpoijSIQ1SSAPSe++Zfr4/JkSQDiH1vM/DMzNn9jmzEjK/vc/aqwiiKCIhISEh0bWQtbUBEhISEhKtjyT+EhISEl0QSfwlJCQkuiCS+EtISEh0QSTxl5CQkOiCSOIvISEh0QVpEfEXBGGZIAglgiAkXeX9ewRBqBYE4XTTv7da4nMlJCQkJG4NeQtdZwXwLbDqGmMOi6I4voU+T0JCQkLiNmiRlb8oioeAipa4loSEhITEnac1ff4DBUGIFwRhryAIvVrxcyUkJCQk/kZLuX2uRxzgJYpinSAIY4GfAd+/DxIEYSGwEMDc3DwsICCglcyTkJCQ6BzExsaWiaLocL1xQkvV9hEEwRvYJYpi7xsYmwWEi6JYdrUx4eHhYkxMTIvYJiEhIdFVEAQhVhTF8OuNaxW3jyAIzoIgCE3PI5s+t7w1PltCQkJC4nJaxO0jCMJ64B7AXhCEPOBtwBBAFMXvgcnAE4IgaIBGYJoolROVkJCQaDNaRPxFUZx+nfe/RR8KKiEhISHRDpAyfCUkJCS6IJL4S0hISHRBJPGXkJCQ6IJI4i8hISHRBWmtJC8JiTZDqxM5cq6M2OxKAARAEEAmCM3PBUHQPyIgE2h+3vweNB2/9Nh1z5FdfuzizzYxMmBgdztMDA3a6tcj0UWRxF+i05JRWseW2Dy2xeVTVKNoa3OuipWJnAf6ujEl3IPebtZtbY5EF0ESf4lORa1Cza6EQrbE5hGbXYlMgLv9HHhrQhAjAh0xMpAhiiACoiiiE0FE5ELWiU4Um9+/8Byx6XnTORfe42/jmt8XaXrddP2Lz20epz+vpFbJtrg8NkTnsup4NkEuVkyN8OCBUDeszQzb5Hco0TVosfIOLY1U3kHiRtHpRI5nlLM5JpdfzhShUOvo6WjB5DB3JvV1w9HKpK1NvC7VDWq2x+ezMTqXMwU1GMll3NfLmakRHgzsbodMJrS1iRIdhBst7yCJv0SHJbu8nq2xeWyNyye/qhFLEzkTQ1x5ONyDEHdrmiqKdDiS8qvZFJPLz6fyqVFo8OhmysNhHkwOc8fVxrStzZNo50jiL9EpqVdq2J2od+tEZVYgCDCkpz0Ph3swKsipU22cKtRa9p0pYmN0LsfOlyMT4C5fB6ZGeHBvoBNGcilYT+JyJPGX6DTodCJRWRVsic1jT2IhDSotPvbmerdOPzdcrDv/ajinvIHNsblsic2jsFpBN3MjHuzrxtQID/ycLNvaPIl2hCT+Eh2evMoGtsbmszUuj5yKBiyM5Yzv48LD4e7087S9YbdOcY2CvYmFJBXUYGIow8xIjqmhAWZG+n8mhgaYGckxMzLA1OjKx43lsnbhRtLqRA6dLWVTdC77U4pRa0VCPWyYGuHB+D4uWJpIm8RdHUn8JTokjSotv5wpZHNMHsfO66t+D+5px+Qwd+7r5YKp0Y25dS4I/p7EIqKzKxBFcLA0RqsTaVBpUKh1N2WXTABTQwNMjeSYGskwM5RfMlGYGskxvTCxGBlgZnhhItGPNzWUXzTWoHkCsjKVY2Z0a0F35XVKfjql3yQ+W1KHqaEB4/q4MDXCg3CvG58cJToXkvhLdBhEUSQ2u5ItsXnsSiikTqnBs5tZs1vH3dbshq5zJcH3d7JkXB8Xxga70NPRonmsTifSqNbSoNLSqNI2PdfQqNIfa1BrUaj0xxrU2r+Oq7QomsZeOLeh6fzGpvGNai1q7Y19r2QCjAh0YtYAL4b0tL+lqB5RFDmVW8Wm6Fx2xhdQr9LS3cGcKeEeTOrnhqNl+492kmg5JPGXaPcUVDXy06l8tsTmkVlWj5mRAWODXXg4zJ0I7243JIQ3I/itiVqru/rEotLSqNbQqNKRXV7Pltg8yutVeNuZMaO/Fw+Hu2NjZnRLn3thQ3xTdC4x2ZUYyASGBzgyNdyDe/wdkBtIm8SdHUn8JdolFyJYtsTmceRcGaII/X26MTnMnbHBLpgbX98F0l4F/1ZRarT8klTEmhPZRGdVYiyXMSHElZkDvG4rZPVcSR2bY3PZGptPWZ0SR0tjHgpzZ0q4Bz725i38U0i0FyTxl2g3iKLI6dwqNsfmsTO+gFqFBjcbUx4Kc+ehfm542V1fiDqb4F+N1KIa1pzI5qe4fOpVWoLdrJk5wJOJIW43vN/xd9RaHQdSS9gUk8uBtFK0OpFIn25MDfdgTLDzLe85SLRPJPGXaHNKahRsa3LrnCupw8RQxpjeerfOgBvIWr2a4I8NdmFcH2d6OnbeEMc6pYafTuWz5ng2acW1WJnImRzmwYwBnvRwuPWJrrhGwda4PDZF55JVro+gmhDiytSIjp0YJ/EXkvhLtBnHzpex+FAGB9NL0YkQ7mXL5DB3xt1AKOKdEHxRFDlTUENSfrW+mqYABjIBA5mATPj7I8hkAgZ/O24g01flvO7xpnNlMvSPQtOxvx03kAk3JLSiKBKTXcnq49nsTSpErRUZ3NOOWQO8uDfQ6ZZ9+KIoEpVZwYboHPYkFqLUiLjamBDkYo2TlTEWJnKsTAyxMpFjaWKIZdOjlelfry2M5FLZiXaIJP4SrY5So+WTX9JYeiQTZysTHgpz46F+7nS/zkr1Tgl+fF41exML2ZtURE5Fw63+WHcUcyMD7glwZGKIK/f4O2Asv7prp7RWyaaYXNadzCG/qhEnK2OmR3oyPdITp6vUL1JpdBRWN5Jf1Uh+pf6xoOrCo4L8qkZUmsvDXg0EAe11tEEQwMJYP0noJ4emCeJvE4aliRwr06bH5jH612ZGBtLdRgsjib9Eq3K2uJZn1p8itaiW2QO9eG1s4DVLLdwJwdfpRE7lVrInsYhfkorIr2pELhMY3NOescHODOqhD6XU6US0OhGtKOqfiyI6nb7K5iXHm56LIpcd14+l6f2msX87fvHYC8d1fxtbVqdk35liKupVWJrIGdPbmYkhbgzsYYfBVVbVWp3IgdQSVp/I5mB6KTIBQj1s6ONujZHc4C+Br2yktE7J37/ijpbGuNma4mpjiruNqf65tf6xXqlh1fFsdsQX0M/Thncm9sLCWE6tQkONQk2tQkNt02ONQkNN49+PXfpao7u2vhjIBCyM5U0Tg+HfJpC/Jg1LE0N6OFjQx926U5XwuBNI4i/RKoiiyJoT2by3OwULYzmfTO7DiECnK469E4Kv1YnEZFWwN6mIvUmFFNcoMTKQcZevPWOCXRgZ6NTuSyOrtTqOnitjR3wBv54ppk6pwcHSmLG9nRnia083MyPyqxXkV168ateLe61Sc8m1BMDW3AhfRwu87MxwtTHFrUng3WxMcbY2uebdxQV+PpXPGz8nIQjw4aRgxvdxvemfSxRFFGpd04SgpkahaZ4Yahr/miD+eu/vY9TUKTVcPH8YGcjo425NuHc3IrxtCfOyveWw2M6KJP4Sd5zyOiWvbEng99QS7vZz4NOH+1yWUHQnBF+j1XEys4I9iYXsO1NEWZ0KY7mMu/0cGBvswvBAR6w6QJkDURTJLm8gt7KhWcxzKhs4U1BDXkUjjWrtZedYmxriZtO0am8SdFcbUxwsjUguqOHn0/mczq3GxFDGA6FuzBzgdcsNYnLKG3h2wylO51YxJdydtyf0uqFQ3JZEFEXqVVqqG9WkFNQQnV1BTFYlCXlVzYl0fk4WzZNBuFc33G1Nu7QrSRJ/iTvKwfRSXtwUT41CzT/HBDBnoHfz5l9FvYodp/NbVPDVWh3Hzpezt0nwKxvUmBoaMDzAkTHBzgzzd2x1YboV6pUajpwr48+0Eg6kll7SYUwmgJOVSfNK3d7CmMoGFWlFtaQU1qATIcDZkgkhrkwMccWj25Uzn5Pyq1l7MpufTxXQqNYS6mHDzAFejO/jctMuE7VWx1f7z/LfP8/hY2fO19P7totuYwq1loS8aqKzKojJqiAmu5Jahf4uyNnKhHBvWyK8uxHubUuAs9VVXWidEUn8Je4ICrV+U3fZ0Uz8nCz4enpfApytAP0qbfvpAt7ecYbqRvVtC75So+XouTL2JBbxW3Ix1Y1qzI0MGBHoxNhgZ+72c7zl2PfWJKO0jgNppRxILSEqswKVVoeFsZy7fO0Z6udAd3tzXJtcMoZXid4pq1OyJ7GQ7acLmnsR9/W04f4QV8b1ccXB0viyc6ob1fwUl8fqE9mcL63HxsyQKeEezOjveUO5FRdz/Hw5/7fxNOX1Sl4ZHcD8IT7tKtJHpxNJK64lJquC6KxKorMqKKzWT6wWxnL6edkS4WVLuHc3Qj1sOsTfza0iib9Ei5NeXMuzTZu6cwd58+qYgOaVZEmtgtd/SuK35GL6etrw3gO96eV68ytEhVrLwfRSfkkqYn9yMbVKDZYmckYGOTGmtwt3+dq3+w0/hVrLycwKDqSW8GdaCVnl+kijno4WDA9w5B5/B8K9ut1yPf68ygZ2xheyI76AlMIaZAIM6mHPxFBXRvdyxtr0UpeXKOo7na09kcO+M0VodCJD/RyY2d+T4QGONxwuWlmv4h9bE/g1uZi7fO35bEpIu64blF/V2DQZ6F1FacW1iCLIZQK93az1biLvboR72WJncfnk2VGRxF+ixRBFkVXHs/lgTwqWJnI+nRzCsADH5vcurPYb1VpeGuXHjP5eVDaomqpgGmAiN7jmKrFBpeHPtFL2JBbyR2oJDSotNmaGjApyYkywC4N72Lf7xiUFVY0cSCvhQGoJR8+V06jWYiyXMaiHXZPgO17VTXM7nC2uZUd8ATviC8gub8DIQMY9/g5MDHVlRIDTZSvc4hoFG6JyWR+VQ1GNAldrEx7p78mUCI8bEnJRFFkXlcO7u5IxN5Lz6cN9GB5w5Q3+9kZ1g5q4nMrmyeB0XlVzmGsPB/MmN5F+78Czm1mH3TeQxF+iRSirU/Ly5ngOpJVyj78Dn04OaXYx/H21/86EXhw9X8bSw5mU16suuY6JoUw/GTRNCMZyAxQaLTWNairqVehEMJbL8LIzJ8DZgh4OFpgbyy8qifxXfX39NWSXvDaWy1rVDaHR6ojLqeKPptV9alEtAO62pgwPcGSYvyMDe9i12l3KhbyGHacL2JVQQEmtEnMjA0b1cmZiiCtDfO0vcSlptDr2p5Sw5kQ2R86VIZcJ3NfbmVkDvIj06XZd4bs4tPfvd4EdBaVGS1J+NdFZlc3uoupGNaAv/31hAznCuxuBLpYdpiieJP4St82BtBJe3hxPjULDa2MCmDPIG0EQEEWRHfH61X6DSsvT9/REI+pYeSyb6kY19/g7MLqXMyqNrrnUcaNaH7GRWVpHdkUDJbXK5ltwCxM5xnIZOp3eZdKg1qK9Tnz4lbi4Ucslz40MMDWU4W5rxmN3dcfZ+tZcFWV1Sg6mlXIgrYRD6aXUKDTIZQIR3t0YFuDA8ABHejhYtPmKUasTOZlRzo74AvYkFlKj0GBrZsjYYBcmhrheVjE1o7SOtSdz2ByTS41Cg5+TBW+MC2Kon8M1P0eh1vLR3lRWHMsiwNmSb6b3xbcDdxXT6UTOl9YR1XRnEJ1VQV5lIwBmRgb087Rt3kgO9bBptwEGkvhL3DIXf6n9nSz5enpf/J31X+qSWgVv/JTEr8nFBLtZ09vVip1NNfhHBTnx9PCe9HG3ab5WVYOKX5OL2ZtYyJFzZai1Is5WJowJdmZMbxfCvGyvGIlxoSSyQn1xWeRLXzc/Nj1XqC+qrd9cj7/puVpLRmk9BjKBx4Z2Z9HQ7tf98up0IkkF1fyRWsKBtFIS8qqam8IM83dgmL8jQ3zt23X3LKVGy6F0fQ7B/uRiGtVaXKxNmiOGerlaNU9WjSotOxMK+P7geTJK61k0tDsvjvK/rsvtj9RiXtqcQINKw5vjg3gk0rPNJ8CWorC6kZiL7gxSimoQRX1yWi9XK4b6OjAl3ANPu5Z36d0qkvhL3BJpRfpN3bTiS2/nL1ntK/Xhgwl5VSi1OsYGu/D0sJ4Euuijfqob1OxJKmRPYiHHz5ej0Ym42ZgyNtiZMcEuhLrbtEmkSE55Ax/vS2V3QiGOlsa8OMqPyWEel0w+NQo1h9PLOJBWwp9ppZTVKRGaMmiH+TsyPMCRIBerdhXpcqPUKzXsTylmx+kCDqaXotGJdLc3Z2KofiK4UIajUaXl3d3JrDuZQ4iHDd9M63tdcSupUfDi5ngOny1jdC8nPprUB1vzzpd8VaNQcyqnipisCqIy9ZvJOlHfbW5ahCejejndUBLdnUQSf4mbQhRFVh7L4oO9qViZGPLpw30Y5q/f1L14tW9vYUR1oxqdCPeHuvLkPT2byymLosjWuHze351MZYMaLzszxvR2YWywM8Fu7adiZGx2Je/vTiYupwp/JwvmDvamplHDH6klxGZXotGJWJsaMtTPgeEBDgz1dehU0SCgvyPbm1TE9tP5nMzU52L0drNiYogrE0JccbE2ZU9iIf/YmgAivD8pmIkh187y1elElhzJ4NN9adiZG/PF1FAG9rBrpZ+obSiqVrA5JpcN0bnkVzXSzdyISX3dmBbp2WZlxiXxl7hhSmuVvLwlnj/TShke4Mgnk/tgb2HcvNp/8+ck6prKCMgEmBzmwRP39LgkVjyjtI7Xf0rieEY5YV62vDk+qN2WCG5UaTl2vowVx7I4dr68eX+hu7059/V2ZliAI309bDrMBt/tUlStYFdCATvjC4jPq0YQYFqEJ6+OCaCmUc1zG04Rl6PP8n1nYq/r1v9PzKvm2Q2nyCqv58l7evD8vX5XzV/oLOh0IofPlbEhKoffkovR6EQivG2ZFuHJuFtIrrsdJPGXuCH+SC3m5c0J1Ck1vD4ukFkDvBAEgZJaBf+34TRHm5qoGxoITI/0ZNHdPXCzMW0+X6nR8v2fGfz3wDmMDWX8c0wg0yI82p1bpKxOye4EfSjp8YxyVBodZkYGDOxhh7GBjINnS2lUaZka4ckLI/2umDTVFcgsq2f18WxWHMvE3sKYdx/ozfAAR77cn853f56nu70530zvR5Cr1TWvU6/U8M6OM2yOzaOvpw1fTb2+66izUFqrZGtcHhujc8ksq8fSRM6Dfd2YFuF53d9bS9Cq4i8IwjJgPFAiimLvK7wvAF8BY4EGYK4oinHXuqYk/ncWhVrLh3tSWHk8mwBn/aaun5Mloijyvz/P88X+dNRaEblMYPZALx6/uweOfysbfDKjnNd+SuR8aT0TQlx5c3xgu0v6SSuqZemRDH4+XYBKo8PH3pxh/o4MC3Ag0qdbs3+2sl7FV7+fZc2JbIzlMp64pwcL7ure4cIXW4rEvGpe2ZpASmENY4OdeWdiL84V1/H8xtNUNap5fWwgswd6XffObmd8Aa/9lIgowvsP9ub+ULdW+gnaHlEUOZGh75mwN6kIlUZHiLs10yI9mRDiisUdihZqbfEfCtQBq64i/mOBZ9CLf3/gK1EU+1/rmpL43zlSCmt4bsMp0ovrmD/Eh5dH+2NiaMDBtBJe2pJAaa0SmQBTwz14abT/Zf7uqgYVH+5JZWNMLu62prz7QO/m/YH2gE4ncvBsKcuOZHL4bBkmhjImh7kzZ6D3dUMRM0rr+GhvKr8mF+NibcLLo/15INSt3d3JtAZqrY4fD2Xw1e9nMTU04PVxgQz3d+DlLQkcSCtlZJATnzx0/Y3d3IoGnt94mtjsSib1dePfD/S+Y8LXXqlqULEtLp8N0TmkF9dhbmTAhBBXpkV6trh7tNXdPoIgeAO7riL+PwB/iqK4vul1GnCPKIqFV7ueJP4tj04nsuJYFh/9ot/U/WxKCHf7ORCTVc6bP58hpSlRaUhPe76e1pduFpd+qUVR5OfT+by3K4WqRjUL7vLh+RF+7aZOikKtZVtcPsuOZnKupA4nK2NmD/TmkUjPm448OZFRzvu7U0jMrybYzZrXxwUyoHvn3ry8GudL6/jn1kSisioY3NOO9x8IZn9KMR//koq9hTFfTg2l/3V+Nxqtjm/+OMc3f5zFo5sZX03rS6iHzTXP6YyIokhcThUbonLYlVBIo1pLgLMl0yM9eaCv22WlOW6F9ib+u4CPRFE80vT6d+AfoiheVd0l8W9ZSmoVvLQ5gUPppYwIcOTjh4JJL67js1/Tic3RFwpztTbhfzPDCLnClzKrrJ43fk7iyLkyQj1s+HBScHNoZ1tTUqtg9fFs1p7MoaJeRW83K+YP8WFcsOttlYXQ6fQb3p/8kkpBtYKRQU78c0zAdTuTdUZ0OpH10Tl8tCcVtU7HiyP9ifC25fmNp8mpaODZEb48M9z3utUzozIreH7DKUpqlbwwyo/Hh/bokndVoA8b3XG6gA3ROSTl12AslzEu2IVpkZ5EeNve8t1AhxR/QRAWAgsBPD09w7Kzs1vEtq7O7ynFvLwlgXqlhjfGBeJua8o3f5wjLqcKAX3P2ufv9eXJe3pe9uVVaXT8eOg8X/9xDmMDGa+MCeCRSM92USI3uaCGpUcy2RlfgFqn495AJ+YP8aH/DZQnuBkUai1Lj2Tyvz/Po1BrmTnAi2dH+NKtE8axX4+iagVv/JzE/pRi+rhb8/aEINaeyGHbqXwifbrx5dRQXC8KCLgS1Q1qXvspkd2JhQzqYcfnU0JvOeu6s5CUX836qBy2ny6gTqmhh4M50yI8eSjM/ab/ztqb+EtunzZAodby/u4UVp/IJtDFkqnhHmw7lU9Cnr7Zh0KtI8TDms8eDr1iTHJ0VgWvbUvkbEkd44JdeGtC0FV7xbYWOp3In+klLDmcybHz5ZgaGjAl3J25g33wsb+5MsU3S2mtki/3p7M+KgdzYzlPD+vJnEHeXW5TWBRFdicW8s6OM1Q1qFl0d3c8u5nxr53JGMllfPJQH0b1cr7uNTbF5PLOjmRMDGV8fAPndAUaVBp2JRSyISqHuJwqDA0ERvVyZnqEJ4N62N3QXVJ7E/9xwNP8teH7tSiKkde6niT+t0dygX5T92xJHcMDHMirbCS9uA57CyMaVFo0OpEXR/qx4K7ul63iqxvUfPRLKuujcnCzMeXf9/e6amvG1qJRpWVrXB7LjmaSUVqPs5UJcwd7Mz3Cs9XbNJ4truWDPSkcSCvF3daUf9wXwPg+Lu0yp+FOUlmv4v09KWyJzaO7gznPjfBl8eEMkvJrmDPQi39ep48z6PcTnl1/ijMFNcwa4MXr465/TlchraiWDdE5bIvLp7pRjWc3M6ZGePBwmPtlkXcX09rRPuuBewB7oBh4GzAEEEXx+6ZQz2+B+9CHes67lr8fJPG/VXQ6kWVHM/n4l1RMDA2wMDagsFqJl50ZViZyEvNr6Otpw6eTQy5b7V9I6np3lz5D99HB3vzfSL/rJvXcSYprFKw6nsXakzlUNajp427N/CE+jA12afPEoSNny3hvdzKpRbX09bThjXGBhHl1a1Ob2oLDZ0v557ZE8iobmRbhgdxAYM2JHAJdrPhmet/rZroqNVr+sy+NxYcvbxAkob+D33emiPVROZzIqMBAJjAiwJHpkZ4M9XO4bPEmJXl1QUpqFLywKZ4j58owNTSgUa3F38mCQT3s+elUPg1q7VVX+znlDbyxPYlD6aWEuFvz/oPBbdquLym/mmVHMtmZUIBGJzIqyIkFd3Un3OvWN8LuBFqdyNa4PP6zL42SWiXjgl145T7/m+6U1dFpUGn4/Nd0lh3NxNHShCnh7qw5mUOjSsu/Jvbi4XD36/6/Xdwa9EbzCLoamWX1bIjOYUtMHuX1KlytTXg43IMpER7NyZeS+Hcx9iQU8tKWeBpVWkQg2M2KuYN8+DW5iH1nign1sOE/D1++2ldrdSw+nMFX+89iaCDjpVF+zBro3SYbujqdyO+pJSw5nMHJzArMjQx4ONyDeYO9272YNqg0/Hgogx8OZqDR6Zgz0Jtnhvu2ukuqrTmdW8WrWxNILarl3kBHqhrUxGRXMiHElfcf7I3VdSqgltUpeWmzvtTIvYGOfDI5pEturF8PlUbH/pRi1kflcORcGQB3+zkwLcKTMcEukvh3BcrrlDy2Koa4nCoAerla8fJof6ob1Ly9U19v/2qr/djsSl7blkhacS2jeznxzsReuFhfO1LjTtCg0rAlNo9lRzLJKm/A1Vrvz58a4dkicc+tSXGNgs9+TWNzbB7WpoY8O9yXmQO82n0nspZEpdHxw8HzfPPHOUyNZAzsYc9vycW42pjwzfR+143vF0WR5Uez+GhvKjZmhnw+JZQhvvatZH3HI7eigU0xuWyKyaW4Rkn2x+Ml8e/snMwoY8aSKDQ6EVcbEz6a1IcAZ0ve3J500Wq/z2XN06sb1Xy6L5W1J3NwtjLhXxN7tUmkRWF1IyuPZbPuZDY1Cg0hHjYsGOLDmN7OHb6oWnJBDR/sSeHIuTK87cx4dUwgo3s5dSk3xrmSWl7dmkhMdiUh7tYU1Sgor1Px0mh/Ft7V/bqRK8kFNTyzPo6MsnoWDu3OiyOv31ugK6PR6vgzrZSRvZwl8e/M/HamiEVrYtGJ8M8xASwc2v2S7lpXWu1fCNH7185kyuuUzB3kwwuj/Fo91T4hr4qlRzLZnVCIThS5r7cz84f40M+zffnzbxdRFPkzrZQP9qRwtqSOSO9uvDE+8JJmN50dnU5k7clsPtqbilYn4m1vTmpRLXf52vP5lNDrFtBrVGn5965k1kflMKiHHUvmhLdpAEJHQPL5d2I2x+TyypYEEODb6X2J9LHjjZ8Tr7naz61o4K3tSRxIK6W3mxUfPtiHYPfW29DV6kR+Sy5m2ZFMorIqsDCWMzXCg7mDvO9IY/P2hEarY2NMLl/8lk5ZnYoHQl15+b6AS6qjdnYKqhp54+ck/kgtwd3WlJIaJVamcj6fEnrddpEAW2LzeGVLPGFetiybG9Guu6e1NZL4d1IWHzrP+3tSkQmwbG4E9Uotr/+ceNXVvkarY9nRTL747SyCAC+O8mfOQK9Wc6vUKTVsjsn4zl+RAAAgAElEQVRl+dEscioacLMxZd5gb6ZGeHS5L3CtQs33B8+z5HAmIjB/iA9P3tOjy/weLoQS/2tnMtUNKqzNjKioV91wu8hdCQU8t+E0wW7WrHw0ssPtB7UWkvh3Qj7ak8L3hzKQywQ2LBxAbHYlH+5NJcTDhs+usNo/nVvFP7clklJYw72BTvz7/l7XTb1vKfKrGll5LIv1UTnUKjT087RhwV3dGRXk1OH9+bdLflUj/9mXxk+n8rG3MOLH2eH087Rta7NajYp6Fe/tSmbbqXysTOTN+z030i5y35kinl4Xh5+TJWvm9++UrSJvF0n8OxGiKPLKlgQ2x+ZhLJex7YmBbI8v5MdDGYzv48LnU0IvWTXVKtT8Z18aq05k42RpwjsTe7XaZmNRtYL//KoXNuASf77EpSTkVfHM+lOU1SpZOjeiy1UN/TOthNd/SiK/qhFDAwFjuQEf3EC7yANpJSxaHYuPnTlrFvTvso13roYk/p0EjVbHotWx/J5agpmRAdufGsz3BzPYGpfH7IFevDOhV3PUhCiK7DtTxNs7zlBSq2TOQG9eHOXXKm6FRpWWHw6d54eDGWh1IjMHePHoEG/cbTu3P/92Ka5RMGPJSfIqG/hxVvgN+b87E/VKDf/5NY3lR7MwNBBQa8Ubahd59FwZC1bG4GJjwroFA7p8YbiLkcS/E6BQa5m55CQx2ZVYmxqy7YmBfLg3lf0pJfzfvX48O6Jn82o+v6qRt7cnsT+lhCAXKz6YFNwq9dJ1OpHt8fl8vDeNohoFY4OdefW+wC7Tsq8lKK9TMnNpFOdL6vjvjH6MDGrbOkptQVxOJf/YEs/ZknoAvO3M+G5G2DXbHkZlVjBveRT2lsase2xAl9pAvxaS+HdwahRqHv7+OGlFtdhbGLF+4QBe26aPmf73/b2ZNcAL0N8ZrDiWxee/pSOK8MJIP+YN9m4Vv3psdgX/3plMfJ6+4cmb44OI9Ol6tW1aguoGNbOXR3Emv5ovp4Uyvs+1XR+dEZVGx3d/6hu+6EQwEATeGBfInEHeV3VZxuVUMmdZFFYmhqx7rH+7zwRvDSTx78CU1CiY9L9j5FU24mpjwrI5ETy/8TTnS+v4YupfwlBco2DR6lhO51YxPMCRf9/fq1XcLLkVDXz0Syq7EwpxsjLmldEBPNi3a7Y6bElqFWrmr4ghJruCTyaHMDnMva1NahPSi2t5YdNpkvJrALjLV99Z7mqbu0n51cxcehITuQFrH+tPjy7YbOdiJPHvoGSV1fPQ98cor1PhY2/OV1NDeWp9HOV1Kn6cFd6c5n6moJoFK2OoblTz8UN9WqWkcJ1Sw3cHzrHkSCYyARYO7cHjd3eXkm5akAaVhoWrYjlyroz3HujNzKY7vK6GViey8lgmH+5NRa0VsTKRs3RuBBHeV76zTC2qYcbikwiCwNoF/fF3vnav5s6MJP4dkKT8aqb9eJw6pZZAF0vemdCLp9bFoRNh+dyI5vaK+5OLeXbDKaxNDVk6J+KaftGWQKsT2RyTy39+TaesTsmDfd14ebR/q4WNdjUUai1PrY3j99QS3hwfxPwhPm1tUpuRV9nAs+tPEZdThUyA72eFMSroyqVIzpXU8sjik6i1OlbP79+mVWnbEkn8OxjHzpcxb3k0So2Ovh42PDvCl2fXn8LK1JCVj0bS09ECURRZeiST9/ekEOxmzZLZ4dds6tBSdr27K4WUwhrCvGx5c3xQl2y83dqoNDqe33iKPYlFvDTKj6eH+7a1SW2GKIosPpzBB3tSEYCPHgpmaoTnFcdmldXzyOIT1Ck1rJrfv0v+rUri34HYm1jI0+tOoRVFBna345H+nry4OR6vbmasmh+Ji7Upaq2Ot3ecYd3JHO7r5cwXU0MxNbpzHY8yy+r5YE8KvyUX42Zjyqtjuma3qrZEo9Xx8pYEfjqVz1PDevDSKP8u/fvfl1TEE2v19axeuc+fJ+/pecVxuRUNPLLkBJX1albMiyD8Kq6izook/h2EtSezef2nJACG+Ttwb6Ajb24/Q4iHDcvmRGBrbkR1o5qn18Vx+GwZT9zTg5dH+d+xzdXqBjVf/3GWVcezMDKQ8eSwnswf4iO11msjdDqR139OZH1ULo8O9uHN8YFdegI4nVPJlB9PoNLomDvIm3cm9rriuMLqRmYsPklRjYIlc8IZ1KPrlISWxL+dI4oiX/9+li/2nwVgbG9nAl2t+OzXdO72c+B/M/thZiQnp7yBR1dGk1VWzweTgpkS7nFH7NFodayLyuGL39KpalQzJcyDF0f74WgpJc+0NaIo8q+dyaw4lsUj/T157/7eXTqyKqe8gbFfH6ZOqWFMb2e+m9HvihNiSa2CGYtPklPRwI+zw7m7iyTQSeLfjtHpRN7ekcTqEzkATOrrho2ZIcuOZnF/qCufTg7BSC4jNruCx1bFotWJfD8zjIE97kz6/59pJby3O4VzJXUM7G7HG+MD6eXaNTfL2iuiKPLpvjS++/M8k/q58clDfbp0jaSqehWjvjxESa2SME9bNi4acMXfR3mdkllLozhXUsd3M/pxbxdIoJPEv52i0uj4v42n2J1YBMD0SA8UKi0/nS5g7iBv3hofhEwmsP10Pi9vScDNxpSlc8Lpfgdil88W1/Le7hQOppfibWfGa2MDGRnUtRqOdDS++f0sn/2Wzrg+Lnw5NbTNm9i3JUq1ljFfHyajtB5vOzN2PjPkiqVMqhpUzFkWxZmCGr6e3pexwS5tYG3rIYl/O6ROqeHx1TEcOVcOwNxB3mSX13MgrZSXRvnx1DD9BtaX+8/y1e9n6e/Tje9nhrV45cKKehVf/JbOuqgczIwMeG6EL7MHektdkjoISw5n8N7uFO4NdOTbR/p16f0YrU7k4e+PE5dTiZ25ETufGYyrzeWJjjUKNfOWR3Mqp5LPp4TyQF+3NrC2dZDEv51RXqdk3vIoEvNrEIHHhvgQm1PJqdwq3nugNzP6e6FQa3llSwI74guYHObOBw8Gt6ggqzQ6Vh3P4qvfz9Kg0jKjvyfP3+snNcjugKw+kc2bPydxl689P84Kv6ORX+0dnU7ksVUx/J5agqmhjI2LBl6xW1q9UsP8ldGczKzg40l9mBJxZ/bP2hpJ/NsReZUNzFpykuyKBnQiPH53dw6klpJZVs+X00IZG+xCWZ2SRatjic2u5JX7/Hni7h4t5n4RRZFfk4v5cE8KWeUN3O3nwBvjAvF16rpZkJ2BzTG5/GNrAuHe3Vg2N6LV23G2J0RR5OUtCWyJzcNAJvD9jH6MvEJf6kaVloWrYzh8tox3H/irRlZnQhL/dkJaUS2zlp6gol6NRify5D092H66gKoGFYtnhzOopz1ni2uZtyKa0lolX0wNbVGf5JmCat7dlcyJjAp8HS14fVwg9/g7ttj1JdqWnfEFPL9R6m4F+gnggz0pLD6cCcBb44N49ArZ0Qq1lqfXxbE/pYQ3xgWy4K7urW3qHUUS/3ZATJa+5KxSo0Ol1Qv/xuhcAFbMiyTY3ZrDZ0t5ck0cJkYGLJkd3lzC4XYpqVXw2b50NsXmYmNqyAsj/Zge6dmlI0Q6K7+eKeLpdafwdbJg9fz+Xd6N9+0fZ/nPr+kAzBroyTsTel/S2hT0LtDnNpxib1IRL4/2b95v6wxI4t/G/JFazBNrYhEQUGl1PDa0O2tP5GBtasjq+ZF0d7BgzYls3t5xBl9HC5bOjWiReuQKtZalRzL57sA5VFodcwZ688wI3y69IuwKHEwvZeGqGDy7mbF2Qf87XvajvbPqWBZv7TgDwDB/R/47o+9lBQg1Wh0vbo5n++kCnh3hy//d69spIt0k8W9DtsTm8cqWeIzlBvpMxMFerD6eg7e9Gase1bede393CsuOZjI8wJGvp/e9bX+tKIrsTCjk472p5Fc1MirIiX+ODcTHXqpv3lU4fr6c+SujcbIyYe2C/l2+8N6W2Dxe3hyPCAS6WLJiXiROf5sUtTqRV7fqW6Q+fncP/nFfxy+hIYl/G/HjofN8sCcVc2MDlBod0yI8WHcyh76etiydE47cQMZz60/xe2oJ8wZ788a4oMtuSW+W07lVvLsrmdjsSgJdrHhzfGCXSmeX+IvY7ErmLtc3N1n/2IAu31FtV0IBz60/jYiIo4Uxyx+NJNDl0iq4Op3Im9uTWHsyh7mDvHl7QlCHngAk8W9lRFHko72p/HAoA0sTOSqNjgl9XNkSl8cwfwe+mxFGZYOK+StjSC+u5Z0JQcwa6H1bn1lRr+K93clsi8vH3sKYl0f7MTnM47YnE4mOTVJ+NbOWnsRILmPtggH0dOzazU1+Tynm8TWxiCIYyWX8b2bYZaUeRFHk3V36u/GOXkJDEv9WRK3V8erWRLbG5WFlIkejE7nL1559Z4p5sK8bn0zuQ0phDfNXxqBQafl2Rr/bqjMiiiJ7Eot4a3sS1Y1qFg7tzpPDenbpUD+JS0krqmXGkpOAyOr5/S9b7XY1jpwtY8GqaHQ60Oh0vNuUW3Mxoijyyb40/vfneSaHufPxQ3065ELqRsVfCv24TRpVWh5fHasXflNDdCKEedqw70wxjw724bOHQ/g9pZgpPxzHWC5j65ODbkv4S2oVPL4mlqfWxeFqY8rOZ4bwyn0BkvBLXIK/syWbFg3A0EDG9MUnSMiramuT2pQhvvasnt8fQ7mAkVzG6z8l8cGeFHS6vxa/giDwymh/nr/Xly2xeTy/8TRqra4Nrb6zSCv/26C6Qc38ldHEZFdiZaoX356OFsRlV/HyaH+euLs7PxzK5ONfUunracPi2eHYWxjf0meJosjWuHze3ZVMo1rLCyP9WDDERwrdlLgmuRUNTF98guoGNcu7YG37v5OQV8XspVGotDoaVNqr9sb435/n+fiXVO7r5czX0/t2qNInktvnDlNUrWDOsijOl9ZhZmSAgUzAycqE9OJaPngwmEn93Hnj50Q2xeQxIcSVTyf3ueUaLPlVjby2LZGD6aWEe9ny8eQ+Xb5JtcSNc6G2fWG1gqVz9ImFXZnUohpmLDmJQqWlXqUlxMOGJbPDcbC8dGG27Egm/96VzPAAR76b0XFqKLWq20cQhPsEQUgTBOGcIAivXuH9uYIglAqCcLrp34KW+Ny24nxpHQ/97xg5FQ2YGhlgJJdhZWJIRlk9380I477ezsxedpJNMXk8O8KXr6eF3tIfjk4nsuZENqM+P0h0VgX/mtiLTYsGSsIvcVO4WJuycdFAPLuZMW9FNAfSStrapDYlwNmKzYsGYmVqiJmRAakFNTzw36OcLa69ZNyjQ3x474He/JFawmOrYmhUadvI4jvDba/8BUEwANKBkUAeEA1MF0Ux+aIxc4FwURSfvtHrtteVf3xuFfNWRKPR6tCKIuZGcgSgXqVl8exwnK1NeHRFNPmVjXw8OZgH+7rf0udkldXzj60JnMysYHBPOz6a1AePbl07bE/i9qisVzFr2UnSimr5Zno/7ut95UboXYUL7R7LalUYyWXoRH3fjMF/uzPaHJPLK1sTiPTuxtIOUEOpNVf+kcA5URQzRFFUARuA+1vguu2Ow2dLmb74BAYCaHQiliaGKDX6SWDDwgEIAjz43VGqG9Wsfaz/LQm/Viey5HAG9311iOSCGj5+KJg18/tLwi9x29iaG7F2wQCC3ax5al0c20/nt7VJbYpHNzM2LxqEq40JCrUWaxND5iyLYlNTCZYLPBzuwZdTQ4nJrmT20pPUKNRtZHHL0hLi7wZc/NvKazr2dx4SBCFBEIQtgiB0uFqqx86XMX9FDHbmRtQqNdiYGlLdoMLSRM7mxweRUljDrKUnsTM34qcnBxFxCxtrZ4trmfz9Md7bncLgHvb89sLdTI3w7NAJJxLtC315kf5EeNvy/MbTlwldV8PZ2oSNiwbiY29Oca0CPycLXtmawCe/pF4SCXR/qBvfTu9LYn41M5ecpKpB1YZWtwyttYW9E/AWRbEP8Buw8kqDBEFYKAhCjCAIMaWlpa1k2vU5W1zLotWx2FsYUVyjxM7cmNJaJV525mxeNJDNMbm8vCWBSJ9ubHtyMF52N1dSQa3V8d8D5xj39RGyyur5alooS+boXUgSEi2NubGcFfMiGerrwCtbE1h1PKutTWpT7C2M2bBwAEGu1qQX1zGohx3f/XmeZzacQqH+y88/JtiF72eGkVpYy7QfT1Bep2xDq2+flhD/fODilbx707FmRFEsF0Xxwm9qCRB2pQuJovijKIrhoiiGOzi0j2bLJbUK5i6PRiYIlNQqcbA0Jr+qkRAPG1bMi+Td3cl89+d5pkd6smLezZfUPVNQzf3fHuXTfWmM7OXEby/czf2hbtJqX+KOYmJowI+zwxgZ5MRb28/ww8HzbW1Sm2JjZsSa+ZH087TlREY544Kd2Z1QyCOLLxX5EYFOLJkTTlZ5PdN+PEFJjaINrb49WkL8owFfQRB8BEEwAqYBOy4eIAjCxQXqJwIpLfC5d5wGlYb5K2Ioq1WiVGuxNTMiv6qREQGOfD4lhEWrY9ibVMQb4wL54MHeN9VPVanR8p99adz/7VFKapV8PzOM/z7S75bzACQkbhZjuQHfzejHhBBXPtybypf702mvod+tgaWJISsfjWRwT3t2JxYxNdyDMwU1PPjdMc6X1jWPG+rnwPK5keRXNTJ98Qkq6jumC+i2xV8URQ3wNLAPvahvEkXxjCAI/xYEYWLTsGcFQTgjCEI88Cww93Y/906j1Yk8u/4USfnVGMplGBsaUFqnZFI/N56/15dpP54gvbiOH2eFs+Cu7je1Uj+VU8n4r4/w7YFz3B/qxv4Xhnb5yAuJtsHQQMaXU0OZHObOl/vP8vEvaV16AjA1MmDJnHBGBjmxMSaXqREeNKg0TPruGMfPlzePG9jDjuVzI8itbGTeimjqlZo2tPrWkJK8roAoiry94wyrjmdjbWqIRqejXqnloX7ujAl24rn1p7E0MWTJnHB6u1nf8HUbVVo++zWNZUczcbYy4f1JwQyTumpJtAN0Ov3f/OoT2cwd5M1b44M6bGGzlkCt1fHCpnh2xhcwd5A3h8+WklPRwEeT+vBQ2F9RfL+eKeLxNbEM8XVgyezwdpEJfKOhnu07YLWNWHokk1XHs7E1M6RBpUWp0TEu2IUgF0sWrool0MWKpXMibmpD9kRGOf/YmkB2eQMz+nvy6pgALE2kBisS7QOZTODf9/fCxFDG4sOZGMllvDY2sK3NajMu3BGZyGWsOJbF7IFeOBbX8uLmeLIrGpobv4zq5cwHDwbz6rZEXt4SzxdTQjvMpCmJ/9/Ym1jIe7tTsDUzpEahQasTGe7vgLedGe/uTmFkkBNfTQu9rCvQ1ahVqPn4l1TWnMjBy86M9Y8NYGAPuzv8U0hI3DyCIPDa2ECUGh0/HsrAy87sssqXXQkDmcDHD/XBzMiAlcezmR7pgZuNKV//fpac8no+ntwHY7kB0yI9Ka9X8em+NLqZG/HW+I7RD0AS/4uIza7kuQ2nsDKRU9WoRgAG9bDDx96c//55ninh7nw46cbLvP6ZVsJr2xIprFGwYIgPL47yv6yAlIREe0IQBN4aH0RuRQNvbT+Du63ZbVWh7ejIZALvTOyFqZGc7w+eZ1JfN14c6cdnv6VTUKXgh1lh2Job8eQ9PSirU7L8aBb2FsYdoidw2zuo2glZZfUsWBmNoVxGjUKDDAj1sMHH3pylR7OYOcCTj25Q+KsaVLy4KZ65y6MxM5az9YlBvDE+SBJ+iQ6B3EDGN4/0w8/JkqfWxpFaVNPWJrUpgiDwj/v8eXGkH9tO5ZNaVMsXU0I4nVfF5O+PUVyjQBAE3hwXxP2hrny6L42N0TltbfZ1kcQffUeseSuiaVBpqVdqMZAJBLhY4WNvztqTOSwY4sO7N9jZ55ekIkZ+cYifT+fz9LCe7H52CP08bVvhp5CQaDksjOUsmxuOubEBjy6P7tDx7C2BIAg8M8KXN8YFsjuxkJ0JhSybE0FRtYIpPxwnv6oRmUzg08khDPVz4J/bEvn1TFFbm31Nurz4K9RaFq6KIaeiAaVGh1wm4G1nhre9GVvj8nlqWA9eHxd4XR9eWZ2Sp9bF8fiaWBwsjNn+1GBeGu2PsVxa7Ut0TFysTVk6J4KqRjULVsXQoOp44YwtzYK7uvP+g705kFbC/w6eY/GccCrqVUz94Ti5FQ36NpEz+hHsbsMz608RlVnR1iZflS4t/jqdyIub44nJrkSrE5HLBFysTfC2N2d3QhEvjvTj5dEB1xR+URTZfjqfkZ8f5Lczxbw0yo/tTw++qRBQCYn2Sm83a76Z3pek/Gqe23Aara59hoa3JjP6e/HZwyEcP1/Ol7+dZdmcCOqUGqb8cJzMsnrMjeUsnxuBm60p81dGk1LYPt1mXVr8P96Xyu6EQgTA0EDA3sIILztzfk8p4bWxATwzwvea5xdVK3hsVQzPbTiNl505u58dwtPDfW8q01dCor0zItCJt8YH8VtyMR/u6RDJ+XecSf3c+WpaX2KyK/jmwDlWzotEpdEx5YfjnC2upZu5EasejcTcSM6cZVHkVjS0tcmX0WVVas2JbH44mIFM0Id0WZnI8bQz48i5Mv41sRcLh/a46rmiKLIxOoeRXxzkyLky3hgXyNYnBuHrZNmKP4GEROsxd7APcwd5s+RIJqtPZLe1Oe2CCSGufDSpD4fSS/n+4HnWLugPwLQfT5BSWIO7rRmr5kei1OiYvSyKsnZWCK5Liv+B1BLe/DkJA5mATBAwNTLA3daM6KxKPpwUzJxB3lc9N7eigVlLo/jH1kSCXKz45bmhLLir+w2Hf0pIdFTeHB/EiABH3t6e1OW7gV1gSoQHb44PYm9SEYsPZ7Jh4QCM5DKmLz5BYl41fk6WLJsbTmF1I/OWR1PXjspAdDnxT8qv5om1sc1ibSSX4WFrSmJ+NZ89HML0SM8rnqfTiaw8lsXoLw9xKqeS9x7ozfrHBuBtf3PlmyUkOioGMoGvp/cl0MWKp9fGtVtfdmszf4gP/3evH1vj8lh9PJuNCwdgYSznkSUniMupJMyrG9/N6EdyYQ2LVseg1LSPdpBdSvzzqxqZuywKtUZEJ4oYyMDFxpS04jq+nt6XSf2u3HmrqFrB7GVRvL3jDOHe3fj1hbuZOcCrw6RxS0i0FObGcpbOicDSxJBHV0RT3MVDQC/w7IieLBjiw4pjWWyOzWPjooF0Mzdi1pKTRGVWMDzAiY8f6sPRc+W8sCm+XWycdxnxr1Gombs0iooGFTpRRBD0oWw55fV8N6Mf4/u4XvG8XQkFjP7yELHZlXzwYDAr50XgZmPaytZLSLQfnK1NWDo3nOpGNfNXRkshoOjzAF4fF8i0CA+++eMcu+IL2LRoIM7WJsxZFsWxc2VMDnPntbEB7E4o5F87z7R59dQuIf4qjY5Fq2M4W1qHTgRBAGcrU4qqFfw4O5zRvS4vp1yjUPN/G0/z9LpT+Nibs+e5u3ikv9RSUUICoJerNd8+0pfkghqeXS+FgIJ+Anj/wWDG93Hhw72p7E8pZsPCgXh2M2PeimgOppeycGgPFg7tzqrj2Xzzx7k2tbfTi78oivxzWwLHz/+VbGFvYUxFvYrlcyOuWFL5REY5Y748zI74Ap6/15ctj+t7fEpISPzF8AAn3pnYi/0pxXwghYAC+n2RL6aGMjzAkTd+TuLY+TLWLxxADwcLHlsZw/7kYl69L4BJ/dz4/Ld01p5su8ipTi/+X+0/y9a4v7pKdjM3okGlZdX8SAb1tL9krFKj5cM9KUxffAJDA4Etjw/k+Xv9kEtx+xISV2T2QG/mDfZuKoOe1dbmtAsMDWR8N6Mf/X268cKmeGKzK1n/2AACXSx5fE0s+84U8fFDfZoniL2JhW1iZ6dWta2xeXz5+9nm19amhmi0OlbPjyTCu9slY9OKanngv8f44VAG0yM92fPcXfSVavJISFyXN8YFcW+gI+/sOMOBVCkEFPQ9kpfMiaC3mzVPrYsjqaCaNQv6E+phw9PrT7EnsZD/PtKPvh42PLfhNMfOl7W6jZ1W/I+dK+OlzfHNr80MZcgEWPfYgEtEXacTWXI4gwnfHqG0VsGS2eF88GDwDdfrl5Do6hjIBL6a1pcgVyueXhdHcoEUAgr64ngr50XgY2fOY6tiSC+uY+WjkUR42/L8xtPsSihg2dwIvOzMWLgqlqT86la1r1OKf3pxLY+uiObCFpSJXMDMWM6GhQMvqblTWN3IrGUneW93CkN97fnl+aHcG+TUNkZLSHRgLoSAWpnqQ0CLqqUQUAAbMyNWL4jE0dKYecujyC5vYPncSIb0tOflLQnsSSxi1fxIrEzkzF0eTXZ5favZ1unEv6RGwSM/nkCh0QH6mj1WpoZsWDgQf+e/yi/sjC9g9BeHOJVTxYeTglk8Oxx7C+O2MltCosPjZGXCsrkR1Cr0IaAdsan5ncDR0oQ1C/pjbixn9rKTFFY3snh2OMMDHHntp0R+SSpi1fz+aHU6Zi2NoqS2dSbOTiX+9UoN0xefoKxeBYBcBg4Wxmx+fBA9HS0AqG5U8/yGUzyz/hTdHSzY8+xdTI+UQjglJFqCQBcrvp3Rj5TCGp7bcEoKAW3C3daMNQv6I4owc8lJyutVfD8zjNG9nPjXzmR+Tylm2dwISmuVzF0WTY1Cfcdt6jTir9HqWLAymvOl+tsmmQCuNqZsenwgXnb6MM3j58sZ8+UhdiYU8n/3+rHl8YFSeQYJiRZmmL8j/7q/N/tTSnhvd3Jbm9Nu6OFgwar5kdQqNcxYfIKqRhXfPtKPCSGufLg3lSNny/h+VhjpxbU8tjIGhfrOloHoFOIviiL/2JrA8Qx9LL8AeNuZsWnRINxtzVBqtHywJ4VHlpzA2NCArU8M4rl7faUQTgmJO8SsAV7MH+LD8qNZrDia2dbmtBt6uVqzYl4ExTVKZi+Nol6p4cupoUzq58Znv6UTnVnBp5P7cDKzgufvcP+ETqF+31l1PaIAABaESURBVP5x7pJYfl8nCzYuGoSztQmpRTXc/+1RfmwK4dz97BBCPWza0FoJia7Ba2MDGRnkxL93JfNHanFbm9NuCPPqxuLZ4WSU1jN3eTSNai3/+f/27jy6qvLc4/j3yTwQEwhhDGGSGZkSwmy1qMWhKBRRBGUUFQcsvW1t7b1ea6/LWutQK7RAGEQFqYJSatU6K5YhzJPMyCwYIBIIgYT3/nEOSBEkIcPeh/w+a52VvU82e/9WFjzsvOfZ79uvLbd2rMefP9zI2j2H+J8bWvD26j385o1V5TYNRMgX/zeW7uSP/1p/ar9l7QReHdmF5PgoJn66md7Pz+PrvAKyBquFU6QiBVpA29GqTiL3vbKU1bsqtpXRz7o3qc6fb2vPyp253Dk1m2NFJ3i8z2Xc0aU+4z/ZzLb9+Yy6ojHTF27jmdPqW1kK6eK/cEsOP3112an9y+omMn1kF/KPFzEoK9jC2TSFtx+8nJ4t1MIpUtHioiLIGpxBUrAFdHduvteRfOOaVrV46uY2zN+Sw32vLKHIOR7t3erU7KD7Dx+jf0Yqf/pgI1M/31rm1w/Z4r9lXx4DJyw41cvfoV4S00d25uP1++j17Ccs236QJ/pexoQ70tXCKeKhGpfEkDWkI4cLihg+JVstoKfp0z6Vx4Ifjv9s5nJOOHj4+hbce2VjZizazvEix1UtavK/f1/N35fvKtNrh2Tx33/4GDf8+TOOBz8MyWxQjbGDOvDw7JU8MH0pjWsEWjhvVQuniC+0qH0JLwzswLqvDnH/dLWAnm5Q5/r8sldz5izfxW/eWAnAz3/UnDFXN2X20p1ER4SRUb8qY2Yu49MN+8rsuiFX/I8eL+LaZz/hcEGgDapzw6qMurIxfcd+ztwVuxlzdVP+dpdaOEX85gdNU3i0dys++GIvj81VC+jp7rmiMfde2ZjpC7fz+Ftrcc7xQM8mPHRtc/6xcjeJsZE0ql6Fu6YtZsWOg2VyzZD69PPECcdNL8zjq0OBhZC7NKpKi9qJDJ2yiIbJ8cy6pytt1ckj4luDOtfny5zDTPh0C/WT4xjaraHXkXzjv65pRt7RQiZ8uoWEmEge6NmEu3/QmKjwMH47dw3dGyeTV1DIkMmLeO3uLjRKqVKq64XUnf/QKQv5Ys8hANLTkth/uJBJ87YysFMacx/orsIvEgJ+dW0LftSqJo/NXcN7a9QCepKZ8ciPW52a63/SZ4HnI4Z1b8jvbmrNZ5tyqJ0YA8DtWQtLvYRmyBT/h2ev4OP1gWlPGyXHsXLnN+QEF2T53U1q4RQJFWFhxrO3tOeyuoncP31phc9m6WdhYcaTP2lDr1a1+O3cNczM3g4EfmN6sl8bFm87QN2kWA4cOcbgSQvJzb/waSBCoviP/XADLy8I/BASYyPZnHOEHzRL4Z0He3Bl8++uxCUi/hYbFc6EwRlUi49i2JRF7DqoFtCTIsLDeG5AO3o0qc5Dr6/gHysCi730z6jHM/3bsXpXLqlVY9m4N48RUxdd8DQQZVL8zayXma0zs41m9tBZvh9tZq8Gv7/AzBoU99xvLtvJk+8EHnIIDzOOF53g9z+5jPG3p5OsFk6RkFUjITALaP6xIoZNWUSeWkBPiY4I56+3p9MhrSoPvrqUD9cFFsm5qX1dnh/Qgc37DlO3aizZWw9w3ytLKCw6UeJrlLr4m1k48AJwLdASGGBmLc84bDhwwDl3KfAM8PvinHvB5hxGz/j2Ia62qYn8c3QPbumoFk6Ri0GzWgm8MLADG/bmcf8FFrGLVVxUBJOGdqRpzQTunraYBZtzALi+TW3GDuzAroP51EqM4b21e/n17JUlngaiLO78M4GNzrnNzrljwAzgxjOOuRGYGtx+Dehp56neBceLuGX8/FP7Y65uysy7vp2hU0QuDpc3TeGxG1vz4bp9PPr3NeU2l00ouiQmkheHZZJaNZbhU7NPtXle06oW4+/IIOfwMZLjo5iZvYMn31lXonOXRfGvC2w/bX9H8L2zHuOcKwRygeTvO+n6vXlAYDGWN+/txgM9NQunyMXqtk5p3HV5I6bN/5JJ87Z6HcdXkqtE89KITiTFRTJ40kLWfxXoeLyyWQ0mD+lIXsFxLomJYNxHm8j6rPgzqPqqmprZSDPLNrNsgPjocJY/co1aOEUqgV/2as61rWvxu3+s4d3Ve7yO4yu1E2N5eUQnIsPDGDRxAdtyjgDQ7dLqvDisE4VFJ4iLCi/Rw3NlUfx3AvVO208NvnfWY8wsAkgEcs48kXNuvHMuwzmXkRAdwepHe6mFU6SSCAsznu7fjjapSYyesYyVO9QCerr6yfG8NKITx4pOcNvE+afWSe7UKJlpIzoTBkRHFL+kl0XxXwQ0MbOGZhYF3ArMOeOYOcDg4HY/4AN3noE9Tc8gUvnERoUz4Y50qsVHMXyqWkDP1LRmAi8Oy+TgkeMMnDifnLzAbAfp9avyysjOFVv8g2P49wHvAGuBmc651Wb2WzPrHTwsC0g2s43AGOA77aAiIhBoAZ089NsW0EMVsJ5tKGmTmkTW4Ax2HMjnjkkLT6332yY1iRkjuxT7PObXT9YzMjJcdna21zFExCOfbtjHkMmL6H5pdbIGZ6jh4wwfrtvLyBezaZuaxIvDM08NkZvZYudcxvn+vH6aIuJLPZqk8LubWvPx+n38799XqwX0DFc2q8Gzt7RnybYD3DVtMQWFJXvSV8VfRHxrQGYad/+gMS/N38bET7UQ/Jmub1ObJ/q24dMNXzN6+rISPSSnVhoR8bVf/KgZ2/cf4f/eWkutxBh+3LaO15F8pX/HehwqKOSxuWv4xesriv3nVPxFxNfCwow/9m/LvkMF/GzmclISounc6HufEa10hndvSN7RQp55r/iLvWvYR0R8LyYynPF3pJOWHMfIF7NPPeUq33qg56Xc2aP4i+Oo+ItISEiKi2LqsExiIsMZPGnhqYecJMDM+PV1LYp9vIq/iISMukmxTB7akUNHCxky+dsedwkoyWzHKv4iElJa1Ulk3KAObNybx93TFnOsUNNAXwgVfxEJOT2apPBkvzZ8vimHX7y2nBMn9AxASanbR0RCUt8OqezOPcof3llHrcRYHrq2udeRQoqKv4iErFFXNGZ3bj5/+XgTdZJiuKNLA68jhQwVfxEJWWbGo71bsye3gEfmrKZGQgy9WtfyOlZI0Ji/iIS08DDj+QHtaVcvidEzlrL4y/1eRwoJKv4iEvJio8LJGtyROkmBtW437cvzOpLvqfiLyEWhWnwUU4dmEhFmDJ60kL2H9BDY91HxF5GLRlpyHJOGdCQn7xjDpiwir6DQ60i+peIvIheVNqlJjB3YgbW7DzHq5SUcL8E0x5WJir+IXHSubF6Dx/u05pP1+/jVrJVaCOYs1OopIhelWzqmsevgUZ57fwN1kmIZc3VTryP5ioq/iFy0HryqCbtz8/nT+xuonRjDgMw0ryP5hoq/iFy0zIz/63MZX31TwG/eWEXNS6L5YfOaXsfyBY35i8hFLTI8jLEDO9Cy9iXc+/JSlm8/6HUkX1DxF5GLXnx0BJOGdKR6QhTDpixi69eHvY7kORV/EakUUhKimTo0kxPOMWTyQnLyCryO5CkVfxGpNBqlVGHi4I7szj3K8KnZ5B8r8jqSZ1T8RaRSSa9flT8NaM+KHQe5f/oSCivpQ2Aq/iJS6fyoVS0e7d2K99bu5X/mrK6UD4Gp1VNEKqXbuzRgV+5Rxn20iTqJMdz3wyZeR6pQKv4iUmn9/Jpm7D6Yz1PvrqdWYiz90lO9jlRhVPxFpNIKCzOe7NeWfXkFPPT6CmokRHN50xSvY1UIjfmLSKUWFRHGuEHpXFqjCve8tJhVO3O9jlQhVPxFpNK7JCaSKUMzSYyNZOiURWzff8TrSOVOxV9EBKiVGMOUYZkUHC9iyOSFHDxyzOtI5UrFX0QkqGnNBMbfkcH2/fmMmJrN0eMX70NgpSr+ZlbNzP5lZhuCX6ue47giM1sWfM0pzTVFRMpT50bJPH1LW7K/PMBPX11G0YmL8xmA0t75PwS875xrArwf3D+bfOdcu+CrdymvKSJSrm5oU4ffXN+Cf67aw2Nz11yUD4GVttXzRuCK4PZU4CPgl6U8p4iI50b0aMTu3KNkfbaFOkkxjLy8sdeRylRp7/xrOud2B7f3AOdaJSHGzLLNbL6Z3VTKa4qIVIiHr2vB9ZfV5vG3vuDNZTu9jlOmznvnb2bvAbXO8q2HT99xzjkzO9fvRvWdczvNrBHwgZmtdM5tOsu1RgIjAdLStNyaiHgrLMz4Y//AQ2D/9bflpCRE07Vxda9jlYnz3vk7565yzrU+y+tN4Cszqw0Q/Lr3HOfYGfy6mcDQUPtzHDfeOZfhnMtISakcT9mJiL/FRIYz4fYMGiTHc9e0xXyx5xuvI5WJ0g77zAEGB7cHA2+eeYCZVTWz6OB2daAbsKaU1xURqTCJcZFMGZZJbGQ4QyYtYnduvteRSq20xf8J4Goz2wBcFdzHzDLMbGLwmBZAtpktBz4EnnDOqfiLSEipmxTLlKGZ5BUUMmTSInLzj3sdqVTMry1MGRkZLjs72+sYIiL/4bMNXzNk8kIyGlRl6rBMoiPCvY70H8xssXMu43zH6QlfEZES6N6kOn+4uQ3zN+9n9PRlIfsUsIq/iEgJ9Wmfyn/f0JK3V+9h0MQF7D8cevMAqfiLiFyA4d0b8sJtHVixM5c+Y+exeV+e15FKRMVfROQCXd+mNtPv7Eze0UL6jP2cBZtzvI5UbCr+IiKlkF6/KrNHdaN6lSgGZS1g1pIdXkcqFhV/EZFSSkuOY9Y93cioX40xM5fzzL/W+34yOBV/EZEykBgXydRhmfRLT+W59zcwZuZyCgr92wmkBdxFRMpIVEQYf+jXhgbJcTz17np2Hsjnr7enUzU+yuto36E7fxGRMmRm3PfDJjx3azuWbT9I33Gfs/Xrw17H+g4VfxGRcnBju7q8fGcnDh45Rp+x88jeut/rSP9BxV9EpJx0bFCN2aO6kRQXxW0TFvhqTQAVfxGRctSgejyz7ulKu7QkRs9Yxp8/2OCLTiAVfxGRclY1PoppwzPp074uT727np+/toJjhSc8zaRuHxGRChAdEc7T/dtSPzmOZ9/bwM4D+fxlUDqJcZGe5NGdv4hIBTEzHryqKU/3b0v2l/vpO24e23KOeJJFxV9EpIL17ZDKtOGd+Dov0Am0+MsDFZ5BxV9ExAOdGyUza1RXqsREMGDCfOau2FWh11fxFxHxSOOUKswe1Y02dRO575WljP1oY4V1Aqn4i4h4qFp8FC+N6MSP29bhybfX8dDrKzleVP6dQOr2ERHxWExkOM/d0o4GyXE8/8FGdhw8wtiB6STGll8nkO78RUR8ICzM+Nk1zfhDvzYs2LyffuM+Z/v+8usEUvEXEfGRmzPq8eKwTL765ih9xn7Osu0Hy+U6Kv4iIj7T9dLqzBrVldioMG4d/2/eXrW7zK+h4i8i4kOX1khg9qhutKh9Cfe8vITxn2wq004gFX8REZ+qXiWa6Xd25rrWtXn8rS94+I1VFJZRJ5C6fUREfCwmMpznB7QnLTmOcR9tYseBfF64rT0JMaXrBNKdv4iIz4WFGb/s1Zwn+l7GvI1fc/Nf/s3Og/mlO2cZZRMRkXJ2a2YaU4Z2ZOeBfG56YR4rd+Re8LlU/EVEQkiPJim8PqorUeFh9P/rv3l39Z4LOo+Kv4hIiGlaM4HZ93alac0q3PXSYrI+21LiTiAVfxGREFQjIYYZI7twTcuaPDZ3DY/MWV2iTiB1+4iIhKjYqHDGDUznibe/YPwnm0s0HYSKv4hICAsLM359XQvSqsXxyJzVxf9zpbmomd1sZqvN7ISZZXzPcb3MbJ2ZbTSzh0pzTRER+a5BneuTNficZfg7SjvmvwroC3xyrgPMLBx4AbgWaAkMMLOWpbyuiIic4YpmNYp9bKmGfZxzayGwKPH3yAQ2Ouc2B4+dAdwIrCnNtUVE5MJVRLdPXWD7afs7gu+JiIhHznvnb2bvAbXO8q2HnXNvlmUYMxsJjARIS0sry1OLiMhpzlv8nXNXlfIaO4F6p+2nBt8727XGA+MBMjIyKmYVYxGRSqgihn0WAU3MrKGZRQG3AnMq4LoiInIOpW317GNmO4AuwD/M7J3g+3XM7C0A51whcB/wDrAWmOmcK34zqoiIlLnSdvvMBmaf5f1dwHWn7b8FvFWaa4mISNnR3D4iIpWQleWakGXJzA4B67zOcRbVga+9DnEGZSoeZSo+P+ZSpuJp5pxLON9Bfp7bZ51zrvjPKlcQM8v2Wy5lKh5lKj4/5lKm4jGz7OIcp2EfEZFKSMVfRKQS8nPxH+91gHPwYy5lKh5lKj4/5lKm4ilWJt9+4CsiIuXHz3f+IiJSTnxZ/P24+IuZTTKzvWa2yussAGZWz8w+NLM1wQV1RnudCcDMYsxsoZktD+Z61OtMJ5lZuJktNbO5XmcBMLOtZrbSzJYVt0OjvJlZkpm9ZmZfmNlaM+vicZ5mwZ/Pydc3Zvagl5lOMrOfBv+OrzKz6WYW44NMo4N5Vp/35+Sc89ULCAc2AY2AKGA50NIHuS4HOgCrvM4SzFMb6BDcTgDW++TnZECV4HYksADo7HWuYJ4xwCvAXK+zBPNsBap7neOMTFOBEcHtKCDJ60ynZQsH9gD1fZClLrAFiA3uzwSGeJypNYEFtuIItPG/B1x6ruP9eOd/avEX59wx4OTiL55yzn0C7Pc6x0nOud3OuSXB7UME5k3yfJ0EF5AX3I0Mvjz/YMnMUoHrgYleZ/ErM0skcJOTBeCcO+acO+htqv/QE9jknPvS6yBBEUCsmUUQKLi7PM7TAljgnDviAnOqfUxgpcWz8mPx1+IvJWRmDYD2BO6yPRccXlkG7AX+5ZzzQ65ngV8AJ7wOchoHvGtmi4NrWXitIbAPmBwcHptoZvFehzrNrcB0r0MAOOd2Ak8B24DdQK5z7l1vU7EK6GFmyWYWR2B+tXrnOtiPxV9KwMyqAK8DDzrnvvE6D4Bzrsg5147A2g2ZZtbayzxmdgOw1zm32MscZ9HdOdeBwPrW95rZ5R7niSAwtDnOOdceOAz45TO3KKA38DevswCYWVUCIxINgTpAvJkN8jKTCyyr+3vgXeBtYBlQdK7j/Vj8i734S2VnZpEECv/LzrlZXuc5U3DI4EOgl8dRugG9zWwrgWHEH5rZS95GOnX3iHNuL4HZcTO9TcQOYMdpv6m9RuA/Az+4FljinPvK6yBBVwFbnHP7nHPHgVlAV48z4ZzLcs6lO+cuBw4Q+CzwrPxY/LX4SzGYmREYm13rnHva6zwnmVmKmSUFt2OBq4EvvMzknPuVcy7VOdeAwN+nD5xznt6lmVm8mSWc3AauIfBru2ecc3uA7WbWLPhWT2CNh5FONwCfDPkEbQM6m1lc8N9iTwKfu3nKzGoEv6YRGO9/5VzH+m5iN+dcoZmdXPwlHJjkfLD4i5lNB64AqgcXsHnEOZflYaRuwO3AyuD4OsCvXWDtBC/VBqaaWTiBm4uZzjlftFb6TE1gdqBuEAG84px729tIANwPvBy88doMDPU4z8n/HK8G7vI6y0nOuQVm9hqwBCgEluKPp31fN7Nk4Dhw7/d9YK8nfEVEKiE/DvuIiEg5U/EXEamEVPxFRCohFX8RkUpIxV9EpBJS8RcRqYRU/EVEKiEVfxGRSuj/AWjEIZXG4feQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate some data to play with\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "SEQ_LEN = 10\n",
    "def create_time_series():\n",
    "    freq = (np.random.random()*0.5) + 0.1  # 0.1 to 0.6\n",
    "    ampl = np.random.random() + 0.5  # 0.5 to 1.5\n",
    "    x = np.sin(np.arange(0,SEQ_LEN) * freq) * ampl\n",
    "    return x\n",
    "\n",
    "for i in range(0, 5):\n",
    "    sns.tsplot( create_time_series() );  # 5 series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(filename, N):\n",
    "    with open(filename, 'w') as ofp:\n",
    "        for lineno in range(0, N):\n",
    "            seq = create_time_series()\n",
    "            line = \",\".join(map(str, seq))\n",
    "            ofp.write(line + '\\n')\n",
    "\n",
    "to_csv('_output/train.csv', 1000)  # 1000 sequences\n",
    "to_csv('_output/valid.csv',  50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> train.csv <==\r\n",
      "0.0,0.3213675206026848,0.6268411629522288,0.901313112568992,1.1312088061525831,1.3051582889611957,1.4145585388326278,1.4539989459794964,1.4215289055980835,1.3187542889591664\r\n",
      "0.0,0.22982614526715603,0.4528559751627079,0.6624941518956339,0.8525413496174805,1.0173775780973462,1.152128374544617,1.2528089490296441,1.316442020898832,1.3411458615786787\r\n",
      "0.0,0.22080532562816035,0.43065281579600434,0.6191284360481678,0.7768787669001846,0.8960751830035983,0.9708023618388778,0.9973518415391679,0.9744060595443933,0.9031037388581403\r\n",
      "0.0,0.6811239929853302,1.1684264622429572,1.3232399873318275,1.101510631471846,0.5663339867292717,-0.12999938920632176,-0.789339970938316,-1.22406495039811,-1.3104684255926047\r\n",
      "0.0,0.6306492001395932,1.0420546308084837,1.09119212360909,0.7609791401959103,0.16621347813318033,-0.48633592404162496,-0.9698117411039756,-1.1161346976703221,-0.8744359485084771\r\n",
      "\r\n",
      "==> valid.csv <==\r\n",
      "0.0,0.16757508043429512,0.32921560349130113,0.4791971801026031,0.6122083148499722,0.7235385089591825,0.8092450794068777,0.8662927863554021,0.8926613241050576,0.8874168688448992\r\n",
      "0.0,0.361630898412143,0.6873160476723899,0.9446826700971687,1.1081487811537072,1.1614660131038659,1.0993346864856048,0.9279305929442199,0.6642911277274616,0.33462178965977296\r\n",
      "0.0,0.2506852123234484,0.49298360899417193,0.7187889600235974,0.9205468195992642,1.0915072643448938,1.2259507158270382,1.319379292288548,1.3686672878283177,1.3721657446611915\r\n",
      "0.0,0.27026904343095914,0.5088026183876817,0.68759169116069,0.7856425330176913,0.7914418409139728,0.7043086498726419,0.5344742930950467,0.30188102074397527,0.03384034570418965\r\n",
      "0.0,0.1509785046375096,0.30021509848167677,0.4459879679922036,0.586615262263317,0.7204744973373333,0.8460212755735168,0.9618071040979714,1.0664961067546368,1.1588804367436678\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 train.csv valid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some more stuff\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.contrib.learn import ModeKeys\n",
    "import tensorflow.contrib.rnn as rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import function\n",
    "DEFAULTS = [[0.0] for x in range(0, SEQ_LEN)]\n",
    "BATCH_SIZE = 20\n",
    "TIMESERIES_COL = 'rawdata'\n",
    "N_OUTPUTS = 2  # in each sequence, 1-8 are features, and 9-10 is label\n",
    "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
    "\n",
    "\n",
    "# read data and convert to needed format\n",
    "def read_dataset(filename, mode=ModeKeys.TRAIN):\n",
    "    def _input_fn():\n",
    "        num_epochs = 100 if mode == ModeKeys.TRAIN else 1\n",
    "\n",
    "        # could be a path to one file or a file pattern.\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "            input_file_names, num_epochs=num_epochs, shuffle=True)\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)\n",
    "\n",
    "        value_column = tf.expand_dims(value, -1, name='value')\n",
    "        print('readcsv={}'.format(value_column))\n",
    "\n",
    "        # all_data is a list of tensors\n",
    "        all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)  \n",
    "        inputs = all_data[:len(all_data)-N_OUTPUTS]  # first few values\n",
    "        label = all_data[len(all_data)-N_OUTPUTS : ] # last few values\n",
    "\n",
    "        # from list of tensors to tensor with one more dimension\n",
    "        inputs = tf.concat(inputs, axis=1)\n",
    "        label = tf.concat(label, axis=1)\n",
    "        print('inputs={}'.format(inputs))\n",
    "\n",
    "        return {TIMESERIES_COL: inputs}, label   # dict of features, label\n",
    "\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rnn\n",
    "LSTM_SIZE = 3  # number of hidden layers in each of the LSTM cells\n",
    "\n",
    "# create the inference model\n",
    "def simple_rnn(features, labels, mode, params):\n",
    "    # 0. Reformat input shape to become a sequence\n",
    "    x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
    "    #print 'x={}'.format(x)\n",
    "\n",
    "    # 1. configure the RNN\n",
    "    lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
    "    outputs, _ = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # slice to keep only the last cell of the RNN\n",
    "    outputs = outputs[-1]\n",
    "    #print 'last outputs={}'.format(outputs)\n",
    "\n",
    "    # output is result of linear activation of last layer of RNN\n",
    "    weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
    "    bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
    "    predictions = tf.matmul(outputs, weight) + bias\n",
    "\n",
    "    # 2. loss function, training/eval ops\n",
    "    if mode == ModeKeys.TRAIN or mode == ModeKeys.EVAL:\n",
    "        loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step(),\n",
    "            learning_rate=0.01,\n",
    "            optimizer=\"SGD\")\n",
    "        eval_metric_ops = {\n",
    "            \"rmse\": tf.metrics.root_mean_squared_error(labels, predictions)\n",
    "        }\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "\n",
    "    # 3. Create predictions\n",
    "    predictions_dict = {\"predicted\": predictions}\n",
    "\n",
    "    # 4. Create export outputs  \n",
    "    export_outputs = {\"predicted\": tf.estimator.export.PredictOutput(predictions)}\n",
    "\n",
    "    # 5. return ModelFnOps\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        export_outputs=export_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_eval_distribute': None, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_is_chief': True, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_id': 0, '_train_distribute': None, '_save_checkpoints_secs': 600, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa4e4c1aa90>, '_device_fn': None, '_tf_random_seed': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': 'outputdir', '_task_type': 'worker', '_master': '', '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_protocol': None}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function simple_rnn at 0x7fa4e4ca9bf8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From <ipython-input-14-22f4f1e6e22c>:19: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-14-22f4f1e6e22c>:20: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "readcsv=Tensor(\"value:0\", shape=(?, 1), dtype=string, device=/device:CPU:0)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-18-603206831cee>:11: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3530476, step = 1\n",
      "INFO:tensorflow:global_step/sec: 210.437\n",
      "INFO:tensorflow:loss = 0.6001655, step = 101 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.99\n",
      "INFO:tensorflow:loss = 0.44096452, step = 201 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.598\n",
      "INFO:tensorflow:loss = 0.33037132, step = 301 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.871\n",
      "INFO:tensorflow:loss = 0.24942613, step = 401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.915\n",
      "INFO:tensorflow:loss = 0.19109628, step = 501 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.475\n",
      "INFO:tensorflow:loss = 0.15020394, step = 601 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.459\n",
      "INFO:tensorflow:loss = 0.12205815, step = 701 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.208\n",
      "INFO:tensorflow:loss = 0.10269301, step = 801 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.241\n",
      "INFO:tensorflow:loss = 0.089129925, step = 901 (0.343 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into outputdir/model.ckpt.\n",
      "readcsv=Tensor(\"value:0\", shape=(?, 1), dtype=string, device=/device:CPU:0)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32, device=/device:CPU:0)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-08-19:35:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-08-19:35:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.08863831, rmse = 0.30555478\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: outputdir/model.ckpt-1000\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "serving: features=Tensor(\"timeseries:0\", shape=(?, 8), dtype=float32)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'predicted']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1000\n",
      "WARNING:tensorflow:From /home/jcworkma/jack/3d-form/.3d-form/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: outputdir/export/timeseries/temp-b'1549654508'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.081579976.\n"
     ]
    }
   ],
   "source": [
    "# experimenting\n",
    "def get_train():\n",
    "    return read_dataset('train.csv', mode=ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid():\n",
    "    return read_dataset('valid.csv', mode=ModeKeys.EVAL)\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    feature_placeholders = {\n",
    "        TIMESERIES_COL: tf.placeholder(tf.float32, [None, N_INPUTS])\n",
    "    }\n",
    "\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "\n",
    "    features[TIMESERIES_COL] = tf.squeeze(features[TIMESERIES_COL], axis=[2], name='timeseries')\n",
    "  \n",
    "    print('serving: features={}'.format(features[TIMESERIES_COL]))\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)\n",
    "\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=get_train(), max_steps=1000)\n",
    "    exporter = tf.estimator.FinalExporter('timeseries',\n",
    "    serving_input_receiver_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=get_valid(), \n",
    "        exporters=[exporter])\n",
    "\n",
    "    estimator = tf.estimator.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
    "\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "OUTPUT_DIR = 'outputdir'\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True) # start fresh each time\n",
    "\n",
    "experiment_fn(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".3d-form",
   "language": "python",
   "name": ".3d-form"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
